{
  "iclr2016_main_neuralprogrammer-interpreters": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Neural Programmer-Interpreters",
    "authors": [
      "Scott Reed",
      "Nando de Freitas"
    ],
    "page_url": "http://arxiv.org/abs/1511.06279",
    "pdf_url": "https://arxiv.org/pdf/1511.06279",
    "published": "2016-05",
    "summary": "We propose the neural programmer-interpreter (NPI): a recurrent and compositional neural network that learns to represent and execute programs. NPI has three learnable components: a task-agnostic recurrent core, a persistent key-value program memory, and domain-specific encoders that enable a single NPI to operate in multiple perceptually diverse environments with distinct affordances. By learning to compose lower-level programs to express higher-level programs, NPI reduces sample complexity and increases generalization ability compared to sequence-to-sequence LSTMs. The program memory allows efficient learning of additional tasks by building on existing programs. NPI can also harness the environment (e.g. a scratch pad with read-write pointers) to cache intermediate results of computation, lessening the long-term memory burden on recurrent hidden units. In this work we train the NPI with fully-supervised execution traces; each program has example sequences of calls to the immediate subprograms conditioned on the input. Rather than training on a huge number of relatively weak labels, NPI learns from a small number of rich examples. We demonstrate the capability of our model to learn several types of compositional programs: addition, sorting, and canonicalizing 3D models. Furthermore, a single NPI learns to execute these programs and all 21 associated subprograms. ",
    "code_link": ""
  },
  "iclr2016_main_regularizingrnnsbystabilizingactivations": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Regularizing RNNs by Stabilizing Activations",
    "authors": [
      "David Krueger",
      "Roland Memisevic"
    ],
    "page_url": "http://arxiv.org/abs/1511.08400",
    "pdf_url": "https://arxiv.org/pdf/1511.08400",
    "published": "2016-05",
    "summary": "We stabilize the activations of Recurrent Neural Networks (RNNs) by penalizing the squared distance between successive hidden states' norms. This penalty term is an effective regularizer for RNNs including LSTMs and IRNNs, improving performance on character-level language modeling and phoneme recognition, and outperforming weight noise and dropout. We achieve competitive performance (18.6\\% PER) on the TIMIT phoneme recognition task for RNNs evaluated without beam search or an RNN transducer. With this penalty term, IRNN can achieve similar performance to LSTM on language modeling, although adding the penalty term to the LSTM results in superior performance. Our penalty term also prevents the exponential growth of IRNN's activations outside of their training horizon, allowing them to generalize to much longer sequences. ",
    "code_link": ""
  },
  "iclr2016_main_blackoutspeedinguprecurrentneuralnetworklanguagemodelswithverylargevocabularies": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "BlackOut: Speeding up Recurrent Neural Network Language Models With Very Large Vocabularies",
    "authors": [
      "Shihao Ji",
      "Swaminathan Vishwanathan",
      "Nadathur Satish",
      "Michael Anderson",
      "Pradeep Dubey"
    ],
    "page_url": "http://arxiv.org/abs/1511.06909",
    "pdf_url": "https://arxiv.org/pdf/1511.06909",
    "published": "2016-05",
    "summary": "We propose BlackOut, an approximation algorithm to efficiently train massive recurrent neural network language models (RNNLMs) with million word vocabularies. BlackOut is motivated by using a discriminative loss, and we describe a new sampling strategy which significantly reduces computation while improving stability, sample efficiency, and rate of convergence. One way to understand BlackOut is to view it as an extension of the DropOut strategy to the output layer, wherein we use a discriminative training loss and a weighted sampling scheme. We also establish close connections between BlackOut, importance sampling, and noise contrastive estimation (NCE). Our experiments, on the recently released one billion word language modeling benchmark, demonstrate scalability and accuracy of BlackOut; we outperform the state-of-the art, and achieve the lowest perplexity scores on this dataset. Moreover, unlike other established methods which typically require GPUs or CPU clusters, we show that a carefully implemented version of BlackOut requires only 1-10 days on a single machine to train a RNNLM with a million word vocabulary and billions of parameters on one billion words. Although we describe BlackOut in the context of RNNLM training, it can be used to any networks with large softmax output layers. ",
    "code_link": "https://github.com/IntelLabs/rnnlm"
  },
  "iclr2016_main_thegoldilocksprinciplereadingchildrensbookswithexplicitmemoryrepresentations": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations",
    "authors": [
      "Felix Hill",
      "Antoine Bordes",
      "Sumit Chopra",
      "Jason Weston"
    ],
    "page_url": "http://arxiv.org/abs/1511.02301",
    "pdf_url": "https://arxiv.org/pdf/1511.02301",
    "published": "2016-05",
    "summary": "We introduce a new test of how well language models capture meaning in children's books. Unlike standard language modelling benchmarks, it distinguishes the task of predicting syntactic function words from that of predicting lower-frequency words, which carry greater semantic content. We compare a range of state-of-the-art models, each with a different way of encoding what has been previously read. We show that models which store explicit representations of long-term contexts outperform state-of-the-art neural language models at predicting semantic content words, although this advantage is not observed for syntactic function words. Interestingly, we find that the amount of text encoded in a single memory representation is highly influential to the performance: there is a sweet-spot, not too big and not too small, between single words and full sentences that allows the most meaningful information in a text to be effectively retained and recalled. Further, the attention over such window-based memories can be trained effectively through self-supervision. We then assess the generality of this principle by applying it to the CNN QA benchmark, which involves identifying named entities in paraphrased summaries of news articles, and achieve state-of-the-art performance. ",
    "code_link": "https://github.com/facebook/MemNN"
  },
  "iclr2016_main_towardsuniversalparaphrasticsentenceembeddings": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Towards Universal Paraphrastic Sentence Embeddings",
    "authors": [
      "John Wieting",
      "Mohit Bansal",
      "Kevin Gimpel",
      "Karen Livescu"
    ],
    "page_url": "http://arxiv.org/abs/1511.08198",
    "pdf_url": "https://arxiv.org/pdf/1511.08198",
    "published": "2016-05",
    "summary": "We consider the problem of learning general-purpose, paraphrastic sentence embeddings based on supervision from the Paraphrase Database (Ganitkevitch et al., 2013). We compare six compositional architectures, evaluating them on annotated textual similarity datasets drawn both from the same distribution as the training data and from a wide range of other domains. We find that the most complex architectures, such as long short-term memory (LSTM) recurrent neural networks, perform best on the in-domain data. However, in out-of-domain scenarios, simple architectures such as word averaging vastly outperform LSTMs. Our simplest averaging model is even competitive with systems tuned for the particular tasks while also being extremely efficient and easy to use. In order to better understand how these architectures compare, we conduct further experiments on three supervised NLP tasks: sentence similarity, entailment, and sentiment classification. We again find that the word averaging models perform well for sentence similarity and entailment, outperforming LSTMs. However, on sentiment classification, we find that the LSTM performs very strongly-even recording new state-of-the-art performance on the Stanford Sentiment Treebank. We then demonstrate how to combine our pretrained sentence embeddings with these supervised tasks, using them both as a prior and as a black box feature extractor. This leads to performance rivaling the state of the art on the SICK similarity and entailment tasks. We release all of our resources to the research community with the hope that they can serve as the new baseline for further work on universal sentence embeddings. ",
    "code_link": ""
  },
  "iclr2016_main_convergentlearningdodifferentneuralnetworkslearnthesamerepresentations?": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Convergent Learning: Do different neural networks learn the same representations?",
    "authors": [
      "Yixuan Li",
      "Jason Yosinski",
      "Jeff Clune",
      "Hod Lipson",
      "John Hopcroft"
    ],
    "page_url": "http://arxiv.org/abs/1511.07543",
    "pdf_url": "https://arxiv.org/pdf/1511.07543",
    "published": "2016-05",
    "summary": "Recent success in training deep neural networks have prompted active investigation into the features learned on their intermediate layers. Such research is difficult because it requires making sense of non-linear computations performed by millions of parameters, but valuable because it increases our ability to understand current models and create improved versions of them. In this paper we investigate the extent to which neural networks exhibit what we call convergent learning, which is when the representations learned by multiple nets converge to a set of features which are either individually similar between networks or where subsets of features span similar low-dimensional spaces. We propose a specific method of probing representations: training multiple networks and then comparing and contrasting their individual, learned representations at the level of neurons or groups of neurons. We begin research into this question using three techniques to approximately align different neural networks on a feature level: a bipartite matching approach that makes one-to-one assignments between neurons, a sparse prediction approach that finds one-to-many mappings, and a spectral clustering approach that finds many-to-many mappings. This initial investigation reveals a few previously unknown properties of neural networks, and we argue that future research into the question of convergent learning will yield many more. The insights described here include (1) that some features are learned reliably in multiple networks, yet other features are not consistently learned; (2) that units learn to span low-dimensional subspaces and, while these subspaces are common to multiple networks, the specific basis vectors learned are not; (3) that the representation codes show evidence of being a mix between a local code and slightly, but not fully, distributed codes across multiple units. ",
    "code_link": "https://github.com/yixuanli/convergent_learning"
  },
  "iclr2016_main_net2netacceleratinglearningviaknowledgetransfer": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Net2Net: Accelerating Learning via Knowledge Transfer",
    "authors": [
      "Tianqi Chen",
      "Ian Goodfellow",
      "Jon Shlens"
    ],
    "page_url": "http://arxiv.org/abs/1511.05641",
    "pdf_url": "https://arxiv.org/pdf/1511.05641",
    "published": "2016-05",
    "summary": "We introduce techniques for rapidly transferring the information stored in one neural net into another neural net. The main purpose is to accelerate the training of a significantly larger neural net. During real-world workflows, one often trains very many different neural networks during the experimentation and design process. This is a wasteful process in which each new model is trained from scratch. Our Net2Net technique accelerates the experimentation process by instantaneously transferring the knowledge from a previous network to each new deeper or wider network. Our techniques are based on the concept of function-preserving transformations between neural network specifications. This differs from previous approaches to pre-training that altered the function represented by a neural net when adding layers to it. Using our knowledge transfer mechanism to add depth to Inception modules, we demonstrate a new state of the art accuracy rating on the ImageNet dataset. ",
    "code_link": ""
  },
  "iclr2016_main_variationalgaussianprocess": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Variational Gaussian Process",
    "authors": [
      "Dustin Tran",
      "Rajesh Ranganath",
      "David Blei"
    ],
    "page_url": "http://arxiv.org/abs/1511.06499",
    "pdf_url": "https://arxiv.org/pdf/1511.06499",
    "published": "2016-05",
    "summary": "Variational inference is a powerful tool for approximate inference, and it has been recently applied for representation learning with deep generative models. We develop the variational Gaussian process (VGP), a Bayesian nonparametric variational family, which adapts its shape to match complex posterior distributions. The VGP generates approximate posterior samples by generating latent inputs and warping them through random non-linear mappings; the distribution over random mappings is learned during inference, enabling the transformed outputs to adapt to varying complexity. We prove a universal approximation theorem for the VGP, demonstrating its representative power for learning any model. For inference we present a variational objective inspired by auto-encoders and perform black box inference over a wide class of models. The VGP achieves new state-of-the-art results for unsupervised learning, inferring models such as the deep latent Gaussian model and the recently proposed DRAW. ",
    "code_link": ""
  },
  "iclr2016_main_thevariationalfairautoencoder": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "The Variational Fair Autoencoder",
    "authors": [
      "Christos Louizos",
      "Kevin Swersky",
      "Yujia Li",
      "Max Welling",
      "Richard Zemel"
    ],
    "page_url": "http://arxiv.org/abs/1511.00830",
    "pdf_url": "https://arxiv.org/pdf/1511.00830",
    "published": "2016-05",
    "summary": "We investigate the problem of learning representations that are invariant to certain nuisance or sensitive factors of variation in the data while retaining as much of the remaining information as possible. Our model is based on a variational autoencoding architecture with priors that encourage independence between sensitive and latent factors of variation. Any subsequent processing, such as classification, can then be performed on this purged latent representation. To remove any remaining dependencies we incorporate an additional penalty term based on the Maximum Mean Discrepancy (MMD) measure. We discuss how these architectures can be efficiently trained on data and show in experiments that this method is more effective than previous work in removing unwanted sources of variation while maintaining informative latent representations. ",
    "code_link": ""
  },
  "iclr2016_main_anoteontheevaluationofgenerativemodels": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "A note on the evaluation of generative models",
    "authors": [
      "Lucas Theis",
      "A\u00e4ron van den Oord",
      "Matthias Bethge"
    ],
    "page_url": "http://arxiv.org/abs/1511.01844",
    "pdf_url": "https://arxiv.org/pdf/1511.01844",
    "published": "2016-05",
    "summary": "Probabilistic generative models can be used for compression, denoising, inpainting, texture synthesis, semi-supervised learning, unsupervised feature learning, and other tasks. Given this wide range of applications, it is not surprising that a lot of heterogeneity exists in the way these models are formulated, trained, and evaluated. As a consequence, direct comparison between models is often difficult. This article reviews mostly known but often underappreciated properties relating to the evaluation and interpretation of generative models with a focus on image models. In particular, we show that three of the currently most commonly used criteria---average log-likelihood, Parzen window estimates, and visual fidelity of samples---are largely independent of each other when the data is high-dimensional. Good performance with respect to one criterion therefore need not imply good performance with respect to the other criteria. Our results show that extrapolation from one criterion to another is not warranted and generative models need to be evaluated directly with respect to the application(s) they were intended for. In addition, we provide examples demonstrating that Parzen window estimates should generally be avoided. ",
    "code_link": ""
  },
  "iclr2016_main_deepcompressioncompressingdeepneuralnetworkswithpruning,trainedquantizationandhuffmancoding": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding",
    "authors": [
      "Song Han",
      "Huizi Mao",
      "Bill Dally"
    ],
    "page_url": "http://arxiv.org/abs/1510.00149",
    "pdf_url": "https://arxiv.org/pdf/1510.00149",
    "published": "2016-05",
    "summary": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce deep compression, a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency. ",
    "code_link": ""
  },
  "iclr2016_main_neuralnetworkswithfewmultiplications": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Neural Networks with Few Multiplications",
    "authors": [
      "Zhouhan Lin",
      "Matthieu Courbariaux",
      "Roland Memisevic",
      "Yoshua Bengio"
    ],
    "page_url": "http://arxiv.org/abs/1510.03009",
    "pdf_url": "https://arxiv.org/pdf/1510.03009",
    "published": "2016-05",
    "summary": "For most deep learning algorithms training is notoriously time consuming. Since most of the computation in training neural networks is typically spent on floating point multiplications, we investigate an approach to training that eliminates the need for most of these. Our method consists of two parts: First we stochastically binarize weights to convert multiplications involved in computing hidden states to sign changes. Second, while back-propagating error derivatives, in addition to binarizing the weights, we quantize the representations at each layer to convert the remaining multiplications into binary shifts. Experimental results across 3 popular datasets (MNIST, CIFAR10, SVHN) show that this approach not only does not hurt classification performance but can result in even better performance than standard stochastic gradient descent training, paving the way to fast, hardware-friendly training of neural networks. ",
    "code_link": ""
  },
  "iclr2016_main_order-embeddingsofimagesandlanguage": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Order-Embeddings of Images and Language",
    "authors": [
      "Ivan Vendrov",
      "Ryan Kiros",
      "Sanja Fidler",
      "Raquel Urtasun"
    ],
    "page_url": "http://arxiv.org/abs/1511.06361",
    "pdf_url": "https://arxiv.org/pdf/1511.06361",
    "published": "2016-05",
    "summary": "Hypernymy, textual entailment, and image captioning can be seen as special cases of a single visual-semantic hierarchy over words, sentences, and images. In this paper we advocate for explicitly modeling the partial order structure of this hierarchy. Towards this goal, we introduce a general method for learning ordered representations, and show how it can be applied to a variety of tasks involving images and language. We show that the resulting representations improve performance over current approaches for hypernym prediction and image-caption retrieval. ",
    "code_link": ""
  },
  "iclr2016_main_generatingimagesfromcaptionswithattention": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Generating Images from Captions with Attention",
    "authors": [
      "Elman Mansimov",
      "Emilio Parisotto",
      "Jimmy Ba",
      "Ruslan Salakhutdinov"
    ],
    "page_url": "http://arxiv.org/abs/1511.02793",
    "pdf_url": "https://arxiv.org/pdf/1511.02793",
    "published": "2016-05",
    "summary": "Motivated by the recent progress in generative models, we introduce a model that generates images from natural language descriptions. The proposed model iteratively draws patches on a canvas, while attending to the relevant words in the description. After training on Microsoft COCO, we compare our model with several baseline generative models on image generation and retrieval tasks. We demonstrate that our model produces higher quality samples than other approaches and generates images with novel scene compositions corresponding to previously unseen captions in the dataset. ",
    "code_link": ""
  },
  "iclr2016_main_densitymodelingofimagesusingageneralizednormalizationtransformation": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Density Modeling of Images using a Generalized Normalization Transformation",
    "authors": [
      "Johannes Ball\u00e9",
      "Valero Laparra",
      "Eero Simoncelli"
    ],
    "page_url": "http://arxiv.org/abs/1511.06281",
    "pdf_url": "https://arxiv.org/pdf/1511.06281",
    "published": "2016-05",
    "summary": "We introduce a parametric nonlinear transformation that is well-suited for Gaussianizing data from natural images. The data are linearly transformed, and each component is then normalized by a pooled activity measure, computed by exponentiating a weighted sum of rectified and exponentiated components and a constant. We optimize the parameters of the full transformation (linear transform, exponents, weights, constant) over a database of natural images, directly minimizing the negentropy of the responses. The optimized transformation substantially Gaussianizes the data, achieving a significantly smaller mutual information between transformed components than alternative methods including ICA and radial Gaussianization. The transformation is differentiable and can be efficiently inverted, and thus induces a density model on images. We show that samples of this model are visually similar to samples of natural image patches. We demonstrate the use of the model as a prior probability density that can be used to remove additive noise. Finally, we show that the transformation can be cascaded, with each layer optimized using the same Gaussianization objective, thus offering an unsupervised method of optimizing a deep network architecture. ",
    "code_link": ""
  },
  "iclr2016_main_multi-scalecontextaggregationbydilatedconvolutions": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Multi-Scale Context Aggregation by Dilated Convolutions",
    "authors": [
      "Fisher Yu",
      "Vladlen Koltun"
    ],
    "page_url": "http://arxiv.org/abs/1511.07122",
    "pdf_url": "https://arxiv.org/pdf/1511.07122",
    "published": "2016-05",
    "summary": "State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed for image classification. However, dense prediction and image classification are structurally different. In this work, we develop a new convolutional network module that is specifically designed for dense prediction. The presented module uses dilated convolutions to systematically aggregate multi-scale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. We show that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems. In addition, we examine the adaptation of image classification networks to dense prediction and show that simplifying the adapted network can increase accuracy. ",
    "code_link": "https://github.com/fyu/dilation"
  },
  "iclr2016_main_learningtodiagnosewithlstmrecurrentneuralnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Learning to Diagnose with LSTM Recurrent Neural Networks",
    "authors": [
      "Zachary Lipton",
      "David Kale",
      "Charles Elkan",
      "Randall Wetzel"
    ],
    "page_url": "http://arxiv.org/abs/1511.03677",
    "pdf_url": "https://arxiv.org/pdf/1511.03677",
    "published": "2016-05",
    "summary": "Clinical medical data, especially in the intensive care unit (ICU), consist of multivariate time series of observations. For each patient visit (or episode), sensor data and lab test results are recorded in the patient's Electronic Health Record (EHR). While potentially containing a wealth of insights, the data is difficult to mine effectively, owing to varying length, irregular sampling and missing data. Recurrent Neural Networks (RNNs), particularly those using Long Short-Term Memory (LSTM) hidden units, are powerful and increasingly popular models for learning from sequence data. They effectively model varying length sequences and capture long range dependencies. We present the first study to empirically evaluate the ability of LSTMs to recognize patterns in multivariate time series of clinical measurements. Specifically, we consider multilabel classification of diagnoses, training a model to classify 128 diagnoses given 13 frequently but irregularly sampled clinical measurements. First, we establish the effectiveness of a simple LSTM network for modeling clinical data. Then we demonstrate a straightforward and effective training strategy in which we replicate targets at each sequence step. Trained only on raw time series, our models outperform several strong baselines, including a multilayer perceptron trained on hand-engineered features. ",
    "code_link": ""
  },
  "iclr2016_main_prioritizedexperiencereplay": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Prioritized Experience Replay",
    "authors": [
      "Tom Schaul",
      "John Quan",
      "Ioannis Antonoglou",
      "David Silver"
    ],
    "page_url": "http://arxiv.org/abs/1511.05952",
    "pdf_url": "https://arxiv.org/pdf/1511.05952",
    "published": "2016-05",
    "summary": "Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games. ",
    "code_link": ""
  },
  "iclr2016_main_importanceweightedautoencoders": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Importance Weighted Autoencoders",
    "authors": [
      "Yuri Burda",
      "Ruslan Salakhutdinov",
      "Roger Grosse"
    ],
    "page_url": "http://arxiv.org/abs/1509.00519",
    "pdf_url": "https://arxiv.org/pdf/1509.00519",
    "published": "2016-05",
    "summary": "The variational autoencoder (VAE; Kingma, Welling (2014)) is a recently proposed generative model pairing a top-down generative network with a bottom-up recognition network which approximates posterior inference. It typically makes strong assumptions about posterior inference, for instance that the posterior distribution is approximately factorial, and that its parameters can be approximated with nonlinear regression from the observations. As we show empirically, the VAE objective can lead to overly simplified representations which fail to use the network's entire modeling capacity. We present the importance weighted autoencoder (IWAE), a generative model with the same architecture as the VAE, but which uses a strictly tighter log-likelihood lower bound derived from importance weighting. In the IWAE, the recognition network uses multiple samples to approximate the posterior, giving it increased flexibility to model complex posteriors which do not fit the VAE modeling assumptions. We show empirically that IWAEs learn richer latent space representations than VAEs, leading to improved test log-likelihood on density estimation benchmarks. ",
    "code_link": ""
  },
  "iclr2016_main_variationallyauto-encodeddeepgaussianprocesses": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Variationally Auto-Encoded Deep Gaussian Processes",
    "authors": [
      "Zhenwen Dai",
      "Andreas Damianou",
      "Javier Gonzalez",
      "Neil Lawrence"
    ],
    "page_url": "http://arxiv.org/abs/1511.06455",
    "pdf_url": "https://arxiv.org/pdf/1511.06455",
    "published": "2016-05",
    "summary": "We develop a scalable deep non-parametric generative model by augmenting deep Gaussian processes with a recognition model. Inference is performed in a novel scalable variational framework where the variational posterior distributions are reparametrized through a multilayer perceptron. The key aspect of this reformulation is that it prevents the proliferation of variational parameters which otherwise grow linearly in proportion to the sample size. We derive a new formulation of the variational lower bound that allows us to distribute most of the computation in a way that enables to handle datasets of the size of mainstream deep learning tasks. We show the efficacy of the method on a variety of challenges including deep unsupervised learning and deep Bayesian optimization. ",
    "code_link": ""
  },
  "iclr2016_main_trainingconvolutionalneuralnetworkswithlow-rankfiltersforefficientimageclassification": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Training Convolutional Neural Networks with Low-rank Filters for Efficient Image Classification",
    "authors": [
      "Yani Ioannou",
      "Duncan Robertson",
      "Jamie Shotton",
      "roberto Cipolla",
      "Antonio Criminisi",
      "Jamie Shotton"
    ],
    "page_url": "http://arxiv.org/abs/1511.06744",
    "pdf_url": "https://arxiv.org/pdf/1511.06744",
    "published": "2016-05",
    "summary": "We propose a new method for creating computationally efficient convolutional neural networks (CNNs) by using low-rank representations of convolutional filters. Rather than approximating filters in previously-trained networks with more efficient versions, we learn a set of small basis filters from scratch; during training, the network learns to combine these basis filters into more complex filters that are discriminative for image classification. To train such networks, a novel weight initialization scheme is used. This allows effective initialization of connection weights in convolutional layers composed of groups of differently-shaped filters. We validate our approach by applying it to several existing CNN architectures and training these networks from scratch using the CIFAR, ILSVRC and MIT Places datasets. Our results show similar or higher accuracy than conventional CNNs with much less compute. Applying our method to an improved version of VGG-11 network using global max-pooling, we achieve comparable validation accuracy using 41% less compute and only 24% of the original VGG-11 model parameters; another variant of our method gives a 1 percentage point increase in accuracy over our improved VGG-11 model, giving a top-5 center-crop validation accuracy of 89.7% while reducing computation by 16% relative to the original VGG-11 model. Applying our method to the GoogLeNet architecture for ILSVRC, we achieved comparable accuracy with 26% less compute and 41% fewer model parameters. Applying our method to a near state-of-the-art network for CIFAR, we achieved comparable accuracy with 46% less compute and 55% fewer parameters. ",
    "code_link": ""
  },
  "iclr2016_main_reducingoverfittingindeepnetworksbydecorrelatingrepresentations": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Reducing Overfitting in Deep Networks by Decorrelating Representations",
    "authors": [
      "Michael Cogswell",
      "Faruk Ahmed",
      "Ross Girshick",
      "Larry Zitnick",
      "Dhruv Batra"
    ],
    "page_url": "http://arxiv.org/abs/1511.06068",
    "pdf_url": "https://arxiv.org/pdf/1511.06068",
    "published": "2016-05",
    "summary": "One major challenge in training Deep Neural Networks is preventing overfitting. Many techniques such as data augmentation and novel regularizers such as Dropout have been proposed to prevent overfitting without requiring a massive amount of training data. In this work, we propose a new regularizer called DeCov which leads to significantly reduced overfitting (as indicated by the difference between train and val performance), and better generalization. Our regularizer encourages diverse or non-redundant representations in Deep Neural Networks by minimizing the cross-covariance of hidden activations. This simple intuition has been explored in a number of past works but surprisingly has never been applied as a regularizer in supervised learning. Experiments across a range of datasets and network architectures show that this loss always reduces overfitting while almost always maintaining or increasing generalization performance and often improving performance over Dropout. ",
    "code_link": ""
  },
  "iclr2016_main_pushingtheboundariesofboundarydetectionusingdeeplearning": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Pushing the Boundaries of Boundary Detection using Deep Learning",
    "authors": [
      "Iasonas Kokkinos"
    ],
    "page_url": "http://arxiv.org/abs/1511.07386",
    "pdf_url": "https://arxiv.org/pdf/1511.07386",
    "published": "2016-05",
    "summary": "In this work we show that adapting Deep Convolutional Neural Network training to the task of boundary detection can result in substantial improvements over the current state-of-the-art in boundary detection. Our contributions consist firstly in combining a careful design of the loss for boundary detection training, a multi-resolution architecture and training with external data to improve the detection accuracy of the current state of the art. When measured on the standard Berkeley Segmentation Dataset, we improve theoptimal dataset scale F-measure from 0.780 to 0.808 - while human performance is at 0.803. We further improve performance to 0.813 by combining deep learning with grouping, integrating the Normalized Cuts technique within a deep network. We also examine the potential of our boundary detector in conjunction with the task of semantic segmentation and demonstrate clear improvements over state-of-the-art systems. Our detector is fully integrated in the popular Caffe framework and processes a 320x420 image in less than a second. ",
    "code_link": ""
  },
  "iclr2016_main_reasoningaboutentailmentwithneuralattention": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Reasoning about Entailment with Neural Attention",
    "authors": [
      "Tim Rockt\u00e4schel",
      "Edward Grefenstette",
      "Karl Moritz Hermann",
      "Tom\u00e1\u0161 Ko\u010disk\u00fd",
      "Phil Blunsom"
    ],
    "page_url": "http://arxiv.org/abs/1509.06664",
    "pdf_url": "https://arxiv.org/pdf/1509.06664",
    "published": "2016-05",
    "summary": "While most approaches to automatically recognizing entailment relations have used classifiers employing hand engineered features derived from complex natural language processing pipelines, in practice their performance has been only slightly better than bag-of-word pair classifiers using only lexical similarity. The only attempt so far to build an end-to-end differentiable neural network for entailment failed to outperform such a simple similarity classifier. In this paper, we propose a neural model that reads two sentences to determine entailment using long short-term memory units. We extend this model with a word-by-word neural attention mechanism that encourages reasoning over entailments of pairs of words and phrases. Furthermore, we present a qualitative analysis of attention weights produced by this model, demonstrating such reasoning capabilities. On a large entailment dataset this model outperforms the previous best neural model and a classifier with engineered features by a substantial margin. It is the first generic end-to-end differentiable system that achieves state-of-the-art accuracy on a textual entailment dataset. ",
    "code_link": ""
  },
  "iclr2016_main_convolutionalneuralnetworkswithlow-rankregularization": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Convolutional Neural Networks With Low-rank Regularization",
    "authors": [
      "Cheng Tai",
      "Tong Xiao",
      "Yi Zhang",
      "Xiaogang Wang",
      "Weinan E"
    ],
    "page_url": "http://arxiv.org/abs/1511.06067",
    "pdf_url": "https://arxiv.org/pdf/1511.06067",
    "published": "2016-05",
    "summary": "Large CNNs have delivered impressive performance in various computer vision applications. But the storage and computation requirements make it problematic for deploying these models on mobile devices. Recently, tensor decompositions have been used for speeding up CNNs. In this paper, we further develop the tensor decomposition technique. We propose a new algorithm for computing the low-rank tensor decomposition for removing the redundancy in the convolution kernels. The algorithm finds the exact global optimizer of the decomposition and is more effective than iterative methods. Based on the decomposition, we further propose a new method for training low-rank constrained CNNs from scratch. Interestingly, while achieving a significant speedup, sometimes the low-rank constrained CNNs delivers significantly better performance than their non-constrained counterparts. On the CIFAR-10 dataset, the proposed low-rank NIN model achieves $91.31\\%$ accuracy (without data augmentation), which also improves upon state-of-the-art result. We evaluated the proposed method on CIFAR-10 and ILSVRC12 datasets for a variety of modern CNNs, including AlexNet, NIN, VGG and GoogleNet with success. For example, the forward time of VGG-16 is reduced by half while the performance is still comparable. Empirical success suggests that low-rank tensor decompositions can be a very useful tool for speeding up large CNNs. ",
    "code_link": ""
  },
  "iclr2016_main_unifyingdistillationandprivilegedinformation": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Unifying distillation and privileged information",
    "authors": [
      "David Lopez-Paz",
      "Leon Bottou",
      "Bernhard Sch\u00f6lkopf",
      "Vladimir Vapnik"
    ],
    "page_url": "http://arxiv.org/abs/1511.03643",
    "pdf_url": "https://arxiv.org/pdf/1511.03643",
    "published": "2016-05",
    "summary": "Distillation (Hinton et al., 2015) and privileged information (Vapnik & Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data. ",
    "code_link": ""
  },
  "iclr2016_main_particularobjectretrievalwithintegralmax-poolingofcnnactivations": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Particular object retrieval with integral max-pooling of CNN activations",
    "authors": [
      "Giorgos Tolias",
      "Ronan Sicre",
      "Herv\u00e9 J\u00e9gou"
    ],
    "page_url": "http://arxiv.org/abs/1511.05879",
    "pdf_url": "https://arxiv.org/pdf/1511.05879",
    "published": "2016-05",
    "summary": "Recently, image representation built upon Convolutional Neural Network (CNN) has been shown to provide effective descriptors for image search, outperforming pre-CNN features as short-vector representations. Yet such models are not compatible with geometry-aware re-ranking methods and still outperformed, on some particular object retrieval benchmarks, by traditional image search systems relying on precise descriptor matching, geometric re-ranking, or query expansion. This work revisits both retrieval stages, namely initial search and re-ranking, by employing the same primitive information derived from the CNN. We build compact feature vectors that encode several image regions without the need to feed multiple inputs to the network. Furthermore, we extend integral images to handle max-pooling on convolutional layer activations, allowing us to efficiently localize matching objects. The resulting bounding box is finally used for image re-ranking. As a result, this paper significantly improves existing CNN-based recognition pipeline: We report for the first time results competing with traditional methods on the challenging Oxford5k and Paris6k datasets. ",
    "code_link": ""
  },
  "iclr2016_main_allyouneedisagoodinit": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "All you need is a good init",
    "authors": [
      "Dmytro Mishkin",
      "Jiri Matas"
    ],
    "page_url": "http://arxiv.org/abs/1511.06422",
    "pdf_url": "https://arxiv.org/pdf/1511.06422",
    "published": "2016-05",
    "summary": "Layer-sequential unit-variance (LSUV) initialization - a simple method for weight initialization for deep net learning - is proposed. The method consists of the two steps. First, pre-initialize weights of each convolution or inner-product layer with orthonormal matrices. Second, proceed from the first to the final layer, normalizing the variance of the output of each layer to be equal to one. Experiment with different activation functions (maxout, ReLU-family, tanh) show that the proposed initialization leads to learning of very deep nets that (i) produces networks with test accuracy better or equal to standard methods and (ii) is at least as fast as the complex schemes proposed specifically for very deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastava et al. (2015)). Performance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual nets and the state-of-the-art, or very close to it, is achieved on the MNIST, CIFAR-10/100 and ImageNet datasets. ",
    "code_link": "https://github.com/ducha-aiki/LSUVinit"
  },
  "iclr2016_main_bayesianrepresentationlearningwithoracleconstraints": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Bayesian Representation Learning with Oracle Constraints",
    "authors": [
      "Theofanis Karaletsos",
      "Serge Belongie",
      "Gunnar R\u00e4tsch"
    ],
    "page_url": "http://arxiv.org/abs/1506.05011",
    "pdf_url": "https://arxiv.org/pdf/1506.05011",
    "published": "2016-05",
    "summary": "Representation learning systems typically rely on massive amounts of labeled data in order to be trained to high accuracy. Recently, high-dimensional parametric models like neural networks have succeeded in building rich representations using either compressive, reconstructive or supervised criteria. However, the semantic structure inherent in observations is oftentimes lost in the process. Human perception excels at understanding semantics but cannot always be expressed in terms of labels. Thus, \\emph{oracles} or \\emph{human-in-the-loop systems}, for example crowdsourcing, are often employed to generate similarity constraints using an implicit similarity function encoded in human perception. In this work we propose to combine \\emph{generative unsupervised feature learning} with a \\emph{probabilistic treatment of oracle information like triplets} in order to transfer implicit privileged oracle knowledge into explicit nonlinear Bayesian latent factor models of the observations. We use a fast variational algorithm to learn the joint model and demonstrate applicability to a well-known image dataset. We show how implicit triplet information can provide rich information to learn representations that outperform previous metric learning approaches as well as generative models without this side-information in a variety of predictive tasks. In addition, we illustrate that the proposed approach compartmentalizes the latent spaces semantically which allows interpretation of the latent variables. ",
    "code_link": ""
  },
  "iclr2016_main_neuralprogrammerinducinglatentprogramswithgradientdescent": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Neural Programmer: Inducing Latent Programs with Gradient Descent",
    "authors": [
      "Arvind Neelakantan",
      "Quoc Le",
      "Ilya Sutskever"
    ],
    "page_url": "http://arxiv.org/abs/1511.04834",
    "pdf_url": "https://arxiv.org/pdf/1511.04834",
    "published": "2016-05",
    "summary": "Deep neural networks have achieved impressive supervised classification performance in many tasks including image recognition, speech recognition, and sequence to sequence learning. However, this success has not been translated to applications like question answering that may involve complex arithmetic and logic reasoning. A major limitation of these models is in their inability to learn even simple arithmetic and logic operations. For example, it has been shown that neural networks fail to learn to add two binary numbers reliably. In this work, we propose Neural Programmer, an end-to-end differentiable neural network augmented with a small set of basic arithmetic and logic operations. Neural Programmer can call these augmented operations over several steps, thereby inducing compositional programs that are more complex than the built-in operations. The model learns from a weak supervision signal which is the result of execution of the correct program, hence it does not require expensive annotation of the correct program itself. The decisions of what operations to call, and what data segments to apply to are inferred by Neural Programmer. Such decisions, during training, are done in a differentiable fashion so that the entire network can be trained jointly by gradient descent. We find that training the model is difficult, but it can be greatly improved by adding random noise to the gradient. On a fairly complex synthetic table-comprehension dataset, traditional recurrent networks and attentional models perform poorly while Neural Programmer typically obtains nearly perfect accuracy. ",
    "code_link": ""
  },
  "iclr2016_main_sparknettrainingdeepnetworksinspark": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "SparkNet: Training Deep Networks in Spark",
    "authors": [
      "Philipp Moritz",
      "Robert Nishihara",
      "Ion Stoica",
      "Michael Jordan"
    ],
    "page_url": "http://arxiv.org/abs/1511.06051",
    "pdf_url": "https://arxiv.org/pdf/1511.06051",
    "published": "2016-05",
    "summary": "Training deep networks is a time-consuming process, with networks for object recognition often requiring multiple days to train. For this reason, leveraging the resources of a cluster to speed up training is an important area of work. However, widely-popular batch-processing computational frameworks like MapReduce and Spark were not designed to support the asynchronous and communication-intensive workloads of existing distributed deep learning systems. We introduce SparkNet, a framework for training deep networks in Spark. Our implementation includes a convenient interface for reading data from Spark RDDs, a Scala interface to the Caffe deep learning framework, and a lightweight multi-dimensional tensor library. Using a simple parallelization scheme for stochastic gradient descent, SparkNet scales well with the cluster size and tolerates very high-latency communication. Furthermore, it is easy to deploy and use with no parameter tuning, and it is compatible with existing Caffe models. We quantify the dependence of the speedup obtained by SparkNet on the number of machines, the communication frequency, and the cluster's communication overhead, and we benchmark our system's performance on the ImageNet dataset. ",
    "code_link": "https://github.com/amplab/SparkNet"
  },
  "iclr2016_main_unsupervisedandsemi-supervisedlearningwithcategoricalgenerativeadversarialnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks",
    "authors": [
      "Jost Tobias Springenberg"
    ],
    "page_url": "http://arxiv.org/abs/1511.06390",
    "pdf_url": "https://arxiv.org/pdf/1511.06390",
    "published": "2016-05",
    "summary": "In this paper we present a method for learning a discriminative classifier from unlabeled or partially labeled data. Our approach is based on an objective function that trades-off mutual information between observed examples and their predicted categorical class distribution, against robustness of the classifier to an adversarial generative model. The resulting algorithm can either be interpreted as a natural generalization of the generative adversarial networks (GAN) framework or as an extension of the regularized information maximization (RIM) framework to robust classification against an optimal adversary. We empirically evaluate our method - which we dub categorical generative adversarial networks (or CatGAN) - on synthetic data as well as on challenging image classification tasks, demonstrating the robustness of the learned classifiers. We further qualitatively assess the fidelity of samples generated by the adversarial generator that is learned alongside the discriminative classifier, and identify links between the CatGAN objective and discriminative clustering algorithms (such as RIM). ",
    "code_link": ""
  },
  "iclr2016_main_mupropunbiasedbackpropagationforstochasticneuralnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "MuProp: Unbiased Backpropagation For Stochastic Neural Networks",
    "authors": [
      "Shixiang Gu",
      "Sergey Levine",
      "Ilya Sutskever",
      "Andriy Mnih"
    ],
    "page_url": "http://arxiv.org/abs/1511.05176",
    "pdf_url": "https://arxiv.org/pdf/1511.05176",
    "published": "2016-05",
    "summary": "Deep neural networks are powerful parametric models that can be trained efficiently using the backpropagation algorithm. Stochastic neural networks combine the power of large parametric functions with that of graphical models, which makes it possible to learn very complex distributions. However, as backpropagation is not directly applicable to stochastic networks that include discrete sampling operations within their computational graph, training such networks remains difficult. We present MuProp, an unbiased gradient estimator for stochastic networks, designed to make this task easier. MuProp improves on the likelihood-ratio estimator by reducing its variance using a control variate based on the first-order Taylor expansion of a mean-field network. Crucially, unlike prior attempts at using backpropagation for training stochastic networks, the resulting estimator is unbiased and well behaved. Our experiments on structured output prediction and discrete latent variable modeling demonstrate that MuProp yields consistently good performance across a range of difficult tasks. ",
    "code_link": ""
  },
  "iclr2016_main_datarepresentationandcompressionusinglinear-programmingapproximations": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Data Representation and Compression Using Linear-Programming Approximations",
    "authors": [
      "Hristo Paskov",
      "John Mitchell",
      "Trevor Hastie"
    ],
    "page_url": "http://arxiv.org/abs/1511.06606",
    "pdf_url": "https://arxiv.org/pdf/1511.06606",
    "published": "2016-05",
    "summary": "We propose `Dracula', a new framework for unsupervised feature selection from sequential data such as text. Dracula learns a dictionary of $n$-grams that efficiently compresses a given corpus and recursively compresses its own dictionary; in effect, Dracula is a `deep' extension of Compressive Feature Learning. It requires solving a binary linear program that may be relaxed to a linear program. Both problems exhibit considerable structure, their solution paths are well behaved, and we identify parameters which control the depth and diversity of the dictionary. We also discuss how to derive features from the compressed documents and show that while certain unregularized linear models are invariant to the structure of the compressed dictionary, this structure may be used to regularize learning. Experiments are presented that demonstrate the efficacy of Dracula's features. ",
    "code_link": ""
  },
  "iclr2016_main_diversitynetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Diversity Networks",
    "authors": [
      "Zelda Mariet",
      "Suvrit Sra"
    ],
    "page_url": "http://arxiv.org/abs/1511.05077",
    "pdf_url": "https://arxiv.org/pdf/1511.05077",
    "published": "2016-05",
    "summary": "We introduce Divnet, a flexible technique for learning networks with diverse neurons. Divnet models neuronal diversity by placing a Determinantal Point Process (DPP) over neurons in a given layer. It uses this DPP to select a subset of diverse neurons and subsequently fuses the redundant neurons into the selected ones. Compared with previous approaches, Divnet offers a more principled, flexible technique for capturing neuronal diversity and thus implicitly enforcing regularization. This enables effective auto-tuning of network architecture and leads to smaller network sizes without hurting performance. Moreover, through its focus on diversity and neuron fusing, Divnet remains compatible with other procedures that seek to reduce memory footprints of networks. We present experimental results to corroborate our claims: for pruning neural networks, Divnet is seen to be notably superior to competing approaches. ",
    "code_link": ""
  },
  "iclr2016_main_deepreinforcementlearninginparameterizedactionspace": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Deep Reinforcement Learning in Parameterized Action Space",
    "authors": [
      "Matthew Hausknecht",
      "Peter Stone"
    ],
    "page_url": "http://arxiv.org/abs/1511.04143",
    "pdf_url": "https://arxiv.org/pdf/1511.04143",
    "published": "2016-05",
    "summary": "Recent work has shown that deep neural networks are capable of approximating both value functions and policies in reinforcement learning domains featuring continuous state and action spaces. However, to the best of our knowledge no previous work has succeeded at using deep neural networks in structured (parameterized) continuous action spaces. To fill this gap, this paper focuses on learning within the domain of simulated RoboCup soccer, which features a small set of discrete action types, each of which is parameterized with continuous variables. The best learned agent can score goals more reliably than the 2012 RoboCup champion agent. As such, this paper represents a successful extension of deep reinforcement learning to the class of parameterized action space MDPs. ",
    "code_link": ""
  },
  "iclr2016_main_learningvisualpredictivemodelsofphysicsforplayingbilliards": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Learning VIsual PredictiveModels of Physics for Playing Billiards",
    "authors": [
      "Katerina Fragkiadaki",
      "Pulkit Agrawal",
      "Sergey Levine",
      "Jitendra Malik"
    ],
    "page_url": "http://arxiv.org/abs/1511.07404",
    "pdf_url": "https://arxiv.org/pdf/1511.07404",
    "published": "2016-05",
    "summary": "The ability to plan and execute goal specific actions in varied, unexpected settings is a central requirement of intelligent agents. In this paper, we explore how an agent can be equipped with an internal model of the dynamics of the external world, and how it can use this model to plan novel actions by running multiple internal simulations (visual imagination). Our models directly process raw visual input, and use a novel object-centric prediction formulation based on visual glimpses centered on objects (fixations) to enforce translational invariance of the learned physical laws. The agent gathers training data through random interaction with a collection of different environments, and the resulting model can then be used to plan goal-directed actions in novel environments that the agent has not seen before. We demonstrate that our agent can accurately plan actions for playing a simulated billiards game, which requires pushing a ball into a target position or into collision with another ball. ",
    "code_link": ""
  },
  "iclr2016_main_towardsai-completequestionansweringasetofprerequisitetoytasks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
    "authors": [
      "Jason Weston",
      "Antoine Bordes",
      "Sumit Chopra",
      "Sasha Rush",
      "Bart van Merrienboer",
      "Armand Joulin",
      "Tomas Mikolov"
    ],
    "page_url": "http://arxiv.org/abs/1502.05698",
    "pdf_url": "https://arxiv.org/pdf/1502.05698",
    "published": "2016-05",
    "summary": "One long-term goal of machine learning research is to produce methods that are applicable to reasoning and natural language, in particular building an intelligent dialogue agent. To measure progress towards that goal, we argue for the usefulness of a set of proxy tasks that evaluate reading comprehension via question answering. Our tasks measure understanding in several ways: whether a system is able to answer questions via chaining facts, simple induction, deduction and many more. The tasks are designed to be prerequisites for any system that aims to be capable of conversing with a human. We believe many existing learning systems can currently not solve them, and hence our aim is to classify these tasks into skill sets, so that researchers can identify (and then rectify) the failings of their systems. We also extend and improve the recently introduced Memory Networks model, and show it is able to solve some, but not all, of the tasks. ",
    "code_link": "https://github.com/facebook/bAbI-tasks"
  },
  "iclr2016_main_evaluatingprerequisitequalitiesforlearningend-to-enddialogsystems": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Evaluating Prerequisite Qualities for Learning End-to-end Dialog Systems",
    "authors": [
      "Jesse Dodge",
      "Andreea Gane",
      "Xiang Zhang",
      "Antoine Bordes",
      "Sumit Chopra",
      "Alexander Miller",
      "Arthur Szlam",
      "Jason Weston"
    ],
    "page_url": "http://arxiv.org/abs/1511.06931",
    "pdf_url": "https://arxiv.org/pdf/1511.06931",
    "published": "2016-05",
    "summary": "A long-term goal of machine learning is to build intelligent conversational agents. One recent popular approach is to train end-to-end models on a large amount of real dialog transcripts between humans (Sordoni et al., 2015; Vinyals & Le, 2015; Shang et al., 2015). However, this approach leaves many questions unanswered as an understanding of the precise successes and shortcomings of each model is hard to assess. A contrasting recent proposal are the bAbI tasks (Weston et al., 2015b) which are synthetic data that measure the ability of learning machines at various reasoning tasks over toy language. Unfortunately, those tests are very small and hence may encourage methods that do not scale. In this work, we propose a suite of new tasks of a much larger scale that attempt to bridge the gap between the two regimes. Choosing the domain of movies, we provide tasks that test the ability of models to answer factual questions (utilizing OMDB), provide personalization (utilizing MovieLens), carry short conversations about the two, and finally to perform on natural dialogs from Reddit. We provide a dataset covering 75k movie entities and with 3.5M training examples. We present results of various models on these tasks, and evaluate their performance. ",
    "code_link": "https://github.com/facebook/SCRNNs"
  },
  "iclr2016_main_bettercomputergoplayerwithneuralnetworkandlong-termprediction": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Better Computer Go Player with Neural Network and Long-term Prediction",
    "authors": [
      "Yuandong Tian",
      "Yan Zhu"
    ],
    "page_url": "http://arxiv.org/abs/1511.06410",
    "pdf_url": "https://arxiv.org/pdf/1511.06410",
    "published": "2016-05",
    "summary": "Competing with top human players in the ancient game of Go has been a long-term goal of artificial intelligence. Go's high branching factor makes traditional search techniques ineffective, even on leading-edge hardware, and Go's evaluation function could change drastically with one stone change. Recent works [Maddison et al. (2015); Clark & Storkey (2015)] show that search is not strictly necessary for machine Go players. A pure pattern-matching approach, based on a Deep Convolutional Neural Network (DCNN) that predicts the next move, can perform as well as Monte Carlo Tree Search (MCTS)-based open source Go engines such as Pachi [Baudis & Gailly (2012)] if its search budget is limited. We extend this idea in our bot named darkforest, which relies on a DCNN designed for long-term predictions. Darkforest substantially improves the win rate for pattern-matching approaches against MCTS-based approaches, even with looser search budgets. Against human players, the newest versions, darkfores2, achieve a stable 3d level on KGS Go Server as a ranked bot, a substantial improvement upon the estimated 4k-5k ranks for DCNN reported in Clark & Storkey (2015) based on games against other machine players. Adding MCTS to darkfores2 creates a much stronger player named darkfmcts3: with 5000 rollouts, it beats Pachi with 10k rollouts in all 250 games; with 75k rollouts it achieves a stable 5d level in KGS server, on par with state-of-the-art Go AIs (e.g., Zen, DolBaram, CrazyStone) except for AlphaGo [Silver et al. (2016)]; with 110k rollouts, it won the 3rd place in January KGS Go Tournament. ",
    "code_link": ""
  },
  "iclr2016_main_distributionalsmoothingwithvirtualadversarialtraining": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Distributional Smoothing with Virtual Adversarial Training",
    "authors": [
      "Takeru Miyato",
      "Shin-ichi Maeda",
      "Masanori Koyama",
      "Ken Nakae",
      "Shin Ishii"
    ],
    "page_url": "http://arxiv.org/abs/1507.00677",
    "pdf_url": "https://arxiv.org/pdf/1507.00677",
    "published": "2016-05",
    "summary": "We propose local distributional smoothness (LDS), a new notion of smoothness for statistical model that can be used as a regularization term to promote the smoothness of the model distribution. We named the LDS based regularization as virtual adversarial training (VAT). The LDS of a model at an input datapoint is defined as the KL-divergence based robustness of the model distribution against local perturbation around the datapoint. VAT resembles adversarial training, but distinguishes itself in that it determines the adversarial direction from the model distribution alone without using the label information, making it applicable to semi-supervised learning. The computational cost for VAT is relatively low. For neural network, the approximated gradient of the LDS can be computed with no more than three pairs of forward and back propagations. When we applied our technique to supervised and semi-supervised learning for the MNIST dataset, it outperformed all the training methods other than the current state of the art method, which is based on a highly advanced generative model. We also applied our method to SVHN and NORB, and confirmed our method's superior performance over the current state of the art semi-supervised method applied to these datasets. ",
    "code_link": "https://github.com/takerum/vat"
  },
  "iclr2016_main_multi-tasksequencetosequencelearning": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Multi-task Sequence to Sequence Learning",
    "authors": [
      "Minh-Thang Luong",
      "Quoc Le",
      "Ilya Sutskever",
      "Oriol Vinyals",
      "Lukasz Kaiser"
    ],
    "page_url": "http://arxiv.org/abs/1511.06114",
    "pdf_url": "https://arxiv.org/pdf/1511.06114",
    "published": "2016-05",
    "summary": "Sequence to sequence learning has recently emerged as a new paradigm in supervised learning. To date, most of its applications focused on only one task and not much work explored this framework for multiple tasks. This paper examines three multi-task learning (MTL) settings for sequence to sequence models: (a) the oneto-many setting - where the encoder is shared between several tasks such as machine translation and syntactic parsing, (b) the many-to-one setting - useful when only the decoder can be shared, as in the case of translation and image caption generation, and (c) the many-to-many setting - where multiple encoders and decoders are shared, which is the case with unsupervised objectives and translation. Our results show that training on a small amount of parsing and image caption data can improve the translation quality between English and German by up to 1.5 BLEU points over strong single-task baselines on the WMT benchmarks. Furthermore, we have established a new state-of-the-art result in constituent parsing with 93.0 F1. Lastly, we reveal interesting properties of the two unsupervised learning objectives, autoencoder and skip-thought, in the MTL context: autoencoder helps less in terms of perplexities but more on BLEU scores compared to skip-thought. ",
    "code_link": ""
  },
  "iclr2016_main_atestofrelativesimilarityformodelselectioningenerativemodels": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "A Test of Relative Similarity for Model Selection in Generative Models",
    "authors": [
      "Eugene Belilovsky",
      "Wacha Bounliphone",
      "Matthew Blaschko",
      "Ioannis Antonoglou",
      "Arthur Gretton"
    ],
    "page_url": "http://arxiv.org/abs/1511.04581",
    "pdf_url": "https://arxiv.org/pdf/1511.04581",
    "published": "2016-05",
    "summary": "Probabilistic generative models provide a powerful framework for representing data that avoids the expense of manual annotation typically needed by discriminative approaches. Model selection in this generative setting can be challenging, however, particularly when likelihoods are not easily accessible. To address this issue, we introduce a statistical test of relative similarity, which is used to determine which of two models generates samples that are significantly closer to a real-world reference dataset of interest. We use as our test statistic the difference in maximum mean discrepancies (MMDs) between the reference dataset and each model dataset, and derive a powerful, low-variance test based on the joint asymptotic distribution of the MMDs between each reference-model pair. In experiments on deep generative models, including the variational auto-encoder and generative moment matching network, the tests provide a meaningful ranking of model performance as a function of parameter and training settings. ",
    "code_link": ""
  },
  "iclr2016_main_compressionofdeepconvolutionalneuralnetworksforfastandlowpowermobileapplications": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications",
    "authors": [
      "Yong-Deok Kim",
      "Eunhyeok Park",
      "Sungjoo Yoo",
      "Taelim Choi",
      "Lu Yang",
      "Dongjun Shin"
    ],
    "page_url": "http://arxiv.org/abs/1511.06530",
    "pdf_url": "https://arxiv.org/pdf/1511.06530",
    "published": "2016-05",
    "summary": "Although the latest high-end smartphone has powerful CPU and GPU, running deeper convolutional neural networks (CNNs) for complex tasks such as ImageNet classification on mobile devices is challenging. To deploy deep CNNs on mobile devices, we present a simple and effective scheme to compress the entire CNN, which we call one-shot whole network compression. The proposed scheme consists of three steps: (1) rank selection with variational Bayesian matrix factorization, (2) Tucker decomposition on kernel tensor, and (3) fine-tuning to recover accumulated loss of accuracy, and each step can be easily implemented using publicly available tools. We demonstrate the effectiveness of the proposed scheme by testing the performance of various compressed CNNs (AlexNet, VGGS, GoogLeNet, and VGG-16) on the smartphone. Significant reductions in model size, runtime, and energy consumption are obtained, at the cost of small loss in accuracy. In addition, we address the important implementation level issue on 1?1 convolution, which is a key operation of inception module of GoogLeNet as well as CNNs compressed by our proposed scheme. ",
    "code_link": ""
  },
  "iclr2016_main_session-basedrecommendationswithrecurrentneuralnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Session-based recommendations with recurrent neural networks",
    "authors": [
      "Bal\u00e1zs Hidasi",
      "Alexandros Karatzoglou",
      "Linas Baltrunas",
      "Domonkos Tikk"
    ],
    "page_url": "http://arxiv.org/abs/1511.06939",
    "pdf_url": "https://arxiv.org/pdf/1511.06939",
    "published": "2016-05",
    "summary": "We apply recurrent neural networks (RNN) on a new domain, namely recommender systems. Real-life recommender systems often face the problem of having to base recommendations only on short session-based data (e.g. a small sportsware website) instead of long user histories (as in the case of Netflix). In this situation the frequently praised matrix factorization approaches are not accurate. This problem is usually overcome in practice by resorting to item-to-item recommendations, i.e. recommending similar items. We argue that by modeling the whole session, more accurate recommendations can be provided. We therefore propose an RNN-based approach for session-based recommendations. Our approach also considers practical aspects of the task and introduces several modifications to classic RNNs such as a ranking loss function that make it more viable for this specific problem. Experimental results on two data-sets show marked improvements over widely used approaches. ",
    "code_link": ""
  },
  "iclr2016_main_continuouscontrolwithdeepreinforcementlearning": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Continuous control with deep reinforcement learning",
    "authors": [
      "Timothy Lillicrap",
      "Jonathan Hunt",
      "Alexander Pritzel",
      "Nicolas Heess",
      "Tom Erez",
      "Yuval Tassa",
      "David Silver",
      "Daan Wierstra"
    ],
    "page_url": "http://arxiv.org/abs/1509.02971",
    "pdf_url": "https://arxiv.org/pdf/1509.02971",
    "published": "2016-05",
    "summary": "We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs. ",
    "code_link": ""
  },
  "iclr2016_main_recurrentgaussianprocesses": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Recurrent Gaussian Processes",
    "authors": [
      "C\u00e9sar Lincoln Mattos",
      "Zhenwen Dai",
      "Andreas Damianou",
      "Jeremy Forth",
      "Guilherme Barreto",
      "Neil Lawrence"
    ],
    "page_url": "http://arxiv.org/abs/1511.06644",
    "pdf_url": "https://arxiv.org/pdf/1511.06644",
    "published": "2016-05",
    "summary": "We define Recurrent Gaussian Processes (RGP) models, a general family of Bayesian nonparametric models with recurrent GP priors which are able to learn dynamical patterns from sequential data. Similar to Recurrent Neural Networks (RNNs), RGPs can have different formulations for their internal states, distinct inference methods and be extended with deep structures. In such context, we propose a novel deep RGP model whose autoregressive states are latent, thereby performing representation and dynamical learning simultaneously. To fully exploit the Bayesian nature of the RGP model we develop the Recurrent Variational Bayes (REVARB) framework, which enables efficient inference and strong regularization through coherent propagation of uncertainty across the RGP layers and states. We also introduce a RGP extension where variational parameters are greatly reduced by being reparametrized through RNN-based sequential recognition models. We apply our model to the tasks of nonlinear system identification and human motion modeling. The promising obtained results indicate that our RGP model maintains its highly flexibility while being able to avoid overfitting and being applicable even when larger datasets are not available. ",
    "code_link": ""
  },
  "iclr2016_main_modelingvisualrepresentationsdefiningpropertiesanddeepapproximations": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Modeling Visual Representations:Defining Properties and Deep Approximations",
    "authors": [
      "Stefano Soatto",
      "Alessandro Chiuso"
    ],
    "page_url": "http://arxiv.org/abs/1411.7676",
    "pdf_url": "https://arxiv.org/pdf/1411.7676",
    "published": "2016-05",
    "summary": "Visual representations are defined in terms of minimal sufficient statistics of visual data, for a class of tasks, that are also invariant to nuisance variability. Minimal sufficiency guarantees that we can store a representation in lieu of raw data with smallest complexity and no performance loss on the task at hand. Invariance guarantees that the statistic is constant with respect to uninformative transformations of the data. We derive analytical expressions for such representations and show they are related to feature descriptors commonly used in computer vision, as well as to convolutional neural networks. This link highlights the assumptions and approximations tacitly assumed by these methods and explains empirical practices such as clamping, pooling and joint normalization. ",
    "code_link": ""
  },
  "iclr2016_main_auxiliaryimageregularizationfordeepcnnswithnoisylabels": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Auxiliary Image Regularization for Deep CNNs with Noisy Labels",
    "authors": [
      "Samaneh Azadi",
      "Jiashi Feng",
      "Stefanie Jegelka",
      "Trevor Darrell"
    ],
    "page_url": "http://arxiv.org/abs/1511.07069",
    "pdf_url": "https://arxiv.org/pdf/1511.07069",
    "published": "2016-05",
    "summary": "Precisely-labeled data sets with sufficient amount of samples are very important for training deep convolutional neural networks (CNNs). However, many of the available real-world data sets contain erroneously labeled samples and those errors substantially hinder the learning of very accurate CNN models. In this work, we consider the problem of training a deep CNN model for image classification with mislabeled training samples - an issue that is common in real image data sets with tags supplied by amateur users. To solve this problem, we propose an auxiliary image regularization technique, optimized by the stochastic Alternating Direction Method of Multipliers (ADMM) algorithm, that automatically exploits the mutual context information among training images and encourages the model to select reliable images to robustify the learning process. Comprehensive experiments on benchmark data sets clearly demonstrate our proposed regularized CNN model is resistant to label noise in training data. ",
    "code_link": ""
  },
  "iclr2016_main_policydistillation": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Policy Distillation",
    "authors": [
      "Andrei Rusu",
      "Sergio Gomez",
      "Caglar Gulcehre",
      "Guillaume Desjardins",
      "James Kirkpatrick",
      "Razvan Pascanu",
      "Volodymyr Mnih",
      "Koray Kavukcuoglu",
      "Raia Hadsell"
    ],
    "page_url": "http://arxiv.org/abs/1511.06295",
    "pdf_url": "https://arxiv.org/pdf/1511.06295",
    "published": "2016-05",
    "summary": "Policies for complex visual tasks have been successfully learned with deep reinforcement learning, using an approach called deep Q-networks (DQN), but relatively large (task-specific) networks and extensive training are needed to achieve good performance. In this work, we present a novel method called policy distillation that can be used to extract the policy of a reinforcement learning agent and train a new network that performs at the expert level while being dramatically smaller and more efficient. Furthermore, the same method can be used to consolidate multiple task-specific policies into a single policy. We demonstrate these claims using the Atari domain and show that the multi-task distilled agent outperforms the single-task teachers as well as a jointly-trained DQN agent. ",
    "code_link": ""
  },
  "iclr2016_main_neuralrandom-accessmachines": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Neural Random-Access Machines",
    "authors": [
      "Karol Kurach",
      "Marcin Andrychowicz",
      "Ilya Sutskever"
    ],
    "page_url": "http://arxiv.org/abs/1511.06392",
    "pdf_url": "https://arxiv.org/pdf/1511.06392",
    "published": "2016-05",
    "summary": "In this paper, we propose and investigate a new neural network architecture called Neural Random Access Machine. It can manipulate and dereference pointers to an external variable-size random-access memory. The model is trained from pure input-output examples using backpropagation. We evaluate the new model on a number of simple algorithmic tasks whose solutions require pointer manipulation and dereferencing. Our results show that the proposed model can learn to solve algorithmic tasks of such type and is capable of operating on simple data structures like linked-lists and binary trees. For easier tasks, the learned solutions generalize to sequences of arbitrary length. Moreover, memory access during inference can be done in a constant time under some assumptions. ",
    "code_link": ""
  },
  "iclr2016_main_gatedgraphsequenceneuralnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Gated Graph Sequence Neural Networks",
    "authors": [
      "Yujia Li",
      "Daniel Tarlow",
      "Marc Brockschmidt",
      "Richard Zemel",
      "CIFAR"
    ],
    "page_url": "http://arxiv.org/abs/1511.05493",
    "pdf_url": "https://arxiv.org/pdf/1511.05493",
    "published": "2016-05",
    "summary": "Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures. ",
    "code_link": ""
  },
  "iclr2016_main_metriclearningwithadaptivedensitydiscrimination": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Metric Learning with Adaptive Density Discrimination",
    "authors": [
      "Oren Rippel",
      "Manohar Paluri",
      "Piotr Dollar",
      "Lubomir Bourdev"
    ],
    "page_url": "http://arxiv.org/abs/1511.05939",
    "pdf_url": "https://arxiv.org/pdf/1511.05939",
    "published": "2016-05",
    "summary": "Distance metric learning (DML) approaches learn a transformation to a representation space where distance is in correspondence with a predefined notion of similarity. While such models offer a number of compelling benefits, it has been difficult for these to compete with modern classification algorithms in performance and even in feature extraction. In this work, we propose a novel approach explicitly designed to address a number of subtle yet important issues which have stymied earlier DML algorithms. It maintains an explicit model of the distributions of the different classes in representation space. It then employs this knowledge to adaptively assess similarity, and achieve local discrimination by penalizing class distribution overlap. We demonstrate the effectiveness of this idea on several tasks. Our approach achieves state-of-the-art classification results on a number of fine-grained visual recognition datasets, surpassing the standard softmax classifier and outperforming triplet loss by a relative margin of 30-40%. In terms of computational performance, it alleviates training inefficiencies in the traditional triplet loss, reaching the same error in 5-30 times fewer iterations. Beyond classification, we further validate the saliency of the learnt representations via their attribute concentration and hierarchy recovery properties, achieving 10-25% relative gains on the softmax classifier and 25-50% on triplet loss in these tasks. ",
    "code_link": ""
  },
  "iclr2016_main_censoringrepresentationswithanadversary": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Censoring Representations with an Adversary",
    "authors": [
      "Harrison Edwards",
      "Amos Storkey"
    ],
    "page_url": "http://arxiv.org/abs/1511.05897",
    "pdf_url": "https://arxiv.org/pdf/1511.05897",
    "published": "2016-05",
    "summary": "In practice, there are often explicit constraints on what representations or decisions are acceptable in an application of machine learning. For example it may be a legal requirement that a decision must not favour a particular group. Alternatively it can be that that representation of data must not have identifying information. We address these two related issues by learning flexible representations that minimize the capability of an adversarial critic. This adversary is trying to predict the relevant sensitive variable from the representation, and so minimizing the performance of the adversary ensures there is little or no information in the representation about the sensitive variable. We demonstrate this adversarial approach on two problems: making decisions free from discrimination and removing private information from images. We formulate the adversarial model as a minimax problem, and optimize that minimax objective using a stochastic gradient alternate min-max optimizer. We demonstrate the ability to provide discriminant free representations for standard test problems, and compare with previous state of the art methods for fairness, showing statistically significant improvement across most cases. The flexibility of this method is shown via a novel problem: removing annotations from images, from unaligned training examples of annotated and unannotated images, and with no a priori knowledge of the form of annotation provided to the model. ",
    "code_link": ""
  },
  "iclr2016_main_variablerateimagecompressionwithrecurrentneuralnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Variable Rate Image Compression with Recurrent Neural Networks",
    "authors": [
      "George Toderici",
      "Sean O'Malley",
      "Damien Vincent",
      "Sung Jin Hwang",
      "Michele Covell",
      "Shumeet Baluja",
      "Rahul Sukthankar",
      "David Minnen"
    ],
    "page_url": "http://arxiv.org/abs/1511.06085",
    "pdf_url": "https://arxiv.org/pdf/1511.06085",
    "published": "2016-05",
    "summary": "A large fraction of Internet traffic is now driven by requests from mobile devices with relatively small screens and often stringent bandwidth requirements. Due to these factors, it has become the norm for modern graphics-heavy websites to transmit low-resolution, low-bytecount image previews (thumbnails) as part of the initial page load process to improve apparent page responsiveness. Increasing thumbnail compression beyond the capabilities of existing codecs is therefore a current research focus, as any byte savings will significantly enhance the experience of mobile device users. Toward this end, we propose a general framework for variable-rate image compression and a novel architecture based on convolutional and deconvolutional LSTM recurrent networks. Our models address the main issues that have prevented autoencoder neural networks from competing with existing image compression algorithms: (1) our networks only need to be trained once (not per-image), regardless of input image dimensions and the desired compression rate; (2) our networks are progressive, meaning that the more bits are sent, the more accurate the image reconstruction; and (3) the proposed architecture is at least as efficient as a standard purpose-trained autoencoder for a given number of bits. On a large-scale benchmark of 32$\\times$32 thumbnails, our LSTM-based approaches provide better visual quality than (headerless) JPEG, JPEG2000 and WebP, with a storage size that is reduced by 10% or more. ",
    "code_link": ""
  },
  "iclr2016_main_delvingdeeperintoconvolutionalnetworksforlearningvideorepresentations": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Delving Deeper into Convolutional Networks for Learning Video Representations",
    "authors": [
      "Nicolas Ballas",
      "Li Yao",
      "Pal Chris",
      "Aaron Courville"
    ],
    "page_url": "http://arxiv.org/abs/1511.06432",
    "pdf_url": "https://arxiv.org/pdf/1511.06432",
    "published": "2016-05",
    "summary": "We propose an approach to learn spatio-temporal features in videos from intermediate visual representations we call percepts using Gated-Recurrent-Unit Recurrent Networks (GRUs).Our method relies on percepts that are extracted from all level of a deep convolutional network trained on the large ImageNet dataset. While high-level percepts contain highly discriminative information, they tend to have a low-spatial resolution. Low-level percepts, on the other hand, preserve a higher spatial resolution from which we can model finer motion patterns. Using low-level percepts can leads to high-dimensionality video representations. To mitigate this effect and control the model number of parameters, we introduce a variant of the GRU model that leverages the convolution operations to enforce sparse connectivity of the model units and share parameters across the input spatial locations. We empirically validate our approach on both Human Action Recognition and Video Captioning tasks. In particular, we achieve results equivalent to state-of-art on the YouTube2Text dataset using a simpler text-decoder model and without extra 3D CNN features. ",
    "code_link": ""
  },
  "iclr2016_main_8-bitapproximationsforparallelismindeeplearning": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "8-Bit Approximations for Parallelism in Deep Learning",
    "authors": [
      "Tim Dettmers"
    ],
    "page_url": "http://arxiv.org/abs/1511.04561",
    "pdf_url": "https://arxiv.org/pdf/1511.04561",
    "published": "2016-05",
    "summary": "The creation of practical deep learning data-products often requires parallelization across processors and computers to make deep learning feasible on large data sets, but bottlenecks in communication bandwidth make it difficult to attain good speedups through parallelism. Here we develop and test 8-bit approximation algorithms which make better use of the available bandwidth by compressing 32-bit gradients and nonlinear activations to 8-bit approximations. We show that these approximations do not decrease predictive performance on MNIST, CIFAR10, and ImageNet for both model and data parallelism and provide a data transfer speedup of 2x relative to 32-bit parallelism. We build a predictive model for speedups based on our experimental data, verify its validity on known speedup data, and show that we can obtain a speedup of 50x and more on a system of 96 GPUs compared to a speedup of 23x for 32-bit. We compare our data types with other methods and show that 8-bit approximations achieve state-of-the-art speedups for model parallelism. Thus 8-bit approximation is an efficient method to parallelize convolutional networks on very large systems of GPUs. ",
    "code_link": ""
  },
  "iclr2016_main_data-dependentinitializationsofconvolutionalneuralnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Data-dependent initializations of Convolutional Neural Networks",
    "authors": [
      "Philipp Kraehenbuehl",
      "Carl Doersch",
      "Jeff Donahue",
      "Trevor Darrell"
    ],
    "page_url": "http://arxiv.org/abs/1511.06856",
    "pdf_url": "https://arxiv.org/pdf/1511.06856",
    "published": "2016-05",
    "summary": "Convolutional Neural Networks spread through computer vision like a wildfire, impacting almost all visual tasks imaginable. Despite this, few researchers dare to train their models from scratch. Most work builds on one of a handful of ImageNet pre-trained models, and fine-tunes or adapts these for specific tasks. This is in large part due to the difficulty of properly initializing these networks from scratch. A small miscalibration of the initial weights leads to vanishing or exploding gradients, as well as poor convergence properties. In this work we present a fast and simple data-dependent initialization procedure, that sets the weights of a network such that all units in the network train at roughly the same rate, avoiding vanishing or exploding gradients. Our initialization matches the current state-of-the-art unsupervised or self-supervised pre-training methods on standard computer vision tasks, such as image classification and object detection, while being roughly three orders of magnitude faster. When combined with pre-training methods, our initialization significantly outperforms prior work, narrowing the gap between supervised and unsupervised pre-training. ",
    "code_link": "https://github.com/philkr/magic_init"
  },
  "iclr2016_main_ordermatterssequencetosequenceforsets": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Order Matters: Sequence to sequence for sets",
    "authors": [
      "Oriol Vinyals",
      "Samy Bengio",
      "Manjunath Kudlur"
    ],
    "page_url": "http://arxiv.org/abs/1511.06391",
    "pdf_url": "https://arxiv.org/pdf/1511.06391",
    "published": "2016-05",
    "summary": "Sequences have become first class citizens in supervised learning thanks to the resurgence of recurrent neural networks. Many complex tasks that require mapping from or to a sequence of observations can now be formulated with the sequence-to-sequence (seq2seq) framework which employs the chain rule to efficiently represent the joint probability of sequences. In many cases, however, variable sized inputs and/or outputs might not be naturally expressed as sequences. For instance, it is not clear how to input a set of numbers into a model where the task is to sort them; similarly, we do not know how to organize outputs when they correspond to random variables and the task is to model their unknown joint probability. In this paper, we first show using various examples that the order in which we organize input and/or output data matters significantly when learning an underlying model. We then discuss an extension of the seq2seq framework that goes beyond sequences and handles input sets in a principled way. In addition, we propose a loss which, by searching over possible orders during training, deals with the lack of structure of output sets. We show empirical evidence of our claims regarding ordering, and on the modifications to the seq2seq framework on benchmark language modeling and parsing tasks, as well as two artificial tasks -- sorting numbers and estimating the joint probability of unknown graphical models. ",
    "code_link": ""
  },
  "iclr2016_main_high-dimensionalcontinuouscontrolusinggeneralizedadvantageestimation": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "High-Dimensional Continuous Control Using Generalized Advantage Estimation",
    "authors": [
      "John Schulman",
      "Philipp Moritz",
      "Sergey Levine",
      "Michael Jordan",
      "Pieter Abbeel"
    ],
    "page_url": "http://arxiv.org/abs/1506.02438",
    "pdf_url": "https://arxiv.org/pdf/1506.02438",
    "published": "2016-05",
    "summary": "Policy gradient methods are an appealing approach in reinforcement learning because they directly optimize the cumulative reward and can straightforwardly be used with nonlinear function approximators such as neural networks. The two main challenges are the large number of samples typically required, and the difficulty of obtaining stable and steady improvement despite the nonstationarity of the incoming data. We address the first challenge by using value functions to substantially reduce the variance of policy gradient estimates at the cost of some bias, with an exponentially-weighted estimator of the advantage function that is analogous to TD(lambda). We address the second challenge by using trust region optimization procedure for both the policy and the value function, which are represented by neural networks. Our approach yields strong empirical results on highly challenging 3D locomotion tasks, learning running gaits for bipedal and quadrupedal simulated robots, and learning a policy for getting the biped to stand up from starting out lying on the ground. In contrast to a body of prior work that uses hand-crafted policy representations, our neural network policies map directly from raw kinematics to joint torques. Our algorithm is fully model-free, and the amount of simulated experience required for the learning tasks on 3D bipeds corresponds to 1-2 weeks of real time. ",
    "code_link": ""
  },
  "iclr2016_main_deepmultiscalevideopredictionbeyondmeansquareerror": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Deep Multi Scale Video Prediction Beyond Mean Square Error",
    "authors": [
      "Michael Mathieu",
      "camille couprie",
      "Yann Lecun"
    ],
    "page_url": "http://arxiv.org/abs/1511.05440",
    "pdf_url": "https://arxiv.org/pdf/1511.05440",
    "published": "2016-05",
    "summary": "Learning to predict future images from a video sequence involves the construction of an internal representation that models the image evolution accurately, and therefore, to some degree, its content and dynamics. This is why pixel-space video prediction may be viewed as a promising avenue for unsupervised feature learning. In addition, while optical flow has been a very studied problem in computer vision for a long time, future frame prediction is rarely approached. Still, many vision applications could benefit from the knowledge of the next frames of videos, that does not require the complexity of tracking every pixel trajectories. In this work, we train a convolutional network to generate future frames given an input sequence. To deal with the inherently blurry predictions obtained from the standard Mean Squared Error (MSE) loss function, we propose three different and complementary feature learning strategies: a multi-scale architecture, an adversarial training method, and an image gradient difference loss function. We compare our predictions to different published results based on recurrent neural networks on the UCF101 dataset ",
    "code_link": ""
  },
  "iclr2016_main_gridlongshort-termmemory": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Grid Long Short-Term Memory",
    "authors": [
      "Nal Kalchbrenner",
      "Alex Graves",
      "Ivo Danihelka"
    ],
    "page_url": "http://arxiv.org/abs/1507.01526",
    "pdf_url": "https://arxiv.org/pdf/1507.01526",
    "published": "2016-05",
    "summary": "This paper introduces Grid Long Short-Term Memory, a network of LSTM cells arranged in a multidimensional grid that can be applied to vectors, sequences or higher dimensional data such as images. The network differs from existing deep LSTM architectures in that the cells are connected between network layers as well as along the spatiotemporal dimensions of the data. The network provides a unified way of using LSTM for both deep and sequential computation. We apply the model to algorithmic tasks such as 15-digit integer addition and sequence memorization, where it is able to significantly outperform the standard LSTM. We then give results for two empirical tasks. We find that 2D Grid LSTM achieves 1.47 bits per character on the Wikipedia character prediction benchmark, which is state-of-the-art among neural approaches. In addition, we use the Grid LSTM to define a novel two-dimensional translation model, the Reencoder, and show that it outperforms a phrase-based reference system on a Chinese-to-English translation task. ",
    "code_link": ""
  },
  "iclr2016_main_predictingdistributionswithlinearizingbeliefnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Predicting distributions with Linearizing Belief Networks",
    "authors": [
      "Yann Dauphin",
      "David Grangier"
    ],
    "page_url": "http://arxiv.org/abs/1511.05622",
    "pdf_url": "https://arxiv.org/pdf/1511.05622",
    "published": "2016-05",
    "summary": "Conditional belief networks introduce stochastic binary variables in neural networks. Contrary to a classical neural network, a belief network can predict more than the expected value of the output $Y$ given the input $X$. It can predict a distribution of outputs $Y$ which is useful when an input can admit multiple outputs whose average is not necessarily a valid answer. Such networks are particularly relevant to inverse problems such as image prediction for denoising, or text to speech. However, traditional sigmoid belief networks are hard to train and are not suited to continuous problems. This work introduces a new family of networks called linearizing belief nets or LBNs. A LBN decomposes into a deep linear network where each linear unit can be turned on or off by non-deterministic binary latent units. It is a universal approximator of real-valued conditional distributions and can be trained using gradient descent. Moreover, the linear pathways efficiently propagate continuous information and they act as multiplicative skip-connections that help optimization by removing gradient diffusion. This yields a model which trains efficiently and improves the state-of-the-art on image denoising and facial expression generation with the Toronto faces dataset. ",
    "code_link": ""
  },
  "iclr2016_main_fastandaccuratedeepnetworklearningbyexponentiallinearunits(elus)": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)",
    "authors": [
      "Djork-Arn\u00e9Clevert",
      "Thomas Unterthiner",
      "Sepp Hochreiter"
    ],
    "page_url": "http://arxiv.org/abs/1511.07289",
    "pdf_url": "https://arxiv.org/pdf/1511.07289",
    "published": "2016-05",
    "summary": "We introduce the exponential linear unit (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with batch normalization while batch normalization does not improve ELU networks. ELU networks are among the top 10 reported CIFAR-10 results and yield the best published result on CIFAR-100, without resorting to multi-view evaluation or model averaging. On ImageNet, ELU networks considerably speed up learning compared to a ReLU network with the same architecture, obtaining less than 10% classification error for a single crop, single model network. ",
    "code_link": ""
  },
  "iclr2016_main_actor-mimicdeepmultitaskandtransferreinforcementlearning": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning",
    "authors": [
      "Emilio Parisotto",
      "Jimmy Ba",
      "Ruslan Salakhutdinov"
    ],
    "page_url": "http://arxiv.org/abs/1511.06342",
    "pdf_url": "https://arxiv.org/pdf/1511.06342",
    "published": "2016-05",
    "summary": "The ability to act in multiple environments and transfer previous knowledge to new situations can be considered a critical aspect of any intelligent agent. Towards this goal, we define a novel method of multitask and transfer learning that enables an autonomous agent to learn how to behave in multiple tasks simultaneously, and then generalize its knowledge to new domains. This method, termed Actor-Mimic, exploits the use of deep reinforcement learning and model compression techniques to train a single policy network that learns how to act in a set of distinct tasks by using the guidance of several expert teachers. We then show that the representations learnt by the deep policy network are capable of generalizing to new tasks with no prior expert guidance, speeding up learning in novel environments. Although our method can in general be applied to a wide range of problems, we use Atari games as a testing environment to demonstrate these methods. ",
    "code_link": ""
  },
  "iclr2016_main_segmentalrecurrentneuralnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Segmental Recurrent Neural Networks",
    "authors": [
      "Lingpeng Kong",
      "Chris Dyer",
      "Noah Smith"
    ],
    "page_url": "http://arxiv.org/abs/1511.06018",
    "pdf_url": "https://arxiv.org/pdf/1511.06018",
    "published": "2016-05",
    "summary": "We introduce segmental recurrent neural networks (SRNNs) which define, given an input sequence, a joint probability distribution over segmentations of the input and labelings of the segments. Representations of the input segments (i.e., contiguous subsequences of the input) are computed by encoding their constituent tokens using bidirectional recurrent neural nets, and these segment embeddings are used to define compatibility scores with output labels. These local compatibility scores are integrated using a global semi-Markov conditional random field. Both fully supervised training -- in which segment boundaries and labels are observed -- as well as partially supervised training -- in which segment boundaries are latent -- are straightforward. Experiments on handwriting recognition and joint Chinese word segmentation/POS tagging show that, compared to models that do not explicitly represent segments such as BIO tagging schemes and connectionist temporal classification (CTC), SRNNs obtain substantially higher accuracies. ",
    "code_link": ""
  },
  "iclr2016_main_deeplineardiscriminantanalysis": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Deep Linear Discriminant Analysis",
    "authors": [
      "Matthias Dorfer",
      "Rainer Kelz",
      "Gerhard Widmer"
    ],
    "page_url": "http://arxiv.org/abs/1511.04707",
    "pdf_url": "https://arxiv.org/pdf/1511.04707",
    "published": "2016-05",
    "summary": "We introduce Deep Linear Discriminant Analysis (DeepLDA) which learns linearly separable latent representations in an end-to-end fashion. Classic LDA extracts features which preserve class separability and is used for dimensionality reduction for many classification problems. The central idea of this paper is to put LDA on top of a deep neural network. This can be seen as a non-linear extension of classic LDA. Instead of maximizing the likelihood of target labels for individual samples, we propose an objective function that pushes the network to produce feature distributions which: (a) have low variance within the same class and (b) high variance between different classes. Our objective is derived from the general LDA eigenvalue problem and still allows to train with stochastic gradient descent and back-propagation. For evaluation we test our approach on three different benchmark datasets (MNIST, CIFAR-10 and STL-10). DeepLDA produces competitive results on MNIST and CIFAR-10 and outperforms a network trained with categorical cross entropy (same architecture) on a supervised setting of STL-10. ",
    "code_link": ""
  },
  "iclr2016_main_large-scaleapproximatekernelcanonicalcorrelationanalysis": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Large-Scale Approximate Kernel Canonical Correlation Analysis",
    "authors": [
      "Weiran Wang",
      "Karen Livescu"
    ],
    "page_url": "http://arxiv.org/abs/1511.04773",
    "pdf_url": "https://arxiv.org/pdf/1511.04773",
    "published": "2016-05",
    "summary": "Kernel canonical correlation analysis (KCCA) is a nonlinear multi-view representation learning technique with broad applicability in statistics and machine learning. Although there is a closed-form solution for the KCCA objective, it involves solving an $N\\times N$ eigenvalue system where $N$ is the training set size, making its computational requirements in both memory and time prohibitive for large-scale problems. Various approximation techniques have been developed for KCCA. A commonly used approach is to first transform the original inputs to an $M$-dimensional random feature space so that inner products in the feature space approximate kernel evaluations, and then apply linear CCA to the transformed inputs. In many applications, however, the dimensionality $M$ of the random feature space may need to be very large in order to obtain a sufficiently good approximation; it then becomes challenging to perform the linear CCA step on the resulting very high-dimensional data matrices. We show how to use a stochastic optimization algorithm, recently proposed for linear CCA and its neural-network extension, to further alleviate the computation requirements of approximate KCCA. This approach allows us to run approximate KCCA on a speech dataset with $1.4$ million training samples and a random feature space of dimensionality $M=100000$ on a typical workstation. ",
    "code_link": ""
  },
  "iclr2016_main_unsupervisedrepresentationlearningwithdeepconvolutionalgenerativeadversarialnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks",
    "authors": [
      "Alec Radford",
      "Luke Metz",
      "Soumith Chintala"
    ],
    "page_url": "http://arxiv.org/abs/1511.06434",
    "pdf_url": "https://arxiv.org/pdf/1511.06434",
    "published": "2016-05",
    "summary": "In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations. ",
    "code_link": ""
  },
  "iclr2016_main_learningrepresentationsfromeegwithdeeprecurrent-convolutionalneuralnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks",
    "authors": [
      "Pouya Bashivan",
      "Irina Rish",
      "Mohammed Yeasin",
      "Noel Codella"
    ],
    "page_url": "http://arxiv.org/abs/1511.06448",
    "pdf_url": "https://arxiv.org/pdf/1511.06448",
    "published": "2016-05",
    "summary": "One of the challenges in modeling cognitive events from electroencephalogram (EEG) data is finding representations that are invariant to inter- and intra-subject differences, as well as to inherent noise associated with such data. Herein, we propose a novel approach for learning such representations from multi-channel EEG time-series, and demonstrate its advantages in the context of mental load classification task. First, we transform EEG activities into a sequence of topology-preserving multi-spectral images, as opposed to standard EEG analysis techniques that ignore such spatial information. Next, we train a deep recurrent-convolutional network inspired by state-of-the-art video classification to learn robust representations from the sequence of images. The proposed approach is designed to preserve the spatial, spectral, and temporal structure of EEG which leads to finding features that are less sensitive to variations and distortions within each dimension. Empirical evaluation on the cognitive load classification task demonstrated significant improvements in classification accuracy over current state-of-the-art approaches in this field. ",
    "code_link": ""
  },
  "iclr2016_main_diggingdeepintothelayersofcnnsinsearchofhowcnnsachieveviewinvariance": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Digging Deep into the layers of CNNs: In Search of How CNNs Achieve View Invariance",
    "authors": [
      "Amr Bakry",
      "Mohamed Elhoseiny",
      "Tarek El-Gaaly",
      "Ahmed Elgammal"
    ],
    "page_url": "http://arxiv.org/abs/1508.01983",
    "pdf_url": "https://arxiv.org/pdf/1508.01983",
    "published": "2016-05",
    "summary": "This paper is focused on studying the view-manifold structure in the feature spaces implied by the different layers of Convolutional Neural Networks (CNN). There are several questions that this paper aims to answer: Does the learned CNN representation achieve viewpoint invariance? How does it achieve viewpoint invariance? Is it achieved by collapsing the view manifolds, or separating them while preserving them? At which layer is view invariance achieved? How can the structure of the view manifold at each layer of a deep convolutional neural network be quantified experimentally? How does fine-tuning of a pre-trained CNN on a multi-view dataset affect the representation at each layer of the network? In order to answer these questions we propose a methodology to quantify the deformation and degeneracy of view manifolds in CNN layers. We apply this methodology and report interesting results in this paper that answer the aforementioned questions. ",
    "code_link": ""
  },
  "iclr2016_main_anexplorationofsoftmaxalternativesbelongingtothesphericallossfamily": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "An Exploration of Softmax Alternatives Belonging to the Spherical Loss Family",
    "authors": [
      "Alexandre De Br\u00e9bisson",
      "Pascal Vincent"
    ],
    "page_url": "http://arxiv.org/abs/1511.05042",
    "pdf_url": "https://arxiv.org/pdf/1511.05042",
    "published": "2016-05",
    "summary": "In a multi-class classification problem, it is standard to model the output of a neural network as a categorical distribution conditioned on the inputs. The output must therefore be positive and sum to one, which is traditionally enforced by a softmax. This probabilistic mapping allows to use the maximum likelihood principle, which leads to the well-known log-softmax loss. However the choice of the softmax function seems somehow arbitrary as there are many other possible normalizing functions. It is thus unclear why the log-softmax loss would perform better than other loss alternatives. In particular Vincent et al. (2015) recently introduced a class of loss functions, called the spherical family, for which there exists an efficient algorithm to compute the updates of the output weights irrespective of the output size. In this paper, we explore several loss functions from this family as possible alternatives to the traditional log-softmax. In particular, we focus our investigation on spherical bounds of the log-softmax loss and on two spherical log-likelihood losses, namely the log-Spherical Softmax suggested by Vincent et al. (2015) and the log-Taylor Softmax that we introduce. Although these alternatives do not yield as good results as the log-softmax loss on two language modeling tasks, they surprisingly outperform it in our experiments on MNIST and CIFAR-10, suggesting that they might be relevant in a broad range of applications. ",
    "code_link": ""
  },
  "iclr2016_main_data-dependentpathnormalizationinneuralnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Data-Dependent Path Normalization in Neural Networks",
    "authors": [
      "Behnam Neyshabur",
      "Ryota Tomioka",
      "Ruslan Salakhutdinov",
      "Nathan Srebro"
    ],
    "page_url": "http://arxiv.org/abs/1511.06747",
    "pdf_url": "https://arxiv.org/pdf/1511.06747",
    "published": "2016-05",
    "summary": "We propose a unified framework for neural net normalization, regularization and optimization, which includes Path-SGD and Batch-Normalization and interpolates between them across two different dimensions. Through this framework we investigate issue of invariance of the optimization, data dependence and the connection with natural gradients. ",
    "code_link": ""
  },
  "iclr2016_main_reasoninginvectorspaceanexploratorystudyofquestionanswering": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Reasoning in Vector Space: An Exploratory Study of Question Answering",
    "authors": [
      "Moontae Lee",
      "Xiaodong He",
      "Wen-tau Yih",
      "Jianfeng Gao",
      "Li Deng",
      "Paul Smolensky"
    ],
    "page_url": "http://arxiv.org/abs/1511.06426",
    "pdf_url": "https://arxiv.org/pdf/1511.06426",
    "published": "2016-05",
    "summary": "Question answering tasks have shown remarkable progress with distributed vector representation. In this paper, we investigate the recently proposed Facebook bAbI tasks which consist of twenty different categories of questions that require complex reasoning. Because the previous work on bAbI are all end-to-end models, errors could come from either an imperfect understanding of semantics or in certain steps of the reasoning. For clearer analysis, we propose two vector space models inspired by Tensor Product Representation (TPR) to perform knowledge encoding and logical reasoning based on common-sense inference. They together achieve near-perfect accuracy on all categories including positional reasoning and path finding that have proved difficult for most of the previous approaches. We hypothesize that the difficulties in these categories are due to the multi-relations in contrast to uni-relational characteristic of other categories. Our exploration sheds light on designing more sophisticated dataset and moving one step toward integrating transparent and interpretable formalism of TPR into existing learning paradigms. ",
    "code_link": ""
  },
  "iclr2016_main_neuralgpuslearnalgorithms": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Neural GPUs Learn Algorithms",
    "authors": [
      "Lukasz Kaiser",
      "Ilya Sutskever"
    ],
    "page_url": "http://arxiv.org/abs/1511.08228",
    "pdf_url": "https://arxiv.org/pdf/1511.08228",
    "published": "2016-05",
    "summary": "Learning an algorithm from examples is a fundamental problem that has been widely studied. Recently it has been addressed using neural networks, in particular by Neural Turing Machines (NTMs). These are fully differentiable computers that use backpropagation to learn their own programming. Despite their appeal NTMs have a weakness that is caused by their sequential nature: they are not parallel and are are hard to train due to their large depth when unfolded. We present a neural network architecture to address this problem: the Neural GPU. It is based on a type of convolutional gated recurrent unit and, like the NTM, is computationally universal. Unlike the NTM, the Neural GPU is highly parallel which makes it easier to train and efficient to run. An essential property of algorithms is their ability to handle inputs of arbitrary size. We show that the Neural GPU can be trained on short instances of an algorithmic task and successfully generalize to long instances. We verified it on a number of tasks including long addition and long multiplication of numbers represented in binary. We train the Neural GPU on numbers with upto 20 bits and observe no errors whatsoever while testing it, even on much longer numbers. To achieve these results we introduce a technique for training deep recurrent networks: parameter sharing relaxation. We also found a small amount of dropout and gradient noise to have a large positive effect on learning and generalization. ",
    "code_link": ""
  },
  "iclr2016_main_acdcastructuredefficientlinearlayer": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "ACDC: A Structured Efficient Linear Layer ",
    "authors": [
      "Marcin Moczulski",
      "Misha Denil",
      "Jeremy Appleyard",
      "Nando de Freitas"
    ],
    "page_url": "http://arxiv.org/abs/1511.05946",
    "pdf_url": "https://arxiv.org/pdf/1511.05946",
    "published": "2016-05",
    "summary": "The linear layer is one of the most pervasive modules in deep learning representations. However, it requires $O(N^2)$ parameters and $O(N^2)$ operations. These costs can be prohibitive in mobile applications or prevent scaling in many domains. Here, we introduce a deep, differentiable, fully-connected neural network module composed of diagonal matrices of parameters, $\\mathbf{A}$ and $\\mathbf{D}$, and the discrete cosine transform $\\mathbf{C}$. The core module, structured as $\\mathbf{ACDC^{-1}}$, has $O(N)$ parameters and incurs $O(N log N )$ operations. We present theoretical results showing how deep cascades of ACDC layers approximate linear layers. ACDC is, however, a stand-alone module and can be used in combination with any other types of module. In our experiments, we show that it can indeed be successfully interleaved with ReLU modules in convolutional neural networks for image recognition. Our experiments also study critical factors in the training of these structured modules, including initialization and depth. Finally, this paper also provides a connection between structured linear transforms used in deep learning and the field of Fourier optics, illustrating how ACDC could in principle be implemented with lenses and diffractive elements. ",
    "code_link": "https://github.com/mdenil/acdc-torch"
  },
  "iclr2016_main_adversarialmanipulationofdeeprepresentations": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Adversarial Manipulation of Deep Representations",
    "authors": [
      "Sara Sabour",
      "Yanshuai Cao",
      "Fartash Faghri",
      "David Fleet"
    ],
    "page_url": "http://arxiv.org/abs/1511.05122",
    "pdf_url": "https://arxiv.org/pdf/1511.05122",
    "published": "2016-05",
    "summary": "We show that the representation of an image in a deep neural network (DNN) can be manipulated to mimic those of other natural images, with only minor, imperceptible perturbations to the original image. Previous methods for generating adversarial images focused on image perturbations designed to produce erroneous class labels, while we concentrate on the internal layers of DNN representations. In this way our new class of adversarial images differs qualitatively from others. While the adversary is perceptually similar to one image, its internal representation appears remarkably similar to a different image, one from a different class, bearing little if any apparent similarity to the input; they appear generic and consistent with the space of natural images. This phenomenon raises questions about DNN representations, as well as the properties of natural images themselves. ",
    "code_link": ""
  },
  "iclr2016_main_geodesicsoflearnedrepresentations": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Geodesics of learned representations",
    "authors": [
      "Olivier H\u00e9naff",
      "Eero Simoncelli"
    ],
    "page_url": "http://arxiv.org/abs/1511.06394",
    "pdf_url": "https://arxiv.org/pdf/1511.06394",
    "published": "2016-05",
    "summary": "We develop a new method for visualizing and refining the invariances of learned representations. Specifically, we test for a general form of invariance, linearization, in which the action of a transformation is confined to a low-dimensional subspace. Given two reference images (typically, differing by some transformation), we synthesize a sequence of images lying on a path between them that is of minimal length in the space of the representation (a representational geodesic). If the transformation relating the two reference images is linearized by the representation, this sequence should follow the gradual evolution of this transformation. We use this method to assess the invariance properties of a state-of-the-art image classification network and find that geodesics generated for image pairs differing by translation, rotation, and dilation do not evolve according to their associated transformations. Our method also suggests a remedy for these failures, and following this prescription, we show that the modified representation is able to linearize a variety of geometric image transformations. ",
    "code_link": ""
  },
  "iclr2016_main_sequenceleveltrainingwithrecurrentneuralnetworks": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Sequence Level Training with Recurrent Neural Networks",
    "authors": [
      "Marc'Aurelio Ranzato",
      "Sumit Chopra",
      "Michael Auli",
      "Wojciech Zaremba"
    ],
    "page_url": "http://arxiv.org/abs/1511.06732",
    "pdf_url": "https://arxiv.org/pdf/1511.06732",
    "published": "2016-05",
    "summary": "Many natural language processing applications use language models to generate text. These models are typically trained to predict the next word in a sequence, given the previous words and some context such as an image. However, at test time the model is expected to generate the entire sequence from scratch. This discrepancy makes generation brittle, as errors may accumulate along the way. We address this issue by proposing a novel sequence level training algorithm that directly optimizes the metric used at test time, such as BLEU or ROUGE. On three different tasks, our approach outperforms several strong baselines for greedy generation. The method is also competitive when these baselines employ beam search, while being several times faster. ",
    "code_link": ""
  },
  "iclr2016_main_super-resolutionwithdeepconvolutionalsufficientstatistics": {
    "conf_id": "ICLR2016",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2016",
    "title": "Super-resolution with deep convolutional sufficient statistics",
    "authors": [
      "Joan Bruna",
      "Pablo Sprechmann",
      "Yann Lecun"
    ],
    "page_url": "http://arxiv.org/abs/1511.05666",
    "pdf_url": "https://arxiv.org/pdf/1511.05666",
    "published": "2016-05",
    "summary": "Inverse problems in image and audio, and super-resolution in particular, can be seen as high-dimensional structured prediction problems, where the goal is to characterize the conditional distribution of a high-resolution output given its low-resolution corrupted observation. When the scaling ratio is small, point estimates achieve impressive performance, but soon they suffer from the regression-to-the-mean problem, result of their inability to capture the multi-modality of this conditional distribution. Modeling high-dimensional image and audio distributions is a hard task, requiring both the ability to model complex geometrical structures and textured regions. In this paper, we propose to use as conditional model a Gibbs distribution, where its sufficient statistics are given by deep convolutional neural networks. The features computed by the network are stable to local deformation, and have reduced variance when the input is a stationary texture. These properties imply that the resulting sufficient statistics minimize the uncertainty of the target signals given the degraded observations, while being highly informative. The filters of the CNN are initialized by multiscale complex wavelets, and then we propose an algorithm to fine-tune them by estimating the gradient of the conditional log-likelihood, which bears some similarities with Generative Adversarial Networks. We evaluate experimentally the proposed approach in the image super-resolution task, but the approach is general and could be used in other challenging ill-posed problems such as audio bandwidth extension. ",
    "code_link": ""
  }
}