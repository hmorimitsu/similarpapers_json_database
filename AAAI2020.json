{
  "aaai2020_main_semi-supervisedlearningtoperceivechildrensaffectivestatesinatablettutor": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Semi-Supervised Learning to Perceive Children's Affective States in a Tablet Tutor ",
    "authors": [
      "Mansi Agarwal",
      "Jack Mostow"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7057",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7057/6911",
    "published": "2020-02",
    "summary": "Like good human tutors, intelligent tutoring systems should detect and respond to students' affective states. However, accuracy in detecting affective states automatically has been limited by the time and expense of manually labeling training data for supervised learning. To combat this limitation, we use semi-supervised learning to train an affective state detector on a sparsely labeled, culturally novel, authentic data set in the form of screen capture videos from a Swahili literacy and numeracy tablet tutor in Tanzania that shows the face of the child using it. We achieved 88% leave-1-child-out cross-validated accuracy in distinguishing pleasant, unpleasant, and neutral affective states, compared to only 61% for the best supervised learning method we tested. This work contributes toward using automated affect detection both off-line to improve the design of intelligent tutors, and at runtime to respond to student affect based on input from a user-facing tablet camera or webcam."
  },
  "aaai2020_main_geospatialclusteringforbalancedandproximalschools": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Geospatial Clustering for Balanced and Proximal Schools ",
    "authors": [
      "Subhodip Biswas",
      "Fanglan Chen",
      "Andreea Sistrunk",
      "Sathappan Muthiah",
      "Zhiqian Chen",
      "Nathan Self",
      "Chang-Tien Lu",
      "Naren Ramakrishnan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7058",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7058/6912",
    "published": "2020-02",
    "summary": "Public school boundaries are redrawn from time to time to ensure effective functioning of school systems. This process, also called school redistricting, is non-trivial due to (1) the presence of multiple design criteria such as capacity utilization, proximity and travel time which are hard for planners to consider simultaneously, (2) the fixed locations of schools with widely differing capacities that need to be balanced, (3) the spatial nature of the data and the need to preserve contiguity in school zones, and (4) the difficulty in quantifying local factors that may arise. Motivated by these challenges and the intricacy of the process, we propose a geospatial clustering algorithm called GeoKmeans for assisting planners in designing school boundaries such that students are assigned to proximal schools while ensuring effective utilization of school capacities. The algorithm operates on polygonal geometries and connects them into geographically contiguous school boundaries while balancing problem-specific constraints. We evaluate our approach on real-world data of two rapidly growing school districts in the US. Results indicate the efficacy of our approach in designing boundaries. Additionally, a case study is included to demonstrate the potential of GeoKmeans to assist planners in drawing boundaries."
  },
  "aaai2020_main_teachingconstraintprogrammingusingfable-basedlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Teaching Constraint Programming Using Fable-Based Learning ",
    "authors": [
      "Mavis Chan",
      "Cecilia Chun",
      "Holly Fung",
      "Jimmy H.M. Lee",
      "Peter J. Stuckey"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7059",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7059/6913",
    "published": "2020-02",
    "summary": "The paper presents the pedagogical innovations and experience of the co-development of three MOOCs on the subject of \u201cModeling and Solving Discrete Optimization Problems\u201d by two universities. In a nutshell, the MOOCs feature the Fable-Based Learning approach, which is a form of problem-based learning encapsulated in a coherent story plot. Each lecture video begins with an animation that tells a story following a novel. The protagonists of the story encounter a problem requiring technical assistance from the two professors from modern time via a magical tablet granted to them by a fairy god. The new pedagogy aims at increasing learners' motivation and interests as well as situating the learners in a coherent learning context. In addition to scriptwriting, animation production and situating the teaching materials in the story plot, another challenge of the project is the remote distance between the two institutions as well as the need to produce all teaching materials in both (Mandarin) Chinese and English to cater for different geographic learning needs. The MOOCs have been running recurrently on Coursera since 2017. We present learner statistics and feedback, and discuss our experience with and preliminary observations of adopting the online materials in a Flipped Classroom setting."
  },
  "aaai2020_main_teachingundergraduateartificialintelligenceclassesanexperimentwithanattendancerequirement": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Teaching Undergraduate Artificial Intelligence Classes: An Experiment with an Attendance Requirement ",
    "authors": [
      "Sven Koenig",
      "Tansel Uras",
      "Liron Cohen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7060",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7060/6914",
    "published": "2020-02",
    "summary": "We report on an experiment that we performed when we taught the undergraduate artificial intelligence class at the University of Southern California. We taught it \u2013 under very similar conditions \u2013 once with and once without an attendance requirement. The attendance requirement substantially increased the attendance of the students. It did not substantially affect their performance but decreased their course ratings across all categories in the official course evaluation, whose results happened to be biased toward the opinions of the students attending the lectures. For example, the overall rating of the instructor was 0.89 lower (on a 1-5 scale) with the attendance requirement and the overall rating of the class was 0.85 lower. Thus, the attendance requirement, combined with the policy for administering the course evaluation, had a large impact on the course ratings, which is a problem if the course ratings influence decisions on promotions, tenure, and salary increments for the instructors but also demonstrates the potential for the manipulation of course ratings."
  },
  "aaai2020_main_zhoraidesigningaconversationalagentforchildrentoexploremachinelearningconcepts": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Zhorai: Designing a Conversational Agent for Children to Explore Machine Learning Concepts ",
    "authors": [
      "Phoebe Lin",
      "Jessica Van Brummelen",
      "Galit Lukin",
      "Randi Williams",
      "Cynthia Breazeal"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7061",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7061/6915",
    "published": "2020-02",
    "summary": "Understanding how machines learn is critical for children to develop useful mental models for exploring artificial intelligence (AI) and smart devices that they now frequently interact with. Although children are very familiar with having conversations with conversational agents like Siri and Alexa, children often have limited knowledge about AI and machine learning. We leverage their existing familiarity and present Zhorai, a conversational platform and curriculum designed to help young children understand how machines learn. Children ages eight to eleven train an agent through conversation and understand how the knowledge is represented using visualizations. This paper describes how we designed the curriculum and evaluated its effectiveness with 14 children in small groups. We found that the conversational aspect of the platform increased engagement during learning and the novel visualizations helped make machine knowledge understandable. As a result, we make recommendations for future iterations of Zhorai and approaches for teaching AI to children."
  },
  "aaai2020_main_multipledataaugmentationstrategiesforimprovingperformanceonautomaticshortanswerscoring": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multiple Data Augmentation Strategies for Improving Performance on Automatic Short Answer Scoring ",
    "authors": [
      "Jiaqi Lun",
      "Jia Zhu",
      "Yong Tang",
      "Min Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7062",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7062/6916",
    "published": "2020-02",
    "summary": "Automatic short answer scoring (ASAS) is a research subject of intelligent education, which is a hot field of natural language understanding. Many experiments have confirmed that the ASAS system is not good enough, because its performance is limited by the training data. Focusing on the problem, we propose MDA-ASAS, multiple data augmentation strategies for improving performance on automatic short answer scoring. MDA-ASAS is designed to learn language representation enhanced by data augmentation strategies, which includes back-translation, correct answer as reference answer, and swap content. We argue that external knowledge has a profound impact on the ASAS process. Meanwhile, the Bidirectional Encoder Representations from Transformers (BERT) model has been shown to be effective for improving many natural language processing tasks, which acquires more semantic, grammatical and other features in large amounts of unsupervised data, and actually adds external knowledge. Combining with the latest BERT model, our experimental results on the ASAS dataset show that MDA-ASAS brings a significant gain over state-of-art. We also perform extensive ablation studies and suggest parameters for practical use."
  },
  "aaai2020_main_lessonslearnedfromteachingmachinelearningandnaturallanguageprocessingtohighschoolstudents": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Lessons Learned from Teaching Machine Learning and Natural Language Processing to High School Students ",
    "authors": [
      "Narges Norouzi",
      "Snigdha Chaturvedi",
      "Matthew Rutledge"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7063",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7063/6917",
    "published": "2020-02",
    "summary": "This paper describes an experience in teaching Machine Learning (ML) and Natural Language Processing (NLP) to a group of high school students over an intense one-month period. In this work, we provide an outline of an AI course curriculum we designed for high school students and then evaluate its effectiveness by analyzing student's feedback and student outcomes. After closely observing students, evaluating their responses to our surveys, and analyzing their contribution to the course project, we identified some possible impediments in teaching AI to high school students and propose some measures to avoid them. These measures include employing a combination of objectivist and constructivist pedagogies, reviewing/introducing basic programming concepts at the beginning of the course, and addressing gender discrepancies throughout the course."
  },
  "aaai2020_main_teachinggameaiasanundergraduatecourseincomputationalmedia": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Teaching Game AI as an Undergraduate Course in Computational Media ",
    "authors": [
      "Adam M. Smith",
      "Daniel Shapiro"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7064",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7064/6918",
    "published": "2020-02",
    "summary": "We need to teach AI to students in and outside of traditional computer science degree programs, including those designer-engineer hybrid students who will design and implement games or engage in technical games research later. The need to rethink AI curriculum is pressing in a design education context because AI powers many emerging practical techniques such as drama management, procedural content generation, player modeling, and machine playtesting. In this paper, we describe a 5-year experimental effort to teach a Game AI course structured around a broad and expanding set of roles AI can play in game design (e.g., Adversary and Actor, as well as Design Assistant and Storyteller). This course sets up computer science and computer game design students to transform practices in the game industry as well as create new forms of media that were previously unreachable. Our students gained mastery over the relevant techniques and further demonstrated (via novel prototype systems) many new roles for AI along the way."
  },
  "aaai2020_main_makinghigh-performancerobotssafeandeasytouseforanintroductiontocomputing": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Making High-Performance Robots Safe and Easy to Use For an Introduction to Computing ",
    "authors": [
      "Joseph Spitzer",
      "Joydeep Biswas",
      "Arjun Guha"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7065",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7065/6919",
    "published": "2020-02",
    "summary": "Robots are a popular platform for introducing computing and artificial intelligence to novice programmers. However, programming state-of-the-art robots is very challenging, and requires knowledge of concurrency, operation safety, and software engineering skills, which can take years to teach. In this paper, we present an approach to introducing computing that allows students to safely and easily program high-performance robots. We develop a platform for students to program RoboCup Small Size League robots using JavaScript. The platform 1) ensures physical safety at several levels of abstraction, 2) allows students to program robots using JavaScript in the browser, without the need to install software, and 3) presents a simplified JavaScript semantics that shields students from confusing language features. We discuss our experience running a week-long workshop using this platform, and analyze over 3,000 student-written program revisions to provide empirical evidence that our approach does help students."
  },
  "aaai2020_main_usingaitechniquesinaseriousgameforsocio-moralreasoningdevelopment": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Using AI Techniques in a Serious Game for Socio-Moral Reasoning Development ",
    "authors": [
      "Ange Tato",
      "Roger Nkambou",
      "Aude Dufresne"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7066",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7066/6920",
    "published": "2020-02",
    "summary": "We present a serious game designed to help players/learners develop socio-moral reasoning (SMR) maturity. It is based on an existing computerized task that was converted into a game to improve the motivation of learners. The learner model is computed using a hybrid deep learning architecture, and adaptation rules are provided by both human experts and machine learning techniques. We conducted some experiments with two versions of the game (the initial version and the adaptive version with AI-Based learner modeling). The results show that the adaptive version provides significant better results in terms of learning gain."
  },
  "aaai2020_main_anexperimentalethicsapproachtorobotethicseducation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Experimental Ethics Approach to Robot Ethics Education ",
    "authors": [
      "Tom Williams",
      "Qin Zhu",
      "Daniel Grollman"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7067",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7067/6921",
    "published": "2020-02",
    "summary": "We propose an experimental ethics-based curricular module for an undergraduate course on Robot Ethics. The proposed module aims to teach students how human subjects research methods can be used to investigate potential ethical concerns arising in human-robot interaction, by engaging those students in real experimental ethics research. In this paper we describe the proposed curricular module, describe our implementation of that module within a Robot Ethics course offered at a medium-sized engineering university, and statistically evaluate the effectiveness of the proposed curricular module in achieving desired learning objectives. While our results do not provide clear evidence of a quantifiable benefit to undergraduate achievement of the described learning objectives, we note that the module did provide additional learning opportunities for graduate students in the course, as they helped to supervise, analyze, and write up the results of this undergraduate-performed research experiment."
  },
  "aaai2020_main_aispace2aninteractivevisualizationtoolforlearningandteachingartificialintelligence": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AISpace2: An Interactive Visualization Tool for Learning and Teaching Artificial Intelligence ",
    "authors": [
      "Chenliang Zhou",
      "Dominic Kuang",
      "Jingru Liu",
      "Hanbo Yang",
      "Zijia Zhang",
      "Alan Mackworth",
      "David Poole"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7068",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7068/6922",
    "published": "2020-02",
    "summary": "AIspace is a set of tools used to learn and teach fundamental AI algorithms. The original version of AIspace was written in Java. There was not a clean separation of the algorithms and visualization; it was too complicated for students to modify the underlying algorithms. Its next generation, AIspace2, is built on AIPython, open source Python code that is designed to be as close as possible to pseudocode. AISpace2, visualized in JupyterLab, keeps the simple Python code, and uses hooks in AIPython to allow visualization of the algorithms. This allows students to see and modify the high-level algorithms in Python, and to visualize the output in a graphical form, aiming to better help them to build confidence and comfort in AI concepts and algorithms. So far we have tools for search, constraint satisfaction problems (CSP), planning and Bayesian network. In this paper we outline the tools and give some evaluations based on user feedback."
  },
  "aaai2020_main_usingcloudtoolsforliterateprogrammingtoredesignanaicoursefornon-traditionalcollegestudents": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Using Cloud Tools for Literate Programming to Redesign an AI Course for Non-Traditional College Students ",
    "authors": [
      "Maria Hwang",
      "Calvin Williamson"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7069",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7069/6923",
    "published": "2020-02",
    "summary": "As more open source educational software applications become available, higher educational institutions have the opportunity to utilize these cost efficient tools to deliver the instruction traditionally taught off line with heavy associated costs. Here we introduce a machine learning course that uses a simple, cloud computing approach to creating course materials. We see this type of serverless, cloud-based, literate programming to be the future of computer science education in non-traditional higher educational institutions in particular serving students who will need the basic literacy for computing and computation but will not pursue the traditional computer scientist path."
  },
  "aaai2020_main_minecraftasaplatformforproject-basedlearninginai": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Minecraft as a Platform for Project-Based Learning in AI ",
    "authors": [
      "Sameer Singh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7070",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7070/6924",
    "published": "2020-02",
    "summary": "Undergraduate courses that focus on open-ended, project-based learning teach students how to define concrete goals, transfer conceptual understanding of algorithms to code, and evaluate/analyze/present their solution. However, AI, along with machine learning, is getting increasingly varied in terms of both the approaches and applications, making it challenging to design project courses that span a sufficiently wide spectrum of AI. For these reasons, existing AI project courses are restricted to a narrow set of approaches (e.g. only reinforcement learning) or applications (e.g. only computer vision)."
  },
  "aaai2020_main_codingintheliberalartsthroughnaturallanguageprocessingandmachinelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Coding in the Liberal Arts through Natural Language Processing and Machine Learning ",
    "authors": [
      "Ursula Wolz",
      "Jennifer Wilson"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7071",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7071/6925",
    "published": "2020-02",
    "summary": "An initiative recently established at our institution is creating new opportunities for students to deepen their understanding of code and computational thinking, and to embrace questions of access, equity and social justice. In this short paper we report on two contextualized computing courses in this initiative that introduce coding and computational thinking through contextualizing two subfields of AI: Natural Language Processing and Machine Learning. The goal was two-fold: to help students gain foundational computational skills to further their own creative and critical practices; and more broadly, to help them develop better-informed critiques of the use of algorithmic systems, especially AI technology."
  },
  "aaai2020_main_modelaiassignments2020": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Model AI Assignments 2020 ",
    "authors": [
      "Todd W. Neller",
      "Stephen Keeley",
      "Michael Guerzhoy",
      "Wolfgang Hoenig",
      "Jiaoyang Li",
      "Sven Koenig",
      "Ameet Soni",
      "Krista Thomason",
      "Lisa Zhang",
      "Bibin Sebastian",
      "Cinjon Resnick",
      "Avital Oliver",
      "Surya Bhupatiraju",
      "Kumar Krishna Agrawal",
      "James Allingham",
      "Sejong Yoon",
      "Jonathan Chen",
      "Tom Larsen",
      "Marion Neumann",
      "Narges Norouzi",
      "Ryan Hausen",
      "Matthew Evett"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7072",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7072/6926",
    "published": "2020-02",
    "summary": "The Model AI Assignments session seeks to gather and disseminate the best assignment designs of the Artificial Intelligence (AI) Education community. Recognizing that assignments form the core of student learning experience, we here present abstracts of nine AI assignments from the 2020 session that are easily adoptable, playfully engaging, and flexible for a variety of instructor needs. Assignment specifications and supporting resources may be found at http://modelai.gettysburg.edu."
  },
  "aaai2020_main_backtothefuturefordialogueresearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Back to the Future for Dialogue Research ",
    "authors": [
      "Philip R Cohen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7073",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7073/6927",
    "published": "2020-02",
    "summary": "This \u201cblue sky\u201d paper argues that future conversational systems that can engage in multiparty, collaborative dialogues will require a more fundamental approach than existing technology. This paper identifies significant limitations of the state of the art, and argues that our returning to the plan-based approach to dialogue will provide a stronger foundation. Finally, I suggest a research strategy that couples neural network-based semantic parsing with plan-based reasoning in order to build a collaborative dialogue manager."
  },
  "aaai2020_main_collectiveinformation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Collective Information ",
    "authors": [
      "Ulle Endriss"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7074",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7074/6928",
    "published": "2020-02",
    "summary": "Many challenging problems of scientific, technological, and societal significance require us to aggregate information supplied by multiple agents into a single piece of information of the same type\u2014the collective information representing the stance of the group as a whole. Examples include expressive forms of voting and democratic decision making (where citizens supply information regarding their preferences), peer evaluation (where participants supply information in the form of assessments of their peers), and crowdsourcing (where volunteers supply information by annotating data). In this position paper, I outline the challenge of modelling, handling, and analysing all of these diverse instances of collective information using a common methodology. Addressing this challenge will facilitate a transfer of knowledge between different application domains, thereby enabling progress in all of them."
  },
  "aaai2020_main_assessingethicalthinkingaboutai": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Assessing Ethical Thinking about AI ",
    "authors": [
      "Judy Goldsmith",
      "Emanuelle Burton",
      "David M. Dueber",
      "Beth Goldstein",
      "Shannon Sampson",
      "Michael D. Toland"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7075",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7075/6929",
    "published": "2020-02",
    "summary": "As is evidenced by the associated AI, Ethics and Society conference, we now take as given the need for ethics education in the AI and general CS curricula. The anticipated surge in AI ethics education will force the field to reckon with delineating and then evaluating learner outcomes to determine what is working and improve what is not. We argue for a more descriptive than normative focus of this ethics education, and propose the development of assessments that can measure descriptive ethical thinking about AI. Such an assessment tool for measuring ethical reasoning capacity in CS contexts must be designed to produce reliable scores for which there is established validity evidence concerning their interpretation and use."
  },
  "aaai2020_main_aiforsoftwarequalityassuranceblueskyideastalk": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AI for Software Quality Assurance Blue Sky Ideas Talk ",
    "authors": [
      "Meir Kalech",
      "Roni Stern"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7076",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7076/6930",
    "published": "2020-02",
    "summary": "Modern software systems are highly complex and often have multiple dependencies on external parts such as other processes or services. This poses new challenges and exacerbate existing challenges in different aspects of software Quality Assurance (QA) including testing, debugging and repair. The goal of this talk is to present a novel AI paradigm for software QA (AI4QA). A quality assessment AI agent uses machine-learning techniques to predict where coding errors are likely to occur. Then a test generation AI agent considers the error predictions to direct automated test generation. Then a test execution AI agent executes tests, that are passed to the root-cause analysis AI agent, which applies automatic debugging algorithms. The candidate root causes are passed to a code repair AI agent that tries to create a patch for correcting the isolated error."
  },
  "aaai2020_main_aiforexplainingdecisionsinmulti-agentenvironments": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AI for Explaining Decisions in Multi-Agent Environments ",
    "authors": [
      "Sarit Kraus",
      "Amos Azaria",
      "Jelena Fiosina",
      "Maike Greve",
      "Noam Hazon",
      "Lutz Kolbe",
      "Tim-Benjamin Lembcke",
      "Jorg P. Muller",
      "Soren Schleibaum",
      "Mark Vollrath"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7077",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7077/6931",
    "published": "2020-02",
    "summary": "Explanation is necessary for humans to understand and accept decisions made by an AI system when the system's goal is known. It is even more important when the AI system makes decisions in multi-agent environments where the human does not know the systems' goals since they may depend on other agents' preferences. In such situations, explanations should aim to increase user satisfaction, taking into account the system's decision, the user's and the other agents' preferences, the environment settings and properties such as fairness, envy and privacy. Generating explanations that will increase user satisfaction is very challenging; to this end, we propose a new research direction: Explainable decisions in Multi-Agent Environments (xMASE). We then review the state of the art and discuss research directions towards efficient methodologies and algorithms for generating explanations that will increase users' satisfaction from AI systems' decisions in multi-agent environments."
  },
  "aaai2020_main_open-worldlearningforradicallyautonomousagents": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Open-World Learning for Radically Autonomous Agents ",
    "authors": [
      "Pat Langley"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7078",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7078/6932",
    "published": "2020-02",
    "summary": "In this paper, I pose a new research challenge \u2013 to develop intelligent agents that exhibit radical autonomy by responding to sudden, long-term changes in their environments. I illustrate this idea with examples, identify abilities that support it, and argue that, although each ability has been studied in isolation, they have not been combined into integrated systems. In addition, I propose a framework for characterizing environments in which goal-directed physical agents operate, along with specifying the ways in which those environments can change over time. In closing, I outline some approaches to the empirical study of such open-world learning."
  },
  "aaai2020_main_learningonthejobonlinelifelongandcontinuallearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning on the Job: Online Lifelong and Continual Learning ",
    "authors": [
      "Bing Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7079",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7079/6933",
    "published": "2020-02",
    "summary": "One of the hallmarks of the human intelligence is the ability to learn continuously, accumulate the knowledge learned in the past and use the knowledge to help learn more and learn better. It is hard to imagine a truly intelligent system without this capability. This type of learning differs significantly than the classic machine learning (ML) paradigm of isolated single-task learning. Although there is already research on learning a sequence of tasks incrementally under the names of lifelong learning or continual learning, they still follow the traditional two-phase separate training and testing paradigm in learning each task. The tasks are also given by the user. This paper adds on-the-job learning to the mix to emphasize the need to learn during application (thus online) after the model has been deployed, which traditional ML cannot do. It aims to leverage the learned knowledge to discover new tasks, interact with humans and the environment, make inferences, and incrementally learn the new tasks on the fly during applications in a self-supervised and interactive manner. This is analogous to human on-the-job learning after formal training. We use chatbots and self-driving cars as examples to discuss the need, some initial work, and key challenges and opportunities in building this capability."
  },
  "aaai2020_main_unveilinghiddenintentions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Unveiling Hidden Intentions ",
    "authors": [
      "Gerardo Ocampo Diaz",
      "Vincent Ng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7080",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7080/6934",
    "published": "2020-02",
    "summary": "Recent years have seen significant advances in machine perception, which have enabled AI systems to become grounded in the world. While AI systems can now \"read\" and \"see\", they still cannot read between the lines and see through the lens, unlike humans. We propose the novel task of hidden message and intention identification: given some perceptual input (i.e., a text, an image), the goal is to produce a short description of the message the input transmits and the hidden intention of its author, if any. Not only will a solution to this task enable machine perception technologies to reach the next level of complexity, but it will be an important step towards addressing a task that has recently received a lot of public attention, political manipulation in social media."
  },
  "aaai2020_main_onlinefairdivisionasurvey": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Online Fair Division: A Survey ",
    "authors": [
      "Martin Aleksandrov",
      "Toby Walsh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7081",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7081/6935",
    "published": "2020-02",
    "summary": "We survey a burgeoning and promising new research area that considers the online nature of many practical fair division problems. We identify wide variety of such online fair division problems, as well as discuss new mechanisms and normative properties that apply to this online setting. The online nature of such fair division problems provides both opportunities and challenges such as the possibility to develop new online mechanisms as well as the difficulty of dealing with an uncertain future."
  },
  "aaai2020_main_developmentsinmulti-agentfairallocation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Developments in Multi-Agent Fair Allocation ",
    "authors": [
      "Haris Aziz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7082",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7082/6936",
    "published": "2020-02",
    "summary": "Fairness is becoming an increasingly important concern when designing markets, allocation procedures, and computer systems. I survey some recent developments in the field of multi-agent fair allocation."
  },
  "aaai2020_main_letslearntheirlanguage?acaseforplanningwithautomata-networklanguagesfrommodelchecking": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Let's Learn Their Language? A Case for Planning with Automata-Network Languages from Model Checking ",
    "authors": [
      "Jorg Hoffmann",
      "Holger Hermanns",
      "Michaela Klauck",
      "Marcel Steinmetz",
      "Erez Karpas",
      "Daniele Magazzeni"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7083",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7083/6937",
    "published": "2020-02",
    "summary": "It is widely known that AI planning and model checking are closely related. Compilations have been devised between various pairs of language fragments. What has barely been voiced yet, though, is the idea to let go of one's own modeling language, and use one from the other area instead. We advocate that idea here \u2013 to use automata-network languages from model checking instead of PDDL \u2013 motivated by modeling difficulties relating to planning agents surrounded by exogenous agents in complex environments. One could, of course, address this by designing additional extended planning languages. But one can also leverage decades of work on modeling in the formal methods community, creating potential for deep synergy and integration with their techniques as a side effect. We believe there's a case to be made for the latter, as one modeling alternative in planning among others."
  },
  "aaai2020_main_softwaretestingformachinelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Software Testing for Machine Learning ",
    "authors": [
      "Dusica Marijan",
      "Arnaud Gotlieb"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7084",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7084/6938",
    "published": "2020-02",
    "summary": "Machine learning has become prevalent across a wide variety of applications. Unfortunately, machine learning has also shown to be susceptible to deception, leading to errors, and even fatal failures. This circumstance calls into question the widespread use of machine learning, especially in safety-critical applications, unless we are able to assure its correctness and trustworthiness properties. Software verification and testing are established technique for assuring such properties, for example by detecting errors. However, software testing challenges for machine learning are vast and profuse - yet critical to address. This summary talk discusses the current state-of-the-art of software testing for machine learning. More specifically, it discusses six key challenge areas for software testing of machine learning systems, examines current approaches to these challenges and highlights their limitations. The paper provides a research agenda with elaborated directions for making progress toward advancing the state-of-the-art on testing of machine learning."
  },
  "aaai2020_main_ontherobustnessoffacerecognitionalgorithmsagainstattacksandbias": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On the Robustness of Face Recognition Algorithms Against Attacks and Bias ",
    "authors": [
      "Richa Singh",
      "Akshay Agarwal",
      "Maneet Singh",
      "Shruti Nagpal",
      "Mayank Vatsa"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7085",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7085/6939",
    "published": "2020-02",
    "summary": "Face recognition algorithms have demonstrated very high recognition performance, suggesting suitability for real world applications. Despite the enhanced accuracies, robustness of these algorithms against attacks and bias has been challenged. This paper summarizes different ways in which the robustness of a face recognition algorithm is challenged, which can severely affect its intended working. Different types of attacks such as physical presentation attacks, disguise/makeup, digital adversarial attacks, and morphing/tampering using GANs have been discussed. We also present a discussion on the effect of bias on face recognition models and showcase that factors such as age and gender variations affect the performance of modern algorithms. The paper also presents the potential reasons for these challenges and some of the future research directions for increasing the robustness of face recognition models."
  },
  "aaai2020_main_generalizedarcconsistencyalgorithmsfortableconstraintsasummaryofalgorithmicideas": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generalized Arc Consistency Algorithms for Table Constraints: A Summary of Algorithmic Ideas ",
    "authors": [
      "Roland H. C. Yap",
      "Wei Xia",
      "Ruiwei Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7086",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7086/6940",
    "published": "2020-02",
    "summary": "Constraint Programming is a powerful paradigm to model and solve combinatorial problems. While there are many kinds of constraints, the table constraint (also called a CSP) is perhaps the most significant\u2014being the most well-studied and has the ability to encode any other constraints defined on finite variables. Thus, designing efficient filtering algorithms on table constraints has attracted significant research efforts. In turn, there have been great improvements in efficiency over time with the evolution and development of AC and GAC algorithms. In this paper, we survey the existing filtering algorithms for table constraint focusing on historically important ideas and recent successful techniques shown to be effective."
  },
  "aaai2020_main_tracehub-aplatformtobridgethegapbetweenstate-of-the-arttime-seriesanalyticsanddatasets": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " TraceHub - A Platform to Bridge the Gap between State-of-the-Art Time-Series Analytics and Datasets ",
    "authors": [
      "Shubham Agarwal",
      "Christian Muise",
      "Mayank Agarwal",
      "Sohini Upadhyay",
      "Zilu Tang",
      "Zhongshen Zeng",
      "Yasaman Khazaeni"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7087",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7087/6941",
    "published": "2020-02",
    "summary": "In this paper, we present TraceHub - a platform that connects new non-trivial state-of-the-art time-series analytics with datasets from different domains. Analytics owners can run their insights on new datasets in an automated setting to find insight's potential and improve it. Dataset owners can find all possible types of non-trivial insights based on latest research. We provide a plug-n-play system as a set of Dataset, Transformer pipeline, and Analytics APIs for both kinds of users. We show a usefulness measure of generated insights across various types of analytics in the system. We believe that this platform can be used to bridge the gap between time-series analytics and datasets by significantly reducing the time to find the true potential of budding time-series research and improving on it faster."
  },
  "aaai2020_main_mapfscenariosoftwareforevaluatingmapfplansonrealrobots": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MAPF Scenario: Software for Evaluating MAPF Plans on Real Robots ",
    "authors": [
      "Roman Bart\u00e1k",
      "Ji\u0159\u00ed \u0161vancara",
      "Ivan Krasi\u010denko"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7088",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7088/6942",
    "published": "2020-02",
    "summary": "Multi-Agent Path Finding (MAPF) deals with finding collision free paths for a set of agents (robots) moving on a graph. The interest in MAPF in the research community started to increase recently partly due to practical applications in areas such as warehousing and computer games. However, the academic community focuses mostly on solving the abstract version of the problem (moving of agents on the graph) with only a few results on real robots. The presented software MAPF Scenario provides a tool for specifying MAPF problems on grid maps, solving the problems using various abstractions (for example, assuming rotation actions or not), simulating execution of plans, and translating the abstract plans to control programs for small robots Ozobots. The tool is intended as a research platform for evaluating abstract MAPF plans on real robots and as an educational and demonstration tool bridging the areas of artificial intelligence and robotics."
  },
  "aaai2020_main_doc2dialaframeworkfordialoguecompositiongroundedindocuments": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Doc2Dial: A Framework for Dialogue Composition Grounded in Documents ",
    "authors": [
      "Song Feng",
      "Kshitij Fadnis",
      "Q. Vera Liao",
      "Luis A. Lastras"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7089",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7089/6943",
    "published": "2020-02",
    "summary": "We introduce Doc2Dial, an end-to-end framework for generating conversational data grounded in given documents. It takes the documents as input and generates the pipelined tasks for obtaining the annotations specifically for producing the simulated dialog flows. Then, the dialog flows are used to guide the collection of the utterances via the integrated crowdsourcing tool. The outcomes include the human-human dialogue data grounded in the given documents, as well as various types of automatically or human labeled annotations that help ensure the quality of the dialog data with the flexibility to (re)composite dialogues. We expect such data can facilitate building automated dialogue agents for goal-oriented tasks. We demonstrate Doc2Dial system with the various domain documents for customer care."
  },
  "aaai2020_main_matchuaninteractivematchingplatform": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MatchU: An Interactive Matching Platform ",
    "authors": [
      "James Ferris",
      "Hadi Hosseini"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7090",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7090/6944",
    "published": "2020-02",
    "summary": "MatchU is a web-based platform that offers an interactive framework to find how to form mutually-beneficial relationships, decide how to distribute resources, or resolve conflicts through a suite of matching algorithms rooted in economics and artificial intelligence. In this paper, we discuss MatchU's vision, solutions, and future directions."
  },
  "aaai2020_main_embeddinghigh-levelknowledgeintodqnstolearnfasterandmoresafely": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": "Embedding High-Level Knowledge into DQNs to Learn Faster and More Safely",
    "authors": [
      "Zihang Gao",
      "Fangzhen Lin",
      "Yi Zhou",
      "Hao Zhang",
      "Kaishun Wu",
      "Haodi Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7091",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7091/6945",
    "published": "2020-02",
    "summary": "Deep reinforcement learning has been successfully applied in many decision making scenarios. However, the slow training process and difficulty in explaining limit its application. In this paper, we attempt to address some of these problems by proposing a framework of Rule-interposing Learning (RIL) that embeds knowledge into deep reinforcement learning. In this framework, the rules dynamically effect the training progress, and accelerate the learning. The embedded knowledge in form of rule not only improves learning efficiency, but also prevents unnecessary or disastrous explorations at early stage of training. Moreover, the modularity of the framework makes it straightforward to transfer high-level knowledge among similar tasks."
  },
  "aaai2020_main_causalknowledgeextractionthroughlarge-scaletextmining": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Causal Knowledge Extraction through Large-Scale Text Mining ",
    "authors": [
      "Oktie Hassanzadeh",
      "Debarun Bhattacharjya",
      "Mark Feblowitz",
      "Kavitha Srinivas",
      "Michael Perrone",
      "Shirin Sohrabi",
      "Michael Katz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7092",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7092/6946",
    "published": "2020-02",
    "summary": "In this demonstration, we present a system for mining causal knowledge from large corpuses of text documents, such as millions of news articles. Our system provides a collection of APIs for causal analysis and retrieval. These APIs enable searching for the effects of a given cause and the causes of a given effect, as well as the analysis of existence of causal relation given a pair of phrases. The analysis includes a score that indicates the likelihood of the existence of a causal relation. It also provides evidence from an input corpus supporting the existence of a causal relation between input phrases. Our system uses generic unsupervised and weakly supervised methods of causal relation extraction that do not impose semantic constraints on causes and effects. We show example use cases developed for a commercial application in enterprise risk management."
  },
  "aaai2020_main_damndefeasiblereasoningtoolformulti-agentreasoning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DAMN: Defeasible Reasoning Tool for Multi-Agent Reasoning ",
    "authors": [
      "Abdelraouf Hecham",
      "Madalina Croitoru",
      "Pierre Bisquert"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7093",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7093/6947",
    "published": "2020-02",
    "summary": "This demonstration paper introduces DAMN: a defeasible reasoning platform available on the web. It is geared towards decision making where each agent has its own knowledge base that can be combined with other agents to detect and visualize conflicts and potentially solve them using a semantics. It allows the use of different defeasible reasoning semantics (ambiguity blocking/propagating with or without team defeat) and integrates agent collaboration and visualization features."
  },
  "aaai2020_main_d-agreecrowddiscussionsupportsystembasedonautomatedfacilitationagent": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " D-Agree: Crowd Discussion Support System Based on Automated Facilitation Agent ",
    "authors": [
      "Takayuki Ito",
      "Shota Suzuki",
      "Naoko Yamaguchi",
      "Tomohiro Nishida",
      "Kentaro Hiraishi",
      "Kai Yoshino"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7094",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7094/6948",
    "published": "2020-02",
    "summary": "Large-scale online discussion platforms are receiving great attention as potential next-generation methods for smart democratic citizen platforms. One of the studies clarified the critical problem faced by human facilitators caused by the difficulty of facilitating large-scale online discussions. In this demonstration, we present our current implementation of D-agree, a crowd-scale discussion support system based on an automated facilitation agent. We conducted a large-scale social experiment with Nagoya local government. The results demonstrate that the agent worked well compared with human facilitators."
  },
  "aaai2020_main_\u2018watchtheflu\u2019atweetmonitoringtoolforepidemicintelligenceofinfluenzainaustralia": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " \u2018Watch the Flu\u2019: A Tweet Monitoring Tool for Epidemic Intelligence of Influenza in Australia ",
    "authors": [
      "Brian Jin",
      "Aditya Joshi",
      "Ross Sparks",
      "Stephen Wan",
      "C\u00e9cile Paris",
      "C Raina MacIntyre"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7095",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7095/6949",
    "published": "2020-02",
    "summary": "\u2018Watch The Flu\u2019 is a tool that monitors tweets posted in Australia for symptoms of influenza. The tool is a unique combination of two areas of artificial intelligence: natural language processing and time series monitoring, in order to assist public health surveillance. Using a real-time data pipeline, it deploys a web-based dashboard for visual analysis, and sends out emails to a set of users when an outbreak is detected. We expect that the tool will assist public health experts with their decision-making for disease outbreaks, by providing them insights from social media."
  },
  "aaai2020_main_dianasworldasituatedmultimodalinteractiveagent": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Diana's World: A Situated Multimodal Interactive Agent ",
    "authors": [
      "Nikhil Krishnaswamy",
      "Pradyumna Narayana",
      "Rahul Bangar",
      "Kyeongmin Rim",
      "Dhruva Patil",
      "David McNeely-White",
      "Jaime Ruiz",
      "Bruce Draper",
      "Ross Beveridge",
      "James Pustejovsky"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7096",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7096/6950",
    "published": "2020-02",
    "summary": "State of the art unimodal dialogue agents lack some core aspects of peer-to-peer communication\u2014the nonverbal and visual cues that are a fundamental aspect of human interaction. To facilitate true peer-to-peer communication with a computer, we present Diana, a situated multimodal agent who exists in a mixed-reality environment with a human interlocutor, is situation- and context-aware, and responds to the human's language, gesture, and affect to complete collaborative tasks."
  },
  "aaai2020_main_geno\u2013optimizationforclassicalmachinelearningmadefastandeasy": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " GENO \u2013 Optimization for Classical Machine Learning Made Fast and Easy ",
    "authors": [
      "S\u00f6ren Laue",
      "Matthias Mitterreiter",
      "Joachim Giesen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7097",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7097/6951",
    "published": "2020-02",
    "summary": "Most problems from classical machine learning can be cast as an optimization problem. We introduce GENO (GENeric Optimization), a framework that lets the user specify a constrained or unconstrained optimization problem in an easy-to-read modeling language. GENO then generates a solver, i.e., Python code, that can solve this class of optimization problems. The generated solver is usually as fast as hand-written, problem-specific, and well-engineered solvers. Often the solvers generated by GENO are faster by a large margin compared to recently developed solvers that are tailored to a specific problem class."
  },
  "aaai2020_main_caireanend-to-endempatheticchatbot": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " CAiRE: An End-to-End Empathetic Chatbot ",
    "authors": [
      "Zhaojiang Lin",
      "Peng Xu",
      "Genta Indra Winata",
      "Farhad Bin Siddique",
      "Zihan Liu",
      "Jamin Shin",
      "Pascale Fung"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7098",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7098/6952",
    "published": "2020-02",
    "summary": "We present CAiRE, an end-to-end generative empathetic chatbot designed to recognize user emotions and respond in an empathetic manner. Our system adapts the Generative Pre-trained Transformer (GPT) to empathetic response generation task via transfer learning. CAiRE is built primarily to focus on empathy integration in fully data-driven generative dialogue systems. We create a web-based user interface which allows multiple users to asynchronously chat with CAiRE. CAiRE also collects user feedback and continues to improve its response quality by discarding undesirable generations via active learning and negative training."
  },
  "aaai2020_main_plan2danceplanningbasedchoreographingfrommusic": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Plan2Dance: Planning Based Choreographing from Music ",
    "authors": [
      "Yuechang Liu",
      "Dongbo Xie",
      "Hankz Hankui Zhuo",
      "Liqian Lai"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7099",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7099/6953",
    "published": "2020-02",
    "summary": "The field of dancing robots has drawn much attention from numerous sources. Despite the success of previous systems on choreography for robots to dance with external stimuli, they are often either limited to a pre-defined set of movements or lack of considering \u201chard\u201d relations among dancing motions. In the demonstration, we design a planning based choreographing system, which views choreography with music as planning problems and solve the problems with off-the-shelf planners. Our demonstration exhibits the effectiveness of our system via evaluating our system with various music."
  },
  "aaai2020_main_deeppoetryachineseclassicalpoetrygenerationsystem": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Poetry: A Chinese Classical Poetry Generation System ",
    "authors": [
      "Yusen Liu",
      "Dayiheng Liu",
      "Jiancheng Lv"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7100",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7100/6954",
    "published": "2020-02",
    "summary": "In this work, we demonstrate a Chinese classical poetry generation system called Deep Poetry. Existing systems for Chinese classical poetry generation are mostly template-based and very few of them can accept multi-modal input. Unlike previous systems, Deep Poetry uses neural networks that are trained on over 200 thousand poems and 3 million ancient Chinese prose. Our system can accept plain text, images or artistic conceptions as inputs to generate Chinese classical poetry. More importantly, users are allowed to participate in the process of writing poetry by our system. For the user's convenience, we deploy the system at the WeChat applet platform, users can use the system on the mobile device whenever and wherever possible."
  },
  "aaai2020_main_pulsesatelliteatoolusinghuman-aifeedbackloopsforsatelliteimageanalysisinhumanitariancontexts": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " PulseSatellite: A Tool Using Human-AI Feedback Loops for Satellite Image Analysis in Humanitarian Contexts ",
    "authors": [
      "Tomaz Logar",
      "Joseph Bullock",
      "Edoardo Nemni",
      "Lars Bromley",
      "John A. Quinn",
      "Miguel Luengo-Oroz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7101",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7101/6955",
    "published": "2020-02",
    "summary": "Humanitarian response to natural disasters and conflicts can be assisted by satellite image analysis. In a humanitarian context, very specific satellite image analysis tasks must be done accurately and in a timely manner to provide operational support. We present PulseSatellite, a collaborative satellite image analysis tool which leverages neural network models that can be retrained on-the fly and adapted to specific humanitarian contexts and geographies. We present two case studies, in mapping shelters and floods respectively, that illustrate the capabilities of PulseSatellite."
  },
  "aaai2020_main_learniton-demandrapidcustomizationforevent-eventrelationextraction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " LearnIt: On-Demand Rapid Customization for Event-Event Relation Extraction ",
    "authors": [
      "Bonan Min",
      "Manaj Srivastava",
      "Haoling Qiu",
      "Prasannakumar Muthukumar",
      "Joshua Fasching"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7102",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7102/6956",
    "published": "2020-02",
    "summary": "We present a system which allows a user to create event-event relation extractors on-demand with a small amount of effort. The system provides a suite of algorithms, flexible workflows, and a user interface (UI), to allow rapid customization of event-event relation extractors for new types and domains of interest. Experiments show that it enables users to create extractors for 6 types of causal and temporal relations, with less than 20 minutes of effort per type. Our system (source code, UI) is available at https://github.com/BBN-E/LearnIt. A demonstration video is available at https://vimeo.com/329950144."
  },
  "aaai2020_main_exploratorynavigationandselectivereading": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Exploratory Navigation and Selective Reading ",
    "authors": [
      "Natwar Modani",
      "Paridhi Maheshwari",
      "Harsh Deshpande",
      "Saurab Sirpurkar",
      "Diviya .",
      "Somak Aditya"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7103",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7103/6957",
    "published": "2020-02",
    "summary": "Navigating a collection of documents can be facilitated by obtaining a human-understandable concept hierarchy with links to the content. This is a non-trivial task for two reasons. First, defining concepts that are understandable by an average consumer and yet meaningful for a large variety of corpora is hard. Second, creating semantically meaningful yet intuitive hierarchical representation is hard, and can be task dependent. We present out system Navigation.ai which automatically processes a document collection, induces a concept hierarchy using Wikipedia and presents an interactive interface that helps user navigate to individual paragraphs using concepts."
  },
  "aaai2020_main_partnerhuman-in-the-loopentitynameunderstandingwithdeeplearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " PARTNER: Human-in-the-Loop Entity Name Understanding with Deep Learning ",
    "authors": [
      "Kun Qian",
      "Poornima Chozhiyath Raman",
      "Yunyao Li",
      "Lucian Popa"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7104",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7104/6958",
    "published": "2020-02",
    "summary": "Entity name disambiguation is an important task for many text-based AI tasks. Entity names usually have internal semantic structures that are useful for resolving different variations of the same entity. We present, PARTNER, a deep learning-based interactive system for entity name understanding. Powered by effective active learning and weak supervision, PARTNER can learn deep learning-based models for identifying entity name structure with low human effort. PARTNER also allows the user to design complex normalization and variant generation functions without coding skills."
  },
  "aaai2020_main_cognitivecomplianceassessingregulatoryriskinfinancialadvicedocuments": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Cognitive Compliance: Assessing Regulatory Risk in Financial Advice Documents ",
    "authors": [
      "Wanita Sherchan",
      "Sue Ann Chen",
      "Simon Harris",
      "Nebula Alam",
      "Khoi-Nguyen Tran",
      "Christopher J. Butler"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7105",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7105/6959",
    "published": "2020-02",
    "summary": "This paper describes Cognitive Compliance - a solution that automates the complex manual process of assessing regulatory compliance of personal financial advice. The solution uses natural language processing (NLP), machine learning and deep learning to characterise the regulatory risk status of personal financial advice documents with traffic light rating for various risk factors. This enables comprehensive coverage of the review and rapid identification of documents at high risk of non-compliance with government regulations."
  },
  "aaai2020_main_dicraiassisted,adaptiveplatformforcontractreview": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DICR: AI Assisted, Adaptive Platform for Contract Review ",
    "authors": [
      "Dan G. Tecuci",
      "Ravi Palla",
      "Hamid R. Motahari Nezhad",
      "Nishchal Ahuja",
      "Alex Monteiro",
      "Tigran Ishkhanov",
      "Nigel Duffy"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7106",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7106/6960",
    "published": "2020-02",
    "summary": "In the regular course of business, companies spend a lot of effort reading and interpreting documents, a highly manual process that involves tedious tasks, such as identifying dates and names or locating the presence or absence of certain clauses in a contract. Dealing with natural language is complex and further complicated by the fact that these documents come in various formats (scanned image, digital formats) and have different degrees of internal structure (spreadsheets, invoices, text documents). We present DICR, an end-to-end, modular, and trainable system that automates the mundane aspects of document review and allows humans to perform the validation. The system is able to speed up this work while increasing quality of information extracted, consistency, throughput, and decreasing time to decision. Extracted data can be fed into other downstream applications (from dashboards to Q&A and to report generation)."
  },
  "aaai2020_main_data-drivenrankingandvisualizationofproductsbycompetitiveness": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Data-Driven Ranking and Visualization of Products by Competitiveness ",
    "authors": [
      "Sheema Usmani",
      "Mariana Bernagozzi",
      "Yufeng Huang",
      "Michelle Morales",
      "Amir Sabet Sarvestani",
      "Biplav Srivastava"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7107",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7107/6961",
    "published": "2020-02",
    "summary": "Competitive analysis is a critical part of any business. Product managers, sellers, and marketers spend time and resources scouring through a huge volume of online and offline content, aiming to discover what their competitors are doing in the marketplace and to understand what type of threat they pose to their business' financial well-being. Currently, this process is slow, costly and labor-intensive. We demonstrate Clarity, a data-driven unsupervised system for assessment of products, which is currently in deployment at IBM. Clarity has been running for more than a year and is used by over 1,500 people to perform over 160 competitive analyses involving over 800 products. The system considers multiple factors from a collection of online content: numeric ratings by users, sentiment towards key product drivers, content volume, and recency of content. The results and explanations of factors leading to the results are visualized in an interactive dashboard that allows users to track the performance of their products as well as understand the main contributing factors. main contributing factors."
  },
  "aaai2020_main_dragon-vdetectionandrecognitionofairplanegoalswithnavigationalvisualization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DRAGON-V: Detection and Recognition of Airplane Goals with Navigational Visualization ",
    "authors": [
      "Christabel Wayllace",
      "Sunwoo Ha",
      "Yuchen Han",
      "Jiaming Hu",
      "Shayan Monadjemi",
      "William Yeoh",
      "Alvitta Ottley"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7108",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7108/6962",
    "published": "2020-02",
    "summary": "We introduce Detection and Recognition of Airplane GOals with Navigational Visualization (DRAGON-V), a visualization system that uses probabilistic goal recognition to infer and display the most probable airport runway that a pilot is approaching. DRAGON-V is especially useful in cases of miscommunication, low visibility, or lack of airport familiarity which may result in a pilot deviating from the assigned taxiing route. The visualization system conveys relevant information, and updates according to the airplane's current geolocation. DRAGON-V aims to assist air traffic controllers in reducing incidents of runway incursions at airports."
  },
  "aaai2020_main_presentationtraineroralpresentationsupportsystemforimpression-relatedfeedback": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " PresentationTrainer: Oral Presentation Support System for Impression-Related Feedback ",
    "authors": [
      "Shengzhou Yi",
      "Hiroshi Yumoto",
      "Xueting Wang",
      "Toshihiko Yamasaki"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7109",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7109/6963",
    "published": "2020-02",
    "summary": "In order to support the pratice of oral presentation, we developed PresentationTrainer which includes (1) a presentation impression prediction system and (2) a presentation slide analysis system. For the presentation impression prediction system, we proposed two methods, using Support Vector Machine and Markov Random Field, or using multimodal neural network, to predict audiences' impressions for speech videos. For the slide analysis system, we used Convolutional Neural Network and Global Average Pooling to evaluate the design of slides. We then used Class Activation Mapping to provide visual feedback for showing which areas should be modified."
  },
  "aaai2020_main_automaticcardamageassessmentsystemreadingandunderstandingvideosasprofessionalinsuranceinspectors": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Automatic Car Damage Assessment System: Reading and Understanding Videos as Professional Insurance Inspectors ",
    "authors": [
      "Wei Zhang",
      "Yuan Cheng",
      "Xin Guo",
      "Qingpei Guo",
      "Jian Wang",
      "Qing Wang",
      "Chen Jiang",
      "Meng Wang",
      "Furong Xu",
      "Wei Chu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7110",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7110/6964",
    "published": "2020-02",
    "summary": "We demonstrate a car damage assessment system in car insurance field based on artificial intelligence techniques, which can exempt insurance inspectors from checking cars on site and help people without professional knowledge to evaluate car damages when accidents happen. Unlike existing approaches, we utilize videos instead of photos to interact with users to make the whole procedure as simple as possible. We adopt object and video detection and segmentation techniques in computer vision, and take advantage of multiple frames extracted from videos to achieve high damage recognition accuracy. The system uploads video streams captured by mobile devices, recognizes car damage on the cloud asynchronously and then returns damaged components and repair costs to users. The system evaluates car damages and returns results automatically and effectively in seconds, which reduces laboratory costs and decreases insurance claim time significantly."
  },
  "aaai2020_main_combiningmachinelearningmodelsusingcombolibrary": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Combining Machine Learning Models Using combo Library ",
    "authors": [
      "Yue Zhao",
      "Xuejian Wang",
      "Cheng Cheng",
      "Xueying Ding"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7111",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7111/6965",
    "published": "2020-02",
    "summary": "Model combination, often regarded as a key sub-field of ensemble learning, has been widely used in both academic research and industry applications. To facilitate this process, we propose and implement an easy-to-use Python toolkit, combo, to aggregate models and scores under various scenarios, including classification, clustering, and anomaly detection. In a nutshell, combo provides a unified and consistent way to combine both raw and pretrained models from popular machine learning libraries, e.g., scikit-learn, XGBoost, and LightGBM. With accessibility and robustness in mind, combo is designed with detailed documentation, interactive examples, continuous integration, code coverage, and maintainability check; it can be installed easily through Python Package Index (PyPI) or {https://github.com/yzhao062/combo}."
  },
  "aaai2020_main_interactivescenegenerationviascenegraphswithattributes": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Interactive Scene Generation via Scene Graphs with Attributes ",
    "authors": [
      "Oron Ashual",
      "Lior Wolf"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7112",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7112/6966",
    "published": "2020-02",
    "summary": "We introduce a simple yet expressive image generation method. On the one hand, it does not require the user to paint the masks or define a bounding box of the various objects, since the model does it by itself. On the other hand, it supports defining a coarse location and size of each object. Based on this, we offer a simple, interactive GUI, that allows a layman user to generate diverse images effortlessly."
  },
  "aaai2020_main_learninghigher-orderprogramsthroughpredicateinvention": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Higher-Order Programs through Predicate Invention ",
    "authors": [
      "Andrew Cropper",
      "Rolf Morel",
      "Stephen H. Muggleton"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7113",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7113/6967",
    "published": "2020-02",
    "summary": "A key feature of inductive logic programming (ILP) is its ability to learn first-order programs, which are intrinsically more expressive than propositional programs. In this paper, we introduce ILP techniques to learn higher-order programs. We implement our idea in Metagolho, an ILP system which can learn higher-order programs with higher-order predicate invention. Our experiments show that, compared to first-order programs, learning higher-order programs can significantly improve predictive accuracies and reduce learning times."
  },
  "aaai2020_main_restrainingboltsforreinforcementlearningagents": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Restraining Bolts for Reinforcement Learning Agents ",
    "authors": [
      "Giuseppe De Giacomo",
      "Luca Iocchi",
      "Marco Favorito",
      "Fabio Patrizi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7114",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7114/6968",
    "published": "2020-02",
    "summary": "In this work we have investigated the concept of \u201crestraining bolt\u201d, inspired by Science Fiction. We have two distinct sets of features extracted from the world, one by the agent and one by the authority imposing some restraining specifications on the behaviour of the agent (the \u201crestraining bolt\u201d). The two sets of features and, hence the model of the world attainable from them, are apparently unrelated since of interest to independent parties. However they both account for (aspects of) the same world. We have considered the case in which the agent is a reinforcement learning agent on a set of low-level (subsymbolic) features, while the restraining bolt is specified logically using linear time logic on finite traces f/f over a set of high-level symbolic features. We show formally, and illustrate with examples, that, under general circumstances, the agent can learn while shaping its goals to suitably conform (as much as possible) to the restraining bolt specifications.1"
  },
  "aaai2020_main_algorithm-in-the-loopdecisionmaking": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Algorithm-in-the-Loop Decision Making ",
    "authors": [
      "Ben Green",
      "Yiling Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7115",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7115/6969",
    "published": "2020-02",
    "summary": "We introduce a new framework for conceiving of and studying algorithms that are deployed to aid human decision making: \u201calgorithm-in-the-loop\u201d systems. The algorithm-in-the-loop framework centers human decision making, providing a more precise lens for studying the social impacts of algorithmic decision making aids. We report on two experiments that evaluate algorithm-in-the-loop decision making and find significant limits to these systems."
  },
  "aaai2020_main_explainingimageclassifiersgeneratingexemplarsandcounter-exemplarsfromlatentrepresentations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Explaining Image Classifiers Generating Exemplars and Counter-Exemplars from Latent Representations ",
    "authors": [
      "Riccardo Guidotti",
      "Anna Monreale",
      "Stan Matwin",
      "Dino Pedreschi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7116",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7116/6970",
    "published": "2020-02",
    "summary": "We present an approach to explain the decisions of black box image classifiers through synthetic exemplar and counter-exemplar learnt in the latent feature space. Our explanation method exploits the latent representations learned through an adversarial autoencoder for generating a synthetic neighborhood of the image for which an explanation is required. A decision tree is trained on a set of images represented in the latent space, and its decision rules are used to generate exemplar images showing how the original image can be modified to stay within its class. Counterfactual rules are used to generate counter-exemplars showing how the original image can \u201cmorph\u201d into another class. The explanation also comprehends a saliency map highlighting the areas that contribute to its classification, and areas that push it into another class. A wide and deep experimental evaluation proves that the proposed method outperforms existing explainers in terms of fidelity, relevance, coherence, and stability, besides providing the most useful and interpretable explanations."
  },
  "aaai2020_main_reasoningaboutpoliticalbiasincontentmoderation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reasoning about Political Bias in Content Moderation ",
    "authors": [
      "Shan Jiang",
      "Ronald E. Robertson",
      "Christo Wilson"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7117",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7117/6971",
    "published": "2020-02",
    "summary": "Content moderation, the AI-human hybrid process of removing (toxic) content from social media to promote community health, has attracted increasing attention from lawmakers due to allegations of political bias. Hitherto, this allegation has been made based on anecdotes rather than logical reasoning and empirical evidence, which motivates us to audit its validity. In this paper, we first introduce two formal criteria to measure bias (i.e., independence and separation) and their contextual meanings in content moderation, and then use YouTube as a lens to investigate if the political leaning of a video plays a role in the moderation decision for its associated comments. Our results show that when justifiable target variables (e.g., hate speech and extremeness) are controlled with propensity scoring, the likelihood of comment moderation is equal across left- and right-leaning videos."
  },
  "aaai2020_main_designingevaluationrulesthatarerobusttostrategicbehavior": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Designing Evaluation Rules That Are Robust to Strategic Behavior ",
    "authors": [
      "Jon Kleinberg",
      "Manish Raghavan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7118",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7118/6972",
    "published": "2020-02",
    "summary": "Machine learning is often used to produce decision-making rules that classify or evaluate individuals. When these individuals have incentives to be classified a certain way, they may behave strategically to influence their outcomes. We develop a model for how strategic agents can invest effort to change the outcomes they receive, and we give a tight characterization of when such agents can be incentivized to invest specified forms of effort into improving their outcomes as opposed to \u201cgaming\u201d the classifier. We show that whenever any \u201creasonable\u201d mechanism can do so, a simple linear mechanism suffices. This work is based on \u201cHow Do Classifiers Induce Agents To Invest Effort Strategically?\u201d published in Economics and Computation 2019 (Kleinberg and Raghavan 2019)."
  },
  "aaai2020_main_identifiabilityfromacombinationofobservationsandexperiments": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Identifiability from a Combination of Observations and Experiments ",
    "authors": [
      "Sanghack Lee",
      "Juan D. Correa",
      "Elias Bareinboim"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7119",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7119/6973",
    "published": "2020-02",
    "summary": "We study the problem of causal identification from an arbitrary collection of observational and experimental distributions, and substantive knowledge about the phenomenon under investigation, which usually comes in the form of a causal graph. We call this problem g-identifiability, or gID for short. In this paper, we introduce a general strategy to prove non-gID based on thickets and hedgelets, which leads to a necessary and sufficient graphical condition for the corresponding decision problem. We further develop a procedure for systematically computing the target effect, and prove that it is sound and complete for gID instances. In other words, the failure of the algorithm in returning an expression implies that the target effect is not computable from the available distributions. Finally, as a corollary of these results, we show that do-calculus is complete for the task of g-identifiability."
  },
  "aaai2020_main_acommentaryontheunsupervisedlearningofdisentangledrepresentations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Commentary on the Unsupervised Learning of Disentangled Representations ",
    "authors": [
      "Francesco Locatello",
      "Stefan Bauer",
      "Mario Lucic",
      "Gunnar R\u00e4tsch",
      "Sylvain Gelly",
      "Bernhard Sch\u00f6lkopf",
      "Olivier Bachem"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7120",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7120/6974",
    "published": "2020-02",
    "summary": "The goal of the unsupervised learning of disentangled representations is to separate the independent explanatory factors of variation in the data without access to supervision. In this paper, we summarize the results of (Locatello et al. 2019b) and focus on their implications for practitioners. We discuss the theoretical result showing that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases and the practical challenges it entails. Finally, we comment on our experimental findings, highlighting the limitations of state-of-the-art approaches and directions for future research."
  },
  "aaai2020_main_constraintprogrammingforanefficientandflexibleblockmodelingsolver": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Constraint Programming for an Efficient and Flexible Block Modeling Solver ",
    "authors": [
      "Alex Luc\u00eda Mattenet",
      "Ian Davidson",
      "Siegfried Nijssen",
      "Pierre Schaus"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7121",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7121/6975",
    "published": "2020-02",
    "summary": "Constraint Programming (CP) is a powerful paradigm for solving combinatorial problems. In CP, the user creates a model by declaring variables with their domains and expresses the constraints that need to be satisfied in any solution. The solver is then in charge of finding feasible solutions\u2014a value in the domain of each variable that satisfies all the constraints. The discovery of solutions is done by exploring a search tree that is pruned by the constraints in charge of removing impossible values. The CP framework has the advantage of exposing a rich high-level declarative constraint language for modeling, as well as efficient purpose-specific filtering algorithms that can be reused in many problems. In this work, we harness this flexibility and efficiency for the Block Modeling problem. It is a variant of the graph clustering problem that has been used extensively in many domains including social science, spatio-temporal data analysis and even medical imaging. We present a new approach based on constraint programming, allowing discrete optimization of block modeling in a manner that is not only scalable, but also allows the easy incorporation of constraints. We introduce a new constraint filtering algorithm that outperforms earlier approaches. We show its use in the analysis of real datasets."
  },
  "aaai2020_main_thest.petersburgparadoxafreshalgorithmicperspective": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " The St. Petersburg Paradox: A Fresh Algorithmic Perspective ",
    "authors": [
      "Ardavan S. Nobandegani",
      "Thomas R. Shultz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7122",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7122/6976",
    "published": "2020-02",
    "summary": "The St. Petersburg paradox is a centuries-old puzzle concerning a lottery with infinite expected payoff on which people are only willing to pay a small amount to play. Despite many attempts and several proposals, no generally-accepted resolution is yet at hand. In a recent paper, we show that this paradox can be understood in terms of the mind optimally using its limited computational resources (Nobandegani et al. 2019). Specifically, we show that the St. Petersburg paradox can be accounted for by a variant of normative expected-utility valuation which acknowledges cognitive limitations: sample-based expected utility (Nobandegani et al. 2018). SbEU provides a unified, algorithmic explanation of major experimental findings on this paradox. We conclude by discussing the implications of our work for algorithmically understanding human cognition and for developing human-like artificial intelligence."
  },
  "aaai2020_main_energyandpolicyconsiderationsformoderndeeplearningresearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Energy and Policy Considerations for Modern Deep Learning Research ",
    "authors": [
      "Emma Strubell",
      "Ananya Ganesh",
      "Andrew McCallum"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7123",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7123/6977",
    "published": "2020-02",
    "summary": "The field of artificial intelligence has experienced a dramatic methodological shift towards large neural networks trained on plentiful data. This shift has been fueled by recent advances in hardware and techniques enabling remarkable levels of computation, resulting in impressive advances in AI across many applications. However, the massive computation required to obtain these exciting results is costly both financially, due to the price of specialized hardware and electricity or cloud compute time, and to the environment, as a result of non-renewable energy used to fuel modern tensor processing hardware. In a paper published this year at ACL, we brought this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training and tuning neural network models for NLP (Strubell, Ganesh, and McCallum 2019). In this extended abstract, we briefly summarize our findings in NLP, incorporating updated estimates and broader information from recent related publications, and provide actionable recommendations to reduce costs and improve equity in the machine learning and artificial intelligence community."
  },
  "aaai2020_main_abstractionandrefinementingameswithdynamicweightedterrain": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Abstraction and Refinement in Games with Dynamic Weighted Terrain ",
    "authors": [
      "Nathan R. Sturtevant",
      "Devon Sigurdson",
      "Bjorn Taylor",
      "Tim Gibson"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7124",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7124/6978",
    "published": "2020-02",
    "summary": "This abstract looks at one version of the pathfinding problem in games and discusses how it motived our recent work at the AIIDE 2019 conference."
  },
  "aaai2020_main_resultsonasuperstrongexponentialtimehypothesis": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Results on a Super Strong Exponential Time Hypothesis ",
    "authors": [
      "Nikhil Vyas",
      "Ryan Williams"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7125",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7125/6979",
    "published": "2020-02",
    "summary": "All known SAT-solving paradigms (backtracking, local search, and the polynomial method) only yield a 2))k(O(1\u22121/n time algorithm for solving k-SAT in the worst case, where the big-O constant is independent of k. For this reason, it has been hypothesized that k-SAT cannot be solved in worst-case 2)k)/k(f(1\u2212n time, for any unbounded \u0192 : \u2115 \u2192 \u2115. This hypothesis has been called the \u201cSuper-Strong Exponential Time Hypothesis\u201d (Super Strong ETH), modeled after the ETH and the Strong ETH. We prove two results concerning the Super-Strong ETH:"
  },
  "aaai2020_main_rankingandratingrankingsandratings": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Ranking and Rating Rankings and Ratings ",
    "authors": [
      "Jingyan Wang",
      "Nihar B. Shah"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7126",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7126/6980",
    "published": "2020-02",
    "summary": "Cardinal scores collected from people are well known to suffer from miscalibrations. A popular approach to address this issue is to assume simplistic models of miscalibration (such as linear biases) to de-bias the scores. This approach, however, often fares poorly because people's miscalibrations are typically far more complex and not well understood. It is widely believed that in the absence of simplifying assumptions on the miscalibration, the only useful information in practice from the cardinal scores is the induced ranking. In this paper we address the fundamental question of whether this widespread folklore belief is actually true. We consider cardinal scores with arbitrary (or even adversarially chosen) miscalibrations that is only required to be consistent with the induced ranking. We design rating-based estimators and prove that despite making no assumptions on the ratings, they strictly and uniformly outperform all possible estimators that rely on only the ranking. These estimators can be used as a plug-in to show the superiority of cardinal scores over ordinal rankings for a variety of applications, including A/B testing and ranking. This work thus provides novel fundamental insights in the eternal debate between cardinal and ordinal data: It ranks the approach of using ratings higher than that of using rankings, and rates both approaches in terms of their estimation errors."
  },
  "aaai2020_main_multisummtowardsaunifiedmodelformulti-lingualabstractivesummarization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MultiSumm: Towards a Unified Model for Multi-Lingual Abstractive Summarization ",
    "authors": [
      "Yue Cao",
      "Xiaojun Wan",
      "Jinge Yao",
      "Dian Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5328",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5328/5184",
    "published": "2020-02",
    "summary": "Automatic text summarization aims at producing a shorter version of the input text that conveys the most important information. However, multi-lingual text summarization, where the goal is to process texts in multiple languages and output summaries in the corresponding languages with a single model, has been rarely studied. In this paper, we present MultiSumm, a novel multi-lingual model for abstractive summarization. The MultiSumm model uses the following training regime: (I) multi-lingual learning that contains language model training, auto-encoder training, translation and back-translation training, and (II) joint summary generation training. We conduct experiments on summarization datasets for five rich-resource languages: English, Chinese, French, Spanish, and German, as well as two low-resource languages: Bosnian and Croatian. Experimental results show that our proposed model significantly outperforms a multi-lingual baseline model. Specifically, our model achieves comparable or even better performance than models trained separately on each language. As an additional contribution, we construct the first summarization dataset for Bosnian and Croatian, containing 177,406 and 204,748 samples, respectively."
  },
  "aaai2020_main_efficientheterogeneouscollaborativefilteringwithoutnegativesamplingforrecommendation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Efficient Heterogeneous Collaborative Filtering without Negative Sampling for Recommendation ",
    "authors": [
      "Chong Chen",
      "Min Zhang",
      "Yongfeng Zhang",
      "Weizhi Ma",
      "Yiqun Liu",
      "Shaoping Ma"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5329",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5329/5185",
    "published": "2020-02",
    "summary": "Recent studies on recommendation have largely focused on exploring state-of-the-art neural networks to improve the expressiveness of models, while typically apply the Negative Sampling (NS) strategy for efficient learning. Despite effectiveness, two important issues have not been well-considered in existing methods: 1) NS suffers from dramatic fluctuation, making sampling-based methods difficult to achieve the optimal ranking performance in practical applications; 2) although heterogeneous feedback (e.g., view, click, and purchase) is widespread in many online systems, most existing methods leverage only one primary type of user feedback such as purchase. In this work, we propose a novel non-sampling transfer learning solution, named Efficient Heterogeneous Collaborative Filtering (EHCF) for Top-N recommendation. It can not only model fine-grained user-item relations, but also efficiently learn model parameters from the whole heterogeneous data (including all unlabeled data) with a rather low time complexity. Extensive experiments on three real-world datasets show that EHCF significantly outperforms state-of-the-art recommendation methods in both traditional (single-behavior) and heterogeneous scenarios. Moreover, EHCF shows significant improvements in training efficiency, making it more applicable to real-world large-scale systems. Our implementation has been released 1 to facilitate further developments on efficient whole-data based neural methods."
  },
  "aaai2020_main_revisitinggraphbasedcollaborativefilteringalinearresidualgraphconvolutionalnetworkapproach": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Revisiting Graph Based Collaborative Filtering: A Linear Residual Graph Convolutional Network Approach ",
    "authors": [
      "Lei Chen",
      "Le Wu",
      "Richang Hong",
      "Kun Zhang",
      "Meng Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5330",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5330/5186",
    "published": "2020-02",
    "summary": "Graph Convolutional Networks~(GCNs) are state-of-the-art graph based representation learning models by iteratively stacking multiple layers of convolution aggregation operations and non-linear activation operations. Recently, in Collaborative Filtering~(CF) based Recommender Systems~(RS), by treating the user-item interaction behavior as a bipartite graph, some researchers model higher-layer collaborative signals with GCNs. These GCN based recommender models show superior performance compared to traditional works. However, these models suffer from training difficulty with non-linear activations for large user-item graphs. Besides, most GCN based models could not model deeper layers due to the over smoothing effect with the graph convolution operation. In this paper, we revisit GCN based CF models from two aspects. First, we empirically show that removing non-linearities would enhance recommendation performance, which is consistent with the theories in simple graph convolutional networks. Second, we propose a residual network structure that is specifically designed for CF with user-item interaction modeling, which alleviates the over smoothing problem in graph convolution aggregation operation with sparse user-item interaction data. The proposed model is a linear model and it is easy to train, scale to large datasets, and yield better efficiency and effectiveness on two real datasets. We publish the source code at https://github.com/newlei/LR-GCCF."
  },
  "aaai2020_main_question-drivenpurchasingpropensityanalysisforrecommendation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Question-Driven Purchasing Propensity Analysis for Recommendation ",
    "authors": [
      "Long Chen",
      "Ziyu Guan",
      "Qibin Xu",
      "Qiong Zhang",
      "Huan Sun",
      "Guangyue Lu",
      "Deng Cai"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5331",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5331/5187",
    "published": "2020-02",
    "summary": "Merchants of e-commerce Websites expect recommender systems to entice more consumption which is highly correlated with the customers' purchasing propensity. However, most existing recommender systems focus on customers' general preference rather than purchasing propensity often governed by instant demands which we deem to be well conveyed by the questions asked by customers. A typical recommendation scenario is: Bob wants to buy a cell phone which can play the game PUBG. He is interested in HUAWEI P20 and asks \u201ccan PUBG run smoothly on this phone?\u201d under it. Then our system will be triggered to recommend the most eligible cell phones to him. Intuitively, diverse user questions could probably be addressed in reviews written by other users who have similar concerns. To address this recommendation problem, we propose a novel Question-Driven Attentive Neural Network (QDANN) to assess the instant demands of questioners and the eligibility of products based on user generated reviews, and do recommendation accordingly. Without supervision, QDANN can well exploit reviews to achieve this goal. The attention mechanisms can be used to provide explanations for recommendations. We evaluate QDANN in three domains of Taobao. The results show the efficacy of our method and its superiority over baseline methods."
  },
  "aaai2020_main_gradientmethodforcontinuousinfluencemaximizationwithbudget-savingconsiderations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Gradient Method for Continuous Influence Maximization with Budget-Saving Considerations ",
    "authors": [
      "Wei Chen",
      "Weizhong Zhang",
      "Haoyu Zhao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5332",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5332/5188",
    "published": "2020-02",
    "summary": "Continuous influence maximization (CIM) generalizes the original influence maximization by incorporating general marketing strategies: a marketing strategy mix is a vector x = (x1, \u2026, xd) such that for each node v in a social network, v could be activated as a seed of diffusion with probability hv(x), where hv is a strategy activation function satisfying DR-submodularity. CIM is the task of selecting a strategy mix x with constraint \u2211ixi \u2264 k where k is a budget constraint, such that the total number of activated nodes after the diffusion process, called influence spread and denoted as g(x), is maximized. In this paper, we extend CIM to consider budget saving, that is, each strategy mix x has a cost c(x) where c is a convex cost function, and we want to maximize the balanced sum g(x) + \u03bb(k \u2212 c(x)) where \u03bb is a balance parameter, subject to the constraint of c(x) \u2264 k. We denote this problem as CIM-BS. The objective function of CIM-BS is neither monotone, nor DR-submodular or concave, and thus neither the greedy algorithm nor the standard result on gradient method could be directly applied. Our key innovation is the combination of the gradient method with reverse influence sampling to design algorithms that solve CIM-BS: For the general case, we give an algorithm that achieves (\u00bd \u2212 \u03b5)-approximation, and for the case of independent strategy activations, we present an algorithm that achieves (1 \u2212 1/e \u2212 \u03b5) approximation."
  },
  "aaai2020_main_norm-explicitquantizationimprovingvectorquantizationformaximuminnerproductsearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Norm-Explicit Quantization: Improving Vector Quantization for Maximum Inner Product Search ",
    "authors": [
      "Xinyan Dai",
      "Xiao Yan",
      "Kelvin K. W. Ng",
      "Jiu Liu",
      "James Cheng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5333",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5333/5189",
    "published": "2020-02",
    "summary": "Vector quantization (VQ) techniques are widely used in similarity search for data compression, computation acceleration and etc. Originally designed for Euclidean distance, existing VQ techniques (e.g., PQ, AQ) explicitly or implicitly minimize the quantization error. In this paper, we present a new angle to analyze the quantization error, which decomposes the quantization error into norm error and direction error. We show that quantization errors in norm have much higher influence on inner products than quantization errors in direction, and small quantization error does not necessarily lead to good performance in maximum inner product search (MIPS). Based on this observation, we propose norm-explicit quantization (NEQ) \u2014 a general paradigm that improves existing VQ techniques for MIPS. NEQ quantizes the norms of items in a dataset explicitly to reduce errors in norm, which is crucial for MIPS. For the direction vectors, NEQ can simply reuse an existing VQ technique to quantize them without modification. We conducted extensive experiments on a variety of datasets and parameter configurations. The experimental results show that NEQ improves the performance of various VQ techniques for MIPS, including PQ, OPQ, RQ and AQ."
  },
  "aaai2020_main_modelingfluencyandfaithfulnessfordiverseneuralmachinetranslation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Modeling Fluency and Faithfulness for Diverse Neural Machine Translation",
    "authors": [
      "Yang Feng",
      "Wanying Xie",
      "Shuhao Gu",
      "Chenze Shao",
      "Wen Zhang",
      "Zhengxin Yang",
      "Dong Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5334",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5334/5190",
    "published": "2020-02",
    "summary": "Neural machine translation models usually adopt the teacher forcing strategy for training which requires the predicted sequence matches ground truth word by word and forces the probability of each prediction to approach a 0-1 distribution. However, the strategy casts all the portion of the distribution to the ground truth word and ignores other words in the target vocabulary even when the ground truth word cannot dominate the distribution. To address the problem of teacher forcing, we propose a method to introduce an evaluation module to guide the distribution of the prediction. The evaluation module accesses each prediction from the perspectives of fluency and faithfulness to encourage the model to generate the word which has a fluent connection with its past and future translation and meanwhile tends to form a translation equivalent in meaning to the source. The experiments on multiple translation tasks show that our method can achieve significant improvements over strong baselines."
  },
  "aaai2020_main_leveragingtitle-abstractattentivesemanticsforpaperrecommendation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Leveraging Title-Abstract Attentive Semantics for Paper Recommendation ",
    "authors": [
      "Guibing Guo",
      "Bowei Chen",
      "Xiaoyan Zhang",
      "Zhirong Liu",
      "Zhenhua Dong",
      "Xiuqiang He"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5335",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5335/5191",
    "published": "2020-02",
    "summary": "Paper recommendation is a research topic to provide users with personalized papers of interest. However, most existing approaches equally treat title and abstract as the input to learn the representation of a paper, ignoring their semantic relationship. In this paper, we regard the abstract as a sequence of sentences, and propose a two-level attentive neural network to capture: (1) the ability of each word within a sentence to reflect if it is semantically close to the words within the title. (2) the extent of each sentence in the abstract relative to the title, which is often a good summarization of the abstract document. Specifically, we propose a Long-Short Term Memory (LSTM) network with attention to learn the representation of sentences, and integrate a Gated Recurrent Unit (GRU) network with a memory network to learn the long-term sequential sentence patterns of interacted papers for both user and item (paper) modeling. We conduct extensive experiments on two real datasets, and show that our approach outperforms other state-of-the-art approaches in terms of accuracy."
  },
  "aaai2020_main_preservingordinalconsensustowardsfeatureselectionforunlabeleddata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Preserving Ordinal Consensus: Towards Feature Selection for Unlabeled Data ",
    "authors": [
      "Jun Guo",
      "Heng Chang",
      "Wenwu Zhu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5336",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5336/5192",
    "published": "2020-02",
    "summary": "To better pre-process unlabeled data, most existing feature selection methods remove redundant and noisy information by exploring some intrinsic structures embedded in samples. However, these unsupervised studies focus too much on the relations among samples, totally neglecting the feature-level geometric information. This paper proposes an unsupervised triplet-induced graph to explore a new type of potential structure at feature level, and incorporates it into simultaneous feature selection and clustering. In the feature selection part, we design an ordinal consensus preserving term based on a triplet-induced graph. This term enforces the projection vectors to preserve the relative proximity of original features, which contributes to selecting more relevant features. In the clustering part, Self-Paced Learning (SPL) is introduced to gradually learn from \u2018easy\u2019 to \u2018complex\u2019 samples. SPL alleviates the dilemma of falling into the bad local minima incurred by noise and outliers. Specifically, we propose a compelling regularizer for SPL to obtain a robust loss. Finally, an alternating minimization algorithm is developed to efficiently optimize the proposed model. Extensive experiments on different benchmark datasets consistently demonstrate the superiority of our proposed method."
  },
  "aaai2020_main_anattentionalrecurrentneuralnetworkforpersonalizednextlocationrecommendation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Attentional Recurrent Neural Network for Personalized Next Location Recommendation ",
    "authors": [
      "Qing Guo",
      "Zhu Sun",
      "Jie Zhang",
      "Yin-Leng Theng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5337",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5337/5193",
    "published": "2020-02",
    "summary": "Most existing studies on next location recommendation propose to model the sequential regularity of check-in sequences, but suffer from the severe data sparsity issue where most locations have fewer than five following locations. To this end, we propose an Attentional Recurrent Neural Network (ARNN) to jointly model both the sequential regularity and transition regularities of similar locations (neighbors). In particular, we first design a meta-path based random walk over a novel knowledge graph to discover location neighbors based on heterogeneous factors. A recurrent neural network is then adopted to model the sequential regularity by capturing various contexts that govern user mobility. Meanwhile, the transition regularities of the discovered neighbors are integrated via the attention mechanism, which seamlessly cooperates with the sequential regularity as a unified recurrent framework. Experimental results on multiple real-world datasets demonstrate that ARNN outperforms state-of-the-art methods."
  },
  "aaai2020_main_re-attentionforvisualquestionanswering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Re-Attention for Visual Question Answering ",
    "authors": [
      "Wenya Guo",
      "Ying Zhang",
      "Xiaoping Wu",
      "Jufeng Yang",
      "Xiangrui Cai",
      "Xiaojie Yuan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5338",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5338/5194",
    "published": "2020-02",
    "summary": "Visual Question Answering~(VQA) requires a simultaneous understanding of images and questions. Existing methods achieve well performance by focusing on both key objects in images and key words in questions. However, the answer also contains rich information which can help to better describe the image and generate more accurate attention maps. In this paper, to utilize the information in answer, we propose a re-attention framework for the VQA task. We first associate image and question by calculating the similarity of each object-word pairs in the feature space. Then, based on the answer, the learned model re-attends the corresponding visual objects in images and reconstructs the initial attention map to produce consistent results. Benefiting from the re-attention procedure, the question can be better understood, and the satisfactory answer is generated. Extensive experiments on the benchmark dataset demonstrate the proposed method performs favorably against the state-of-the-art approaches."
  },
  "aaai2020_main_semi-supervisedmulti-modallearningwithbalancedspectraldecomposition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Semi-Supervised Multi-Modal Learning with Balanced Spectral Decomposition ",
    "authors": [
      "Peng Hu",
      "Hongyuan Zhu",
      "Xi Peng",
      "Jie Lin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5339",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5339/5195",
    "published": "2020-02",
    "summary": "Cross-modal retrieval aims to retrieve the relevant samples across different modalities, of which the key problem is how to model the correlations among different modalities while narrowing the large heterogeneous gap. In this paper, we propose a Semi-supervised Multimodal Learning Network method (SMLN) which correlates different modalities by capturing the intrinsic structure and discriminative correlation of the multimedia data. To be specific, the labeled and unlabeled data are used to construct a similarity matrix which integrates the cross-modal correlation, discrimination, and intra-modal graph information existing in the multimedia data. What is more important is that we propose a novel optimization approach to optimize our loss within a neural network which involves a spectral decomposition problem derived from a ratio trace criterion. Our optimization enjoys two advantages given below. On the one hand, the proposed approach is not limited to our loss, which could be applied to any case that is a neural network with the ratio trace criterion. On the other hand, the proposed optimization is different from existing ones which alternatively maximize the minor eigenvalues, thus overemphasizing the minor eigenvalues and ignore the dominant ones. In contrast, our method will exactly balance all eigenvalues, thus being more competitive to existing methods. Thanks to our loss and optimization strategy, our method could well preserve the discriminative and instinct information into the common space and embrace the scalability in handling large-scale multimedia data. To verify the effectiveness of the proposed method, extensive experiments are carried out on three widely-used multimodal datasets comparing with 13 state-of-the-art approaches."
  },
  "aaai2020_main_mumodamicro-unitconnectionapproachforhybrid-ordercommunitydetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MuMod: A Micro-Unit Connection Approach for Hybrid-Order Community Detection ",
    "authors": [
      "Ling Huang",
      "Hong-Yang Chao",
      "Quangqiang Xie"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5340",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5340/5196",
    "published": "2020-02",
    "summary": "In the past few years, higher-order community detection has drawn an increasing amount of attention. Compared with the lower-order approaches that rely on the connectivity pattern of individual nodes and edges, the higher-order approaches discover communities by leveraging the higher-order connectivity pattern via constructing a motif-based hypergraph. Despite success in capturing the building blocks of complex networks, recent study has shown that the higher-order approaches unavoidably suffer from the hypergraph fragmentation issue. Although an edge enhancement strategy has been designed previously to address this issue, adding additional edges may corrupt the original lower-order connectivity pattern. To this end, this paper defines a new problem of community detection, namely hybrid-order community detection, which aims to discover communities by simultaneously leveraging the lower-order connectivity pattern and the higherorder connectivity pattern. For addressing this new problem, a new Micro-unit Modularity (MuMod) approach is designed. The basic idea lies in constructing a micro-unit connection network, where both of the lower-order connectivity pattern and the higher-order connectivity pattern are utilized. And then a new micro-unit modularity model is proposed for generating the micro-unit groups, from which the overlapping community structure of the original network can be derived. Extensive experiments are conducted on five real-world networks. Comparison results with twelve existing approaches confirm the effectiveness of the proposed method."
  },
  "aaai2020_main_cross-lingualpre-trainingbasedtransferforzero-shotneuralmachinetranslation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Cross-Lingual Pre-Training Based Transfer for Zero-Shot Neural Machine Translation ",
    "authors": [
      "Baijun Ji",
      "Zhirui Zhang",
      "Xiangyu Duan",
      "Min Zhang",
      "Boxing Chen",
      "Weihua Luo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5341",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5341/5197",
    "published": "2020-02",
    "summary": "Transfer learning between different language pairs has shown its effectiveness for Neural Machine Translation (NMT) in low-resource scenario. However, existing transfer methods involving a common target language are far from success in the extreme scenario of zero-shot translation, due to the language space mismatch problem between transferor (the parent model) and transferee (the child model) on the source side. To address this challenge, we propose an effective transfer learning approach based on cross-lingual pre-training. Our key idea is to make all source languages share the same feature space and thus enable a smooth transition for zero-shot translation. To this end, we introduce one monolingual pre-training method and two bilingual pre-training methods to obtain a universal encoder for different languages. Once the universal encoder is constructed, the parent model built on such encoder is trained with large-scale annotated data and then directly applied in zero-shot translation scenario. Experiments on two public datasets show that our approach significantly outperforms strong pivot-based baseline and various multilingual NMT approaches."
  },
  "aaai2020_main_functionalitydiscoveryandpredictionofphysicalobjects": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Functionality Discovery and Prediction of Physical Objects ",
    "authors": [
      "Lei Ji",
      "Botian Shi",
      "Xianglin Guo",
      "Xilin Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5342",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5342/5198",
    "published": "2020-02",
    "summary": "Functionality is a fundamental attribute of an object which indicates the capability to be used to perform specific actions. It is critical to empower robots the functionality knowledge in discovering appropriate objects for a task e.g. cut cake using knife. Existing research works have focused on understanding object functionality through human-object-interaction from extensively annotated image or video data and are hard to scale up. In this paper, we (1) mine object-functionality knowledge through pattern-based and model-based methods from text, (2) introduce a novel task on physical object-functionality prediction, which consumes an image and an action query to predict whether the object in the image can perform the action, and (3) propose a method to leverage the mined functionality knowledge for the new task. Our experimental results show the effectiveness of our methods."
  },
  "aaai2020_main_truenonlineardynamicsfromincompletenetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " True Nonlinear Dynamics from Incomplete Networks ",
    "authors": [
      "Chunheng Jiang",
      "Jianxi Gao",
      "Malik Magdon-Ismail"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5343",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5343/5199",
    "published": "2020-02",
    "summary": "We study nonlinear dynamics on complex networks. Each vertex i has a state xi which evolves according to a networked dynamics to a steady-state xi*. We develop fundamental tools to learn the true steady-state of a small part of the network, without knowing the full network. A naive approach and the current state-of-the-art is to follow the dynamics of the observed partial network to local equilibrium. This dramatically fails to extract the true steady state. We use a mean-field approach to map the dynamics of the unseen part of the network to a single node, which allows us to recover accurate estimates of steady-state on as few as 5 observed vertices in domains ranging from ecology to social networks to gene regulation. Incomplete networks are the norm in practice, and we offer new ways to think about nonlinear dynamics when only sparse information is available."
  },
  "aaai2020_main_understandingandimprovingproximitygraphbasedmaximuminnerproductsearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Understanding and Improving Proximity Graph Based Maximum Inner Product Search ",
    "authors": [
      "Jie Liu",
      "Xiao Yan",
      "Xinyan Dai",
      "Zhirong Li",
      "James Cheng",
      "Ming-Chang Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5344",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5344/5200",
    "published": "2020-02",
    "summary": "The inner-product navigable small world graph (ip-NSW) represents the state-of-the-art method for approximate maximum inner product search (MIPS) and it can achieve an order of magnitude speedup over the fastest baseline. However, to date it is still unclear where its exceptional performance comes from. In this paper, we show that there is a strong norm bias in the MIPS problem, which means that the large norm items are very likely to become the result of MIPS. Then we explain the good performance of ip-NSW as matching the norm bias of the MIPS problem \u2014 large norm items have big in-degrees in the ip-NSW proximity graph and a walk on the graph spends the majority of computation on these items, thus effectively avoids unnecessary computation on small norm items. Furthermore, we propose the ip-NSW+ algorithm, which improves ip-NSW by introducing an additional angular proximity graph. Search is first conducted on the angular graph to find the angular neighbors of a query and then the MIPS neighbors of these angular neighbors are used to initialize the candidate pool for search on the inner-product proximity graph. Experiment results show that ip-NSW+ consistently and significantly outperforms ip-NSW and provides more robust performance under different data distributions."
  },
  "aaai2020_main_type-awareanchorlinkpredictionacrossheterogeneousnetworksbasedongraphattentionnetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Type-Aware Anchor Link Prediction across Heterogeneous Networks Based on Graph Attention Network ",
    "authors": [
      "Xiaoxue Li",
      "Yanmin Shang",
      "Yanan Cao",
      "Yangxi Li",
      "Jianlong Tan",
      "Yanbing Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5345",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5345/5201",
    "published": "2020-02",
    "summary": "Anchor Link Prediction (ALP) across heterogeneous networks plays a pivotal role in inter-network applications. The difficulty of anchor link prediction in heterogeneous networks lies in how to consider the factors affecting nodes alignment comprehensively. In recent years, predicting anchor links based on network embedding has become the main trend. For heterogeneous networks, previous anchor link prediction methods first integrate various types of nodes associated with a user node to obtain a fusion embedding vector from global perspective, and then predict anchor links based on the similarity between fusion vectors corresponding with different user nodes. However, the fusion vector ignores effects of the local type information on user nodes alignment. To address the challenge, we propose a novel type-aware anchor link prediction across heterogeneous networks (TALP), which models the effect of type information and fusion information on user nodes alignment from local and global perspective simultaneously. TALP can solve the network embedding and type-aware alignment under a unified optimization framework based on a two-layer graph attention architecture. Through extensive experiments on real heterogeneous network datasets, we demonstrate that TALP significantly outperforms the state-of-the-art methods."
  },
  "aaai2020_main_deepmatchtorankmodelforpersonalizedclick-throughrateprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Match to Rank Model for Personalized Click-Through Rate Prediction ",
    "authors": [
      "Ze Lyu",
      "Yu Dong",
      "Chengfu Huo",
      "Weijun Ren"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5346",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5346/5202",
    "published": "2020-02",
    "summary": "Click-through rate (CTR) prediction is a core task in the field of recommender system and many other applications. For CTR prediction model, personalization is the key to improve the performance and enhance the user experience. Recently, several models are proposed to extract user interest from user behavior data which reflects user's personalized preference implicitly. However, existing works in the field of CTR prediction mainly focus on user representation and pay less attention on representing the relevance between user and item, which directly measures the intensity of user's preference on target item. Motivated by this, we propose a novel model named Deep Match to Rank (DMR) which combines the thought of collaborative filtering in matching methods for the ranking task in CTR prediction. In DMR, we design User-to-Item Network and Item-to-Item Network to represent the relevance in two forms. In User-to-Item Network, we represent the relevance between user and item by inner product of the corresponding representation in the embedding space. Meanwhile, an auxiliary match network is presented to supervise the training and push larger inner product to represent higher relevance. In Item-to-Item Network, we first calculate the item-to-item similarities between user interacted items and target item by attention mechanism, and then sum up the similarities to obtain another form of user-to-item relevance. We conduct extensive experiments on both public and industrial datasets to validate the effectiveness of our model, which outperforms the state-of-art models significantly."
  },
  "aaai2020_main_modalitytomodalitytranslationanadversarialrepresentationlearningandgraphfusionnetworkformultimodalfusion": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Modality to Modality Translation: An Adversarial Representation Learning and Graph Fusion Network for Multimodal Fusion ",
    "authors": [
      "Sijie Mai",
      "Haifeng Hu",
      "Songlong Xing"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5347",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5347/5203",
    "published": "2020-02",
    "summary": "Learning joint embedding space for various modalities is of vital importance for multimodal fusion. Mainstream modality fusion approaches fail to achieve this goal, leaving a modality gap which heavily affects cross-modal fusion. In this paper, we propose a novel adversarial encoder-decoder-classifier framework to learn a modality-invariant embedding space. Since the distributions of various modalities vary in nature, to reduce the modality gap, we translate the distributions of source modalities into that of target modality via their respective encoders using adversarial training. Furthermore, we exert additional constraints on embedding space by introducing reconstruction loss and classification loss. Then we fuse the encoded representations using hierarchical graph neural network which explicitly explores unimodal, bimodal and trimodal interactions in multi-stage. Our method achieves state-of-the-art performance on multiple datasets. Visualization of the learned embeddings suggests that the joint embedding space learned by our method is discriminative."
  },
  "aaai2020_main_avariationalpointprocessmodelforsocialeventsequences": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Variational Point Process Model for Social Event Sequences ",
    "authors": [
      "Zhen Pan",
      "Zhenya Huang",
      "Defu Lian",
      "Enhong Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5348",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5348/5204",
    "published": "2020-02",
    "summary": "Many events occur in real-world and social networks. Events are related to the past and there are patterns in the evolution of event sequences. Understanding the patterns can help us better predict the type and arriving time of the next event. In the literature, both feature-based approaches and generative approaches are utilized to model the event sequence. Feature-based approaches extract a variety of features, and train a regression or classification model to make a prediction. Yet, their performance is dependent on the experience-based feature exaction. Generative approaches usually assume the evolution of events follow a stochastic point process (e.g., Poisson process or its complexer variants). However, the true distribution of events is never known and the performance depends on the design of stochastic process in practice. To solve the above challenges, in this paper, we present a novel probabilistic generative model for event sequences. The model is termed Variational Event Point Process (VEPP). Our model introduces variational auto-encoder to event sequence modeling that can better use the latent information and capture the distribution over inter-arrival time and types of event sequences. Experiments on real-world datasets prove effectiveness of our proposed model."
  },
  "aaai2020_main_incrementalfairnessintwo-sidedmarketplatformsonsmoothlyupdatingrecommendations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Incremental Fairness in Two-Sided Market Platforms: On Smoothly Updating Recommendations ",
    "authors": [
      "Gourab K. Patro",
      "Abhijnan Chakraborty",
      "Niloy Ganguly",
      "Krishna Gummadi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5349",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5349/5205",
    "published": "2020-02",
    "summary": "Major online platforms today can be thought of as two-sided markets with producers and customers of goods and services. There have been concerns that over-emphasis on customer satisfaction by the platforms may affect the well-being of the producers. To counter such issues, few recent works have attempted to incorporate fairness for the producers. However, these studies have overlooked an important issue in such platforms -- to supposedly improve customer utility, the underlying algorithms are frequently updated, causing abrupt changes in the exposure of producers. In this work, we focus on the fairness issues arising out of such frequent updates, and argue for incremental updates of the platform algorithms so that the producers have enough time to adjust (both logistically and mentally) to the change. However, naive incremental updates may become unfair to the customers. Thus focusing on recommendations deployed on two-sided platforms, we formulate an ILP based online optimization to deploy changes incrementally in \u03b7 steps, where we can ensure smooth transition of the exposure of items while guaranteeing a minimum utility for every customer. Evaluations over multiple real world datasets show that our proposed mechanism for platform updates can be efficient and fair to both the producers and the customers in two-sided platforms."
  },
  "aaai2020_main_towardscomprehensiverecommendersystemstime-awareunifiedrecommendationsbasedonlistwiserankingofimplicitcross-networkdata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Comprehensive Recommender Systems: Time-Aware Unified Recommendations Based on Listwise Ranking of Implicit Cross-Network Data ",
    "authors": [
      "Dilruk Perera",
      "Roger Zimmermann"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5350",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5350/5206",
    "published": "2020-02",
    "summary": "The abundance of information in web applications make recommendation essential for users as well as applications. Despite the effectiveness of existing recommender systems, we find two major limitations that reduce their overall performance: (1) inability to provide timely recommendations for both new and existing users by considering the dynamic nature of user preferences, and (2) not fully optimized for the ranking task when using implicit feedback. Therefore, we propose a novel deep learning based unified cross-network solution to mitigate cold-start and data sparsity issues and provide timely recommendations for new and existing users. Furthermore, we consider the ranking problem under implicit feedback as a classification task, and propose a generic personalized listwise optimization criterion for implicit data to effectively rank a list of items. We illustrate our cross-network model using Twitter auxiliary information for recommendations on YouTube target network. Extensive comparisons against multiple time aware and cross-network baselines show that the proposed solution is superior in terms of accuracy, novelty and diversity. Furthermore, experiments conducted on the popular MovieLens dataset suggest that the proposed listwise ranking method outperforms existing state-of-the-art ranking techniques."
  },
  "aaai2020_main_minimizingthebag-of-ngramsdifferencefornon-autoregressiveneuralmachinetranslation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural Machine Translation ",
    "authors": [
      "Chenze Shao",
      "Jinchao Zhang",
      "Yang Feng",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5351",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5351/5207",
    "published": "2020-02",
    "summary": "Non-Autoregressive Neural Machine Translation (NAT) achieves significant decoding speedup through generating target words independently and simultaneously. However, in the context of non-autoregressive translation, the word-level cross-entropy loss cannot model the target-side sequential dependency properly, leading to its weak correlation with the translation quality. As a result, NAT tends to generate influent translations with over-translation and under-translation errors. In this paper, we propose to train NAT to minimize the Bag-of-Ngrams (BoN) difference between the model output and the reference sentence. The bag-of-ngrams training objective is differentiable and can be efficiently calculated, which encourages NAT to capture the target-side sequential dependency and correlates well with the translation quality. We validate our approach on three translation tasks and show that our approach largely outperforms the NAT baseline by about 5.0 BLEU scores on WMT14 En\u2194De and about 2.5 BLEU scores on WMT16 En\u2194Ro."
  },
  "aaai2020_main_peiapersonalityandemotionintegratedattentivemodelformusicrecommendationonsocialmediaplatforms": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " PEIA: Personality and Emotion Integrated Attentive Model for Music Recommendation on Social Media Platforms ",
    "authors": [
      "Tiancheng Shen",
      "Jia Jia",
      "Yan Li",
      "Yihui Ma",
      "Yaohua Bu",
      "Hanjie Wang",
      "Bo Chen",
      "Tat-Seng Chua",
      "Wendy Hall"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5352",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5352/5208",
    "published": "2020-02",
    "summary": "With the rapid expansion of digital music formats, it's indispensable to recommend users with their favorite music. For music recommendation, users' personality and emotion greatly affect their music preference, respectively in a long-term and short-term manner, while rich social media data provides effective feedback on these information. In this paper, aiming at music recommendation on social media platforms, we propose a Personality and Emotion Integrated Attentive model (PEIA), which fully utilizes social media data to comprehensively model users' long-term taste (personality) and short-term preference (emotion). Specifically, it takes full advantage of personality-oriented user features, emotion-oriented user features and music features of multi-faceted attributes. Hierarchical attention is employed to distinguish the important factors when incorporating the latent representations of users' personality and emotion. Extensive experiments on a large real-world dataset of 171,254 users demonstrate the effectiveness of our PEIA model which achieves an NDCG of 0.5369, outperforming the state-of-the-art methods. We also perform detailed parameter analysis and feature contribution analysis, which further verify our scheme and demonstrate the significance of co-modeling of user personality and emotion in music recommendation."
  },
  "aaai2020_main_wheretogonextmodelinglong-andshort-termuserpreferencesforpoint-of-interestrecommendation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Where to Go Next: Modeling Long- and Short-Term User Preferences for Point-of-Interest Recommendation ",
    "authors": [
      "Ke Sun",
      "Tieyun Qian",
      "Tong Chen",
      "Yile Liang",
      "Quoc Viet Hung Nguyen",
      "Hongzhi Yin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5353",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5353/5209",
    "published": "2020-02",
    "summary": "Point-of-Interest (POI) recommendation has been a trending research topic as it generates personalized suggestions on facilities for users from a large number of candidate venues. Since users' check-in records can be viewed as a long sequence, methods based on recurrent neural networks (RNNs) have recently shown promising applicability for this task. However, existing RNN-based methods either neglect users' long-term preferences or overlook the geographical relations among recently visited POIs when modeling users' short-term preferences, thus making the recommendation results unreliable. To address the above limitations, we propose a novel method named Long- and Short-Term Preference Modeling (LSTPM) for next-POI recommendation. In particular, the proposed model consists of a nonlocal network for long-term preference modeling and a geo-dilated RNN for short-term preference learning. Extensive experiments on two real-world datasets demonstrate that our model yields significant improvements over the state-of-the-art methods."
  },
  "aaai2020_main_knowledgegraphalignmentnetworkwithgatedmulti-hopneighborhoodaggregation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Knowledge Graph Alignment Network with Gated Multi-Hop Neighborhood Aggregation ",
    "authors": [
      "Zequn Sun",
      "Chengming Wang",
      "Wei Hu",
      "Muhao Chen",
      "Jian Dai",
      "Wei Zhang",
      "Yuzhong Qu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5354",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5354/5210",
    "published": "2020-02",
    "summary": "Graph neural networks (GNNs) have emerged as a powerful paradigm for embedding-based entity alignment due to their capability of identifying isomorphic subgraphs. However, in real knowledge graphs (KGs), the counterpart entities usually have non-isomorphic neighborhood structures, which easily causes GNNs to yield different representations for them. To tackle this problem, we propose a new KG alignment network, namely AliNet, aiming at mitigating the non-isomorphism of neighborhood structures in an end-to-end manner. As the direct neighbors of counterpart entities are usually dissimilar due to the schema heterogeneity, AliNet introduces distant neighbors to expand the overlap between their neighborhood structures. It employs an attention mechanism to highlight helpful distant neighbors and reduce noises. Then, it controls the aggregation of both direct and distant neighborhood information using a gating mechanism. We further propose a relation loss to refine entity representations. We perform thorough experiments with detailed ablation studies and analyses on five entity alignment datasets, demonstrating the effectiveness of AliNet."
  },
  "aaai2020_main_learningwithunsureresponses": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning with Unsure Responses ",
    "authors": [
      "Kunihiro Takeoka",
      "Yuyang Dong",
      "Masafumi Oyamada"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5355",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5355/5211",
    "published": "2020-02",
    "summary": "Many annotation systems provide to add an unsure option in the labels, because the annotators have different expertise, and they may not have enough confidence to choose a label for some assigned instances. However, all the existing approaches only learn the labels with a clear class name and ignore the unsure responses. Due to the unsure response also account for a proportion of the dataset (e.g., about 10-30% in real datasets), existing approaches lead to high costs such as paying more money or taking more time to collect enough size of labeled data. Therefore, it is a significant issue to make use of these unsure."
  },
  "aaai2020_main_authornamedisambiguationonheterogeneousinformationnetworkwithadversarialrepresentationlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Author Name Disambiguation on Heterogeneous Information Network with Adversarial Representation Learning ",
    "authors": [
      "Haiwen Wang",
      "Ruijie Wan",
      "Chuan Wen",
      "Shuhao Li",
      "Yuting Jia",
      "Weinan Zhang",
      "Xinbing Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5356",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5356/5212",
    "published": "2020-02",
    "summary": "Author name ambiguity causes inadequacy and inconvenience in academic information retrieval, which raises the necessity of author name disambiguation (AND). Existing AND methods can be divided into two categories: the models focusing on content information to distinguish whether two papers are written by the same author, the models focusing on relation information to represent information as edges on the network and to quantify the similarity among papers. However, the former requires adequate labeled samples and informative negative samples, and are also ineffective in measuring the high-order connections among papers, while the latter needs complicated feature engineering or supervision to construct the network. We propose a novel generative adversarial framework to grow the two categories of models together: (i) the discriminative module distinguishes whether two papers are from the same author, and (ii) the generative module selects possibly homogeneous papers directly from the heterogeneous information network, which eliminates the complicated feature engineering. In such a way, the discriminative module guides the generative module to select homogeneous papers, and the generative module generates high-quality negative samples to train the discriminative module to make it aware of high-order connections among papers. Furthermore, a self-training strategy for the discriminative module and a random walk based generating algorithm are designed to make the training stable and efficient. Extensive experiments on two real-world AND benchmarks demonstrate that our model provides significant performance improvement over the state-of-the-art methods."
  },
  "aaai2020_main_socialinfluencedoesmatteruseractionpredictionforin-feedadvertising": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Social Influence Does Matter: User Action Prediction for In-Feed Advertising ",
    "authors": [
      "Hongyang Wang",
      "Qingfei Meng",
      "Ju Fan",
      "Yuchen Li",
      "Laizhong Cui",
      "Xiaoman Zhao",
      "Chong Peng",
      "Gong Chen",
      "Xiaoyong Du"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5357",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5357/5213",
    "published": "2020-02",
    "summary": "Social in-feed advertising delivers ads that seamlessly fit inside a user\u2019s feed, and allows users to engage in social actions (likes or comments) with the ads. Many businesses pay higher attention to \u201cengagement marketing\u201d that maximizes social actions, as social actions can effectively promote brand awareness. This paper studies social action prediction for in-feed advertising. Most existing works overlook the social influence as a user\u2019s action may be affected by her friends\u2019 actions. This paper introduces an end-to-end approach that leverages social influence for action prediction, and focuses on addressing the high sparsity challenge for in-feed ads. We propose to learn influence structure that models who tends to be influenced. We extract a subgraph with the near neighbors a user interacts with, and learn topological features of the subgraph by developing structure-aware graph encoding methods. We also introduce graph attention networks to learn influence dynamics that models how a user is influenced by neighbors\u2019 actions. We conduct extensive experiments on real datasets from the commercial advertising platform of WeChat and a public dataset. The experimental results demonstrate that social influence learned by our approach can significantly boost performance of social action prediction."
  },
  "aaai2020_main_asphericalconvolutionapproachforlearninglongtermviewportpredictionin360immersivevideo": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Spherical Convolution Approach for Learning Long Term Viewport Prediction in 360 Immersive Video",
    "authors": [
      "Chenglei Wu",
      "Ruixiao Zhang",
      "Zhi Wang",
      "Lifeng Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7377",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/7377/7241",
    "published": "2020-02",
    "summary": "Viewport prediction for 360 video forecasts a viewer\u2019s viewport when he/she watches a 360 video with a head-mounted display, which benefits many VR/AR applications such as 360 video streaming and mobile cloud VR. Existing studies based on planar convolutional neural network (CNN) suffer from the image distortion and split caused by the sphere-to-plane projection. In this paper, we start by proposing a spherical convolution based feature extraction network to distill spatial-temporal 360 information. We provide a solution for training such a network without a dedicated 360 image or video classification dataset. We differ with previous methods, which base their predictions on image pixel-level information, and propose a semantic content and preference based viewport prediction scheme. In this paper, we adopt a recurrent neural network (RNN) network to extract a user's personal preference of 360 video content from minutes of embedded viewing histories. We utilize this semantic preference as spatial attention to help network find the \"interested'' regions on a future video. We further design a tailored mixture density network (MDN) based viewport prediction scheme, including viewport modeling, tailored loss function, etc, to improve efficiency and accuracy. Our extensive experiments demonstrate the rationality and performance of our method, which outperforms state-of-the-art methods, especially in long-term prediction."
  },
  "aaai2020_main_miningunfollowbehaviorinlarge-scaleonlinesocialnetworksviaspatial-temporalinteraction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Mining Unfollow Behavior in Large-Scale Online Social Networks via Spatial-Temporal Interaction ",
    "authors": [
      "Haozhe Wu",
      "Zhiyuan Hu",
      "Jia Jia",
      "Yaohua Bu",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5358",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5358/5214",
    "published": "2020-02",
    "summary": "Online Social Networks (OSNs) evolve through two pervasive behaviors: follow and unfollow, which respectively signify relationship creation and relationship dissolution. Researches on social network evolution mainly focus on the follow behavior, while the unfollow behavior has largely been ignored. Mining unfollow behavior is challenging because user's decision on unfollow is not only affected by the simple combination of user's attributes like informativeness and reciprocity, but also affected by the complex interaction among them. Meanwhile, prior datasets seldom contain sufficient records for inferring such complex interaction. To address these issues, we first construct a large-scale real-world Weibo1 dataset, which records detailed post content and relationship dynamics of 1.8 million Chinese users. Next, we define user's attributes as two categories: spatial attributes (e.g., social role of user) and temporal attributes (e.g., post content of user). Leveraging the constructed dataset, we systematically study how the interaction effects between user's spatial and temporal attributes contribute to the unfollow behavior. Afterwards, we propose a novel unified model with heterogeneous information (UMHI) for unfollow prediction. Specifically, our UMHI model: 1) captures user's spatial attributes through social network structure; 2) infers user's temporal attributes through user-posted content and unfollow history; and 3) models the interaction between spatial and temporal attributes by the nonlinear MLP layers. Comprehensive evaluations on the constructed dataset demonstrate that the proposed UMHI model outperforms baseline methods by 16.44 on average in terms of precision. In addition, factor analyses verify that both spatial attributes and temporal attributes are essential for mining unfollow behavior."
  },
  "aaai2020_main_wholikeswhat?--splitlbiinexploringpreferentialdiversityofratings": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Who Likes What? -- SplitLBI in Exploring Preferential Diversity of Ratings ",
    "authors": [
      "Qianqian Xu",
      "Jiechao Xiong",
      "Zhiyong Yang",
      "Xiaochun Cao",
      "Qingming Huang",
      "Yuan Yao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5359",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5359/5215",
    "published": "2020-02",
    "summary": "In recent years, learning user preferences has received significant attention. A shortcoming of existing learning to rank work lies in that they do not take into account the multi-level hierarchies from social choice to individuals. In this paper, we propose a multi-level model which learns both the common preference or utility function over the population based on features of alternatives to-be-compared, and preferential diversity functions conditioning on user categories. Such a multi-level model, enables us to simultaneously learn a coarse-grained social preference function together with a fine-grained personalized diversity. It provides us prediction power for the choices of new users on new alternatives. The key algorithm in this paper is based on Split Linearized Bregman Iteration (SplitLBI) algorithm which generates a dynamic path from the common utility to personalized preferential diversity, at different levels of sparsity on personalization. A synchronized parallel version of SplitLBI is proposed to meet the needs of fast analysis of large-scale data. The validity of the methodology are supported by experiments with both simulated and real-world datasets such as movie and dining restaurant ratings which provides us a coarse-to-fine grained preference learning."
  },
  "aaai2020_main_multi-featurediscretecollaborativefilteringforfastcold-startrecommendation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Feature Discrete Collaborative Filtering for Fast Cold-Start Recommendation ",
    "authors": [
      "Yang Xu",
      "Lei Zhu",
      "Zhiyong Cheng",
      "Jingjing Li",
      "Jiande Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5360",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5360/5216",
    "published": "2020-02",
    "summary": "Hashing is an effective technique to address the large-scale recommendation problem, due to its high computation and storage efficiency on calculating the user preferences on items. However, existing hashing-based recommendation methods still suffer from two important problems: 1) Their recommendation process mainly relies on the user-item interactions and single specific content feature. When the interaction history or the content feature is unavailable (the cold-start problem), their performance will be seriously deteriorated. 2) Existing methods learn the hash codes with relaxed optimization or adopt discrete coordinate descent to directly solve binary hash codes, which results in significant quantization loss or consumes considerable computation time. In this paper, we propose a fast cold-start recommendation method, called Multi-Feature Discrete Collaborative Filtering (MFDCF), to solve these problems. Specifically, a low-rank self-weighted multi-feature fusion module is designed to adaptively project the multiple content features into binary yet informative hash codes by fully exploiting their complementarity. Additionally, we develop a fast discrete optimization algorithm to directly compute the binary hash codes with simple operations. Experiments on two public recommendation datasets demonstrate that MFDCF outperforms the state-of-the-arts on various aspects."
  },
  "aaai2020_main_cross-modalattentionnetworkfortemporalinconsistentaudio-visualeventlocalization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Cross-Modal Attention Network for Temporal Inconsistent Audio-Visual Event Localization ",
    "authors": [
      "Hanyu Xuan",
      "Zhenyu Zhang",
      "Shuo Chen",
      "Jian Yang",
      "Yan Yan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5361",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5361/5217",
    "published": "2020-02",
    "summary": "In human multi-modality perception systems, the benefits of integrating auditory and visual information are extensive as they provide plenty supplementary cues for understanding the events. Despite some recent methods proposed for such application, they cannot deal with practical conditions with temporal inconsistency. Inspired by human system which puts different focuses at specific locations, time segments and media while performing multi-modality perception, we provide an attention-based method to simulate such process. Similar to human mechanism, our network can adaptively select \u201cwhere\u201d to attend, \u201cwhen\u201d to attend and \u201cwhich\u201d to attend for audio-visual event localization. In this way, even with large temporal inconsistent between vision and audio, our network is able to adaptively trade information between different modalities and successfully achieve event localization. Our method achieves state-of-the-art performance on AVE (Audio-Visual Event) dataset collected in the real life. In addition, we also systemically investigate audio-visual event localization tasks. The visualization results also help us better understand how our model works."
  },
  "aaai2020_main_learningtomatchongraphforfashioncompatibilitymodeling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Match on Graph for Fashion Compatibility Modeling ",
    "authors": [
      "Xun Yang",
      "Xiaoyu Du",
      "Meng Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5362",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5362/5218",
    "published": "2020-02",
    "summary": "Understanding the mix-and-match relationships between items receives increasing attention in the fashion industry. Existing methods have primarily learned visual compatibility from dyadic co-occurrence or co-purchase information of items to model the item-item matching interaction. Despite effectiveness, rich extra-connectivities between compatible items, e.g., user-item interactions and item-item substitutable relationships, which characterize the structural properties of items, have been largely ignored. This paper presents a graph-based fashion matching framework named Deep Relational Embedding Propagation (DREP), aiming to inject the extra-connectivities between items into the pairwise compatibility modeling. Specifically, we first build a multi-relational item-item-user graph which encodes diverse item-item and user-item relationships. Then we compute structured representations of items by an attentive relational embedding propagation rule that performs messages propagation along edges of the relational graph. This leads to expressive modeling of higher-order connectivity between items and also better representation of fashion items. Finally, we predict pairwise compatibility based on a compatibility metric learning module. Extensive experiments show that DREP can significantly improve the performance of state-of-the-art methods."
  },
  "aaai2020_main_d2d-lstmlstm-basedpathpredictionofcontentdiffusiontreeindevice-to-devicesocialnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " D2D-LSTM: LSTM-Based Path Prediction of Content Diffusion Tree in Device-to-Device Social Networks ",
    "authors": [
      "Heng Zhang",
      "Xiaofei Wang",
      "Jiawen Chen",
      "Chenyang Wang",
      "Jianxin Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5363",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5363/5219",
    "published": "2020-02",
    "summary": "With the proliferation of mobile device users, the Device-to-Device (D2D) communication has ascended to the spotlight in social network for users to share and exchange enormous data. Different from classic online social network (OSN) like Twitter and Facebook, each single data file to be shared in the D2D social network is often very large in data size, e.g., video, image or document. Sometimes, a small number of interesting data files may dominate the network traffic, and lead to heavy network congestion. To reduce the traffic congestion and design effective caching strategy, it is highly desirable to investigate how the data files are propagated in offline D2D social network and derive the diffusion model that fits to the new form of social network. However, existing works mainly concern about link prediction, which cannot predict the overall diffusion path when network topology is unknown. In this article, we propose D2D-LSTM based on Long Short-Term Memory (LSTM), which aims to predict complete content propagation paths in D2D social network. Taking the current user's time, geography and category preference into account, historical features of the previous path can be captured as well. It utilizes prototype users for prediction so as to achieve a better generalization ability. To the best of our knowledge, it is the first attempt to use real world large-scale dataset of mobile social network (MSN) to predict propagation path trees in a top-down order. Experimental results corroborate that the proposed algorithm can achieve superior prediction performance than state-of-the-art approaches. Furthermore, D2D-LSTM can achieve 95% average precision for terminal class and 17% accuracy for tree path hit."
  },
  "aaai2020_main_anend-to-endvisual-audioattentionnetworkforemotionrecognitioninuser-generatedvideos": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An End-to-End Visual-Audio Attention Network for Emotion Recognition in User-Generated Videos ",
    "authors": [
      "Sicheng Zhao",
      "Yunsheng Ma",
      "Yang Gu",
      "Jufeng Yang",
      "Tengfei Xing",
      "Pengfei Xu",
      "Runbo Hu",
      "Hua Chai",
      "Kurt Keutzer"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5364",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5364/5220",
    "published": "2020-02",
    "summary": "Emotion recognition in user-generated videos plays an important role in human-centered computing. Existing methods mainly employ traditional two-stage shallow pipeline, i.e. extracting visual and/or audio features and training classifiers. In this paper, we propose to recognize video emotions in an end-to-end manner based on convolutional neural networks (CNNs). Specifically, we develop a deep Visual-Audio Attention Network (VAANet), a novel architecture that integrates spatial, channel-wise, and temporal attentions into a visual 3D CNN and temporal attentions into an audio 2D CNN. Further, we design a special classification loss, i.e. polarity-consistent cross-entropy loss, based on the polarity-emotion hierarchy constraint to guide the attention generation. Extensive experiments conducted on the challenging VideoEmotion-8 and Ekman-6 datasets demonstrate that the proposed VAANet outperforms the state-of-the-art approaches for video emotion recognition. Our source code is released at: https://github.com/maysonma/VAANet."
  },
  "aaai2020_main_multi-channelreversedictionarymodel": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Channel Reverse Dictionary Model ",
    "authors": [
      "Lei Zheng",
      "Fanchao Qi",
      "Zhiyuan Liu",
      "Yasheng Wang",
      "Qun Liu",
      "Maosong Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5365",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5365/5221",
    "published": "2020-02",
    "summary": "A reverse dictionary takes the description of a target word as input and outputs the target word together with other words that match the description. Existing reverse dictionary methods cannot deal with highly variable input queries and low-frequency target words successfully. Inspired by the description-to-word inference process of humans, we propose the multi-channel reverse dictionary model, which can mitigate the two problems simultaneously. Our model comprises a sentence encoder and multiple predictors. The predictors are expected to identify different characteristics of the target word from the input query. We evaluate our model on English and Chinese datasets including both dictionary definitions and human-written descriptions. Experimental results show that our model achieves the state-of-the-art performance, and even outperforms the most popular commercial reverse dictionary system on the human-written description dataset. We also conduct quantitative analyses and a case study to demonstrate the effectiveness and robustness of our model. All the code and data of this work can be obtained on https://github.com/thunlp/MultiRD."
  },
  "aaai2020_main_table2analysismodelingandrecommendationofcommonanalysispatternsformulti-dimensionaldata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Table2Analysis: Modeling and Recommendation of Common Analysis Patterns for Multi-Dimensional Data ",
    "authors": [
      "Mengyu Zhou",
      "Wang Tao",
      "Ji Pengxin",
      "Han Shi",
      "Zhang Dongmei"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5366",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5366/5222",
    "published": "2020-02",
    "summary": "Given a table of multi-dimensional data, what analyses would human create to extract information from it? From scientific exploration to business intelligence (BI), this is a key problem to solve towards automation of knowledge discovery and decision making. In this paper, we propose Table2Analysis to learn commonly conducted analysis patterns from large amount of (table, analysis) pairs, and recommend analyses for any given table even not seen before. Multi-dimensional data as input challenges existing model architectures and training techniques to fulfill the task. Based on deep Q-learning with heuristic search, Table2Analysis does table to sequence generation, with each sequence encoding an analysis. Table2Analysis has 0.78 recall at top-5 and 0.65 recall at top-1 in our evaluation against a large scale spreadsheet corpus on the PivotTable recommendation task."
  },
  "aaai2020_main_arecurrentmodelforcollectiveentitylinkingwithadaptivefeatures": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Recurrent Model for Collective Entity Linking with Adaptive Features ",
    "authors": [
      "Xiaoling Zhou",
      "Yukai Miao",
      "Wei Wang",
      "Jianbin Qin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5367",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5367/5223",
    "published": "2020-02",
    "summary": "The vast amount of web data enables us to build knowledge bases with unprecedented quality and coverage. Named Entity Disambiguation (NED) is an important task that automatically resolves ambiguous mentions in free text to correct target entries in the knowledge base. Traditional machine learning based methods for NED were outperformed and made obsolete by the state-of-the-art deep learning based models. However, deep learning models are more complex, requiring large amount of training data and lengthy training and parameter tuning time. In this paper, we revisit traditional machine learning techniques and propose a light-weight, tuneable and time-efficient method without using deep learning or deep learning generated features. We propose novel adaptive features that focus on extracting discriminative features to better model similarities between candidate entities and the mention's context. We learn a local ranking model based on traditional and the new adaptive features based on the learning-to-rank framework. While arriving at linking decisions individually via the local model, our method also takes into consideration the correlation between decisions by running multiple recurrent global models, which can be deemed as a learned local search method. Our method attains performances comparable to the state-of-the-art deep learning-based methods on NED benchmark datasets while being significantly faster to train."
  },
  "aaai2020_main_fairytedafairratingpredictorfortedtalkdata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " FairyTED: A Fair Rating Predictor for TED Talk Data ",
    "authors": [
      "Rupam Acharyya",
      "Shouman Das",
      "Ankani Chattoraj",
      "Md. Iftekhar Tanveer"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5368",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5368/5224",
    "published": "2020-02",
    "summary": "With the recent trend of applying machine learning in every aspect of human life, it is important to incorporate fairness into the core of the predictive algorithms. We address the problem of predicting the quality of public speeches while being fair with respect to sensitive attributes of the speakers, e.g. gender and race. We use the TED talks as an input repository of public speeches because it consists of speakers from a diverse community and has a wide outreach. Utilizing the theories of Causal Models, Counterfactual Fairness and state-of-the-art neural language models, we propose a mathematical framework for fair prediction of the public speaking quality. We employ grounded assumptions to construct a causal model capturing how different attributes affect public speaking quality. This causal model contributes in generating counterfactual data to train a fair predictive model. Our framework is general enough to utilize any assumption within the causal model. Experimental results show that while prediction accuracy is comparable to recent work on this dataset, our predictions are counterfactually fair with respect to a novel metric when compared to true data labels. The FairyTED setup not only allows organizers to make informed and diverse selection of speakers from the unobserved counterfactual possibilities but it also ensures that viewers and new users are not influenced by unfair and unbalanced ratings from arbitrary visitors to the ted.com website when deciding to view a talk."
  },
  "aaai2020_main_crisis-diastowardsmultimodaldamageanalysis-deployment,challengesandassessment": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Crisis-DIAS: Towards Multimodal Damage Analysis - Deployment, Challenges and Assessment ",
    "authors": [
      "Mansi Agarwal",
      "Maitree Leekha",
      "Ramit Sawhney",
      "Rajiv Ratn Shah"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5369",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5369/5225",
    "published": "2020-02",
    "summary": "In times of a disaster, the information available on social media can be useful for several humanitarian tasks as disseminating messages on social media is quick and easily accessible. Disaster damage assessment is inherently multi-modal, yet most existing work on damage identification has focused solely on building generic classification models that rely exclusively on text or image analysis of online social media sessions (e.g., posts). Despite their empirical success, these efforts ignore the multi-modal information manifested in social media data. Conventionally, when information from various modalities is presented together, it often exhibits complementary insights about the application domain and facilitates better learning performance. In this work, we present Crisis-DIAS, a multi-modal sequential damage identification, and severity detection system. We aim to support disaster management and aid in planning by analyzing and exploiting the impact of linguistic cues on a unimodal visual system. Through extensive qualitative, quantitative and theoretical analysis on a real-world multi-modal social media dataset, we show that the Crisis-DIAS framework is superior to the state-of-the-art damage assessment models in terms of bias, responsiveness, computational efficiency, and assessment performance."
  },
  "aaai2020_main_unsuperviseddetectionofsub-eventsinlargescaledisasters": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Unsupervised Detection of Sub-Events in Large Scale Disasters ",
    "authors": [
      "Chidubem Arachie",
      "Manas Gaur",
      "Sam Anzaroot",
      "William Groves",
      "Ke Zhang",
      "Alejandro Jaimes"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5370",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5370/5226",
    "published": "2020-02",
    "summary": "Social media plays a major role during and after major natural disasters (e.g., hurricanes, large-scale fires, etc.), as people \u201con the ground\u201d post useful information on what is actually happening. Given the large amounts of posts, a major challenge is identifying the information that is useful and actionable. Emergency responders are largely interested in finding out what events are taking place so they can properly plan and deploy resources. In this paper we address the problem of automatically identifying important sub-events (within a large-scale emergency \u201cevent\u201d, such as a hurricane). In particular, we present a novel, unsupervised learning framework to detect sub-events in Tweets for retrospective crisis analysis. We first extract noun-verb pairs and phrases from raw tweets as sub-event candidates. Then, we learn a semantic embedding of extracted noun-verb pairs and phrases, and rank them against a crisis-specific ontology. We filter out noisy and irrelevant information then cluster the noun-verb pairs and phrases so that the top-ranked ones describe the most important sub-events. Through quantitative experiments on two large crisis data sets (Hurricane Harvey and the 2015 Nepal Earthquake), we demonstrate the effectiveness of our approach over the state-of-the-art. Our qualitative evaluation shows better performance compared to our baseline."
  },
  "aaai2020_main_spatio-temporalattention-basedneuralnetworkforcreditcardfrauddetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Spatio-Temporal Attention-Based Neural Network for Credit Card Fraud Detection ",
    "authors": [
      "Dawei Cheng",
      "Sheng Xiang",
      "Chencheng Shang",
      "Yiyi Zhang",
      "Fangzhou Yang",
      "Liqing Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5371",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5371/5227",
    "published": "2020-02",
    "summary": "Credit card fraud is an important issue and incurs a considerable cost for both cardholders and issuing institutions. Contemporary methods apply machine learning-based approaches to detect fraudulent behavior from transaction records. But manually generating features needs domain knowledge and may lay behind the modus operandi of fraud, which means we need to automatically focus on the most relevant patterns in fraudulent behavior. Therefore, in this work, we propose a spatial-temporal attention-based neural network (STAN) for fraud detection. In particular, transaction records are modeled by attention and 3D convolution mechanisms by integrating the corresponding information, including spatial and temporal behaviors. Attentional weights are jointly learned in an end-to-end manner with 3D convolution and detection networks. Afterward, we conduct extensive experiments on real-word fraud transaction dataset, the result shows that STAN performs better than other state-of-the-art baselines in both AUC and precision-recall curves. Moreover, we conduct empirical studies with domain experts on the proposed method for fraud post-analysis; the result demonstrates the effectiveness of our proposed method in both detecting suspicious transactions and mining fraud patterns."
  },
  "aaai2020_main_trackingdisasterfootprintswithsocialstreamingdata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Tracking Disaster Footprints with Social Streaming Data ",
    "authors": [
      "Lu Cheng",
      "Jundong Li",
      "K. Selcuk Candan",
      "Huan Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5372",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5372/5228",
    "published": "2020-02",
    "summary": "Social media has become an indispensable tool in the face of natural disasters due to its broad appeal and ability to quickly disseminate information. For instance, Twitter is an important source for disaster responders to search for (1) topics that have been identified as being of particular interest over time, i.e., common topics such as \u201cdisaster rescue\u201d; (2) new emerging themes of disaster-related discussions that are fast gathering in social media streams (Saha and Sindhwani 2012), i.e., distinct topics such as \u201cthe latest tsunami destruction\u201d. To understand the status quo and allocate limited resources to most urgent areas, emergency managers need to quickly sift through relevant topics generated over time and investigate their commonness and distinctiveness. A major obstacle to the effective usage of social media, however, is its massive amount of noisy and undesired data. Hence, a naive method, such as set intersection/difference to find common/distinct topics, is often not practical. To address this challenge, this paper studies a new topic tracking problem that seeks to effectively identify the common and distinct topics with social streaming data. The problem is important as it presents a promising new way to efficiently search for accurate information during emergency response. This is achieved by an online Nonnegative Matrix Factorization (NMF) scheme that conducts a faster update of latent factors, and a joint NMF technique that seeks the balance between the reconstruction error of topic identification and the losses induced by discovering common and distinct topics. Extensive experimental results on real-world datasets collected during Hurricane Harvey and Florence reveal the effectiveness of our framework."
  },
  "aaai2020_main_detectingandtrackingcommunalbirdroostsinweatherradardata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Detecting and Tracking Communal Bird Roosts in Weather Radar Data ",
    "authors": [
      "Zezhou Cheng",
      "Saadia Gabriel",
      "Pankaj Bhambhani",
      "Daniel Sheldon",
      "Subhransu Maji",
      "Andrew Laughlin",
      "David Winkler"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5373",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5373/5229",
    "published": "2020-02",
    "summary": "The US weather radar archive holds detailed information about biological phenomena in the atmosphere over the last 20 years. Communally roosting birds congregate in large numbers at nighttime roosting locations, and their morning exodus from the roost is often visible as a distinctive pattern in radar images. This paper describes a machine learning system to detect and track roost signatures in weather radar data. A significant challenge is that labels were collected opportunistically from previous research studies and there are systematic differences in labeling style. We contribute a latent-variable model and EM algorithm to learn a detection model together with models of labeling styles for individual annotators. By properly accounting for these variations we learn a significantly more accurate detector. The resulting system detects previously unknown roosting locations and provides comprehensive spatio-temporal data about roosts across the US. This data will provide biologists important information about the poorly understood phenomena of broad-scale habitat use and movements of communally roosting birds during the non-breeding season."
  },
  "aaai2020_main_hindi-englishhatespeechdetectionauthorprofiling,debiasing,andpracticalperspectives": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Hindi-English Hate Speech Detection: Author Profiling, Debiasing, and Practical Perspectives ",
    "authors": [
      "Shivang Chopra",
      "Ramit Sawhney",
      "Puneet Mathur",
      "Rajiv Ratn Shah"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5374",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5374/5230",
    "published": "2020-02",
    "summary": "Code-switching in linguistically diverse, low resource languages is often semantically complex and lacks sophisticated methodologies that can be applied to real-world data for precisely detecting hate speech. In an attempt to bridge this gap, we introduce a three-tier pipeline that employs profanity modeling, deep graph embeddings, and author profiling to retrieve instances of hate speech in Hindi-English code-switched language (Hinglish) on social media platforms like Twitter. Through extensive comparison against several baselines on two real-world datasets, we demonstrate how targeted hate embeddings combined with social network-based features outperform state of the art, both quantitatively and qualitatively. Additionally, we present an expert-in-the-loop algorithm for bias elimination in the proposed model pipeline and study the prevalence and performance impact of the debiasing. Finally, we discuss the computational, practical, ethical, and reproducibility aspects of the deployment of our pipeline across the Web."
  },
  "aaai2020_main_inferringnighttimesatelliteimageryfromhumanmobility": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Inferring Nighttime Satellite Imagery from Human Mobility ",
    "authors": [
      "Brian Dickinson",
      "Gourab Ghoshal",
      "Xerxes Dotiwalla",
      "Adam Sadilek",
      "Henry Kautz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5375",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5375/5231",
    "published": "2020-02",
    "summary": "Nighttime lights satellite imagery has been used for decades as a uniform, global source of data for studying a wide range of socioeconomic factors. Recently, another more terrestrial source is producing data with similarly uniform global coverage: anonymous and aggregated smart phone location. This data, which measures the movement patterns of people and populations rather than the light they produce, could prove just as valuable in decades to come. In fact, since human mobility is far more directly related to the socioeconomic variables being predicted, it has an even greater potential. Additionally, since cell phone locations can be aggregated in real time while preserving individual user privacy, it will be possible to conduct studies that would previously have been impossible because they require data from the present. Of course, it will take quite some time to establish the new techniques necessary to apply human mobility data to problems traditionally studied with satellite imagery and to conceptualize and develop new real time applications. In this study we demonstrate that it is possible to accelerate this process by inferring artificial nighttime satellite imagery from human mobility data, while maintaining a strong differential privacy guarantee. We also show that these artificial maps can be used to infer socioeconomic variables, often with greater accuracy than using actual satellite imagery. Along the way, we find that the relationship between mobility and light emissions is both nonlinear and varies considerably around the globe. Finally, we show that models based on human mobility can significantly improve our understanding of society at a global scale."
  },
  "aaai2020_main_adistributedmulti-sensormachinelearningapproachtoearthquakeearlywarning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Distributed Multi-Sensor Machine Learning Approach to Earthquake Early Warning ",
    "authors": [
      "Kevin Fauvel",
      "Daniel Balouek-Thomert",
      "Diego Melgar",
      "Pedro Silva",
      "Anthony Simonet",
      "Gabriel Antoniu",
      "Alexandru Costan",
      "V\u00e9ronique Masson",
      "Manish Parashar",
      "Ivan Rodero",
      "Alexandre Termier"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5376",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5376/5232",
    "published": "2020-02",
    "summary": "Our research aims to improve the accuracy of Earthquake Early Warning (EEW) systems by means of machine learning. EEW systems are designed to detect and characterize medium and large earthquakes before their damaging effects reach a certain location. Traditional EEW methods based on seismometers fail to accurately identify large earthquakes due to their sensitivity to the ground motion velocity. The recently introduced high-precision GPS stations, on the other hand, are ineffective to identify medium earthquakes due to its propensity to produce noisy data. In addition, GPS stations and seismometers may be deployed in large numbers across different locations and may produce a significant volume of data consequently, affecting the response time and the robustness of EEW systems."
  },
  "aaai2020_main_fakingfairnessviastealthilybiasedsampling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Faking Fairness via Stealthily Biased Sampling ",
    "authors": [
      "Kazuto Fukuchi",
      "Satoshi Hara",
      "Takanori Maehara"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5377",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5377/5233",
    "published": "2020-02",
    "summary": "Auditing fairness of decision-makers is now in high demand. To respond to this social demand, several fairness auditing tools have been developed. The focus of this study is to raise an awareness of the risk of malicious decision-makers who fake fairness by abusing the auditing tools and thereby deceiving the social communities. The question is whether such a fraud of the decision-maker is detectable so that the society can avoid the risk of fake fairness. In this study, we answer this question negatively. We specifically put our focus on a situation where the decision-maker publishes a benchmark dataset as the evidence of his/her fairness and attempts to deceive a person who uses an auditing tool that computes a fairness metric. To assess the (un)detectability of the fraud, we explicitly construct an algorithm, the stealthily biased sampling, that can deliberately construct an evil benchmark dataset via subsampling. We show that the fraud made by the stealthily based sampling is indeed difficult to detect both theoretically and empirically."
  },
  "aaai2020_main_discriminatingcognitivedisequilibriumandflowinproblemsolvingasemi-supervisedapproachusinginvoluntarydynamicbehavioralsignals": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Discriminating Cognitive Disequilibrium and Flow in Problem Solving: A Semi-Supervised Approach Using Involuntary Dynamic Behavioral Signals ",
    "authors": [
      "Mononito Goswami",
      "Lujie Chen",
      "Artur Dubrawski"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5378",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5378/5234",
    "published": "2020-02",
    "summary": "Problem solving is one of the most important 21st century skills. However, effectively coaching young students in problem solving is challenging because teachers must continuously monitor their cognitive and affective states, and make real-time pedagogical interventions to maximize their learning outcomes. It is an even more challenging task in social environments with limited human coaching resources. To lessen the cognitive load on a teacher and enable affect-sensitive intelligent tutoring, many researchers have investigated automated cognitive and affective detection methods. However, most of the studies use culturally-sensitive indices of affect that are prone to social editing such as facial expressions, and only few studies have explored involuntary dynamic behavioral signals such as gross body movements. In addition, most current methods rely on expensive labelled data from trained annotators for supervised learning. In this paper, we explore a semi-supervised learning framework that can learn low-dimensional representations of involuntary dynamic behavioral signals (mainly gross-body movements) from a modest number of short time series segments. Experiments on a real-world dataset reveal a significant advantage of these representations in discriminating cognitive disequilibrium and flow, as compared to traditional complexity measures from dynamical systems literature, and demonstrate their potential in transferring learned models to previously unseen subjects."
  },
  "aaai2020_main_lightweightandrobustrepresentationofeconomicscalesfromsatelliteimagery": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Lightweight and Robust Representation of Economic Scales from Satellite Imagery ",
    "authors": [
      "Sungwon Han",
      "Donghyun Ahn",
      "Hyunji Cha",
      "Jeasurk Yang",
      "Sungwon Park",
      "Meeyoung Cha"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5379",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5379/5235",
    "published": "2020-02",
    "summary": "Satellite imagery has long been an attractive data source providing a wealth of information regarding human-inhabited areas. While high-resolution satellite images are rapidly becoming available, limited studies have focused on how to extract meaningful information regarding human habitation patterns and economic scales from such data. We present READ, a new approach for obtaining essential spatial representation for any given district from high-resolution satellite imagery based on deep neural networks. Our method combines transfer learning and embedded statistics to efficiently learn the critical spatial characteristics of arbitrary size areas and represent such characteristics in a fixed-length vector with minimal information loss. Even with a small set of labels, READ can distinguish subtle differences between rural and urban areas and infer the degree of urbanization. An extensive evaluation demonstrates that the model outperforms state-of-the-art models in predicting economic scales, such as the population density in South Korea (R2=0.9617), and shows a high use potential in developing countries where district-level economic scales are unknown."
  },
  "aaai2020_main_theunreasonableeffectivenessofinversereinforcementlearninginadvancingcancerresearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " The Unreasonable Effectiveness of Inverse Reinforcement Learning in Advancing Cancer Research ",
    "authors": [
      "John Kalantari",
      "Heidi Nelson",
      "Nicholas Chia"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5380",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5380/5236",
    "published": "2020-02",
    "summary": "The \u201cNo Free Lunch\u201d theorem states that for any algorithm, elevated performance over one class of problems is offset by its performance over another. Stated differently, no algorithm works for everything. Instead, designing effective algorithms often means exploiting prior knowledge of data relationships specific to a given problem. This \u201cunreasonable efficacy\u201d is especially desirable for complex and seemingly intractable problems in the natural sciences. One such area that is rife with the need for better algorithms is cancer biology\u2014a field where relatively few insights are being generated from relatively large amounts of data. In part, this is due to the inability of mere statistics to reflect cancer as a genetic evolutionary process\u2014one that involves cells actively mutating in order to navigate host barriers, outcompete neighboring cells, and expand spatially."
  },
  "aaai2020_main_linguisticfingerprintsofinternetcensorshipthecaseofsinaweibo": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Linguistic Fingerprints of Internet Censorship: The Case of Sina Weibo ",
    "authors": [
      "Kei Yin Ng",
      "Anna Feldman",
      "Jing Peng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5381",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5381/5237",
    "published": "2020-02",
    "summary": "This paper studies how the linguistic components of blogposts collected from Sina Weibo, a Chinese microblogging platform, might affect the blogposts' likelihood of being censored. Our results go along with King et al. (2013)'s Collective Action Potential (CAP) theory, which states that a blogpost's potential of causing riot or assembly in real life is the key determinant of it getting censored. Although there is not a definitive measure of this construct, the linguistic features that we identify as discriminatory go along with the CAP theory. We build a classifier that significantly outperforms non-expert humans in predicting whether a blogpost will be censored. The crowdsourcing results suggest that while humans tend to see censored blogposts as more controversial and more likely to trigger action in real life than the uncensored counterparts, they in general cannot make a better guess than our model when it comes to \u2018reading the mind\u2019 of the censors in deciding whether a blogpost should be censored. We do not claim that censorship is only determined by the linguistic features. There are many other factors contributing to censorship decisions. The focus of the present paper is on the linguistic form of blogposts. Our work suggests that it is possible to use linguistic properties of social media posts to automatically predict if they are going to be censored."
  },
  "aaai2020_main_voiceforthevoicelessactivesamplingtodetectcommentssupportingtherohingyas": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Voice for the Voiceless: Active Sampling to Detect Comments Supporting the Rohingyas ",
    "authors": [
      "Shriphani Palakodety",
      "Ashiqur R. KhudaBukhsh",
      "Jaime G. Carbonell",
      "Shriphani Palakodety",
      "Ashiqur R. KhudaBukhsh",
      "Jaime G. Carbonell"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5382",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5382/5238",
    "published": "2020-02",
    "summary": "The Rohingya refugee crisis is one of the biggest humanitarian crises of modern times with more than 700,000 Rohingyas rendered homeless according to the United Nations High Commissioner for Refugees. While it has received sustained press attention globally, no comprehensive research has been performed on social media pertaining to this large evolving crisis. In this work, we construct a substantial corpus of YouTube video comments (263,482 comments from 113,250 users in 5,153 relevant videos) with an aim to analyze the possible role of AI in helping a marginalized community. Using a novel combination of multiple Active Learning strategies and a novel active sampling strategy based on nearest-neighbors in the comment-embedding space, we construct a classifier that can detect comments defending the Rohingyas among larger numbers of disparaging and neutral ones. We advocate that beyond the burgeoning field of hate speech detection, automatic detection of help speech can lend voice to the voiceless people and make the internet safer for marginalized communities."
  },
  "aaai2020_main_guidedweaksupervisionforactionrecognitionwithscarcedatatoassessskillsofchildrenwithautism": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Guided Weak Supervision for Action Recognition with Scarce Data to Assess Skills of Children with Autism ",
    "authors": [
      "Prashant Pandey",
      "Prathosh AP",
      "Manu Kohli",
      "Josh Pritchard"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5383",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5383/5239",
    "published": "2020-02",
    "summary": "Diagnostic and intervention methodologies for skill assessment of autism typically requires a clinician repetitively initiating several stimuli and recording the child's response. In this paper, we propose to automate the response measurement through video recording of the scene following the use of Deep Neural models for human action recognition from videos. However, supervised learning of neural networks demand large amounts of annotated data that is hard to come by. This issue is addressed by leveraging the \u2018similarities\u2019 between the action categories in publicly available large-scale video action (source) datasets and the dataset of interest. A technique called Guided Weak Supervision is proposed, where every class in the target data is matched to a class in the source data using the principle of posterior likelihood maximization. Subsequently, classifier on the target data is re-trained by augmenting samples from the matched source classes, along with a new loss encouraging inter-class separability. The proposed method is evaluated on two skill assessment autism datasets, SSBD (Sundar Rajagopalan, Dhall, and Goecke 2013) and a real world Autism dataset comprising 37 children of different ages and ethnicity who are diagnosed with autism. Our proposed method is found to improve the performance of the state-of-the-art multi-class human action recognition models in-spite of supervision with scarce data."
  },
  "aaai2020_main_thestanfordacuitytestaprecisevisiontestusingbayesiantechniquesandadiscoveryinhumanvisualresponse": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " The Stanford Acuity Test: A Precise Vision Test Using Bayesian Techniques and a Discovery in Human Visual Response ",
    "authors": [
      "Chris Piech",
      "Ali Malik",
      "Laura M. Scott",
      "Robert T. Chang",
      "Charles Lin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5384",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5384/5240",
    "published": "2020-02",
    "summary": "Chart-based visual acuity measurements are used by billions of people to diagnose and guide treatment of vision impairment. However, the ubiquitous eye exam has no mechanism for reasoning about uncertainty and as such, suffers from a well-documented reproducibility problem. In this paper we make two core contributions. First, we uncover a new parametric probabilistic model of visual acuity response based on detailed measurements of patients with eye disease. Then, we present an adaptive, digital eye exam using modern artificial intelligence techniques which substantially reduces acuity exam error over existing approaches, while also introducing the novel ability to model its own uncertainty and incorporate prior beliefs. Using standard evaluation metrics, we estimate a 74% reduction in prediction error compared to the ubiquitous chart-based eye exam and up to 67% reduction compared to the previous best digital exam. For patients with eye disease, the novel ability to finely measure acuity from home could be a crucial part in early diagnosis. We provide a web implementation of our algorithm for anyone in the world to use. The insights in this paper also provide interesting implications for the field of psychometric Item Response Theory."
  },
  "aaai2020_main_automaticallyneutralizingsubjectivebiasintext": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Automatically Neutralizing Subjective Bias in Text ",
    "authors": [
      "Reid Pryzant",
      "Richard Diehl Martinez",
      "Nathan Dass",
      "Sadao Kurohashi",
      "Dan Jurafsky",
      "Diyi Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5385",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5385/5241",
    "published": "2020-02",
    "summary": "Texts like news, encyclopedias, and some social media strive for objectivity. Yet bias in the form of inappropriate subjectivity \u2014 introducing attitudes via framing, presupposing truth, and casting doubt \u2014 remains ubiquitous. This kind of bias erodes our collective trust and fuels social conflict. To address this issue, we introduce a novel testbed for natural language generation: automatically bringing inappropriately subjective text into a neutral point of view (\u201cneutralizing\u201d biased text). We also offer the first parallel corpus of biased language. The corpus contains 180,000 sentence pairs and originates from Wikipedia edits that removed various framings, presuppositions, and attitudes from biased sentences. Last, we propose two strong encoder-decoder baselines for the task. A straightforward yet opaque concurrent system uses a BERT encoder to identify subjective words as part of the generation process. An interpretable and controllable modular algorithm separates these steps, using (1) a BERT-based classifier to identify problematic words and (2) a novel join embedding through which the classifier can edit the hidden states of the encoder. Large-scale human evaluation across four domains (encyclopedias, news headlines, books, and political speeches) suggests that these algorithms are a first step towards the automatic identification and reduction of bias."
  },
  "aaai2020_main_capturingthestyleoffakenews": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Capturing the Style of Fake News ",
    "authors": [
      "Piotr Przybyla"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5386",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5386/5242",
    "published": "2020-02",
    "summary": "In this study we aim to explore automatic methods that can detect online documents of low credibility, especially fake news, based on the style they are written in. We show that general-purpose text classifiers, despite seemingly good performance when evaluated simplistically, in fact overfit to sources of documents in training data. In order to achieve a truly style-based prediction, we gather a corpus of 103,219 documents from 223 online sources labelled by media experts, devise realistic evaluation scenarios and design two new classifiers: a neural network and a model based on stylometric features. The evaluation shows that the proposed classifiers maintain high accuracy in case of documents on previously unseen topics (e.g. new events) and from previously unseen sources (e.g. emerging news websites). An analysis of the stylometric model indicates it indeed focuses on sensational and affective vocabulary, known to be typical for fake news."
  },
  "aaai2020_main_onidentifyinghashtagsindisastertwitterdata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On Identifying Hashtags in Disaster Twitter Data ",
    "authors": [
      "Jishnu Ray Chowdhury",
      "Cornelia Caragea",
      "Doina Caragea"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5387",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5387/5243",
    "published": "2020-02",
    "summary": "Tweet hashtags have the potential to improve the search for information during disaster events. However, there is a large number of disaster-related tweets that do not have any user-provided hashtags. Moreover, only a small number of tweets that contain actionable hashtags are useful for disaster response. To facilitate progress on automatic identification (or extraction) of disaster hashtags for Twitter data, we construct a unique dataset of disaster-related tweets annotated with hashtags useful for filtering actionable information. Using this dataset, we further investigate Long Short-Term Memory-based models within a Multi-Task Learning framework. The best performing model achieves an F1-score as high as $92.22%$. The dataset, code, and other resources are available on Github.1"
  },
  "aaai2020_main_neuralapproximatedynamicprogrammingforon-demandride-pooling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Neural Approximate Dynamic Programming for On-Demand Ride-Pooling ",
    "authors": [
      "Sanket Shah",
      "Meghna Lowalekar",
      "Pradeep Varakantham"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5388",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5388/5244",
    "published": "2020-02",
    "summary": "On-demand ride-pooling (e.g., UberPool, LyftLine, GrabShare) has recently become popular because of its ability to lower costs for passengers while simultaneously increasing revenue for drivers and aggregation companies (e.g., Uber). Unlike in Taxi on Demand (ToD) services \u2013 where a vehicle is assigned one passenger at a time \u2013 in on-demand ride-pooling, each vehicle must simultaneously serve multiple passengers with heterogeneous origin and destination pairs without violating any quality constraints. To ensure near real-time response, existing solutions to the real-time ride-pooling problem are myopic in that they optimise the objective (e.g., maximise the number of passengers served) for the current time step without considering the effect such an assignment could have on assignments in future time steps. However, considering the future effects of an assignment that also has to consider what combinations of passenger requests can be assigned to vehicles adds a layer of combinatorial complexity to the already challenging problem of considering future effects in the ToD case."
  },
  "aaai2020_main_weaksupervisionforfakenewsdetectionviareinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Weak Supervision for Fake News Detection via Reinforcement Learning ",
    "authors": [
      "Yaqing Wang",
      "Weifeng Yang",
      "Fenglong Ma",
      "Jin Xu",
      "Bin Zhong",
      "Qiang Deng",
      "Jing Gao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5389",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5389/5245",
    "published": "2020-02",
    "summary": "Today social media has become the primary source for news. Via social media platforms, fake news travel at unprecedented speeds, reach global audiences and put users and communities at great risk. Therefore, it is extremely important to detect fake news as early as possible. Recently, deep learning based approaches have shown improved performance in fake news detection. However, the training of such models requires a large amount of labeled data, but manual annotation is time-consuming and expensive. Moreover, due to the dynamic nature of news, annotated samples may become outdated quickly and cannot represent the news articles on newly emerged events. Therefore, how to obtain fresh and high-quality labeled samples is the major challenge in employing deep learning models for fake news detection. In order to tackle this challenge, we propose a reinforced weakly-supervised fake news detection framework, i.e., WeFEND, which can leverage users' reports as weak supervision to enlarge the amount of training data for fake news detection. The proposed framework consists of three main components: the annotator, the reinforced selector and the fake news detector. The annotator can automatically assign weak labels for unlabeled news based on users' reports. The reinforced selector using reinforcement learning techniques chooses high-quality samples from the weakly labeled data and filters out those low-quality ones that may degrade the detector's prediction performance. The fake news detector aims to identify fake news based on the news content. We tested the proposed framework on a large collection of news articles published via WeChat official accounts and associated user reports. Extensive experiments on this dataset show that the proposed WeFEND model achieves the best performance compared with the state-of-the-art methods."
  },
  "aaai2020_main_protectinggeolocationprivacyofphotocollections": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Protecting Geolocation Privacy of Photo Collections ",
    "authors": [
      "Jinghan Yang",
      "Ayan Chakrabarti",
      "Yevgeniy Vorobeychik"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5390",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5390/5246",
    "published": "2020-02",
    "summary": "People increasingly share personal information, including their photos and photo collections, on social media. This information, however, can compromise individual privacy, particularly as social media platforms use it to infer detailed models of user behavior, including tracking their location. We consider the specific issue of location privacy as potentially revealed by posting photo collections, which facilitate accurate geolocation with the help of deep learning methods even in the absence of geotags. One means to limit associated inadvertent geolocation privacy disclosure is by carefully pruning select photos from photo collections before these are posted publicly. We study this problem formally as a combinatorial optimization problem in the context of geolocation prediction facilitated by deep learning. We first demonstrate the complexity both by showing that a natural greedy algorithm can be arbitrarily bad and by proving that the problem is NP-Hard. We then exhibit an important tractable special case, as well as a more general approach based on mixed-integer linear programming. Through extensive experiments on real photo collections, we demonstrate that our approaches are indeed highly effective at preserving geolocation privacy."
  },
  "aaai2020_main_weakly-supervisedfine-grainedeventrecognitiononsocialmediatextsfordisastermanagement": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Weakly-Supervised Fine-Grained Event Recognition on Social Media Texts for Disaster Management ",
    "authors": [
      "Wenlin Yao",
      "Cheng Zhang",
      "Shiva Saravanan",
      "Ruihong Huang",
      "Ali Mostafavi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5391",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5391/5247",
    "published": "2020-02",
    "summary": "People increasingly use social media to report emergencies, seek help or share information during disasters, which makes social networks an important tool for disaster management. To meet these time-critical needs, we present a weakly supervised approach for rapidly building high-quality classifiers that label each individual Twitter message with fine-grained event categories. Most importantly, we propose a novel method to create high-quality labeled data in a timely manner that automatically clusters tweets containing an event keyword and asks a domain expert to disambiguate event word senses and label clusters quickly. In addition, to process extremely noisy and often rather short user-generated messages, we enrich tweet representations using preceding context tweets and reply tweets in building event recognition classifiers. The evaluation on two hurricanes, Harvey and Florence, shows that using only 1-2 person-hours of human supervision, the rapidly trained weakly supervised classifiers outperform supervised classifiers trained using more than ten thousand annotated tweets created in over 50 person-hours."
  },
  "aaai2020_main_interactivelearningwithproactivecognitionenhancementforcrowdworkers": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Interactive Learning with Proactive Cognition Enhancement for Crowd Workers ",
    "authors": [
      "Jing Zhang",
      "Huihui Wang",
      "Shunmei Meng",
      "Victor S. Sheng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5392",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5392/5248",
    "published": "2020-02",
    "summary": "Learning from crowds often performs in an active learning paradigm, aiming to improve learning performance quickly as well as to reduce labeling cost by selecting proper workers to (re)label critical instances. Previous active learning methods for learning from crowds do not have any proactive mechanism to effectively improve the reliability of workers, which prevents to obtain steadily rising learning curves. To help workers improve their reliability while performing tasks, this paper proposes a novel Interactive Learning framework with Proactive Cognitive Enhancement (ILPCE) for crowd workers. The ILPCE framework includes an interactive learning mechanism: When crowd workers perform labeling tasks in active learning, their cognitive ability to the specific domain can be enhanced through learning the exemplars selected by a psychological model-based machine teaching method. A novel probabilistic truth inference model and an interactive labeling scheme are proposed to ensure the effectiveness of the interactive learning mechanism and the performance of learning models can be simultaneously improved through a fast and low-cost way. Experimental results on three real-world learning tasks demonstrate that our ILPCE significantly outperforms five representative state-of-the-art methods."
  },
  "aaai2020_main_rumordetectiononsocialmediawithbi-directionalgraphconvolutionalnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks ",
    "authors": [
      "Tian Bian",
      "Xi Xiao",
      "Tingyang Xu",
      "Peilin Zhao",
      "Wenbing Huang",
      "Yu Rong",
      "Junzhou Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5393",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5393/5249",
    "published": "2020-02",
    "summary": "Social media has been developing rapidly in public due to its nature of spreading new information, which leads to rumors being circulated. Meanwhile, detecting rumors from such massive information in social media is becoming an arduous challenge. Therefore, some deep learning methods are applied to discover rumors through the way they spread, such as Recursive Neural Network (RvNN) and so on. However, these deep learning methods only take into account the patterns of deep propagation but ignore the structures of wide dispersion in rumor detection. Actually, propagation and dispersion are two crucial characteristics of rumors. In this paper, we propose a novel bi-directional graph model, named Bi-Directional Graph Convolutional Networks (Bi-GCN), to explore both characteristics by operating on both top-down and bottom-up propagation of rumors. It leverages a GCN with a top-down directed graph of rumor spreading to learn the patterns of rumor propagation; and a GCN with an opposite directed graph of rumor diffusion to capture the structures of rumor dispersion. Moreover, the information from source post is involved in each layer of GCN to enhance the influences from the roots of rumors. Encouraging empirical results on several benchmarks confirm the superiority of the proposed method over the state-of-the-art approaches."
  },
  "aaai2020_main_doctor2vecdynamicdoctorrepresentationlearningforclinicaltrialrecruitment": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Doctor2Vec: Dynamic Doctor Representation Learning for Clinical Trial Recruitment ",
    "authors": [
      "Siddharth Biswal",
      "Cao Xiao",
      "Lucas M. Glass",
      "Elizabeth Milkovits",
      "Jimeng Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5394",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5394/5250",
    "published": "2020-02",
    "summary": "Massive electronic health records (EHRs) enable the success of learning accurate patient representations to support various predictive health applications. In contrast, doctor representation was not well studied despite that doctors play pivotal roles in healthcare. How to construct the right doctor representations? How to use doctor representation to solve important health analytic problems? In this work, we study the problem on clinical trial recruitment, which is about identifying the right doctors to help conduct the trials based on the trial description and patient EHR data of those doctors. We propose Doctor2Vec which simultaneously learns 1) doctor representations from EHR data and 2) trial representations from the description and categorical information about the trials. In particular, Doctor2Vec utilizes a dynamic memory network where the doctor's experience with patients are stored in the memory bank and the network will dynamically assign weights based on the trial representation via an attention mechanism. Validated on large real-world trials and EHR data including 2,609 trials, 25K doctors and 430K patients, Doctor2Vec demonstrated improved performance over the best baseline by up to 8.7% in PR-AUC. We also demonstrated that the Doctor2Vec embedding can be transferred to benefit data insufficiency settings including trial recruitment in less populated/newly explored country with 13.7% improvement or for rare diseases with 8.1% improvement in PR-AUC."
  },
  "aaai2020_main_truelearnafamilyofbayesianalgorithmstomatchlifelonglearnerstoopeneducationalresources": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " TrueLearn: A Family of Bayesian Algorithms to Match Lifelong Learners to Open Educational Resources ",
    "authors": [
      "Sahan Bulathwela",
      "Maria Perez-Ortiz",
      "Emine Yilmaz",
      "John Shawe-Taylor"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5395",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5395/5251",
    "published": "2020-02",
    "summary": "The recent advances in computer-assisted learning systems and the availability of open educational resources today promise a pathway to providing cost-efficient high-quality education to large masses of learners. One of the most ambitious use cases of computer-assisted learning is to build a lifelong learning recommendation system. Unlike short-term courses, lifelong learning presents unique challenges, requiring sophisticated recommendation models that account for a wide range of factors such as background knowledge of learners or novelty of the material while effectively maintaining knowledge states of masses of learners for significantly longer periods of time (ideally, a lifetime). This work presents the foundations towards building a dynamic, scalable and transparent recommendation system for education, modelling learner's knowledge from implicit data in the form of engagement with open educational resources. We i) use a text ontology based on Wikipedia to automatically extract knowledge components of educational resources and, ii) propose a set of online Bayesian strategies inspired by the well-known areas of item response theory and knowledge tracing. Our proposal, TrueLearn, focuses on recommendations for which the learner has enough background knowledge (so they are able to understand and learn from the material), and the material has enough novelty that would help the learner improve their knowledge about the subject and keep them engaged. We further construct a large open educational video lectures dataset and test the performance of the proposed algorithms, which show clear promise towards building an effective educational recommendation system."
  },
  "aaai2020_main_real-timeroutesearchbylocations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Real-Time Route Search by Locations ",
    "authors": [
      "Lisi Chen",
      "Shuo Shang",
      "Tao Guo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5396",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5396/5252",
    "published": "2020-02",
    "summary": "With the proliferation of GPS-based data (e.g., routes and trajectories), it is of great importance to enable the functionality of real-time route search and recommendations. We define and study a novel Continuous Route-Search-by-Location (C-RSL) problem to enable real-time route search by locations for a large number of users over route data streams. Given a set of C-RSL queries where each query q contains a set of places q.O to visit and a threshold q.\u03b8, we continuously feed each query q with routes that has similarity to q.O no less than q.\u03b8. We also extend our proposal to support top-k C-RSL problem where each query continuously maintains k most similar routes. The C-RSL problem targets a variety of applications, including real-time route planning, ridesharing, and other location-based services that have real-time demand. To enable efficient route matching on a large number of C-RSL queries, we develop novel parallel route matching algorithms with good time complexity. Extensive experiments with real data offer insight into the performance of our algorithms, indicating that our proposal is capable of achieving high efficiency and scalability."
  },
  "aaai2020_main_payyourtripfortrafficcongestiondynamicpricingintraffic-awareroadnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Pay Your Trip for Traffic Congestion: Dynamic Pricing in Traffic-Aware Road Networks ",
    "authors": [
      "Lisi Chen",
      "Shuo Shang",
      "Bin Yao",
      "Jing Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5397",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5397/5253",
    "published": "2020-02",
    "summary": "Pricing is essential in optimizing transportation resource allocation. Congestion pricing is widely used to reduce urban traffic congestion. We propose and investigate a novel Dynamic Pricing Strategy (DPS) to price travelers' trips in intelligent transportation platforms (e.g., DiDi, Lyft, Uber). The trips are charged according to their \u201ccongestion contributions\u201d to global urban traffic systems. The dynamic pricing strategy retrieves a matching between n travelers' trips and the potential travel routes (each trip has k potential routes) to minimize the global traffic congestion. We believe that DPS holds the potential to benefit society and the environment, such as reducing traffic congestion and enabling smarter and greener transportation. The DPS problem is challenging due to its high computation complexity (there exist kn matching possibilities). We develop an efficient and effective approximate matching algorithm based on local search, as well as pruning techniques to further enhance the matching efficiency. The accuracy and efficiency of the dynamic pricing strategy are verified by extensive experiments on real datasets."
  },
  "aaai2020_main_adaptivegreedyversusnon-adaptivegreedyforinfluencemaximization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adaptive Greedy versus Non-Adaptive Greedy for Influence Maximization ",
    "authors": [
      "Wei Chen",
      "Binghui Peng",
      "Grant Schoenebeck",
      "Biaoshuai Tao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5398",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5398/5254",
    "published": "2020-02",
    "summary": "We consider the adaptive influence maximization problem: given a network and a budget k, iteratively select k seeds in the network to maximize the expected number of adopters. In the full-adoption feedback model, after selecting each seed, the seed-picker observes all the resulting adoptions. In the myopic feedback model, the seed-picker only observes whether each neighbor of the chosen seed adopts. Motivated by the extreme success of greedy-based algorithms/heuristics for influence maximization, we propose the concept of greedy adaptivity gap, which compares the performance of the adaptive greedy algorithm to its non-adaptive counterpart. Our first result shows that, for submodular influence maximization, the adaptive greedy algorithm can perform up to a (1-1/e)-fraction worse than the non-adaptive greedy algorithm, and that this ratio is tight. More specifically, on one side we provide examples where the performance of the adaptive greedy algorithm is only a (1-1/e) fraction of the performance of the non-adaptive greedy algorithm in four settings: for both feedback models and both the independent cascade model and the linear threshold model. On the other side, we prove that in any submodular cascade, the adaptive greedy algorithm always outputs a (1-1/e)-approximation to the expected number of adoptions in the optimal non-adaptive seed choice. Our second result shows that, for the general submodular cascade model with full-adoption feedback, the adaptive greedy algorithm can outperform the non-adaptive greedy algorithm by an unbounded factor. Finally, we propose a risk-free variant of the adaptive greedy algorithm that always performs no worse than the non-adaptive greedy algorithm."
  },
  "aaai2020_main_deepvaranend-to-enddeeplearningapproachforgenomicvariantrecognitioninbiomedicalliterature": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DeepVar: An End-to-End Deep Learning Approach for Genomic Variant Recognition in Biomedical Literature ",
    "authors": [
      "Chaoran Cheng",
      "Fei Tan",
      "Zhi Wei"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5399",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5399/5255",
    "published": "2020-02",
    "summary": "We consider the problem of Named Entity Recognition (NER) on biomedical scientific literature, and more specifically the genomic variants recognition in this work. Significant success has been achieved for NER on canonical tasks in recent years where large data sets are generally available. However, it remains a challenging problem on many domain-specific areas, especially the domains where only small gold annotations can be obtained. In addition, genomic variant entities exhibit diverse linguistic heterogeneity, differing much from those that have been characterized in existing canonical NER tasks. The state-of-the-art machine learning approaches heavily rely on arduous feature engineering to characterize those unique patterns. In this work, we present the first successful end-to-end deep learning approach to bridge the gap between generic NER algorithms and low-resource applications through genomic variants recognition. Our proposed model can result in promising performance without any hand-crafted features or post-processing rules. Our extensive experiments and results may shed light on other similar low-resource NER applications."
  },
  "aaai2020_main_learningthegraphicalstructureofelectronichealthrecordswithgraphconvolutionaltransformer": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning the Graphical Structure of Electronic Health Records with Graph Convolutional Transformer ",
    "authors": [
      "Edward Choi",
      "Zhen Xu",
      "Yujia Li",
      "Michael Dusenberry",
      "Gerardo Flores",
      "Emily Xue",
      "Andrew Dai"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5400",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5400/5256",
    "published": "2020-02",
    "summary": "Effective modeling of electronic health records (EHR) is rapidly becoming an important topic in both academia and industry. A recent study showed that using the graphical structure underlying EHR data (e.g. relationship between diagnoses and treatments) improves the performance of prediction tasks such as heart failure prediction. However, EHR data do not always contain complete structure information. Moreover, when it comes to claims data, structure information is completely unavailable to begin with. Under such circumstances, can we still do better than just treating EHR data as a flat-structured bag-of-features? In this paper, we study the possibility of jointly learning the hidden structure of EHR while performing supervised prediction tasks on EHR data. Specifically, we discuss that Transformer is a suitable basis model to learn the hidden EHR structure, and propose Graph Convolutional Transformer, which uses data statistics to guide the structure learning process. The proposed model consistently outperformed previous approaches empirically, on both synthetic data and publicly available EHR data, for various prediction tasks such as graph reconstruction and readmission prediction, indicating that it can serve as an effective general-purpose representation learning algorithm for EHR data."
  },
  "aaai2020_main_conancomplementarypatternaugmentationforrarediseasedetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " CONAN: Complementary Pattern Augmentation for Rare Disease Detection ",
    "authors": [
      "Limeng Cui",
      "Siddharth Biswal",
      "Lucas M. Glass",
      "Greg Lever",
      "Jimeng Sun",
      "Cao Xiao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5401",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5401/5257",
    "published": "2020-02",
    "summary": "Rare diseases affect hundreds of millions of people worldwide but are hard to detect since they have extremely low prevalence rates (varying from 1/1,000 to 1/200,000 patients) and are massively underdiagnosed. How do we reliably detect rare diseases with such low prevalence rates? How to further leverage patients with possibly uncertain diagnosis to improve detection? In this paper, we propose a Complementary pattern Augmentation (CONAN) framework for rare disease detection. CONAN combines ideas from both adversarial training and max-margin classification. It first learns self-attentive and hierarchical embedding for patient pattern characterization. Then, we develop a complementary generative adversarial networks (GAN) model to generate candidate positive and negative samples from the uncertain patients by encouraging a max-margin between classes. In addition, CONAN has a disease detector that serves as the discriminator during the adversarial training for identifying rare diseases. We evaluated CONAN on two disease detection tasks. For low prevalence inflammatory bowel disease (IBD) detection, CONAN achieved .96 precision recall area under the curve (PR-AUC) and 50.1% relative improvement over the best baseline. For rare disease idiopathic pulmonary fibrosis (IPF) detection, CONAN achieves .22 PR-AUC with 41.3% relative improvement over the best baseline."
  },
  "aaai2020_main_differentiallyprivateandfairclassificationviacalibratedfunctionalmechanism": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Differentially Private and Fair Classification via Calibrated Functional Mechanism ",
    "authors": [
      "Jiahao Ding",
      "Xinyue Zhang",
      "Xiaohuan Li",
      "Junyi Wang",
      "Rong Yu",
      "Miao Pan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5402",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5402/5258",
    "published": "2020-02",
    "summary": "Machine learning is increasingly becoming a powerful tool to make decisions in a wide variety of applications, such as medical diagnosis and autonomous driving. Privacy concerns related to the training data and unfair behaviors of some decisions with regard to certain attributes (e.g., sex, race) are becoming more critical. Thus, constructing a fair machine learning model while simultaneously providing privacy protection becomes a challenging problem. In this paper, we focus on the design of classification model with fairness and differential privacy guarantees by jointly combining functional mechanism and decision boundary fairness. In order to enforce \u03f5-differential privacy and fairness, we leverage the functional mechanism to add different amounts of Laplace noise regarding different attributes to the polynomial coefficients of the objective function in consideration of fairness constraint. We further propose an utility-enhancement scheme, called relaxed functional mechanism by adding Gaussian noise instead of Laplace noise, hence achieving (\u03f5, \u03b4)-differential privacy. Based on the relaxed functional mechanism, we can design (\u03f5, \u03b4)-differentially private and fair classification model. Moreover, our theoretical analysis and empirical results demonstrate that our two approaches achieve both fairness and differential privacy while preserving good utility and outperform the state-of-the-art algorithms."
  },
  "aaai2020_main_predictingacoptimalpowerflowscombiningdeeplearningandlagrangiandualmethods": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Predicting AC Optimal Power Flows: Combining Deep Learning and Lagrangian Dual Methods ",
    "authors": [
      "Ferdinando Fioretto",
      "Terrence W.K. Mak",
      "Pascal Van Hentenryck"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5403",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5403/5259",
    "published": "2020-02",
    "summary": "The Optimal Power Flow (OPF) problem is a fundamental building block for the optimization of electrical power systems. It is nonlinear and nonconvex and computes the generator setpoints for power and voltage, given a set of load demands. It is often solved repeatedly under various conditions, either in real-time or in large-scale studies. This need is further exacerbated by the increasing stochasticity of power systems due to renewable energy sources in front and behind the meter. To address these challenges, this paper presents a deep learning approach to the OPF. The learning model exploits the information available in the similar states of the system (which is commonly available in practical applications), as well as a dual Lagrangian method to satisfy the physical and engineering constraints present in the OPF. The proposed model is evaluated on a large collection of realistic medium-sized power systems. The experimental results show that its predictions are highly accurate with average errors as low as 0.2%. Additionally, the proposed approach is shown to improve the accuracy of the widely adopted linear DC approximation by at least two orders of magnitude."
  },
  "aaai2020_main_coreautomaticmoleculeoptimizationusingcopy&refinestrategy": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " CORE: Automatic Molecule Optimization Using Copy & Refine Strategy ",
    "authors": [
      "Tianfan Fu",
      "Cao Xiao",
      "Jimeng Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5404",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5404/5260",
    "published": "2020-02",
    "summary": "Molecule optimization is about generating molecule Y with more desirable properties based on an input molecule X. The state-of-the-art approaches partition the molecules into a large set of substructures S and grow the new molecule structure by iteratively predicting which substructure from S to add. However, since the set of available substructures S is large, such an iterative prediction task is often inaccurate especially for substructures that are infrequent in the training data. To address this challenge, we propose a new generating strategy called \u201cCopy&Refine\u201d (CORE), where at each step the generator first decides whether to copy an existing substructure from input X or to generate a new substructure, then the most promising substructure will be added to the new molecule. Combining together with scaffolding tree generation and adversarial training, CORE can significantly improve several latest molecule optimization methods in various measures including drug likeness (QED), dopamine receptor (DRD2) and penalized LogP. We tested CORE and baselines using the ZINC database and CORE obtained up to 11% and 21% relatively improvement over the baselines on success rate on the complete test set and the subset with infrequent substructures, respectively."
  },
  "aaai2020_main_gan-basedunpairedchinesecharacterimagetranslationviaskeletontransformationandstrokerendering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " GAN-Based Unpaired Chinese Character Image Translation via Skeleton Transformation and Stroke Rendering ",
    "authors": [
      "Yiming Gao",
      "Jiangqin Wu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5405",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5405/5261",
    "published": "2020-02",
    "summary": "The automatic style translation of Chinese characters (CH-Char) is a challenging problem. Different from English or general artistic style transfer, Chinese characters contain a large number of glyphs with the complicated content and characteristic style. Early methods on CH-Char synthesis are inefficient and require manual intervention. Recently some GAN-based methods are proposed for font generation. The supervised GAN-based methods require numerous image pairs, which is difficult for many chirography styles. In addition, unsupervised methods often cause the blurred and incorrect strokes. Therefore, in this work, we propose a three-stage Generative Adversarial Network (GAN) architecture for multi-chirography image translation, which is divided into skeleton extraction, skeleton transformation and stroke rendering with unpaired training data. Specifically, we first propose a fast skeleton extraction method (ENet). Secondly, we utilize the extracted skeleton and the original image to train a GAN model, RNet (a stroke rendering network), to learn how to render the skeleton with stroke details in target style. Finally, the pre-trained model RNet is employed to assist another GAN model, TNet (a skeleton transformation network), to learn to transform the skeleton structure on the unlabeled skeleton set. We demonstrate the validity of our method on two chirography datasets we established."
  },
  "aaai2020_main_predictivestudentmodelingineducationalgameswithmulti-tasklearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Predictive Student Modeling in Educational Games with Multi-Task Learning ",
    "authors": [
      "Michael Geden",
      "Andrew Emerson",
      "Jonathan Rowe",
      "Roger Azevedo",
      "James Lester"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5406",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5406/5262",
    "published": "2020-02",
    "summary": "Modeling student knowledge is critical in adaptive learning environments. Predictive student modeling enables formative assessment of student knowledge and skills, and it drives personalized support to create learning experiences that are both effective and engaging. Traditional approaches to predictive student modeling utilize features extracted from students\u2019 interaction trace data to predict student test performance, aggregating student test performance as a single output label. We reformulate predictive student modeling as a multi-task learning problem, modeling questions from student test data as distinct \u201ctasks.\u201d We demonstrate the effectiveness of this approach by utilizing student data from a series of laboratory-based and classroom-based studies conducted with a game-based learning environment for microbiology education, Crystal Island. Using sequential representations of student gameplay, results show that multi-task stacked LSTMs with residual connections significantly outperform baseline models that do not use the multi-task formulation. Additionally, the accuracy of predictive student models is improved as the number of tasks increases. These findings have significant implications for the design and development of predictive student models in adaptive learning environments."
  },
  "aaai2020_main_enhancingpersonalizedtriprecommendationwithattractiveroutes": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Enhancing Personalized Trip Recommendation with Attractive Routes ",
    "authors": [
      "Jiqing Gu",
      "Chao Song",
      "Wenjun Jiang",
      "Xiaomin Wang",
      "Ming Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5407",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5407/5263",
    "published": "2020-02",
    "summary": "Personalized trip recommendation tries to recommend a sequence of point of interests (POIs) for a user. Most of existing studies search POIs only according to the popularity of POIs themselves. In fact, the routes among the POIs also have attractions to visitors, and some of these routes have high popularity. We term this kind of route as Attractive Route (AR), which brings extra user experience. In this paper, we study the attractive routes to improve personalized trip recommendation. To deal with the challenges of discovery and evaluation of ARs, we propose a personalized Trip Recommender with POIs and Attractive Route (TRAR). It discovers the attractive routes based on the popularity and the Gini coefficient of POIs, then it utilizes a gravity model in a category space to estimate the rating scores and preferences of the attractive routes. Based on that, TRAR recommends a trip with ARs to maximize user experience and leverage the tradeoff between the time cost and the user experience. The experimental results show the superiority of TRAR compared with other state-of-the-art methods."
  },
  "aaai2020_main_graduateemploymentpredictionwithbias": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Graduate Employment Prediction with Bias ",
    "authors": [
      "Teng Guo",
      "Feng Xia",
      "Shihao Zhen",
      "Xiaomei Bai",
      "Dongyu Zhang",
      "Zitao Liu",
      "Jiliang Tang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5408",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5408/5264",
    "published": "2020-02",
    "summary": "The failure of landing a job for college students could cause serious social consequences such as drunkenness and suicide. In addition to academic performance, unconscious biases can become one key obstacle for hunting jobs for graduating students. Thus, it is necessary to understand these unconscious biases so that we can help these students at an early stage with more personalized intervention. In this paper, we develop a framework, i.e., MAYA (Multi-mAjor emploYment stAtus) to predict students' employment status while considering biases. The framework consists of four major components. Firstly, we solve the heterogeneity of student courses by embedding academic performance into a unified space. Then, we apply a generative adversarial network (GAN) to overcome the class imbalance problem. Thirdly, we adopt Long Short-Term Memory (LSTM) with a novel dropout mechanism to comprehensively capture sequential information among semesters. Finally, we design a bias-based regularization to capture the job market biases. We conduct extensive experiments on a large-scale educational dataset and the results demonstrate the effectiveness of our prediction framework."
  },
  "aaai2020_main_multi-scaleanomalydetectiononattributednetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Scale Anomaly Detection on Attributed Networks ",
    "authors": [
      "Leonardo Guti\u00e9rrez-G\u00f3mez",
      "Alexandre Bovet",
      "Jean-Charles Delvenne"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5409",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5409/5265",
    "published": "2020-02",
    "summary": "Many social and economic systems can be represented as attributed networks encoding the relations between entities who are themselves described by different node attributes. Finding anomalies in these systems is crucial for detecting abuses such as credit card frauds, web spams or network intrusions. Intuitively, anomalous nodes are defined as nodes whose attributes differ starkly from the attributes of a certain set of nodes of reference, called the context of the anomaly. While some methods have proposed to spot anomalies locally, globally or within a community context, the problem remain challenging due to the multi-scale composition of real networks and the heterogeneity of node metadata. Here, we propose a principled way to uncover outlier nodes simultaneously with the context with respect to which they are anomalous, at all relevant scales of the network. We characterize anomalous nodes in terms of the concentration retained for each node after smoothing specific signals localized on the vertices of the graph. Besides, we introduce a graph signal processing formulation of the Markov stability framework used in community detection, in order to find the context of anomalies. The performance of our method is assessed on synthetic and real-world attributed networks and shows superior results concerning state of the art algorithms. Finally, we show the scalability of our approach in large networks employing Chebychev polynomial approximations."
  },
  "aaai2020_main_accuratestructured-textspottingforarithmeticalexercisecorrection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Accurate Structured-Text Spotting for Arithmetical Exercise Correction ",
    "authors": [
      "Yiqing Hu",
      "Yan Zheng",
      "Hao Liu",
      "Dequang Jiang",
      "Yinsong Liu",
      "Bo Ren"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5410",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5410/5266",
    "published": "2020-02",
    "summary": "Correcting arithmetical exercise is a labor intensive and time consuming task for primary school teachers all the time. To reduce their burdens, we propose Arithmetical Exercise Checker (AEC), which is the first system that automatically evaluates all arithmetical expressions (AEs) on exercise images. The major challenge is that AE is formed by printed and handwritten texts with particular arithmetical patterns (e.g., multi-line, fraction). Despite being part of AE, handwritten texts usually lead to zigzag boundaries and tangled rows. What's worse, AE may be arithmetical incorrect, which makes the contextual information less valuable for recognition. To tackle these problems, we introduce integrated detection, recognition and evaluation branches by leveraging AE's intrinsic features, namely 1) boundary indistinctive, 2) locally relevant patterns and 3) globally irrelevant symbols. Experimental results demonstrate that AEC yields a 93.72% correction accuracy on 40 kinds of mainstream primary arithmetical exercises. So far, the online service of AEC processes 75, 000 arbitrary exercises on average per day, and already reduced the burden of over 1, 000, 000 users. AEC shows the benefits for implementing an vision-based system as a way to aid teachers in reducing reduplicative tasks."
  },
  "aaai2020_main_pairwiselearningwithdifferentialprivacyguarantees": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Pairwise Learning with Differential Privacy Guarantees ",
    "authors": [
      "Mengdi Huai",
      "Di Wang",
      "Chenglin Miao",
      "Jinhui Xu",
      "Aidong Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5411",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5411/5267",
    "published": "2020-02",
    "summary": "Pairwise learning has received much attention recently as it is more capable of modeling the relative relationship between pairs of samples. Many machine learning tasks can be categorized as pairwise learning, such as AUC maximization and metric learning. Existing techniques for pairwise learning all fail to take into consideration a critical issue in their design, i.e., the protection of sensitive information in the training set. Models learned by such algorithms can implicitly memorize the details of sensitive information, which offers opportunity for malicious parties to infer it from the learned models. To address this challenging issue, in this paper, we propose several differentially private pairwise learning algorithms for both online and offline settings. Specifically, for the online setting, we first introduce a differentially private algorithm (called OnPairStrC) for strongly convex loss functions. Then, we extend this algorithm to general convex loss functions and give another differentially private algorithm (called OnPairC). For the offline setting, we also present two differentially private algorithms (called OffPairStrC and OffPairC) for strongly and general convex loss functions, respectively. These proposed algorithms can not only learn the model effectively from the data but also provide strong privacy protection guarantee for sensitive information in the training set. Extensive experiments on real-world datasets are conducted to evaluate the proposed algorithms and the experimental results support our theoretical analysis."
  },
  "aaai2020_main_casterpredictingdruginteractionswithchemicalsubstructurerepresentation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " CASTER: Predicting Drug Interactions with Chemical Substructure Representation ",
    "authors": [
      "Kexin Huang",
      "Cao Xiao",
      "Trong Hoang",
      "Lucas Glass",
      "Jimeng Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5412",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5412/5268",
    "published": "2020-02",
    "summary": "Adverse drug-drug interactions (DDIs) remain a leading cause of morbidity and mortality. Identifying potential DDIs during the drug design process is critical for patients and society. Although several computational models have been proposed for DDI prediction, there are still limitations: (1) specialized design of drug representation for DDI predictions is lacking; (2) predictions are based on limited labelled data and do not generalize well to unseen drugs or DDIs; and (3) models are characterized by a large number of parameters, thus are hard to interpret. In this work, we develop a ChemicAl SubstrucTurE Representation (CASTER) framework that predicts DDIs given chemical structures of drugs. CASTER aims to mitigate these limitations via (1) a sequential pattern mining module rooted in the DDI mechanism to efficiently characterize functional sub-structures of drugs; (2) an auto-encoding module that leverages both labelled and unlabelled chemical structure data to improve predictive accuracy and generalizability; and (3) a dictionary learning module that explains the prediction via a small set of coefficients which measure the relevance of each input sub-structures to the DDI outcome. We evaluated CASTER on two real-world DDI datasets and showed that it performed better than state-of-the-art baselines and provided interpretable predictions."
  },
  "aaai2020_main_rl-duetonlinemusicaccompanimentgenerationusingdeepreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " RL-Duet: Online Music Accompaniment Generation Using Deep Reinforcement Learning ",
    "authors": [
      "Nan Jiang",
      "Sheng Jin",
      "Zhiyao Duan",
      "Changshui Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5413",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5413/5269",
    "published": "2020-02",
    "summary": "This paper presents a deep reinforcement learning algorithm for online accompaniment generation, with potential for real-time interactive human-machine duet improvisation. Different from offline music generation and harmonization, online music accompaniment requires the algorithm to respond to human input and generate the machine counterpart in a sequential order. We cast this as a reinforcement learning problem, where the generation agent learns a policy to generate a musical note (action) based on previously generated context (state). The key of this algorithm is the well-functioning reward model. Instead of defining it using music composition rules, we learn this model from monophonic and polyphonic training data. This model considers the compatibility of the machine-generated note with both the machine-generated context and the human-generated context. Experiments show that this algorithm is able to respond to the human part and generate a melodic, harmonic and diverse machine part. Subjective evaluations on preferences show that the proposed algorithm generates music pieces of higher quality than the baseline method."
  },
  "aaai2020_main_agraphauto-encoderforhaplotypeassemblyandviralquasispeciesreconstruction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Graph Auto-Encoder for Haplotype Assembly and Viral Quasispecies Reconstruction ",
    "authors": [
      "Ziqi Ke",
      "Haris Vikalo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5414",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5414/5270",
    "published": "2020-02",
    "summary": "Reconstructing components of a genomic mixture from data obtained by means of DNA sequencing is a challenging problem encountered in a variety of applications including single individual haplotyping and studies of viral communities. High-throughput DNA sequencing platforms oversample mixture components to provide massive amounts of reads whose relative positions can be determined by mapping the reads to a known reference genome; assembly of the components, however, requires discovery of the reads' origin \u2013 an NP-hard problem that the existing methods struggle to solve with the required level of accuracy. In this paper, we present a learning framework based on a graph auto-encoder designed to exploit structural properties of sequencing data. The algorithm is a neural network which essentially trains to ignore sequencing errors and infers the posterior probabilities of the origin of sequencing reads. Mixture components are then reconstructed by finding consensus of the reads determined to originate from the same genomic component. Results on realistic synthetic as well as experimental data demonstrate that the proposed framework reliably assembles haplotypes and reconstructs viral communities, often significantly outperforming state-of-the-art techniques. Source codes, datasets and supplementary document are available at https://github.com/WuLoli/GAEseq."
  },
  "aaai2020_main_generatingrealisticstockmarketorderstreams": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generating Realistic Stock Market Order Streams ",
    "authors": [
      "Junyi Li",
      "Xintong Wang",
      "Yaoyang Lin",
      "Arunesh Sinha",
      "Michael Wellman"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5415",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5415/5271",
    "published": "2020-02",
    "summary": "We propose an approach to generate realistic and high-fidelity stock market data based on generative adversarial networks (GANs). Our Stock-GAN model employs a conditional Wasserstein GAN to capture history dependence of orders. The generator design includes specially crafted aspects including components that approximate the market's auction mechanism, augmenting the order history with order-book constructions to improve the generation task. We perform an ablation study to verify the usefulness of aspects of our network structure. We provide a mathematical characterization of distribution learned by the generator. We also propose statistics to measure the quality of generated orders. We test our approach with synthetic and actual market data, compare to many baseline generative models, and find the generated data to be close to real data."
  },
  "aaai2020_main_synsig2veclearningrepresentationsfromsyntheticdynamicsignaturesforreal-worldverification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " SynSig2Vec: Learning Representations from Synthetic Dynamic Signatures for Real-World Verification ",
    "authors": [
      "Songxuan Lai",
      "Lianwen Jin",
      "Luojun Lin",
      "Yecheng Zhu",
      "Huiyun Mao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5416",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5416/5272",
    "published": "2020-02",
    "summary": "An open research problem in automatic signature verification is the skilled forgery attacks. However, the skilled forgeries are very difficult to acquire for representation learning. To tackle this issue, this paper proposes to learn dynamic signature representations through ranking synthesized signatures. First, a neuromotor inspired signature synthesis method is proposed to synthesize signatures with different distortion levels for any template signature. Then, given the templates, we construct a lightweight one-dimensional convolutional network to learn to rank the synthesized samples, and directly optimize the average precision of the ranking to exploit relative and fine-grained signature similarities. Finally, after training, fixed-length representations can be extracted from dynamic signatures of variable lengths for verification. One highlight of our method is that it requires neither skilled nor random forgeries for training, yet it surpasses the state-of-the-art by a large margin on two public benchmarks."
  },
  "aaai2020_main_deepalertsdeeplearningbasedmulti-horizonalertsforclinicaldeteriorationononcologyhospitalwards": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DeepAlerts: Deep Learning Based Multi-Horizon Alerts for Clinical Deterioration on Oncology Hospital Wards ",
    "authors": [
      "Dingwen Li",
      "Patrick G. Lyons",
      "Chenyang Lu",
      "Marin Kollef"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5417",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5417/5273",
    "published": "2020-02",
    "summary": "Machine learning and data mining techniques are increasingly being applied to electronic health record (EHR) data to discover underlying patterns and make predictions for clinical use. For instance, these data may be evaluated to predict clinical deterioration events such as cardiopulmonary arrest or escalation of care to the intensive care unit (ICU). In clinical practice, early warning systems with multiple time horizons could indicate different levels of urgency, allowing clinicians to make decisions regarding triage, testing, and interventions for patients at risk of poor outcomes. These different horizon alerts are related and have intrinsic dependencies, which elicit multi-task learning. In this paper, we investigate approaches to properly train deep multi-task models for predicting clinical deterioration events via generating multi-horizon alerts for hospitalized patients outside the ICU, with particular application to oncology patients. Prior knowledge is used as a regularization to exploit the positive effects from the task relatedness. Simultaneously, we propose task-specific loss balancing to reduce the negative effects when optimizing the joint loss function of deep multi-task models. In addition, we demonstrate the effectiveness of the feature-generating techniques from prediction outcome interpretation. To evaluate the model performance of predicting multi-horizon deterioration alerts in a real world scenario, we apply our approaches to the EHR data from 20,700 hospitalizations of adult oncology patients. These patients' baseline high-risk status provides a unique opportunity: the application of an accurate model to an enriched population could produce improved positive predictive value and reduce false positive alerts. With our dataset, the model applying all proposed learning techniques achieves the best performance compared with common models previously developed for clinical deterioration warning."
  },
  "aaai2020_main_regionfocusnetworkforjointopticdiscandcupsegmentation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Region Focus Network for Joint Optic Disc and Cup Segmentation ",
    "authors": [
      "Ge Li",
      "Changsheng Li",
      "Chan Zeng",
      "Peng Gao",
      "Guotong Xie"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5418",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5418/5274",
    "published": "2020-02",
    "summary": "Glaucoma is one of the three leading causes of blindness in the world and is predicted to affect around 80 million people by 2020. The optic cup (OC) to optic disc (OD) ratio (CDR) in fundus images plays a pivotal role in the screening and diagnosis of glaucoma. Existing methods usually crop the optic disc region first, and subsequently perform segmentation in this region. However, these approaches come up with high complexities due to the separate operations. To remedy this issue, we propose a Region Focus Network (RF-Net) that innovatively integrates detection and multi-class segmentation into a unified architecture for end-to-end joint optic disc and cup segmentation with global optimization. The key idea of our method is designing a novel multi-class mask branch which generates a high-quality segmentation in the detected region for both disc and cup. To bridge the connection between the backbone and multi-class mask branch, a Fusion Feature Pooling (FFP) structure is presented to extract features from each level of the pyramid network and fuse them into a final feature representation for segmentation. Extensive experimental results on the REFUGE-2018 challenge dataset and the Drishti-GS dataset show that the proposed method achieves the best performance, compared with competitive approaches reported in the literature and the official leaderboard. Our code will be released soon."
  },
  "aaai2020_main_pose-assistedmulti-cameracollaborationforactiveobjecttracking": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Pose-Assisted Multi-Camera Collaboration for Active Object Tracking ",
    "authors": [
      "Jing Li",
      "Jing Xu",
      "Fangwei Zhong",
      "Xiangyu Kong",
      "Yu Qiao",
      "Yizhou Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5419",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5419/5275",
    "published": "2020-02",
    "summary": "Active Object Tracking (AOT) is crucial to many vision-based applications, e.g., mobile robot, intelligent surveillance. However, there are a number of challenges when deploying active tracking in complex scenarios, e.g., target is frequently occluded by obstacles. In this paper, we extend the single-camera AOT to a multi-camera setting, where cameras tracking a target in a collaborative fashion. To achieve effective collaboration among cameras, we propose a novel Pose-Assisted Multi-Camera Collaboration System, which enables a camera to cooperate with the others by sharing camera poses for active object tracking. In the system, each camera is equipped with two controllers and a switcher: The vision-based controller tracks targets based on observed images. The pose-based controller moves the camera in accordance to the poses of the other cameras. At each step, the switcher decides which action to take from the two controllers according to the visibility of the target. The experimental results demonstrate that our system outperforms all the baselines and is capable of generalizing to unseen environments. The code and demo videos are available on our website https://sites.google.com/view/pose-assisted-collaboration."
  },
  "aaai2020_main_robustlow-rankdiscoveryofdata-drivenpartialdifferentialequations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Robust Low-Rank Discovery of Data-Driven Partial Differential Equations ",
    "authors": [
      "Jun Li",
      "Gan Sun",
      "Guoshuai Zhao",
      "Li-wei H. Lehman"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5420",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5420/5276",
    "published": "2020-02",
    "summary": "Partial differential equations (PDEs) are essential foundations to model dynamic processes in natural sciences. Discovering the underlying PDEs of complex data collected from real world is key to understanding the dynamic processes of natural laws or behaviors. However, both the collected data and their partial derivatives are often corrupted by noise, especially from sparse outlying entries, due to measurement/process noise in the real-world applications. Our work is motivated by the observation that the underlying data modeled by PDEs are in fact often low rank. We thus develop a robust low-rank discovery framework to recover both the low-rank data and the sparse outlying entries by integrating double low-rank and sparse recoveries with a (group) sparse regression method, which is implemented as a minimization problem using mixed nuclear norms with \u21131 and \u21130 norms. We propose a low-rank sequential (grouped) threshold ridge regression algorithm to solve the minimization problem. Results from several experiments on seven canonical models (i.e., four PDEs and three parametric PDEs) verify that our framework outperforms the state-of-art sparse and group sparse regression methods. Code is available at https://github.com/junli2019/Robust-Discovery-of-PDEs"
  },
  "aaai2020_main_towardscross-modalitymedicalimagesegmentationwithonlinemutualknowledgedistillation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Cross-Modality Medical Image Segmentation with Online Mutual Knowledge Distillation ",
    "authors": [
      "Kang Li",
      "Lequan Yu",
      "Shujun Wang",
      "Pheng-Ann Heng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5421",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5421/5277",
    "published": "2020-02",
    "summary": "The success of deep convolutional neural networks is partially attributed to the massive amount of annotated training data. However, in practice, medical data annotations are usually expensive and time-consuming to be obtained. Considering multi-modality data with the same anatomic structures are widely available in clinic routine, in this paper, we aim to exploit the prior knowledge (e.g., shape priors) learned from one modality (aka., assistant modality) to improve the segmentation performance on another modality (aka., target modality) to make up annotation scarcity. To alleviate the learning difficulties caused by modality-specific appearance discrepancy, we first present an Image Alignment Module (IAM) to narrow the appearance gap between assistant and target modality data. We then propose a novel Mutual Knowledge Distillation (MKD) scheme to thoroughly exploit the modality-shared knowledge to facilitate the target-modality segmentation. To be specific, we formulate our framework as an integration of two individual segmentors. Each segmentor not only explicitly extracts one modality knowledge from corresponding annotations, but also implicitly explores another modality knowledge from its counterpart in mutual-guided manner. The ensemble of two segmentors would further integrate the knowledge from both modalities and generate reliable segmentation results on target modality. Experimental results on the public multi-class cardiac segmentation data, i.e., MM-WHS 2017, show that our method achieves large improvements on CT segmentation by utilizing additional MRI data and outperforms other state-of-the-art multi-modality learning methods."
  },
  "aaai2020_main_privacy-preservinggradientboostingdecisiontrees": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Privacy-Preserving Gradient Boosting Decision Trees ",
    "authors": [
      "Qinbin Li",
      "Zhaomin Wu",
      "Zeyi Wen",
      "Bingsheng He"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5422",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5422/5278",
    "published": "2020-02",
    "summary": "The Gradient Boosting Decision Tree (GBDT) is a popular machine learning model for various tasks in recent years. In this paper, we study how to improve model accuracy of GBDT while preserving the strong guarantee of differential privacy. Sensitivity and privacy budget are two key design aspects for the effectiveness of differential private models. Existing solutions for GBDT with differential privacy suffer from the significant accuracy loss due to too loose sensitivity bounds and ineffective privacy budget allocations (especially across different trees in the GBDT model). Loose sensitivity bounds lead to more noise to obtain a fixed privacy level. Ineffective privacy budget allocations worsen the accuracy loss especially when the number of trees is large. Therefore, we propose a new GBDT training algorithm that achieves tighter sensitivity bounds and more effective noise allocations. Specifically, by investigating the property of gradient and the contribution of each tree in GBDTs, we propose to adaptively control the gradients of training data for each iteration and leaf node clipping in order to tighten the sensitivity bounds. Furthermore, we design a novel boosting framework to allocate the privacy budget between trees so that the accuracy loss can be further reduced. Our experiments show that our approach can achieve much better model accuracy than other baselines."
  },
  "aaai2020_main_mrireconstructionwithinterpretablepixel-wiseoperationsusingreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MRI Reconstruction with Interpretable Pixel-Wise Operations Using Reinforcement Learning ",
    "authors": [
      "Wentian Li",
      "Xidong Feng",
      "Haotian An",
      "Xiang Yao Ng",
      "Yu-Jin Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5423",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5423/5279",
    "published": "2020-02",
    "summary": "Compressed sensing magnetic resonance imaging (CS-MRI) is a technique aimed at accelerating the data acquisition of MRI. While down-sampling in k-space proportionally reduces the data acquisition time, it results in images corrupted by aliasing artifacts and blur. To reconstruct images from the down-sampled k-space, recent deep-learning based methods have shown better performance compared with classical optimization-based CS-MRI methods. However, they usually use deep neural networks as a black-box, which directly maps the corrupted images to the target images from fully-sampled k-space data. This lack of transparency may impede practical usage of such methods. In this work, we propose a deep reinforcement learning based method to reconstruct the corrupted images with meaningful pixel-wise operations (e.g. edge enhancing filters), so that the reconstruction process is transparent to users. Specifically, MRI reconstruction is formulated as Markov Decision Process with discrete actions and continuous action parameters. We conduct experiments on MICCAI dataset of brain tissues and fastMRI dataset of knee images. Our proposed method performs favorably against previous approaches. Our trained model learns to select pixel-wise operations that correspond to the anatomical structures in the MR images. This makes the reconstruction process more interpretable, which would be helpful for further medical analysis."
  },
  "aaai2020_main_psenetpsoriasisseverityevaluationnetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " PSENet: Psoriasis Severity Evaluation Network ",
    "authors": [
      "Yi Li",
      "Zhe Wu",
      "Shuang Zhao",
      "Xian Wu",
      "Yehong Kuang",
      "Yangtian Yan",
      "Shen Ge",
      "Kai Wang",
      "Wei Fan",
      "Xiang Chen",
      "Yong Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5424",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5424/5280",
    "published": "2020-02",
    "summary": "Psoriasis is a chronic skin disease which affects hundreds of millions of people around the world. This disease cannot be fully cured and requires lifelong caring. If the deterioration of Psoriasis is not detected and properly treated in time, it could cause serious complications or even lead to a life threat. Therefore, a quantitative measurement that can track the Psoriasis severity is necessary. Currently, PASI (Psoriasis Area and Severity Index) is the most frequently used measurement in clinical practices. However, PASI has the following disadvantages: (1) Time consuming: calculating PASI usually takes more than 30 minutes which poses a heavy burden on dermatologists; and (2) Inconsistency: due to the complexity of PASI calculation, different or even the same dermatologist could give different scores for the same case. To overcome these drawbacks, we propose PSENet which applies deep neural networks to estimate Psoriasis severity based on skin lesion images. Different from typical deep learning frameworks for image processing, PSENet has the following characteristics: (1) PSENet introduces a score refine module which is able to capture the visual features of skin at both coarse and fine-grained granularities; (2) PSENet uses siamese structure in training and accepts pairwise inputs, which reduces the dependency on large amount of training data; and (3) PSENet can not only estimate the severity, but also locate the skin lesion regions from the input image. To train and evaluate PSENet, we work with professional dermatologists from a top hospital and spend years in building a golden dataset. The experimental results show that PSENet can achieve the mean absolute error of 2.21 and the accuracy of 77.87% in pair comparison, outperforming baseline methods. Overall, PSENet not only relieves dermatologists from the dull PASI calculation but also enables patients to track Psoriasis severity in a much more convenient manner."
  },
  "aaai2020_main_learninggeo-contextualembeddingsforcommutingflowprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Geo-Contextual Embeddings for Commuting Flow Prediction ",
    "authors": [
      "Zhicheng Liu",
      "Fabio Miranda",
      "Weiting Xiong",
      "Junyan Yang",
      "Qiao Wang",
      "Claudio Silva"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5425",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5425/5281",
    "published": "2020-02",
    "summary": "Predicting commuting flows based on infrastructure and land-use information is critical for urban planning and public policy development. However, it is a challenging task given the complex patterns of commuting flows. Conventional models, such as gravity model, are mainly derived from physics principles and limited by their predictive power in real-world scenarios where many factors need to be considered. Meanwhile, most existing machine learning-based methods ignore the spatial correlations and fail to model the influence of nearby regions. To address these issues, we propose Geo-contextual Multitask Embedding Learner (GMEL), a model that captures the spatial correlations from geographic contextual information for commuting flow prediction. Specifically, we first construct a geo-adjacency network containing the geographic contextual information. Then, an attention mechanism is proposed based on the framework of graph attention network (GAT) to capture the spatial correlations and encode geographic contextual information to embedding space. Two separate GATs are used to model supply and demand characteristics. To enhance the effectiveness of the embedding representation, a multitask learning framework is used to introduce stronger restrictions, forcing the embeddings to encapsulate effective representation for flow prediction. Finally, a gradient boosting machine is trained based on the learned embeddings to predict commuting flows. We evaluate our model using real-world dataset from New York City and the experimental results demonstrate the effectiveness of our proposed method against the state of the art."
  },
  "aaai2020_main_learningmulti-modalbiomarkerrepresentationsviagloballyalignedlongitudinalenrichments": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Multi-Modal Biomarker Representations via Globally Aligned Longitudinal Enrichments ",
    "authors": [
      "Lyujian Lu",
      "Saad Elbeleidy",
      "Lauren Zoe Baker",
      "Hua Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5426",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5426/5282",
    "published": "2020-02",
    "summary": "Alzheimer's Disease (AD) is a chronic neurodegenerative disease that severely impacts patients' thinking, memory and behavior. To aid automatic AD diagnoses, many longitudinal learning models have been proposed to predict clinical outcomes and/or disease status, which, though, often fail to consider missing temporal phenotypic records of the patients that can convey valuable information of AD progressions. Another challenge in AD studies is how to integrate heterogeneous genotypic and phenotypic biomarkers to improve diagnosis prediction. To cope with these challenges, in this paper we propose a longitudinal multi-modal method to learn enriched genotypic and phenotypic biomarker representations in the format of fixed-length vectors that can simultaneously capture the baseline neuroimaging measurements of the entire dataset and progressive variations of the varied counts of follow-up measurements over time of every participant from different biomarker sources. The learned global and local projections are aligned by a soft constraint and the structured-sparsity norm is used to uncover the multi-modal structure of heterogeneous biomarker measurements. While the proposed objective is clearly motivated to characterize the progressive information of AD developments, it is a nonsmooth objective that is difficult to efficiently optimize in general. Thus, we derive an efficient iterative algorithm, whose convergence is rigorously guaranteed in mathematics. We have conducted extensive experiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) data using one genotypic and two phenotypic biomarkers. Empirical results have demonstrated that the learned enriched biomarker representations are more effective in predicting the outcomes of various cognitive assessments. Moreover, our model has successfully identified disease-relevant biomarkers supported by existing medical findings that additionally warrant the correctness of our method from the clinical perspective."
  },
  "aaai2020_main_adacareexplainableclinicalhealthstatusrepresentationlearningviascale-adaptivefeatureextractionandrecalibration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AdaCare: Explainable Clinical Health Status Representation Learning via Scale-Adaptive Feature Extraction and Recalibration ",
    "authors": [
      "Liantao Ma",
      "Junyi Gao",
      "Yasha Wang",
      "Chaohe Zhang",
      "Jiangtao Wang",
      "Wenjie Ruan",
      "Wen Tang",
      "Xin Gao",
      "Xinyu Ma"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5427",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5427/5283",
    "published": "2020-02",
    "summary": "Deep learning-based health status representation learning and clinical prediction have raised much research interest in recent years. Existing models have shown superior performance, but there are still several major issues that have not been fully taken into consideration. First, the historical variation pattern of the biomarker in diverse time scales plays a vital role in indicating the health status, but it has not been explicitly extracted by existing works. Second, key factors that strongly indicate the health risk are different among patients. It is still challenging to adaptively make use of the features for patients in diverse conditions. Third, using prediction models as the black box will limit the reliability in clinical practice. However, none of the existing works can provide satisfying interpretability and meanwhile achieve high prediction performance. In this work, we develop a general health status representation learning model, named AdaCare. It can capture the long and short-term variations of biomarkers as clinical features to depict the health status in multiple time scales. It also models the correlation between clinical features to enhance the ones which strongly indicate the health status and thus can maintain a state-of-the-art performance in terms of prediction accuracy while providing qualitative interpretability. We conduct a health risk prediction experiment on two real-world datasets. Experiment results indicate that AdaCare outperforms state-of-the-art approaches and provides effective interpretability, which is verifiable by clinical experts."
  },
  "aaai2020_main_concarepersonalizedclinicalfeatureembeddingviacapturingthehealthcarecontext": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ConCare: Personalized Clinical Feature Embedding via Capturing the Healthcare Context ",
    "authors": [
      "Liantao Ma",
      "Chaohe Zhang",
      "Yasha Wang",
      "Wenjie Ruan",
      "Jiangtao Wang",
      "Wen Tang",
      "Xinyu Ma",
      "Xin Gao",
      "Junyi Gao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5428",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5428/5284",
    "published": "2020-02",
    "summary": "Predicting the patient's clinical outcome from the historical electronic medical records (EMR) is a fundamental research problem in medical informatics. Most deep learning-based solutions for EMR analysis concentrate on learning the clinical visit embedding and exploring the relations between visits. Although those works have shown superior performances in healthcare prediction, they fail to explore the personal characteristics during the clinical visits thoroughly. Moreover, existing works usually assume that the more recent record weights more in the prediction, but this assumption is not suitable for all conditions. In this paper, we propose ConCare to handle the irregular EMR data and extract feature interrelationship to perform individualized healthcare prediction. Our solution can embed the feature sequences separately by modeling the time-aware distribution. ConCare further improves the multi-head self-attention via the cross-head decorrelation, so that the inter-dependencies among dynamic features and static baseline information can be effectively captured to form the personal health context. Experimental results on two real-world EMR datasets demonstrate the effectiveness of ConCare. The medical findings extracted by ConCare are also empirically confirmed by human experts and medical literature."
  },
  "aaai2020_main_burstingthefilterbubblefairness-awarenetworklinkprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bursting the Filter Bubble: Fairness-Aware Network Link Prediction ",
    "authors": [
      "Farzan Masrour",
      "Tyler Wilson",
      "Heng Yan",
      "Pang-Ning Tan",
      "Abdol Esfahanian"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5429",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5429/5285",
    "published": "2020-02",
    "summary": "Link prediction is an important task in online social networking as it can be used to infer new or previously unknown relationships of a network. However, due to the homophily principle, current algorithms are susceptible to promoting links that may lead to increase segregation of the network\u2014an effect known as filter bubble. In this study, we examine the filter bubble problem from the perspective of algorithm fairness and introduce a dyadic-level fairness criterion based on network modularity measure. We show how the criterion can be utilized as a postprocessing step to generate more heterogeneous links in order to overcome the filter bubble problem. In addition, we also present a novel framework that combines adversarial network representation learning with supervised link prediction to alleviate the filter bubble problem. Experimental results conducted on several real-world datasets showed the effectiveness of the proposed methods compared to other baseline approaches, which include conventional link prediction and fairness-aware methods for i.i.d data."
  },
  "aaai2020_main_gaitrecognitionforco-existingmultiplepeopleusingmillimeterwavesensing": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Gait Recognition for Co-Existing Multiple People Using Millimeter Wave Sensing ",
    "authors": [
      "Zhen Meng",
      "Song Fu",
      "Jie Yan",
      "Hongyuan Liang",
      "Anfu Zhou",
      "Shilin Zhu",
      "Huadong Ma",
      "Jianhua Liu",
      "Ning Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5430",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5430/5286",
    "published": "2020-02",
    "summary": "Gait recognition, i.e., recognizing persons from their walking postures, has found versatile applications in security check, health monitoring, and novel human-computer interaction. The millimeter-wave (mmWave) based gait recognition represents the most recent advance. Compared with traditional camera-based solutions, mmWave based gait recognition bears unique advantages of being still effective under non-line-of-sight scenarios, such as in black, weak light, or blockage conditions. Moreover, they are able to accomplish person identification while preserving privacy. Currently, there are only few works in mmWave gait recognition, since no public data set is available. In this paper, we build a first-of-its-kind mmWave gait data set, in which we collect gait of 95 volunteers 'seen' from two mmWave radars in two different scenarios, which together lasts about 30 hours. Using the data set, we propose a novel deep-learning driven mmWave gait recognition method called mmGaitNet, and compare it with five state-of-the-art algorithms. We find that mmGaitNet is able to achieve 90% accuracy for single-person scenarios, 88% accuracy for five co-existing persons, while the existing methods achieve less than 66% accuracy for both scenarios."
  },
  "aaai2020_main_generalizableresourceallocationinstreamprocessingviadeepreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generalizable Resource Allocation in Stream Processing via Deep Reinforcement Learning ",
    "authors": [
      "Xiang Ni",
      "Jing Li",
      "Mo Yu",
      "Wang Zhou",
      "Kun-Lung Wu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5431",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5431/5287",
    "published": "2020-02",
    "summary": "This paper considers the problem of resource allocation in stream processing, where continuous data flows must be processed in real time in a large distributed system. To maximize system throughput, the resource allocation strategy that partitions the computation tasks of a stream processing graph onto computing devices must simultaneously balance workload distribution and minimize communication. Since this problem of graph partitioning is known to be NP-complete yet crucial to practical streaming systems, many heuristic-based algorithms have been developed to find reasonably good solutions. In this paper, we present a graph-aware encoder-decoder framework to learn a generalizable resource allocation strategy that can properly distribute computation tasks of stream processing graphs unobserved from training data. We, for the first time, propose to leverage graph embedding to learn the structural information of the stream processing graphs. Jointly trained with the graph-aware decoder using deep reinforcement learning, our approach can effectively find optimized solutions for unseen graphs. Our experiments show that the proposed model outperforms both METIS, a state-of-the-art graph partitioning algorithm, and an LSTM-based encoder-decoder model, in about 70% of the test cases."
  },
  "aaai2020_main_activethiefmodelextractionusingactivelearningandunannotatedpublicdata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ActiveThief: Model Extraction Using Active Learning and Unannotated Public Data ",
    "authors": [
      "Soham Pal",
      "Yash Gupta",
      "Aditya Shukla",
      "Aditya Kanade",
      "Shirish Shevade",
      "Vinod Ganapathy"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5432",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5432/5288",
    "published": "2020-02",
    "summary": "Machine learning models are increasingly being deployed in practice. Machine Learning as a Service (MLaaS) providers expose such models to queries by third-party developers through application programming interfaces (APIs). Prior work has developed model extraction attacks, in which an attacker extracts an approximation of an MLaaS model by making black-box queries to it. We design ActiveThief \u2013 a model extraction framework for deep neural networks that makes use of active learning techniques and unannotated public datasets to perform model extraction. It does not expect strong domain knowledge or access to annotated data on the part of the attacker. We demonstrate that (1) it is possible to use ActiveThief to extract deep classifiers trained on a variety of datasets from image and text domains, while querying the model with as few as 10-30% of samples from public datasets, (2) the resulting model exhibits a higher transferability success rate of adversarial examples than prior work, and (3) the attack evades detection by the state-of-the-art model extraction detection method, PRADA."
  },
  "aaai2020_main_chemicallyinterpretablegraphinteractionnetworkforpredictionofpharmacokineticpropertiesofdrug-likemolecules": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Chemically Interpretable Graph Interaction Network for Prediction of Pharmacokinetic Properties of Drug-Like Molecules ",
    "authors": [
      "Yashaswi Pathak",
      "Siddhartha Laghuvarapu",
      "Sarvesh Mehta",
      "U. Deva Priyakumar"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5433",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5433/5289",
    "published": "2020-02",
    "summary": "Solubility of drug molecules is related to pharmacokinetic properties such as absorption and distribution, which affects the amount of drug that is available in the body for its action. Computational or experimental evaluation of solvation free energies of drug-like molecules/solute that quantify solubilities is an arduous task and hence development of reliable computationally tractable models is sought after in drug discovery tasks in pharmaceutical industry. Here, we report a novel method based on graph neural network to predict solvation free energies. Previous studies considered only the solute for solvation free energy prediction and ignored the nature of the solvent, limiting their practical applicability. The proposed model is an end-to-end framework comprising three phases namely, message passing, interaction and prediction phases. In the first phase, message passing neural network was used to compute inter-atomic interaction within both solute and solvent molecules represented as molecular graphs. In the interaction phase, features from the preceding step is used to calculate a solute-solvent interaction map, since the solvation free energy depends on how (un)favorable the solute and solvent molecules interact with each other. The calculated interaction map that captures the solute-solvent interactions along with the features from the message passing phase is used to predict the solvation free energies in the final phase. The model predicts solvation free energies involving a large number of solvents with high accuracy. We also show that the interaction map captures the electronic and steric factors that govern the solubility of drug-like molecules and hence is chemically interpretable."
  },
  "aaai2020_main_fuzzefuzzyfairnessevaluationofoffensivelanguageclassifiersonafrican-americanenglish": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " FuzzE: Fuzzy Fairness Evaluation of Offensive Language Classifiers on African-American English ",
    "authors": [
      "Anthony Rios"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5434",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5434/5290",
    "published": "2020-02",
    "summary": "Hate speech and offensive language are rampant on social media. Machine learning has provided a way to moderate foul language at scale. However, much of the current research focuses on overall performance. Models may perform poorly on text written in a minority dialectal language. For instance, a hate speech classifier may produce more false positives on tweets written in African-American Vernacular English (AAVE). To measure these problems, we need text written in both AAVE and Standard American English (SAE). Unfortunately, it is challenging to curate data for all linguistic styles in a timely manner\u2014especially when we are constrained to specific problems, social media platforms, or by limited resources. In this paper, we answer the question, \u201cHow can we evaluate the performance of classifiers across minority dialectal languages when they are not present within a particular dataset?\u201d Specifically, we propose an automated fairness fuzzing tool called FuzzE to quantify the fairness of text classifiers applied to AAVE text using a dataset that only contains text written in SAE. Overall, we find that the fairness estimates returned by our technique moderately correlates with the use of real ground-truth AAVE text. Warning: Offensive language is displayed in this manuscript."
  },
  "aaai2020_main_learningtogeneratemapsfromtrajectories": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Generate Maps from Trajectories ",
    "authors": [
      "Sijie Ruan",
      "Cheng Long",
      "Jie Bao",
      "Chunyang Li",
      "Zisheng Yu",
      "Ruiyuan Li",
      "Yuxuan Liang",
      "Tianfu He",
      "Yu Zheng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5435",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5435/5291",
    "published": "2020-02",
    "summary": "Accurate and updated road network data is vital in many urban applications, such as car-sharing, and logistics. The traditional approach to identifying the road network, i.e., field survey, requires a significant amount of time and effort. With the wide usage of GPS embedded devices, a huge amount of trajectory data has been generated by different types of mobile objects, which provides a new opportunity to extract the underlying road network. However, the existing trajectory-based map recovery approaches require many empirical parameters and do not utilize the prior knowledge in existing maps, which over-simplifies or over-complicates the reconstructed road network. To this end, we propose a deep learning-based map generation framework, i.e., DeepMG, which learns the structure of the existing road network to overcome the noisy GPS positions. More specifically, DeepMG extracts features from trajectories in both spatial view and transition view and uses a convolutional deep neural network T2RNet to infer road centerlines. After that, a trajectory-based post-processing algorithm is proposed to refine the topological connectivity of the recovered map. Extensive experiments on two real-world trajectory datasets confirm that DeepMG significantly outperforms the state-of-the-art methods."
  },
  "aaai2020_main_spatialclassificationwithlimitedobservationsbasedonphysics-awarestructuralconstraint": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Spatial Classification with Limited Observations Based on Physics-Aware Structural Constraint ",
    "authors": [
      "Arpan Man Sainju",
      "Wenchong He",
      "Zhe Jiang",
      "Da Yan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5436",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5436/5292",
    "published": "2020-02",
    "summary": "Spatial classification with limited feature observations has been a challenging problem in machine learning. The problem exists in applications where only a subset of sensors are deployed at certain regions or partial responses are collected in field surveys. Existing research mostly focuses on addressing incomplete or missing data, e.g., data cleaning and imputation, classification models that allow for missing feature values, or modeling missing features as hidden variables and applying the EM algorithm. These methods, however, assume that incomplete feature observations only happen on a small subset of samples, and thus cannot solve problems where the vast majority of samples have missing feature observations. To address this issue, we propose a new approach that incorporates physics-aware structural constraints into the model representation. Our approach assumes that a spatial contextual feature is observed for all sample locations and establishes spatial structural constraint from the spatial contextual feature map. We design efficient algorithms for model parameter learning and class inference. Evaluations on real-world hydrological applications show that our approach significantly outperforms several baseline methods in classification accuracy, and the proposed solution is computationally efficient on a large data volume."
  },
  "aaai2020_main_effectivedecodingingraphauto-encoderusingtriadicclosure": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Effective Decoding in Graph Auto-Encoder Using Triadic Closure ",
    "authors": [
      "Han Shi",
      "Haozheng Fan",
      "James T. Kwok"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5437",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5437/5293",
    "published": "2020-02",
    "summary": "The (variational) graph auto-encoder and its variants have been popularly used for representation learning on graph-structured data. While the encoder is often a powerful graph convolutional network, the decoder reconstructs the graph structure by only considering two nodes at a time, thus ignoring possible interactions among edges. On the other hand, structured prediction, which considers the whole graph simultaneously, is computationally expensive. In this paper, we utilize the well-known triadic closure property which is exhibited in many real-world networks. We propose the triad decoder, which considers and predicts the three edges involved in a local triad together. The triad decoder can be readily used in any graph-based auto-encoder. In particular, we incorporate this to the (variational) graph auto-encoder. Experiments on link prediction, node clustering and graph generation show that the use of triads leads to more accurate prediction, clustering and better preservation of the graph characteristics."
  },
  "aaai2020_main_spatial-temporalsynchronousgraphconvolutionalnetworksanewframeworkforspatial-temporalnetworkdataforecasting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting ",
    "authors": [
      "Chao Song",
      "Youfang Lin",
      "Shengnan Guo",
      "Huaiyu Wan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5438",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5438/5294",
    "published": "2020-02",
    "summary": "Spatial-temporal network data forecasting is of great importance in a huge amount of applications for traffic management and urban planning. However, the underlying complex spatial-temporal correlations and heterogeneities make this problem challenging. Existing methods usually use separate components to capture spatial and temporal correlations and ignore the heterogeneities in spatial-temporal data. In this paper, we propose a novel model, named Spatial-Temporal Synchronous Graph Convolutional Networks (STSGCN), for spatial-temporal network data forecasting. The model is able to effectively capture the complex localized spatial-temporal correlations through an elaborately designed spatial-temporal synchronous modeling mechanism. Meanwhile, multiple modules for different time periods are designed in the model to effectively capture the heterogeneities in localized spatial-temporal graphs. Extensive experiments are conducted on four real-world datasets, which demonstrates that our method achieves the state-of-the-art performance and consistently outperforms other baselines."
  },
  "aaai2020_main_continuousmultiagentcontrolusingcollectivebehaviorentropyforlarge-scalehomeenergymanagement": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Continuous Multiagent Control Using Collective Behavior Entropy for Large-Scale Home Energy Management ",
    "authors": [
      "Jianwen Sun",
      "Yan Zheng",
      "Jianye Hao",
      "Zhaopeng Meng",
      "Yang Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5439",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5439/5295",
    "published": "2020-02",
    "summary": "With the increasing popularity of electric vehicles, distributed energy generation and storage facilities in smart grid systems, an efficient Demand-Side Management (DSM) is urgent for energy savings and peak loads reduction. Traditional DSM works focusing on optimizing the energy activities for a single household can not scale up to large-scale home energy management problems. Multi-agent Deep Reinforcement Learning (MA-DRL) shows a potential way to solve the problem of scalability, where modern homes interact together to reduce energy consumers consumption while striking a balance between energy cost and peak loads reduction. However, it is difficult to solve such an environment with the non-stationarity, and existing MA-DRL approaches cannot effectively give incentives for expected group behavior. In this paper, we propose a collective MA-DRL algorithm with continuous action space to provide fine-grained control on a large scale microgrid. To mitigate the non-stationarity of the microgrid environment, a novel predictive model is proposed to measure the collective market behavior. Besides, a collective behavior entropy is introduced to reduce the high peak loads incurred by the collective behaviors of all householders in the smart grid. Empirical results show that our approach significantly outperforms the state-of-the-art methods regarding power cost reduction and daily peak loads optimization."
  },
  "aaai2020_main_data-grudual-attentiontime-awaregatedrecurrentunitforirregularmultivariatetimeseries": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DATA-GRU: Dual-Attention Time-Aware Gated Recurrent Unit for Irregular Multivariate Time Series ",
    "authors": [
      "Qingxiong Tan",
      "Mang Ye",
      "Baoyao Yang",
      "Siqi Liu",
      "Andy Jinhua Ma",
      "Terry Cheuk-Fung Yip",
      "Grace Lai-Hung Wong",
      "PongChi Yuen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5440",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5440/5296",
    "published": "2020-02",
    "summary": "Due to the discrepancy of diseases and symptoms, patients usually visit hospitals irregularly and different physiological variables are examined at each visit, producing large amounts of irregular multivariate time series (IMTS) data with missing values and varying intervals. Existing methods process IMTS into regular data so that standard machine learning models can be employed. However, time intervals are usually determined by the status of patients, while missing values are caused by changes in symptoms. Therefore, we propose a novel end-to-end Dual-Attention Time-Aware Gated Recurrent Unit (DATA-GRU) for IMTS to predict the mortality risk of patients. In particular, DATA-GRU is able to: 1) preserve the informative varying intervals by introducing a time-aware structure to directly adjust the influence of the previous status in coordination with the elapsed time, and 2) tackle missing values by proposing a novel dual-attention structure to jointly consider data-quality and medical-knowledge. A novel unreliability-aware attention mechanism is designed to handle the diversity in the reliability of different data, while a new symptom-aware attention mechanism is proposed to extract medical reasons from original clinical records. Extensive experimental results on two real-world datasets demonstrate that DATA-GRU can significantly outperform state-of-the-art methods and provide meaningful clinical interpretation."
  },
  "aaai2020_main_findingminimum-weightlink-disjointpathswithafewcommonnodes": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Finding Minimum-Weight Link-Disjoint Paths with a Few Common Nodes ",
    "authors": [
      "Binglin Tao",
      "Mingyu Xiao",
      "Jingyang Zhao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5441",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5441/5297",
    "published": "2020-02",
    "summary": "Network survivability has drawn certain interest in network optimization. However, the demand for full protection of a network is usually too restrictive. To overcome the limitation of geographical environments and to save network resources, we turn to establish backup networks allowing a few common nodes. It comes out the problem of finding k link-disjoint paths between a given pair of source and sink in a network such that the number of common nodes shared by at least two paths is bounded by a constant and the total link weight of all paths is minimized under the above constraints. For the case k = 2, where we have only one backup path, several fast algorithms have been developed in the literature. For the case k > 2, little results are known. In this paper, we first establish the NP-hardness of the problem with general k. Motivated by the situation that each node in a network may have a capability of multicasting, we also study a restricted version with one more requirement that each node can be shared by at most two paths. For the restricted version, we build an ILP model and design a fast algorithm by using the techniques of augmenting paths and splitting nodes. Furthermore, experimental results on synthetic and real networks show that our algorithm is effective in practice."
  },
  "aaai2020_main_findingneedlesinamovinghaystackprioritizingalertswithadversarialreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Finding Needles in a Moving Haystack: Prioritizing Alerts with Adversarial Reinforcement Learning ",
    "authors": [
      "Liang Tong",
      "Aron Laszka",
      "Chao Yan",
      "Ning Zhang",
      "Yevgeniy Vorobeychik"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5442",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5442/5298",
    "published": "2020-02",
    "summary": "Detection of malicious behavior is a fundamental problem in security. One of the major challenges in using detection systems in practice is in dealing with an overwhelming number of alerts that are triggered by normal behavior (the so-called false positives), obscuring alerts resulting from actual malicious activities. We introduce a novel approach for computing a policy for prioritizing alerts using adversarial reinforcement learning. Our approach assumes that the attacker knows the full state of the detection system and the defender's alert prioritization policy, and will dynamically choose an optimal attack. The first step of our approach is to capture the interaction between the defender and attacker in a game theoretic model. To tackle the computational complexity of solving this game to obtain a dynamic stochastic alert prioritization policy, we propose an adversarial reinforcement learning framework. In this framework, we use neural reinforcement learning to compute best response policies for both the defender and the adversary to an arbitrary stochastic policy of the other. We then use these in a double-oracle framework to obtain an approximate equilibrium of the game, which in turn yields a robust stochastic policy for the defender. We use case studies in network intrusion and fraud detection to demonstrate that our approach is effective in creating robust alert prioritization policies.1"
  },
  "aaai2020_main_robustadversarialobjectsagainstdeeplearningmodels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Robust Adversarial Objects against Deep Learning Models ",
    "authors": [
      "Tzungyu Tsai",
      "Kaichen Yang",
      "Tsung-Yi Ho",
      "Yier Jin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5443",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5443/5299",
    "published": "2020-02",
    "summary": "Previous work has shown that Deep Neural Networks (DNNs), including those currently in use in many fields, are extremely vulnerable to maliciously crafted inputs, known as adversarial examples. Despite extensive and thorough research of adversarial examples in many areas, adversarial 3D data, such as point clouds, remain comparatively unexplored. The study of adversarial 3D data is crucial considering its impact in real-life, high-stakes scenarios including autonomous driving. In this paper, we propose a novel adversarial attack against PointNet++, a deep neural network that performs classification and segmentation tasks using features learned directly from raw 3D points. In comparison to existing works, our attack generates not only adversarial point clouds, but also robust adversarial objects that in turn generate adversarial point clouds when sampled both in simulation and after construction in real world. We also demonstrate that our objects can bypass existing defense mechanisms designed especially against adversarial 3D data."
  },
  "aaai2020_main_omuletonlinemulti-leadtimelocationpredictionforhurricanetrajectoryforecasting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " OMuLeT: Online Multi-Lead Time Location Prediction for Hurricane Trajectory Forecasting ",
    "authors": [
      "Ding Wang",
      "Boyang Liu",
      "Pang-Ning Tan",
      "Lifeng Luo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5444",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5444/5300",
    "published": "2020-02",
    "summary": "Hurricanes are powerful tropical cyclones with sustained wind speeds ranging from at least 74 mph (for category 1 storms) to more than 157 mph (for category 5 storms). Accurate prediction of the storm tracks is essential for hurricane preparedness and mitigation of storm impacts. In this paper, we cast the hurricane trajectory forecasting task as an online multi-lead time location prediction problem and present a framework called OMuLeT to improve path prediction by combining the 6-hourly and 12-hourly forecasts generated from an ensemble of dynamical (physical) hurricane models. OMuLeT employs an online learning with restart strategy to incrementally update the weights of the ensemble model combination as new observation data become available. It can also handle the varying dynamical models available for predicting the trajectories of different hurricanes. Experimental results using the Atlantic and Eastern Pacific hurricane data showed that OMuLeT significantly outperforms various baseline methods, including the official forecasts produced by the U.S. National Hurricane Center (NHC), by more than 10% in terms of its 48-hour lead time forecasts."
  },
  "aaai2020_main_incorporatingexpert-basedinvestmentopinionsignalsinstockpredictionadeeplearningframework": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Incorporating Expert-Based Investment Opinion Signals in Stock Prediction: A Deep Learning Framework ",
    "authors": [
      "Heyuan Wang",
      "Tengjiao Wang",
      "Yi Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5445",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5445/5301",
    "published": "2020-02",
    "summary": "Investment messages published on social media platforms are highly valuable for stock prediction. Most previous work regards overall message sentiments as forecast indicators and relies on shallow features (bag-of-words, noun phrases, etc.) to determine the investment opinion signals. These methods neither capture the time-sensitive and target-aware characteristics of stock investment reviews, nor consider the impact of investor's reliability. In this study, we provide an in-depth analysis of public stock reviews and their application in stock movement prediction. Specifically, we propose a novel framework which includes the following three key components: time-sensitive and target-aware investment stance detection, expert-based dynamic stance aggregation, and stock movement prediction. We first introduce our stance detection model named MFN, which learns the representation of each review by integrating multi-view textual features and extended knowledge in financial domain to distill bullish/bearish investment opinions. Then we show how to identify the validity of each review, and enhance stock movement prediction by incorporating expert-based aggregated opinion signals. Experiments on real datasets show our framework can effectively improve the performance of both investment opinion mining and individual stock forecasting."
  },
  "aaai2020_main_graph-drivengenerativemodelsforheterogeneousmulti-tasklearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Graph-Driven Generative Models for Heterogeneous Multi-Task Learning ",
    "authors": [
      "Wenlin Wang",
      "Hongteng Xu",
      "Zhe Gan",
      "Bai Li",
      "Guoyin Wang",
      "Liqun Chen",
      "Qian Yang",
      "Wenqi Wang",
      "Lawrence Carin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5446",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5446/5302",
    "published": "2020-02",
    "summary": "We propose a novel graph-driven generative model, that unifies multiple heterogeneous learning tasks into the same framework. The proposed model is based on the fact that heterogeneous learning tasks, which correspond to different generative processes, often rely on data with a shared graph structure. Accordingly, our model combines a graph convolutional network (GCN) with multiple variational autoencoders, thus embedding the nodes of the graph (i.e., samples for the tasks) in a uniform manner, while specializing their organization and usage to different tasks. With a focus on healthcare applications (tasks), including clinical topic modeling, procedure recommendation and admission-type prediction, we demonstrate that our method successfully leverages information across different tasks, boosting performance in all tasks and outperforming existing state-of-the-art approaches."
  },
  "aaai2020_main_topicenhancedsentimentspreadingmodelinsocialnetworksconsideringuserinterest": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Topic Enhanced Sentiment Spreading Model in Social Networks Considering User Interest ",
    "authors": [
      "Xiaobao Wang",
      "Di Jin",
      "Katarzyna Musial",
      "Jianwu Dang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5447",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5447/5303",
    "published": "2020-02",
    "summary": "Emotion is a complex emotional state, which can affect our physiology and psychology and lead to behavior changes. The spreading process of emotions in the text-based social networks is referred to as sentiment spreading. In this paper, we study an interesting problem of sentiment spreading in social networks. In particular, by employing a text-based social network (Twitter) , we try to unveil the correlation between users' sentimental statuses and topic distributions embedded in the tweets, then to automatically learn the influence strength between linked users. Furthermore, we introduce user interest to refine the influence strength. We develop a unified probabilistic framework to formalize the problem into a topic-enhanced sentiment spreading model. The model can predict users' sentimental statuses based on their historical emotional status, topic distributions in tweets and social structures. Experiments on the Twitter dataset show that the proposed model significantly outperforms several alternative methods in predicting users' sentimental status. We also discover an intriguing phenomenon that positive and negative sentiment is more relevant to user interest than neutral ones. Our method offers a new opportunity to understand the underlying mechanism of sentimental spreading in online social networks."
  },
  "aaai2020_main_hdktowardhigh-performancedeep-learning-basedkirchhoffanalysis": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " HDK: Toward High-Performance Deep-Learning-Based Kirchhoff Analysis ",
    "authors": [
      "Xinying Wang",
      "Olamide Timothy Tawose",
      "Feng Yan",
      "Dongfang Zhao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5448",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5448/5304",
    "published": "2020-02",
    "summary": "The Kirchhoff law is one of the most widely used physical laws in many engineering principles, e.g., biomedical engineering, electrical engineering, and computer engineering. One challenge of applying the Kirchhoff law to real-world applications at scale lies in the high, if not prohibitive, computational cost to solve a large number of nonlinear equations. Despite recent advances in leveraging a convolutional neural network (CNN) to estimate the solutions of Kirchhoff equations, the low performance is still significantly hindering the broad adoption of CNN-based approaches. This paper proposes a high-performance deep-learning-based approach for Kirchhoff analysis, namely HDK. HDK employs two techniques to improve the performance: (i) early pruning of unqualified input candidates and (ii) parallelization of forward labelling. To retain high accuracy, HDK also applies various optimizations to the data such as randomized augmentation and dimension reduction. Collectively, the aforementioned techniques improve the analysis speed by 8\u00d7 with accuracy as high as 99.6%."
  },
  "aaai2020_main_actorcriticdeepreinforcementlearningforneuralmalwarecontrol": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Actor Critic Deep Reinforcement Learning for Neural Malware Control ",
    "authors": [
      "Yu Wang",
      "Jack Stokes",
      "Mady Marinescu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5449",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5449/5305",
    "published": "2020-02",
    "summary": "In addition to using signatures, antimalware products also detect malicious attacks by evaluating unknown files in an emulated environment, i.e. sandbox, prior to execution on a computer's native operating system. During emulation, a file cannot be scanned indefinitely, and antimalware engines often set the number of instructions to be executed based on a set of heuristics. These heuristics only make the decision of when to halt emulation using partial information leading to the execution of the file for either too many or too few instructions. Also this method is vulnerable if the attackers learn this set of heuristics."
  },
  "aaai2020_main_urban2vecincorporatingstreetviewimageryandpoisformulti-modalurbanneighborhoodembedding": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Urban2Vec: Incorporating Street View Imagery and POIs for Multi-Modal Urban Neighborhood Embedding ",
    "authors": [
      "Zhecheng Wang",
      "Haoyuan Li",
      "Ram Rajagopal"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5450",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5450/5306",
    "published": "2020-02",
    "summary": "Understanding intrinsic patterns and predicting spatiotemporal characteristics of cities require a comprehensive representation of urban neighborhoods. Existing works relied on either inter- or intra-region connectivities to generate neighborhood representations but failed to fully utilize the informative yet heterogeneous data within neighborhoods. In this work, we propose Urban2Vec, an unsupervised multi-modal framework which incorporates both street view imagery and point-of-interest (POI) data to learn neighborhood embeddings. Specifically, we use a convolutional neural network to extract visual features from street view images while preserving geospatial similarity. Furthermore, we model each POI as a bag-of-words containing its category, rating, and review information. Analog to document embedding in natural language processing, we establish the semantic similarity between neighborhood (\u201cdocument\u201d) and the words from its surrounding POIs in the vector space. By jointly encoding visual, textual, and geospatial information into the neighborhood representation, Urban2Vec can achieve performances better than baseline models and comparable to fully-supervised methods in downstream prediction tasks. Extensive experiments on three U.S. metropolitan areas also demonstrate the model interpretability, generalization capability, and its value in neighborhood similarity analysis."
  },
  "aaai2020_main_hidinginmultilayernetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Hiding in Multilayer Networks ",
    "authors": [
      "Marcin Waniek",
      "Tomasz Michalak",
      "Talal Rahwan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5451",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5451/5307",
    "published": "2020-02",
    "summary": "Multilayer networks allow for modeling complex relationships, where individuals are embedded in multiple social networks at the same time. Given the ubiquity of such relationships, these networks have been increasingly gaining attention in the literature. This paper presents the first analysis of the robustness of centrality measures against strategic manipulation in multilayer networks. More specifically, we consider an \u201cevader\u201d who strategically chooses which connections to form in a multilayer network in order to obtain a low centrality-based ranking\u2014thereby reducing the chance of being highlighted as a key figure in the network\u2014while ensuring that she remains connected to a certain group of people. We prove that determining an optimal way to \u201chide\u201d is NP-complete and hard to approximate for most centrality measures considered in our study. Moreover, we empirically evaluate a number of heuristics that the evader can use. Our results suggest that the centrality measures that are functions of the entire network topology are more robust to such a strategic evader than their counterparts which consider each layer separately."
  },
  "aaai2020_main_adeepneuralnetworkmodelofparticlethermalradiationinpackedbed": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Deep Neural Network Model of Particle Thermal Radiation in Packed Bed ",
    "authors": [
      "Hao Wu",
      "Shuang Hao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5452",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5452/5308",
    "published": "2020-02",
    "summary": "Prediction of particle radiative heat transfer flux is an important task in the large discrete granular systems, such as pebble bed in power plants and industrial fluidized beds. For particle motion and packing, discrete element method (DEM) now is widely accepted as the excellent Lagrangian approach. For thermal radiation, traditional methods focus on calculating the obstructed view factor directly by numerical algorithms. The major challenge for the simulation is that the method is proven to be time-consuming and not feasible to be applied in the practical cases. In this work, we propose an analytical model to calculate macroscopic effective conductivity from particle packing structures Then, we develop a deep neural network (DNN) model used as a predictor of the complex view factor function. The DNN model is trained by a large dataset and the computational speed is greatly improved with good accuracy. It is feasible to perform real-time simulation with DNN model for radiative heat transfer in large pebble bed. The trained model also can be coupled with DEM and used to analyze efficiently the directional radiative conductivity, anisotropic factor and wall effect of the particle thermal radiation."
  },
  "aaai2020_main_deepdualmapperagatedfusionnetworkforautomaticmapextractionusingaerialimagesandtrajectories": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DeepDualMapper: A Gated Fusion Network for Automatic Map Extraction Using Aerial Images and Trajectories ",
    "authors": [
      "Hao Wu",
      "Hanyuan Zhang",
      "Xinyu Zhang",
      "Weiwei Sun",
      "Baihua Zheng",
      "Yuning Jiang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5453",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5453/5309",
    "published": "2020-02",
    "summary": "Automatic map extraction is of great importance to urban computing and location-based services. Aerial image and GPS trajectory data refer to two different data sources that could be leveraged to generate the map, although they carry different types of information. Most previous works on data fusion between aerial images and data from auxiliary sensors do not fully utilize the information of both modalities and hence suffer from the issue of information loss. We propose a deep convolutional neural network called DeepDualMapper which fuses the aerial image and trajectory data in a more seamless manner to extract the digital map. We design a gated fusion module to explicitly control the information flows from both modalities in a complementary-aware manner. Moreover, we propose a novel densely supervised refinement decoder to generate the prediction in a coarse-to-fine way. Our comprehensive experiments demonstrate that DeepDualMapper can fuse the information of images and trajectories much more effectively than existing approaches, and is able to generate maps with higher accuracy."
  },
  "aaai2020_main_acceleratingandimprovingalphazerousingpopulationbasedtraining": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Accelerating and Improving AlphaZero Using Population Based Training ",
    "authors": [
      "Ti-Rong Wu",
      "Ting-Han Wei",
      "I-Chen Wu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5454",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5454/5310",
    "published": "2020-02",
    "summary": "AlphaZero has been very successful in many games. Unfortunately, it still consumes a huge amount of computing resources, the majority of which is spent in self-play. Hyperparameter tuning exacerbates the training cost since each hyperparameter configuration requires its own time to train one run, during which it will generate its own self-play records. As a result, multiple runs are usually needed for different hyperparameter configurations. This paper proposes using population based training (PBT) to help tune hyperparameters dynamically and improve strength during training time. Another significant advantage is that this method requires a single run only, while incurring a small additional time cost, since the time for generating self-play records remains unchanged though the time for optimization is increased following the AlphaZero training algorithm. In our experiments for 9x9 Go, the PBT method is able to achieve a higher win rate for 9x9 Go than the baselines, each with its own hyperparameter configuration and trained individually. For 19x19 Go, with PBT, we are able to obtain improvements in playing strength. Specifically, the PBT agent can obtain up to 74% win rate against ELF OpenGo, an open-source state-of-the-art AlphaZero program using a neural network of a comparable capacity. This is compared to a saturated non-PBT agent, which achieves a win rate of 47% against ELF OpenGo under the same circumstances."
  },
  "aaai2020_main_graphconvolutionalnetworkswithmarkovrandomfieldreasoningforsocialspammerdetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Graph Convolutional Networks with Markov Random Field Reasoning for Social Spammer Detection ",
    "authors": [
      "Yongji Wu",
      "Defu Lian",
      "Yiheng Xu",
      "Le Wu",
      "Enhong Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5455",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5455/5311",
    "published": "2020-02",
    "summary": "The recent growth of social networking platforms also led to the emergence of social spammers, who overwhelm legitimate users with unwanted content. The existing social spammer detection methods can be characterized into two categories: features based ones and propagation-based ones. Features based methods mainly rely on matrix factorization using tweet text features, and regularization using social graphs is incorporated. However, these methods are fully supervised and can only utilize labeled part of social graphs, which fail to work in a real-world semi-supervised setting. The propagation-based methods primarily employ Markov Random Fields (MRFs) to capture human intuitions in user following relations, which cannot take advantages of rich text features. In this paper, we propose a novel social spammer detection model based on Graph Convolutional Networks (GCNs) that operate on directed social graphs by explicitly considering three types of neighbors. Furthermore, inspired by the propagation-based methods, we propose a MRF layer with refining effects to encapsulate these human insights in social relations, which can be formulated as a RNN through mean-field approximate inference, and stack on top of GCN layers to enable end-to-end training. We evaluate our proposed method on two real-world social network datasets, and the results demonstrate that our method outperforms the state-of-the-art approaches."
  },
  "aaai2020_main_generativeadversarialregularizedmutualinformationpolicygradientframeworkforautomaticdiagnosis": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generative Adversarial Regularized Mutual Information Policy Gradient Framework for Automatic Diagnosis ",
    "authors": [
      "Yuan Xia",
      "Jingbo Zhou",
      "Zhenhui Shi",
      "Chao Lu",
      "Haifeng Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5456",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5456/5312",
    "published": "2020-02",
    "summary": "Automatic diagnosis systems have attracted increasing attention in recent years. The reinforcement learning (RL) is an attractive technique for building an automatic diagnosis system due to its advantages for handling sequential decision making problem. However, the RL method still cannot achieve good enough prediction accuracy. In this paper, we propose a Generative Adversarial regularized Mutual information Policy gradient framework (GAMP) for automatic diagnosis which aims to make a diagnosis rapidly and accurately. We first propose a new policy gradient framework based on the Generative Adversarial Network (GAN) to optimize the RL model for automatic diagnosis. In our framework, we take the generator of GAN as a policy network, and also use the discriminator of GAN as a part of the reward function. This generative adversarial regularized policy gradient framework can try to avoid generating randomized trials of symptom inquires deviated from the common diagnosis paradigm. In addition, we add mutual information to enhance the reward function to encourage the model to select the most discriminative symptoms to make a diagnosis. Experiment evaluations on two public datasets show that our method beats the state-of-art methods, not only can achieve higher diagnosis accuracy, but also can use a smaller number of inquires to make diagnosis decision."
  },
  "aaai2020_main_generate(non-software)bugstofoolclassifiers": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generate (Non-Software) Bugs to Fool Classifiers ",
    "authors": [
      "Hiromu Yakura",
      "Youhei Akimoto",
      "Jun Sakuma"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5457",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5457/5313",
    "published": "2020-02",
    "summary": "In adversarial attacks intended to confound deep learning models, most studies have focused on limiting the magnitude of the modification so that humans do not notice the attack. On the other hand, during an attack against autonomous cars, for example, most drivers would not find it strange if a small insect image were placed on a stop sign, or they may overlook it. In this paper, we present a systematic approach to generate natural adversarial examples against classification models by employing such natural-appearing perturbations that imitate a certain object or signal. We first show the feasibility of this approach in an attack against an image classifier by employing generative adversarial networks that produce image patches that have the appearance of a natural object to fool the target model. We also introduce an algorithm to optimize placement of the perturbation in accordance with the input image, which makes the generation of adversarial examples fast and likely to succeed. Moreover, we experimentally show that the proposed approach can be extended to the audio domain, for example, to generate perturbations that sound like the chirping of birds to fool a speech classifier."
  },
  "aaai2020_main_fairness-awaredemandpredictionfornewmobility": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fairness-Aware Demand Prediction for New Mobility ",
    "authors": [
      "An Yan",
      "Bill Howe"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5458",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5458/5314",
    "published": "2020-02",
    "summary": "Emerging transportation modes, including car-sharing, bike-sharing, and ride-hailing, are transforming urban mobility yet have been shown to reinforce socioeconomic inequity. These services rely on accurate demand prediction, but the demand data on which these models are trained reflect biases around demographics, socioeconomic conditions, and entrenched geographic patterns. To address these biases and improve fairness, we present FairST, a fairness-aware demand prediction model for spatiotemporal urban applications, with emphasis on new mobility. We use 1D (time-varying, space-constant), 2D (space-varying, time-constant) and 3D (both time- and space-varying) convolutional branches to integrate heterogeneous features, while including fairness metrics as a form of regularization to improve equity across demographic groups. We propose two spatiotemporal fairness metrics, region-based fairness gap (RFG), applicable when demographic information is provided as a constant for a region, and individual-based fairness gap (IFG), applicable when a continuous distribution of demographic information is available. Experimental results on bike share and ride share datasets show that FairST can reduce inequity in demand prediction for multiple sensitive attributes (i.e. race, age, and education level), while achieving better accuracy than even state-of-the-art fairness-oblivious methods."
  },
  "aaai2020_main_beyonddigitaldomainfoolingdeeplearningbasedrecognitionsysteminphysicalworld": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Beyond Digital Domain: Fooling Deep Learning Based Recognition System in Physical World ",
    "authors": [
      "Kaichen Yang",
      "Tzungyu Tsai",
      "Honggang Yu",
      "Tsung-Yi Ho",
      "Yier Jin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5459",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5459/5315",
    "published": "2020-02",
    "summary": "Adversarial examples that can fool deep neural network (DNN) models in computer vision present a growing threat. The current methods of launching adversarial attacks concentrate on attacking image classifiers by adding noise to digital inputs. The problem of attacking object detection models and adversarial attacks in physical world are rarely touched. Some prior works are proposed to launch physical adversarial attack against object detection models, but limited by certain aspects. In this paper, we propose a novel physical adversarial attack targeting object detection models. Instead of simply printing images, we manufacture real metal objects that could achieve the adversarial effect. In both indoor and outdoor experiments we show our physical adversarial objects can fool widely applied object detection models including SSD, YOLO and Faster R-CNN in various environments. We also test our attack in a variety of commercial platforms for object detection and demonstrate that our attack is still valid on these platforms. Consider the potential defense mechanisms our adversarial objects may encounter, we conduct a series of experiments to evaluate the effect of existing defense methods on our physical attack."
  },
  "aaai2020_main_scalableandgeneralizablesocialbotdetectionthroughdataselection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Scalable and Generalizable Social Bot Detection through Data Selection ",
    "authors": [
      "Kai-Cheng Yang",
      "Onur Varol",
      "Pik-Mai Hui",
      "Filippo Menczer"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5460",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5460/5316",
    "published": "2020-02",
    "summary": "Efficient and reliable social bot classification is crucial for detecting information manipulation on social media. Despite rapid development, state-of-the-art bot detection models still face generalization and scalability challenges, which greatly limit their applications. In this paper we propose a framework that uses minimal account metadata, enabling efficient analysis that scales up to handle the full stream of public tweets of Twitter in real time. To ensure model accuracy, we build a rich collection of labeled datasets for training and validation. We deploy a strict validation system so that model performance on unseen datasets is also optimized, in addition to traditional cross-validation. We find that strategically selecting a subset of training data yields better model accuracy and generalization than exhaustively training on all available data. Thanks to the simplicity of the proposed model, its logic can be interpreted to provide insights into social bot characteristics."
  },
  "aaai2020_main_instance-wisedynamicsensorselectionforhumanactivityrecognition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Instance-Wise Dynamic Sensor Selection for Human Activity Recognition ",
    "authors": [
      "Xiaodong Yang",
      "Yiqiang Chen",
      "Hanchao Yu",
      "Yingwei Zhang",
      "Wang Lu",
      "Ruizhe Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5461",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5461/5317",
    "published": "2020-02",
    "summary": "Human Activity Recognition (HAR) is an important application of smart wearable/mobile systems for many human-centric problems such as healthcare. The multi-sensor synchronous measurement has shown better performance for HAR than a single sensor. However, the multi-sensor setting increases the costs of data transmission, computation and energy. Therefore, the efficient sensor selection to balance recognition accuracy and sensor cost is the critical challenge. In this paper, we propose an Instance-wise Dynamic Sensor Selection (IDSS) method for HAR. Firstly, we formalize this problem as minimizing both activity classification loss and sensor number by dynamically selecting a sparse subset for each instance. Then, IDSS solves the above minimization problem via Markov Decision Process whose policy for sensor selection is learned by exploiting the instance-wise states using Imitation Learning. In order to optimize the parameters of the activity classification model and the sensor selection policy, an algorithm named Mutual DAgger is proposed to alternatively enhance their learning process. To evaluate the performance of IDSS, we conduct experiments on three real-world HAR datasets. The experimental results show that IDSS can effectively reduce the overall sensor number without losing accuracy and outperforms the state-of-the-art methods regarding the combined measurement of accuracy and sensor number."
  },
  "aaai2020_main_reinforcement-learningbasedportfoliomanagementwithaugmentedassetmovementpredictionstates": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reinforcement-Learning Based Portfolio Management with Augmented Asset Movement Prediction States ",
    "authors": [
      "Yunan Ye",
      "Hengzhi Pei",
      "Boxin Wang",
      "Pin-Yu Chen",
      "Yada Zhu",
      "Ju Xiao",
      "Bo Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5462",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5462/5318",
    "published": "2020-02",
    "summary": "Portfolio management (PM) is a fundamental financial planning task that aims to achieve investment goals such as maximal profits or minimal risks. Its decision process involves continuous derivation of valuable information from various data sources and sequential decision optimization, which is a prospective research direction for reinforcement learning (RL). In this paper, we propose SARL, a novel State-Augmented RL framework for PM. Our framework aims to address two unique challenges in financial PM: (1) data heterogeneity \u2013 the collected information for each asset is usually diverse, noisy and imbalanced (e.g., news articles); and (2) environment uncertainty \u2013 the financial market is versatile and non-stationary. To incorporate heterogeneous data and enhance robustness against environment uncertainty, our SARL augments the asset information with their price movement prediction as additional states, where the prediction can be solely based on financial data (e.g., asset prices) or derived from alternative sources such as news. Experiments on two real-world datasets, (i) Bitcoin market and (ii) HighTech stock market with 7-year Reuters news articles, validate the effectiveness of SARL over existing PM approaches, both in terms of accumulated profits and risk-adjusted profits. Moreover, extensive simulations are conducted to demonstrate the importance of our proposed state augmentation, providing new insights and boosting performance significantly over standard RL-based PM method and other baselines."
  },
  "aaai2020_main_attentionbaseddatahidingwithgenerativeadversarialnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Attention Based Data Hiding with Generative Adversarial Networks ",
    "authors": [
      "Chong Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5463",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5463/5319",
    "published": "2020-02",
    "summary": "Recently, the generative adversarial network is the hotspot in research and industrial areas. Its application on data generation is the most common usage. In this paper, we propose the novel end-to-end framework to extend its application to data hiding area. The discriminative model simulates the detection process, which can help us understand the sensitivity of the cover image to semantic changes. The generative model is to generate the target image which is aligned with the original cover image. An attention model is introduced to generate the attention mask. This mask can help to generate a better target image without perturbation of the spotlight. The introduction of cycle discriminative model and inconsistent loss can help to enhance the quality of the generated target image in the iterative training process. The training dataset is mixed with intact images and attacked images. The mix training process can further improve robustness. Through the qualitative, quantitative experiments and analysis, this novel framework shows compelling performance and advantages over the current state-of-the-art methods in data hiding applications."
  },
  "aaai2020_main_airnetacalibrationmodelforlow-costairmonitoringsensorsusingdualsequenceencodernetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AirNet: A Calibration Model for Low-Cost Air Monitoring Sensors Using Dual Sequence Encoder Networks ",
    "authors": [
      "Haomin Yu",
      "Qingyong Li",
      "Yangli-ao Geng",
      "Yingjun Zhang",
      "Zhi Wei"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5464",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5464/5320",
    "published": "2020-02",
    "summary": "Air pollution monitoring has attracted much attention in recent years. However, accurate and high-resolution monitoring of atmospheric pollution remains challenging. There are two types of devices for air pollution monitoring, i.e., static stations and mobile stations. Static stations can provide accurate pollution measurements but their spatial distribution is sparse because of their high expense. In contrast, mobile stations offer an effective solution for dense placement by utilizing low-cost air monitoring sensors, whereas their measurements are less accurate. In this work, we propose a data-driven model based on deep neural networks, referred to as AirNet, for calibrating low-cost air monitoring sensors. Unlike traditional methods, which treat the calibration task as a point-to-point regression problem, we model it as a sequence-to-point mapping problem by introducing historical data sequences from both a mobile station (to be calibrated) and the referred static station. Specifically, AirNet first extracts an observation trend feature of the mobile station and a reference trend feature of the static station via dual encoder neural networks. Then, a social-based guidance mechanism is designed to select periodic and adjacent features. Finally, the features are fused and fed into a decoder to obtain a calibrated measurement. We evaluate the proposed method on two real-world datasets and compare it with six baselines. The experimental results demonstrate that our method yields the best performance."
  },
  "aaai2020_main_towardshands-freevisualdialoginteractiverecommendation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Hands-Free Visual Dialog Interactive Recommendation ",
    "authors": [
      "Tong Yu",
      "Yilin Shen",
      "Hongxia Jin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5465",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5465/5321",
    "published": "2020-02",
    "summary": "With the recent advances of multimodal interactive recommendations, the users are able to express their preference by natural language feedback to the item images, to find the desired items. However, the existing systems either retrieve only one item or require the user to specify (e.g., by click or touch) the commented items from a list of recommendations in each user interaction. As a result, the users are not hands-free and the recommendations may be impractical. We propose a hands-free visual dialog recommender system to interactively recommend a list of items. At each time, the system shows a list of items with visual appearance. The user can comment on the list in natural language, to describe the desired features they further want. With these multimodal data, the system chooses another list of items to recommend. To understand the user preference from these multimodal data, we develop neural network models which identify the described items among the list and further predict the desired attributes. To achieve efficient interactive recommendations, we leverage the inferred user preference and further develop a novel bandit algorithm. Specifically, to avoid the system exploring more than needed, the desired attributes are utilized to reduce the exploration space. More importantly, to achieve sample efficient learning in this hands-free setting, we derive additional samples from the user's relative preference expressed in natural language and design a pairwise logistic loss in bandit learning. Our bandit model is jointly updated by the pairwise logistic loss on the additional samples derived from natural language feedback and the traditional logistic loss. The empirical results show that the probability of finding the desired items by our system is about 3 times as high as that by the traditional interactive recommenders, after a few user interactions."
  },
  "aaai2020_main_ordermatterssemantic-awareneuralnetworksforbinarycodesimilaritydetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Order Matters: Semantic-Aware Neural Networks for Binary Code Similarity Detection ",
    "authors": [
      "Zeping Yu",
      "Rui Cao",
      "Qiyi Tang",
      "Sen Nie",
      "Junzhou Huang",
      "Shi Wu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5466",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5466/5322",
    "published": "2020-02",
    "summary": "Binary code similarity detection, whose goal is to detect similar binary functions without having access to the source code, is an essential task in computer security. Traditional methods usually use graph matching algorithms, which are slow and inaccurate. Recently, neural network-based approaches have made great achievements. A binary function is first represented as an control-flow graph (CFG) with manually selected block features, and then graph neural network (GNN) is adopted to compute the graph embedding. While these methods are effective and efficient, they could not capture enough semantic information of the binary code. In this paper we propose semantic-aware neural networks to extract the semantic information of the binary code. Specially, we use BERT to pre-train the binary code on one token-level task, one block-level task, and two graph-level tasks. Moreover, we find that the order of the CFG's nodes is important for graph similarity detection, so we adopt convolutional neural network (CNN) on adjacency matrices to extract the order information. We conduct experiments on two tasks with four datasets. The results demonstrate that our method outperforms the state-of-art models."
  },
  "aaai2020_main_metalightvalue-basedmeta-reinforcementlearningfortrafficsignalcontrol": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MetaLight: Value-Based Meta-Reinforcement Learning for Traffic Signal Control ",
    "authors": [
      "Xinshi Zang",
      "Huaxiu Yao",
      "Guanjie Zheng",
      "Nan Xu",
      "Kai Xu",
      "Zhenhui Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5467",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5467/5323",
    "published": "2020-02",
    "summary": "Using reinforcement learning for traffic signal control has attracted increasing interests recently. Various value-based reinforcement learning methods have been proposed to deal with this classical transportation problem and achieved better performances compared with traditional transportation methods. However, current reinforcement learning models rely on tremendous training data and computational resources, which may have bad consequences (e.g., traffic jams or accidents) in the real world. In traffic signal control, some algorithms have been proposed to empower quick learning from scratch, but little attention is paid to learning by transferring and reusing learned experience. In this paper, we propose a novel framework, named as MetaLight, to speed up the learning process in new scenarios by leveraging the knowledge learned from existing scenarios. MetaLight is a value-based meta-reinforcement learning workflow based on the representative gradient-based meta-learning algorithm (MAML), which includes periodically alternate individual-level adaptation and global-level adaptation. Moreover, MetaLight improves the-state-of-the-art reinforcement learning model FRAP in traffic signal control by optimizing its model structure and updating paradigm. The experiments on four real-world datasets show that our proposed MetaLight not only adapts more quickly and stably in new traffic scenarios, but also achieves better performance."
  },
  "aaai2020_main_geometry-constrainedcarrecognitionusinga3dperspectivenetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Geometry-Constrained Car Recognition Using a 3D Perspective Network ",
    "authors": [
      "Zeng Rui",
      "Ge Zongyuan",
      "Denman Simon",
      "Sridharan Sridha",
      "Fookes Clinton"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5468",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5468/5324",
    "published": "2020-02",
    "summary": "We present a novel learning framework for vehicle recognition from a single RGB image. Unlike existing methods which only use attention mechanisms to locate 2D discriminative information, our work learns a novel 3D perspective feature representation of a vehicle, which is then fused with 2D appearance feature to predict the category. The framework is composed of a global network (GN), a 3D perspective network (3DPN), and a fusion network. The GN is used to locate the region of interest (RoI) and generate the 2D global feature. With the assistance of the RoI, the 3DPN estimates the 3D bounding box under the guidance of the proposed vanishing point loss, which provides a perspective geometry constraint. Then the proposed 3D representation is generated by eliminating the viewpoint variance of the 3D bounding box using perspective transformation. Finally, the 3D and 2D feature are fused to predict the category of the vehicle. We present qualitative and quantitative results on the vehicle classification and verification tasks in the BoxCars dataset. The results demonstrate that, by learning such a concise 3D representation, we can achieve superior performance to methods that only use 2D information while retain 3D meaningful information without the challenge of requiring a 3D CAD model."
  },
  "aaai2020_main_generatingadversarialexamplesforholdingrobustnessofsourcecodeprocessingmodels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generating Adversarial Examples for Holding Robustness of Source Code Processing Models ",
    "authors": [
      "Huangzhao Zhang",
      "Zhuo Li",
      "Ge Li",
      "Lei Ma",
      "Yang Liu",
      "Zhi Jin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5469",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5469/5325",
    "published": "2020-02",
    "summary": "Automated processing, analysis, and generation of source code are among the key activities in software and system lifecycle. To this end, while deep learning (DL) exhibits a certain level of capability in handling these tasks, the current state-of-the-art DL models still suffer from non-robust issues and can be easily fooled by adversarial attacks."
  },
  "aaai2020_main_spatio-temporalgraphstructurelearningfortrafficforecasting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Spatio-Temporal Graph Structure Learning for Traffic Forecasting ",
    "authors": [
      "Qi Zhang",
      "Jianlong Chang",
      "Gaofeng Meng",
      "Shiming Xiang",
      "Chunhong Pan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5470",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5470/5326",
    "published": "2020-02",
    "summary": "As an indispensable part in Intelligent Traffic System (ITS), the task of traffic forecasting inherently subjects to the following three challenging aspects. First, traffic data are physically associated with road networks, and thus should be formatted as traffic graphs rather than regular grid-like tensors. Second, traffic data render strong spatial dependence, which implies that the nodes in the traffic graphs usually have complex and dynamic relationships between each other. Third, traffic data demonstrate strong temporal dependence, which is crucial for traffic time series modeling. To address these issues, we propose a novel framework named Structure Learning Convolution (SLC) that enables to extend the traditional convolutional neural network (CNN) to graph domains and learn the graph structure for traffic forecasting. Technically, SLC explicitly models the structure information into the convolutional operation. Under this framework, various non-Euclidean CNN methods can be considered as particular instances of our formulation, yielding a flexible mechanism for learning on the graph. Along this technical line, two SLC modules are proposed to capture the global and local structures respectively and they are integrated to construct an end-to-end network for traffic forecasting. Additionally, in this process, Pseudo three Dimensional convolution (P3D) networks are combined with SLC to capture the temporal dependencies in traffic data. Extensively comparative experiments on six real-world datasets demonstrate our proposed approach significantly outperforms the state-of-the-art ones."
  },
  "aaai2020_main_semi-supervisedhierarchicalrecurrentgraphneuralnetworkforcity-wideparkingavailabilityprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Semi-Supervised Hierarchical Recurrent Graph Neural Network for City-Wide Parking Availability Prediction ",
    "authors": [
      "Weijia Zhang",
      "Hao Liu",
      "Yanchi Liu",
      "Jingbo Zhou",
      "Hui Xiong"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5471",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5471/5327",
    "published": "2020-02",
    "summary": "The ability to predict city-wide parking availability is crucial for the successful development of Parking Guidance and Information (PGI) systems. Indeed, the effective prediction of city-wide parking availability can improve parking efficiency, help urban planning, and ultimately alleviate city congestion. However, it is a non-trivial task for predicting city-wide parking availability because of three major challenges: 1) the non-Euclidean spatial autocorrelation among parking lots, 2) the dynamic temporal autocorrelation inside of and between parking lots, and 3) the scarcity of information about real-time parking availability obtained from real-time sensors (e.g., camera, ultrasonic sensor, and GPS). To this end, we propose  (SHARE) for predicting city-wide parking availability. Specifically, we first propose a hierarchical graph convolution structure to model non-Euclidean spatial autocorrelation among parking lots. Along this line, a contextual graph convolution block and a soft clustering graph convolution block are respectively proposed to capture local and global spatial dependencies between parking lots. Additionally, we adopt a recurrent neural network to incorporate dynamic temporal dependencies of parking lots. Moreover, we propose a parking availability approximation module to estimate missing real-time parking availabilities from both spatial and temporal domain. Finally, experiments on two real-world datasets demonstrate the prediction performance of \\hmgnn outperforms seven state-of-the-art baselines.Hierarchical Recurrent Graph Neural NetworkSemi-supervised "
  },
  "aaai2020_main_shorelinedata-driventhresholdestimationofonlinereservesofcryptocurrencytradingplatforms": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Shoreline: Data-Driven Threshold Estimation of Online Reserves of Cryptocurrency Trading Platforms ",
    "authors": [
      "Xitong Zhang",
      "He Zhu",
      "Jiayu Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5472",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5472/5328",
    "published": "2020-02",
    "summary": "With the proliferation of blockchain projects and applications, cryptocurrency exchanges, which provides exchange services among different types of cryptocurrencies, become pivotal platforms that allow customers to trade digital assets on different blockchains. Because of the anonymity and trustlessness nature of cryptocurrency, one major challenge of crypto-exchanges is asset safety, and all-time amount hacked from crypto-exchanges until 2018 is over $1.5 billion even with carefully maintained secure trading systems. The most critical vulnerability of crypto-exchanges is from the so-called hot wallet, which is used to store a certain portion of the total asset of an exchange and programmatically sign transactions when a withdraw happens. Whenever hackers managed to gain control over the computing infrastructure of the exchange, they usually immediately obtain all the assets in the hot wallet. It is important to develop network security mechanisms. However, the fact is that there is no guarantee that the system can defend all attacks. Thus, accurately controlling the available assets in the hot wallets becomes the key to minimize the risk of running an exchange. However, determining such optimal threshold remains a challenging task because of the complicated dynamics inside exchanges. In this paper, we propose Shoreline, a deep learning-based threshold estimation framework that estimates the optimal threshold of hot wallets from historical wallet activities and dynamic trading networks. We conduct extensive empirical studies on the real trading data from a trading platform and demonstrate the effectiveness of the proposed approach."
  },
  "aaai2020_main_anovellearningframeworkforsampling-basedmotionplanninginautonomousdriving": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Novel Learning Framework for Sampling-Based Motion Planning in Autonomous Driving ",
    "authors": [
      "Yifan Zhang",
      "Jinghuai Zhang",
      "Jindi Zhang",
      "Jianping Wang",
      "Kejie Lu",
      "Jeff Hong"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5473",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5473/5329",
    "published": "2020-02",
    "summary": "Sampling-based motion planning (SBMP) is a major trajectory planning approach in autonomous driving given its high efficiency in practice. As the core of SBMP schemes, sampling strategy holds the key to whether a smooth and collision-free trajectory can be found in real-time. Although some bias sampling strategies have been explored in the literature to accelerate SBMP, the trajectory generated under existing bias sampling strategies may lead to sharp lane changing. To address this issue, we propose a new learning framework for SBMP. Specifically, we develop a novel automatic labeling scheme and a 2-Stage prediction model to improve the accuracy in predicting the intention of surrounding vehicles. We then develop an imitation learning scheme to generate sample points based on the experience of human drivers. Using the prediction results, we design a new bias sampling strategy to accelerate the SBMP algorithm by strategically selecting necessary sample points that can generate a smooth and collision-free trajectory and avoid sharp lane changing. Data-driven experiments show that the proposed sampling strategy outperforms existing sampling strategies, in terms of the computing time, traveling time, and smoothness of the trajectory. The results also show that our scheme is even better than human drivers."
  },
  "aaai2020_main_dynamicmalwareanalysiswithfeatureengineeringandfeaturelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Dynamic Malware Analysis with Feature Engineering and Feature Learning ",
    "authors": [
      "Zhaoqi Zhang",
      "Panpan Qi",
      "Wei Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5474",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5474/5330",
    "published": "2020-02",
    "summary": "Dynamic malware analysis executes the program in an isolated environment and monitors its run-time behaviour (e.g. system API calls) for malware detection. This technique has been proven to be effective against various code obfuscation techniques and newly released (\u201czero-day\u201d) malware. However, existing works typically only consider the API name while ignoring the arguments, or require complex feature engineering operations and expert knowledge to process the arguments. In this paper, we propose a novel and low-cost feature extraction approach, and an effective deep neural network architecture for accurate and fast malware detection. Specifically, the feature representation approach utilizes a feature hashing trick to encode the API call arguments associated with the API name. The deep neural network architecture applies multiple Gated-CNNs (convolutional neural networks) to transform the extracted features of each API call. The outputs are further processed through bidirectional LSTM (long-short term memory networks) to learn the sequential correlation among API calls. Experiments show that our solution outperforms baselines significantly on a large real dataset. Valuable insights about feature engineering and architecture design are derived from the ablation study."
  },
  "aaai2020_main_of-msrnopticalflow-auxiliarymulti-taskregressionnetworkfordirectquantitativemeasurement,segmentationandmotionestimation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " OF-MSRN: Optical Flow-Auxiliary Multi-Task Regression Network for Direct Quantitative Measurement, Segmentation and Motion Estimation ",
    "authors": [
      "Chengqian Zhao",
      "Cheng Feng",
      "Dengwang Li",
      "Shuo Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5475",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5475/5331",
    "published": "2020-02",
    "summary": "Comprehensively analyzing the carotid artery is critically significant to diagnosing and treating cardiovascular diseases. The object of this work is to simultaneously achieve direct quantitative measurement and automated segmentation of the lumen diameter and intima-media thickness as well as the motion estimation of the carotid wall. No work has simultaneously achieved the comprehensive analysis of carotid artery due to three intractable challenges: 1) Tiny intima-media is more challenging to measure and segment; 2) Artifact generated by radial motion restrict the accuracy of measurement and segmentation; 3) Occlusions on diseased carotid walls generate dynamic complexity and indeterminacy. In this paper, we propose a novel optical flow-auxiliary multi-task regression network named OF-MSRN to overcome these challenges. We concatenate multi-scale features to a regression network to simultaneously achieve measurement and segmentation, which makes full use of the potential correlation between the two tasks. More importantly, we creatively explore an optical flow auxiliary module to take advantage of the co-promotion of segmentation and motion estimation to overcome the restrictions of the radial motion. Besides, we evaluate consistency between forward and backward optical flow to improve the accuracy of motion estimation of the diseased carotid wall. Extensive experiments on US sequences of 101 patients demonstrate the superior performance of OF-MSRN on the comprehensive analysis of the carotid artery by utilizing the dual optimization of the optical flow auxiliary module."
  },
  "aaai2020_main_maskgecimprovingneuralgrammaticalerrorcorrectionviadynamicmasking": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MaskGEC: Improving Neural Grammatical Error Correction via Dynamic Masking ",
    "authors": [
      "Zewei Zhao",
      "Houfeng Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5476",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5476/5332",
    "published": "2020-02",
    "summary": "Grammatical error correction (GEC) is a promising natural language processing (NLP) application, whose goal is to change the sentences with grammatical errors into the correct ones. Neural machine translation (NMT) approaches have been widely applied to this translation-like task. However, such methods need a fairly large parallel corpus of error-annotated sentence pairs, which is not easy to get especially in the field of Chinese grammatical error correction. In this paper, we propose a simple yet effective method to improve the NMT-based GEC models by dynamic masking. By adding random masks to the original source sentences dynamically in the training procedure, more diverse instances of error-corrected sentence pairs are generated to enhance the generalization ability of the grammatical error correction model without additional data. The experiments on NLPCC 2018 Task 2 show that our MaskGEC model improves the performance of the neural GEC models. Besides, our single model for Chinese GEC outperforms the current state-of-the-art ensemble system in NLPCC 2018 Task 2 without any extra knowledge."
  },
  "aaai2020_main_gmanagraphmulti-attentionnetworkfortrafficprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " GMAN: A Graph Multi-Attention Network for Traffic Prediction ",
    "authors": [
      "Chuanpan Zheng",
      "Xiaoliang Fan",
      "Cheng Wang",
      "Jianzhong Qi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5477",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5477/5333",
    "published": "2020-02",
    "summary": "Long-term traffic prediction is highly challenging due to the complexity of traffic systems and the constantly changing nature of many impacting factors. In this paper, we focus on the spatio-temporal factors, and propose a graph multi-attention network (GMAN) to predict traffic conditions for time steps ahead at different locations on a road network graph. GMAN adapts an encoder-decoder architecture, where both the encoder and the decoder consist of multiple spatio-temporal attention blocks to model the impact of the spatio-temporal factors on traffic conditions. The encoder encodes the input traffic features and the decoder predicts the output sequence. Between the encoder and the decoder, a transform attention layer is applied to convert the encoded traffic features to generate the sequence representations of future time steps as the input of the decoder. The transform attention mechanism models the direct relationships between historical and future time steps that helps to alleviate the error propagation problem among prediction time steps. Experimental results on two real-world traffic prediction tasks (i.e., traffic volume prediction and traffic speed prediction) demonstrate the superiority of GMAN. In particular, in the 1 hour ahead prediction, GMAN outperforms state-of-the-art methods by up to 4% improvement in MAE measure. The source code is available at https://github.com/zhengchuanpan/GMAN."
  },
  "aaai2020_main_indextrackingwithcardinalityconstraintsastochasticneuralnetworksapproach": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Index Tracking with Cardinality Constraints: A Stochastic Neural Networks Approach ",
    "authors": [
      "Yu Zheng",
      "Bowei Chen",
      "Timothy M. Hospedales",
      "Yongxin Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5478",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5478/5334",
    "published": "2020-02",
    "summary": "Partial (replication) index tracking is a popular passive investment strategy. It aims to replicate the performance of a given index by constructing a tracking portfolio which contains some constituents of the index. The tracking error optimisation is quadratic and NP-hard when taking the \u21130 constraint into account so it is usually solved by heuristic methods such as evolutionary algorithms. This paper introduces a simple, efficient and scalable connectionist model as an alternative. We propose a novel reparametrisation method and then solve the optimisation problem with stochastic neural networks. The proposed approach is examined with S&P 500 index data for more than 10 years and compared with widely used index tracking approaches such as forward and backward selection and the largest market capitalisation methods. The empirical results show our model achieves excellent performance. Compared with the benchmarked models, our model has the lowest tracking error, across a range of portfolio sizes. Meanwhile it offers comparable performance to the others on secondary criteria such as volatility, Sharpe ratio and maximum drawdown."
  },
  "aaai2020_main_iterativelyquestioningandansweringforinterpretablelegaljudgmentprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Iteratively Questioning and Answering for Interpretable Legal Judgment Prediction ",
    "authors": [
      "Haoxi Zhong",
      "Yuzhong Wang",
      "Cunchao Tu",
      "Tianyang Zhang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5479",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5479/5335",
    "published": "2020-02",
    "summary": "Legal Judgment Prediction (LJP) aims to predict judgment results according to the facts of cases. In recent years, LJP has drawn increasing attention rapidly from both academia and the legal industry, as it can provide references for legal practitioners and is expected to promote judicial justice. However, the research to date usually suffers from the lack of interpretability, which may lead to ethical issues like inconsistent judgments or gender bias. In this paper, we present QAjudge, a model based on reinforcement learning to visualize the prediction process and give interpretable judgments. QAjudge follows two essential principles in legal systems across the world: Presumption of Innocence and Elemental Trial. During inference, a Question Net will select questions from the given set and an Answer Net will answer the question according to the fact description. Finally, a Predict Net will produce judgment results based on the answers. Reward functions are designed to minimize the number of questions asked. We conduct extensive experiments on several real-world datasets. Experimental results show that QAjudge can provide interpretable judgments while maintaining comparable performance with other state-of-the-art LJP models. The codes can be found from https://github.com/thunlp/QAjudge."
  },
  "aaai2020_main_riskoracleaminute-levelcitywidetrafficaccidentforecastingframework": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " RiskOracle: A Minute-Level Citywide Traffic Accident Forecasting Framework ",
    "authors": [
      "Zhengyang Zhou",
      "Yang Wang",
      "Xike Xie",
      "Lianliang Chen",
      "Hengchang Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5480",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5480/5336",
    "published": "2020-02",
    "summary": "Real-time traffic accident forecasting is increasingly important for public safety and urban management (e.g., real-time safe route planning and emergency response deployment). Previous works on accident forecasting are often performed on hour levels, utilizing existed neural networks with static region-wise correlations taken into account. However, it is still challenging when the granularity of forecasting step improves as the highly dynamic nature of road network and inherent rareness of accident records in one training sample, which leads to biased results and zero-inflated issue. In this work, we propose a novel framework RiskOracle, to improve the prediction granularity to minute levels. Specifically, we first transform the zero-risk values in labels to fit the training network. Then, we propose the Differential Time-varying Graph neural network (DTGN) to capture the immediate changes of traffic status and dynamic inter-subregion correlations. Furthermore, we adopt multi-task and region selection schemes to highlight citywide most-likely accident subregions, bridging the gap between biased risk values and sporadic accident distribution. Extensive experiments on two real-world datasets demonstrate the effectiveness and scalability of our RiskOracle framework."
  },
  "aaai2020_main_deepreservoircomputingmeets5gmimo-ofdmsystemsinsymboldetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Reservoir Computing Meets 5G MIMO-OFDM Systems in Symbol Detection ",
    "authors": [
      "Zhou Zhou",
      "Lingjia Liu",
      "Vikram Chandrasekhar",
      "Jianzhong Zhang",
      "Yang Yi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5481",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5481/5337",
    "published": "2020-02",
    "summary": "Conventional reservoir computing (RC) is a shallow recurrent neural network (RNN) with fixed high dimensional hidden dynamics and one trainable output layer. It has the nice feature of requiring limited training which is critical for certain applications where training data is extremely limited and costly to obtain. In this paper, we consider two ways to extend the shallow architecture to deep RC to improve the performance without sacrificing the underlying benefit: (1) Extend the output layer to a three layer structure which promotes a joint time-frequency processing to neuron states; (2) Sequentially stack RCs to form a deep neural network. Using the new structure of the deep RC we redesign the physical layer receiver for multiple-input multiple-output with orthogonal frequency division multiplexing (MIMO-OFDM) signals since MIMO-OFDM is a key enabling technology in the 5th generation (5G) cellular network. The combination of RNN dynamics and the time-frequency structure of MIMO-OFDM signals allows deep RC to handle miscellaneous interference in nonlinear MIMO-OFDM channels to achieve improved performance compared to existing techniques. Meanwhile, rather than deep feedforward neural networks which rely on a massive amount of training, our introduced deep RC framework can provide a decent generalization performance using the same amount of pilots as conventional model-based methods in 5G systems. Numerical experiments show that the deep RC based receiver can offer a faster learning convergence and effectively mitigate unknown non-linear radio frequency (RF) distortion yielding twenty percent gain in terms of bit error rate (BER) over the shallow RC structure."
  },
  "aaai2020_main_mixedadascalablealgorithmfordetectingmixedanomaliesinattributedgraphs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MixedAD: A Scalable Algorithm for Detecting Mixed Anomalies in Attributed Graphs ",
    "authors": [
      "Mengxiao Zhu",
      "Haogang Zhu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5482",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5482/5338",
    "published": "2020-02",
    "summary": "Attributed graphs, where nodes are associated with a rich set of attributes, have been widely used in various domains. Among all the nodes, those with patterns that deviate significantly from others are of particular interest. There are mainly two challenges for anomaly detection. For one thing, we often encounter large graphs with lots of nodes and attributes in the real-life scenario, which requires a scalable algorithm. For another, there are anomalies w.r.t. both the structure and attribute in a mixed manner. The algorithm should identify all of them simultaneously. State-of-art algorithms often fail in some respects. In this paper, we propose the scalable algorithm called MixedAD. Theoretical analysis is provided to prove its superiority. Extensive experiments are also conducted on both synthetic and real-life datasets. Specifically, the results show that MixedAD often achieves the F1 scores greater than those of others by at least 25% and runs at least 10 times faster than the others."
  },
  "aaai2020_main_theory-basedcausaltransferintegratinginstance-levelinductionandabstract-levelstructurelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Theory-Based Causal Transfer:Integrating Instance-Level Induction and Abstract-Level Structure Learning ",
    "authors": [
      "Mark Edmonds",
      "Xiaojian Ma",
      "Siyuan Qi",
      "Yixin Zhu",
      "Hongjing Lu",
      "Song-Chun Zhu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5483",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5483/5339",
    "published": "2020-02",
    "summary": "Learning transferable knowledge across similar but different settings is a fundamental component of generalized intelligence. In this paper, we approach the transfer learning challenge from a causal theory perspective. Our agent is endowed with two basic yet general theories for transfer learning: (i) a task shares a common abstract structure that is invariant across domains, and (ii) the behavior of specific features of the environment remain constant across domains. We adopt a Bayesian perspective of causal theory induction and use these theories to transfer knowledge between environments. Given these general theories, the goal is to train an agent by interactively exploring the problem space to (i) discover, form, and transfer useful abstract and structural knowledge, and (ii) induce useful knowledge from the instance-level attributes observed in the environment. A hierarchy of Bayesian structures is used to model abstract-level structural causal knowledge, and an instance-level associative learning scheme learns which specific objects can be used to induce state changes through interaction. This model-learning scheme is then integrated with a model-based planner to achieve a task in the OpenLock environment, a virtual \u201cescape room\u201d with a complex hierarchy that requires agents to reason about an abstract, generalized causal structure. We compare performances against a set of predominate model-free reinforcement learning (RL) algorithms. RL agents showed poor ability transferring learned knowledge across different trials. Whereas the proposed model revealed similar performance trends as human learners, and more importantly, demonstrated transfer behavior across trials and learning situations.1"
  },
  "aaai2020_main_deepspikingdelayedfeedbackreservoirsanditsapplicationinspectrumsensingofmimo-ofdmdynamicspectrumsharing": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Spiking Delayed Feedback Reservoirs and Its Application in Spectrum Sensing of MIMO-OFDM Dynamic Spectrum Sharing ",
    "authors": [
      "Kian Hamedani",
      "Lingjia Liu",
      "Shiya Liu",
      "Haibo He",
      "Yang Yi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5484",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5484/5340",
    "published": "2020-02",
    "summary": "In this paper, we introduce a deep spiking delayed feedback reservoir (DFR) model to combine DFR with spiking neuros: DFRs are a new type of recurrent neural networks (RNNs) that are able to capture the temporal correlations in time series while spiking neurons are energy-efficient and biologically plausible neurons models. The introduced deep spiking DFR model is energy-efficient and has the capability of analyzing time series signals. The corresponding field programmable gate arrays (FPGA)-based hardware implementation of such deep spiking DFR model is introduced and the underlying energy-efficiency and recourse utilization are evaluated. Various spike encoding schemes are explored and the optimal spike encoding scheme to analyze the time series has been identified. To be specific, we evaluate the performance of the introduced model using the spectrum occupancy time series data in MIMO-OFDM based cognitive radio (CR) in dynamic spectrum sharing (DSS) networks. In a MIMO-OFDM DSS system, available spectrum is very scarce and efficient utilization of spectrum is very essential. To improve the spectrum efficiency, the first step is to identify the frequency bands that are not utilized by the existing users so that a secondary user (SU) can use them for transmission. Due to the channel correlation as well as users' activities, there is a significant temporal correlation in the spectrum occupancy behavior of the frequency bands in different time slots. The introduced deep spiking DFR model is used to capture the temporal correlation of the spectrum occupancy time series and predict the idle/busy subcarriers in future time slots for potential spectrum access. Evaluation results suggest that our introduced model achieves higher area under curve (AUC) in the receiver operating characteristic (ROC) curve compared with the traditional energy detection-based strategies and the learning-based support vector machines (SVMs)."
  },
  "aaai2020_main_peopledonotjustplan,theyplantoplan": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " People Do Not Just Plan,They Plan to Plan ",
    "authors": [
      "Mark Ho",
      "David Abel",
      "Jonathan Cohen",
      "Michael Littman",
      "Thomas Griffiths"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5485",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5485/5341",
    "published": "2020-02",
    "summary": "Planning is useful. It lets people take actions that have desirable long-term consequences. But, planning is hard. It requires thinking about consequences, which consumes limited computational and cognitive resources. Thus, people should plan their actions, but they should also be smart about how they deploy resources used for planning their actions. Put another way, people should also \u201cplan their plans\u201d. Here, we formulate this aspect of planning as a meta-reasoning problem and formalize it in terms of a recursive Bellman objective that incorporates both task rewards and information-theoretic planning costs. Our account makes quantitative predictions about how people should plan and meta-plan as a function of the overall structure of a task, which we test in two experiments with human participants. We find that people's reaction times reflect a planned use of information processing, consistent with our account. This formulation of planning to plan provides new insight into the function of hierarchical planning, state abstraction, and cognitive control in both humans and machines."
  },
  "aaai2020_main_effectiveaerobjectclassificationusingsegmentedprobability-maximizationlearninginspikingneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Effective AER Object Classification Using Segmented Probability-Maximization Learning in Spiking Neural Networks ",
    "authors": [
      "Qianhui Liu",
      "Haibo Ruan",
      "Dong Xing",
      "Huajin Tang",
      "Gang Pan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5486",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5486/5342",
    "published": "2020-02",
    "summary": " Address event representation (AER) cameras have recently attracted more attention due to the advantages of high temporal resolution and low power consumption, compared with traditional frame-based cameras. Since AER cameras record the visual input as asynchronous discrete events, they are inherently suitable to coordinate with the spiking neural network (SNN), which is biologically plausible and energy-efficient on neuromorphic hardware. However, using SNN to perform the AER object classification is still challenging, due to the lack of effective learning algorithms for this new representation. To tackle this issue, we propose an AER object classification model using a novel segmented probability-maximization (SPA) learning algorithm. Technically, 1) the SPA learning algorithm iteratively maximizes the probability of the classes that samples belong to, in order to improve the reliability of neuron responses and effectiveness of learning; 2) a peak detection (PD) mechanism is introduced in SPA to locate informative time points segment by segment, based on which information within the whole event stream can be fully utilized by the learning. Extensive experimental results show that, compared to state-of-the-art methods, not only our model is more effective, but also it requires less information to reach a certain level of accuracy."
  },
  "aaai2020_main_biologicallyplausiblesequencelearningwithspikingneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Biologically Plausible Sequence Learning with Spiking Neural Networks ",
    "authors": [
      "Zuozhu Liu",
      "Thiparat Chotibut",
      "Christopher Hillar",
      "Shaowei Lin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5487",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5487/5343",
    "published": "2020-02",
    "summary": "Motivated by the celebrated discrete-time model of nervous activity outlined by McCulloch and Pitts in 1943, we propose a novel continuous-time model, the McCulloch-Pitts network (MPN), for sequence learning in spiking neural networks. Our model has a local learning rule, such that the synaptic weight updates depend only on the information directly accessible by the synapse. By exploiting asymmetry in the connections between binary neurons, we show that MPN can be trained to robustly memorize multiple spatiotemporal patterns of binary vectors, generalizing the ability of the symmetric Hopfield network to memorize static spatial patterns. In addition, we demonstrate that the model can efficiently learn sequences of binary pictures as well as generative models for experimental neural spike-train data. Our learning rule is consistent with spike-timing-dependent plasticity (STDP), thus providing a theoretical ground for the systematic design of biologically inspired networks with large and robust long-range sequence storage capacity."
  },
  "aaai2020_main_transferreinforcementlearningusingoutput-gatedworkingmemory": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Transfer Reinforcement Learning Using Output-Gated Working Memory ",
    "authors": [
      "Arthur Williams",
      "Joshua Phillips"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5488",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5488/5344",
    "published": "2020-02",
    "summary": "Transfer learning allows for knowledge to generalize across tasks, resulting in increased learning speed and/or performance. These tasks must have commonalities that allow for knowledge to be transferred. The main goal of transfer learning in the reinforcement learning domain is to train and learn on one or more source tasks in order to learn a target task that exhibits better performance than if transfer was not used (Taylor and Stone 2009). Furthermore, the use of output-gated neural network models of working memory has been shown to increase generalization for supervised learning tasks (Kriete and Noelle 2011; Kriete et al. 2013). We propose that working memory-based generalization plays a significant role in a model's ability to transfer knowledge successfully across tasks. Thus, we extended the Holographic Working Memory Toolkit (HWMtk) (Dubois and Phillips 2017; Phillips and Noelle 2005) to utilize the generalization benefits of output gating within a working memory system. Finally, the model's utility was tested on a temporally extended, partially observable 5x5 2D grid-world maze task that required the agent to learn 3 tasks over the duration of the training period. The results indicate that the addition of output gating increases the initial learning performance of an agent in target tasks and decreases the learning time required to reach a fixed performance threshold."
  },
  "aaai2020_main_machinenumbersenseadatasetofvisualarithmeticproblemsforabstractandrelationalreasoning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Machine Number Sense: A Dataset of Visual Arithmetic Problems for Abstract and Relational Reasoning ",
    "authors": [
      "Wenhe Zhang",
      "Chi Zhang",
      "Yixin Zhu",
      "Song-Chun Zhu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5489",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5489/5345",
    "published": "2020-02",
    "summary": "As a comprehensive indicator of mathematical thinking and intelligence, the number sense (Dehaene 2011) bridges the induction of symbolic concepts and the competence of problem-solving. To endow such a crucial cognitive ability to machine intelligence, we propose a dataset, Machine Number Sense (MNS), consisting of visual arithmetic problems automatically generated using a grammar model\u2014And-Or Graph (AOG). These visual arithmetic problems are in the form of geometric figures: each problem has a set of geometric shapes as its context and embedded number symbols. Solving such problems is not trivial; the machine not only has to recognize the number, but also to interpret the number with its contexts, shapes, and relations (e.g., symmetry) together with proper operations. We benchmark the MNS dataset using four predominant neural network models as baselines in this visual reasoning task. Comprehensive experiments show that current neural-network-based models still struggle to understand number concepts and relational operations. We show that a simple brute-force search algorithm could work out some of the problems without context information. Crucially, taking geometric context into account by an additional perception module would provide a sharp performance gain with fewer search steps. Altogether, we call for attention in fusing the classic search-based algorithms with modern neural networks to discover the essential number concepts in future research."
  },
  "aaai2020_main_stepspatialtemporalgraphconvolutionalnetworksforemotionperceptionfromgaits": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " STEP: Spatial Temporal Graph Convolutional Networks for Emotion Perception from Gaits ",
    "authors": [
      "Uttaran Bhattacharya",
      "Trisha Mittal",
      "Rohan Chandra",
      "Tanmay Randhavane",
      "Aniket Bera",
      "Dinesh Manocha"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5490",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5490/5346",
    "published": "2020-02",
    "summary": "We present a novel classifier network called STEP, to classify perceived human emotion from gaits, based on a Spatial Temporal Graph Convolutional Network (ST-GCN) architecture. Given an RGB video of an individual walking, our formulation implicitly exploits the gait features to classify the perceived emotion of the human into one of four emotions: happy, sad, angry, or neutral. We train STEP on annotated real-world gait videos, augmented with annotated synthetic gaits generated using a novel generative network called STEP-Gen, built on an ST-GCN based Conditional Variational Autoencoder (CVAE). We incorporate a novel push-pull regularization loss in the CVAE formulation of STEP-Gen to generate realistic gaits and improve the classification accuracy of STEP. We also release a novel dataset (E-Gait), which consists of 4,227 human gaits annotated with perceived emotions along with thousands of synthetic gaits. In practice, STEP can learn the affective features and exhibits classification accuracy of 88% on E-Gait, which is 14\u201330% more accurate over prior methods."
  },
  "aaai2020_main_synch-graphmultisensoryemotionrecognitionthroughneuralsynchronyviagraphconvolutionalnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Synch-Graph: Multisensory Emotion Recognition Through Neural Synchrony via Graph Convolutional Networks ",
    "authors": [
      "Esma Mansouri-Benssassi",
      "Juan Ye"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5491",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5491/5347",
    "published": "2020-02",
    "summary": "Human emotions are essentially multisensory, where emotional states are conveyed through multiple modalities such as facial expression, body language, and non-verbal and verbal signals. Therefore having multimodal or multisensory learning is crucial for recognising emotions and interpreting social signals. Existing multisensory emotion recognition approaches focus on extracting features on each modality, while ignoring the importance of constant interaction and co-learning between modalities. In this paper, we present a novel bio-inspired approach based on neural synchrony in audio-visual multisensory integration in the brain, named Synch-Graph. We model multisensory interaction using spiking neural networks (SNN) and explore the use of Graph Convolutional Networks (GCN) to represent and learn neural synchrony patterns. We hypothesise that modelling interactions between modalities will improve the accuracy of emotion recognition. We have evaluated Synch-Graph on two state-of-the-art datasets and achieved an overall accuracy of 98.3% and 96.82%, which are significantly higher than the existing techniques."
  },
  "aaai2020_main_m3ermultiplicativemultimodalemotionrecognitionusingfacial,textual,andspeechcues": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " M3ER: Multiplicative Multimodal Emotion Recognition using Facial, Textual, and Speech Cues ",
    "authors": [
      "Trisha Mittal",
      "Uttaran Bhattacharya",
      "Rohan Chandra",
      "Aniket Bera",
      "Dinesh Manocha"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5492",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5492/5348",
    "published": "2020-02",
    "summary": "We present M3ER, a learning-based method for emotion recognition from multiple input modalities. Our approach combines cues from multiple co-occurring modalities (such as face, text, and speech) and also is more robust than other methods to sensor noise in any of the individual modalities. M3ER models a novel, data-driven multiplicative fusion method to combine the modalities, which learn to emphasize the more reliable cues and suppress others on a per-sample basis. By introducing a check step which uses Canonical Correlational Analysis to differentiate between ineffective and effective modalities, M3ER is robust to sensor noise. M3ER also generates proxy features in place of the ineffectual modalities. We demonstrate the efficiency of our network through experimentation on two benchmark datasets, IEMOCAP and CMU-MOSEI. We report a mean accuracy of 82.7% on IEMOCAP and 89.0% on CMU-MOSEI, which, collectively, is an improvement of about 5% over prior work."
  },
  "aaai2020_main_tosignalornottosignalexploitinguncertainreal-timeinformationinsignalinggamesforsecurityandsustainability": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " To Signal or Not To Signal: Exploiting Uncertain Real-Time Information in Signaling Games for Security and Sustainability ",
    "authors": [
      "Elizabeth Bondi",
      "Hoon Oh",
      "Haifeng Xu",
      "Fei Fang",
      "Bistra Dilkina",
      "Milind Tambe"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5493",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5493/5349",
    "published": "2020-02",
    "summary": "Motivated by real-world deployment of drones for conservation, this paper advances the state-of-the-art in security games with signaling. The well-known defender-attacker security games framework can help in planning for such strategic deployments of sensors and human patrollers, and warning signals to ward off adversaries. However, we show that defenders can suffer significant losses when ignoring real-world uncertainties despite carefully planned security game strategies with signaling. In fact, defenders may perform worse than forgoing drones completely in this case. We address this shortcoming by proposing a novel game model that integrates signaling and sensor uncertainty; perhaps surprisingly, we show that defenders can still perform well via a signaling strategy that exploits uncertain real-time information. For example, even in the presence of uncertainty, the defender still has an informational advantage in knowing that she has or has not actually detected the attacker; and she can design a signaling scheme to \u201cmislead\u201d the attacker who is uncertain as to whether he has been detected. We provide theoretical results, a novel algorithm, scale-up techniques, and experimental results from simulation based on our ongoing deployment of a conservation drone system in South Africa."
  },
  "aaai2020_main_end-to-endgame-focusedlearningofadversarybehaviorinsecuritygames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " End-to-End Game-Focused Learning of Adversary Behavior in Security Games ",
    "authors": [
      "Andrew Perrault",
      "Bryan Wilder",
      "Eric Ewing",
      "Aditya Mate",
      "Bistra Dilkina",
      "Milind Tambe"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5494",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5494/5350",
    "published": "2020-02",
    "summary": "Stackelberg security games are a critical tool for maximizing the utility of limited defense resources to protect important targets from an intelligent adversary. Motivated by green security, where the defender may only observe an adversary's response to defense on a limited set of targets, we study the problem of learning a defense that generalizes well to a new set of targets with novel feature values and combinations. Traditionally, this problem has been addressed via a two-stage approach where an adversary model is trained to maximize predictive accuracy without considering the defender's optimization problem. We develop an end-to-end game-focused approach, where the adversary model is trained to maximize a surrogate for the defender's expected utility. We show both in theory and experimental results that our game-focused approach achieves higher defender expected utility than the two-stage alternative when there is limited data."
  },
  "aaai2020_main_modelingelectricalmotordynamicsusingencoder-decoderwithrecurrentskipconnection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Modeling Electrical Motor Dynamics Using Encoder-Decoder with Recurrent Skip Connection ",
    "authors": [
      "Sagar Verma",
      "Nicolas Henwood",
      "Marc Castella",
      "Francois Malrait",
      "Jean-Christophe Pesquet"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5495",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5495/5351",
    "published": "2020-02",
    "summary": "Electrical motors are the most important source of mechanical energy in the industrial world. Their modeling traditionally relies on a physics-based approach, which aims at taking their complex internal dynamics into account. In this paper, we explore the feasibility of modeling the dynamics of an electrical motor by following a data-driven approach, which uses only its inputs and outputs and does not make any assumption on its internal behaviour. We propose a novel encoder-decoder architecture which benefits from recurrent skip connections. We also propose a novel loss function that takes into account the complexity of electrical motor quantities and helps in avoiding model bias. We show that the proposed architecture can achieve a good learning performance on our high-frequency high-variance datasets. Two datasets are considered: the first one is generated using a simulator based on the physics of an induction motor and the second one is recorded from an industrial electrical motor. We benchmark our solution using variants of traditional neural networks like feedforward, convolutional, and recurrent networks. We evaluate various design choices of our architecture and compare it to the baselines. We show the domain adaptation capability of our model to learn dynamics just from simulated data by testing it on the raw sensor data. We finally show the effect of signal complexity on the proposed method ability to model temporal dynamics."
  },
  "aaai2020_main_tensorizedlstmwithadaptivesharedmemoryforlearningtrendsinmultivariatetimeseries": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Tensorized LSTM with Adaptive Shared Memory for Learning Trends in Multivariate Time Series ",
    "authors": [
      "Dongkuan Xu",
      "Wei Cheng",
      "Bo Zong",
      "Dongjin Song",
      "Jingchao Ni",
      "Wenchao Yu",
      "Yanchi Liu",
      "Haifeng Chen",
      "Xiang Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5496",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5496/5352",
    "published": "2020-02",
    "summary": "The problem of learning and forecasting underlying trends in time series data arises in a variety of applications, such as traffic management, energy optimization, etc. In literature, a trend in time series is characterized by the slope and duration, and its prediction is then to forecast the two values of the subsequent trend given historical data of the time series. For this problem, existing approaches mainly deal with the case in univariate time series. However, in many real-world applications, there are multiple variables at play, and handling all of them at the same time is crucial for an accurate prediction. A natural way is to employ multi-task learning (MTL) techniques in which the trend learning of each time series is treated as a task. The key point of MTL is to learn task relatedness to achieve better parameter sharing, which however is challenging in trend prediction task. First, effectively modeling the complex temporal patterns in different tasks is hard as the temporal and spatial dimensions are entangled. Second, the relatedness among tasks may change over time. In this paper, we propose a neural network, DeepTrends, for multivariate time series trend prediction. The core module of DeepTrends is a tensorized LSTM with adaptive shared memory (TLASM). TLASM employs the tensorized LSTM to model the temporal patterns of long-term trend sequences in an MTL setting. With an adaptive shared memory, TLASM is able to learn the relatedness among tasks adaptively, based upon which it can dynamically vary degrees of parameter sharing among tasks. To further consider short-term patterns, DeepTrends utilizes a multi-task 1dCNN to learn the local time series features, and employs a task-specific sub-network to learn a mixture of long-term and short-term patterns for trend prediction. Extensive experiments on real datasets demonstrate the effectiveness of the proposed model."
  },
  "aaai2020_main_deepunsupervisedbinarycodingnetworksformultivariatetimeseriesretrieval": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Unsupervised Binary Coding Networks for Multivariate Time Series Retrieval ",
    "authors": [
      "Dixian Zhu",
      "Dongjin Song",
      "Yuncong Chen",
      "Cristian Lumezanu",
      "Wei Cheng",
      "Bo Zong",
      "Jingchao Ni",
      "Takehiko Mizoguchi",
      "Tianbao Yang",
      "Haifeng Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5497",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5497/5353",
    "published": "2020-02",
    "summary": "Multivariate time series data are becoming increasingly ubiquitous in varies real-world applications such as smart city, power plant monitoring, wearable devices, etc. Given the current time series segment, how to retrieve similar segments within the historical data in an efficient and effective manner is becoming increasingly important. As it can facilitate underlying applications such as system status identification, anomaly detection, etc. Despite the fact that various binary coding techniques can be applied to this task, few of them are specially designed for multivariate time series data in an unsupervised setting. To this end, we present Deep Unsupervised Binary Coding Networks (DUBCNs) to perform multivariate time series retrieval. DUBCNs employ the Long Short-Term Memory (LSTM) encoder-decoder framework to capture the temporal dynamics within the input segment and consist of three key components, i.e., a temporal encoding mechanism to capture the temporal order of different segments within a mini-batch, a clustering loss on the hidden feature space to capture the hidden feature structure, and an adversarial loss based upon Generative Adversarial Networks (GANs) to enhance the generalization capability of the generated binary codes. Thoroughly empirical studies on three public datasets demonstrated that the proposed DUBCNs can outperform state-of-the-art unsupervised binary coding techniques."
  },
  "aaai2020_main_improvedfilteringfortheeuclideantravelingsalespersonprobleminclp(fd)": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Improved Filtering for the Euclidean Traveling Salesperson Problem in CLP(FD) ",
    "authors": [
      "Alessandro Bertagnon",
      "Marco Gavanelli"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5498",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5498/5354",
    "published": "2020-02",
    "summary": "The Traveling Salesperson Problem (TSP) is one of the best-known problems in computer science. The Euclidean TSP is a special case in which each node is identified by its coordinates on the plane and the Euclidean distance is used as cost function."
  },
  "aaai2020_main_chainlengthandcspslearnablewithfewqueries": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Chain Length and CSPs Learnable with Few Queries ",
    "authors": [
      "Christian Bessiere",
      "C\u00e9ment Carbonnel",
      "George Katsirelos"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5499",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5499/5355",
    "published": "2020-02",
    "summary": "The goal of constraint acquisition is to learn exactly a constraint network given access to an oracle that answers truthfully certain types of queries. In this paper we focus on partial membership queries and initiate a systematic investigation of the learning complexity of constraint languages. First, we use the notion of chain length to show that a wide class of languages can be learned with as few as O(n log(n)) queries. Then, we combine this result with generic lower bounds to derive a dichotomy in the learning complexity of binary languages. Finally, we identify a class of ternary languages that eludes our framework and hints at new research directions."
  },
  "aaai2020_main_guidingcdclsatsearchviarandomexplorationamidconflictdepression": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Guiding CDCL SAT Search via Random Exploration amid Conflict Depression ",
    "authors": [
      "Md Solimul Chowdhury",
      "Martin M\u00fcller",
      "Jia You"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5500",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5500/5356",
    "published": "2020-02",
    "summary": "The efficiency of Conflict Driven Clause Learning (CDCL) SAT solving depends crucially on finding conflicts at a fast rate. State-of-the-art CDCL branching heuristics such as VSIDS, CHB and LRB conform to this goal. We take a closer look at the way in which conflicts are generated over the course of a CDCL SAT search. Our study of the VSIDS branching heuristic shows that conflicts are typically generated in short bursts, followed by what we call a conflict depression phase in which the search fails to generate any conflicts in a span of decisions. The lack of conflict indicates that the variables that are currently ranked highest by the branching heuristic fail to generate conflicts. Based on this analysis, we propose an exploration strategy, called expSAT, which randomly samples variable selection sequences in order to learn an updated heuristic from the generated conflicts. The goal is to escape from conflict depressions expeditiously. The branching heuristic deployed in expSAT combines these updates with the standard VSIDS activity scores. An extensive empirical evaluation with four state-of-the-art CDCL SAT solvers demonstrates good-to-strong performance gains with the expSAT approach."
  },
  "aaai2020_main_representativesolutionsforbi-objectiveoptimisation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Representative Solutions for Bi-Objective Optimisation ",
    "authors": [
      "Emir Demirovi?",
      "Nicolas Schwind"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5501",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5501/5357",
    "published": "2020-02",
    "summary": "Bi-objective optimisation aims to optimise two generally competing objective functions. Typically, it consists in computing the set of nondominated solutions, called the Pareto front. This raises two issues: 1) time complexity, as the Pareto front in general can be infinite for continuous problems and exponentially large for discrete problems, and 2) lack of decisiveness. This paper focusses on the computation of a small, \u201crelevant\u201d subset of the Pareto front called the representative set, which provides meaningful trade-offs between the two objectives. We introduce a procedure which, given a pre-computed Pareto front, computes a representative set in polynomial time, and then we show how to adapt it to the case where the Pareto front is not provided. This has three important consequences for computing the representative set: 1) does not require the whole Pareto front to be provided explicitly, 2) can be done in polynomial time for bi-objective mixed-integer linear programs, and 3) only requires a polynomial number of solver calls for bi-objective problems, as opposed to the case where a higher number of objectives is involved. We implement our algorithm and empirically illustrate the efficiency on two families of benchmarks."
  },
  "aaai2020_main_dynamicprogrammingforpredict+optimise": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Dynamic Programming for Predict+Optimise ",
    "authors": [
      "Emir Demirovi?",
      "Peter J. Stuckey",
      "Tias Guns",
      "James Bailey",
      "Christopher Leckie",
      "Kotagiri Ramamohanarao",
      "Jeffrey Chan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5502",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5502/5358",
    "published": "2020-02",
    "summary": "We study the predict+optimise problem, where machine learning and combinatorial optimisation must interact to achieve a common goal. These problems are important when optimisation needs to be performed on input parameters that are not fully observed but must instead be estimated using machine learning. We provide a novel learning technique for predict+optimise to directly reason about the underlying combinatorial optimisation problem, offering a meaningful integration of machine learning and optimisation. This is done by representing the combinatorial problem as a piecewise linear function parameterised by the coefficients of the learning model and then iteratively performing coordinate descent on the learning coefficients. Our approach is applicable to linear learning functions and any optimisation problem solvable by dynamic programming. We illustrate the effectiveness of our approach on benchmarks from the literature."
  },
  "aaai2020_main_acceleratingprimalsolutionfindingsformixedintegerprogramsbasedonsolutionprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Accelerating Primal Solution Findings for Mixed Integer Programs Based on Solution Prediction ",
    "authors": [
      "Jian-Ya Ding",
      "Chao Zhang",
      "Lei Shen",
      "Shengyin Li",
      "Bing Wang",
      "Yinghui Xu",
      "Le Song"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5503",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5503/5359",
    "published": "2020-02",
    "summary": "Mixed Integer Programming (MIP) is one of the most widely used modeling techniques for combinatorial optimization problems. In many applications, a similar MIP model is solved on a regular basis, maintaining remarkable similarities in model structures and solution appearances but differing in formulation coefficients. This offers the opportunity for machine learning methods to explore the correlations between model structures and the resulting solution values. To address this issue, we propose to represent a MIP instance using a tripartite graph, based on which a Graph Convolutional Network (GCN) is constructed to predict solution values for binary variables. The predicted solutions are used to generate a local branching type cut which can be either treated as a global (invalid) inequality in the formulation resulting in a heuristic approach to solve the MIP, or as a root branching rule resulting in an exact approach. Computational evaluations on 8 distinct types of MIP problems show that the proposed framework improves the primal solution finding performance significantly on a state-of-the-art open-source MIP solver."
  },
  "aaai2020_main_optimizationofchance-constrainedsubmodularfunctions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Optimization of Chance-Constrained Submodular Functions ",
    "authors": [
      "Benjamin Doerr",
      "Carola Doerr",
      "Aneta Neumann",
      "Frank Neumann",
      "Andrew Sutton"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5504",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5504/5360",
    "published": "2020-02",
    "summary": " Submodular optimization plays a key role in many real-world problems. In many real-world scenarios, it is also necessary to handle uncertainty, and potentially disruptive events that violate constraints in stochastic settings need to be avoided. In this paper, we investigate submodular optimization problems with chance constraints. We provide a first analysis on the approximation behavior of popular greedy algorithms for submodular problems with chance constraints. Our results show that these algorithms are highly effective when using surrogate functions that estimate constraint violations based on Chernoff bounds. Furthermore, we investigate the behavior of the algorithms on popular social network problems and show that high quality solutions can still be obtained even if there are strong restrictions imposed by the chance constraint."
  },
  "aaai2020_main_addmcweightedmodelcountingwithalgebraicdecisiondiagrams": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ADDMC: Weighted Model Counting with Algebraic Decision Diagrams ",
    "authors": [
      "Jeffrey Dudek",
      "Vu Phan",
      "Moshe Vardi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5505",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5505/5361",
    "published": "2020-02",
    "summary": "We present an algorithm to compute exact literal-weighted model counts of Boolean formulas in Conjunctive Normal Form. Our algorithm employs dynamic programming and uses Algebraic Decision Diagrams as the main data structure. We implement this technique in ADDMC, a new model counter. We empirically evaluate various heuristics that can be used with ADDMC. We then compare ADDMC to four state-of-the-art weighted model counters (Cachet, c2d, d4, and miniC2D) on 1914 standard model counting benchmarks and show that ADDMC significantly improves the virtual best solver."
  },
  "aaai2020_main_modellingandsolvingonlineoptimisationproblems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Modelling and Solving Online Optimisation Problems ",
    "authors": [
      "Alexander Ek",
      "Maria Garcia de la Banda",
      "Andreas Schutt",
      "Peter J. Stuckey",
      "Guido Tack"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5506",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5506/5362",
    "published": "2020-02",
    "summary": " Many optimisation problems are of an online\u2014also called dynamic\u2014nature, where new information is expected to arrive and the problem must be resolved in an ongoing fashion to (a) improve or revise previous decisions and (b) take new ones. Typically, building an online decision-making system requires substantial ad-hoc coding to ensure the offline version of the optimisation problem is continually adjusted and resolved. This paper defines a general framework for automatically solving online optimisation problems. This is achieved by extending a model of the offline optimisation problem, from which an online version is automatically constructed, thus requiring no further modelling effort. In doing so, it formalises many of the aspects that arise in online optimisation problems. The same framework can be applied for automatically creating sliding-window solving approaches for problems that have a large time horizon. Experiments show we can automatically create efficient online and sliding-window solutions to optimisation problems."
  },
  "aaai2020_main_justifyingalldifferencesusingpseudo-booleanreasoning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Justifying All Differences Using Pseudo-Boolean Reasoning ",
    "authors": [
      "Jan Elffers",
      "Stephan Gocht",
      "Ciaran McCreesh",
      "Jakob Nordstom"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5507",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5507/5363",
    "published": "2020-02",
    "summary": "Constraint programming solvers support rich global constraints and propagators, which make them both powerful and hard to debug. In the Boolean satisfiability community, proof-logging is the standard solution for generating trustworthy outputs, and this has become key to the social acceptability of computer-generated proofs. However, reusing this technology for constraint programming requires either much weaker propagation, or an impractical blowup in proof length. This paper demonstrates that simple, clean, and efficient proof logging is still possible for the all-different constraint, through pseudo-Boolean reasoning. We explain how such proofs can be expressed and verified mechanistically, describe an implementation, and discuss the broader implications for proof logging in constraint programming."
  },
  "aaai2020_main_acardinalimprovementtopseudo-booleansolving": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Cardinal Improvement to Pseudo-Boolean Solving ",
    "authors": [
      "Jan Elffers",
      "Jakob Nordstr\u00f6m"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5508",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5508/5364",
    "published": "2020-02",
    "summary": " Pseudo-Boolean solvers hold out the theoretical potential of exponential improvements over conflict-driven clause learning (CDCL) SAT solvers, but in practice perform very poorly if the input is given in the standard conjunctive normal form (CNF) format. We present a technique to remedy this problem by recovering cardinality constraints from CNF on the fly during search. This is done by collecting potential building blocks of cardinality constraints during propagation and combining these blocks during conflict analysis. Our implementation has a non-negligible but manageable overhead when detection is not successful, and yields significant gains for some SAT competition and crafted benchmarks for which pseudo-Boolean reasoning is stronger than CDCL. It also boosts performance for some native pseudo-Boolean formulas where this approach helps to improve learned constraints."
  },
  "aaai2020_main_mipaalmixedintegerprogramasalayer": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MIPaaL: Mixed Integer Program as a Layer ",
    "authors": [
      "Aaron Ferber",
      "Bryan Wilder",
      "Bistra Dilkina",
      "Milind Tambe"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5509",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5509/5365",
    "published": "2020-02",
    "summary": "Machine learning components commonly appear in larger decision-making pipelines; however, the model training process typically focuses only on a loss that measures average accuracy between predicted values and ground truth values. Decision-focused learning explicitly integrates the downstream decision problem when training the predictive model, in order to optimize the quality of decisions induced by the predictions. It has been successfully applied to several limited combinatorial problem classes, such as those that can be expressed as linear programs (LP), and submodular optimization. However, these previous applications have uniformly focused on problems with simple constraints. Here, we enable decision-focused learning for the broad class of problems that can be encoded as a mixed integer linear program (MIP), hence supporting arbitrary linear constraints over discrete and continuous variables. We show how to differentiate through a MIP by employing a cutting planes solution approach, an algorithm that iteratively tightens the continuous relaxation by adding constraints removing fractional solutions. We evaluate our new end-to-end approach on several real world domains and show that it outperforms the standard two phase approaches that treat prediction and optimization separately, as well as a baseline approach of simply applying decision-focused learning to the LP relaxation of the MIP. Lastly, we demonstrate generalization performance in several transfer learning tasks."
  },
  "aaai2020_main_usingapproximationwithinconstraintprogrammingtosolvetheparallelmachineschedulingproblemwithadditionalunitresources": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Using Approximation within Constraint Programming to Solve the Parallel Machine Scheduling Problem with Additional Unit Resources ",
    "authors": [
      "Arthur Godet",
      "Xavier Lorca",
      "Emmanuel Hebrard",
      "Gilles Simonin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5510",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5510/5366",
    "published": "2020-02",
    "summary": "In this paper, we consider the Parallel Machine Scheduling Problem with Additional Unit Resources, which consists in scheduling a set of n jobs on m parallel unrelated machines and subject to exactly one of r unit resources. This problem arises from the download of acquisitions from satellites to ground stations. We first introduce two baseline constraint models for this problem. Then, we build on an approximation algorithm for this problem, and we discuss about the efficiency of designing an improved constraint model based on these approximation results. In particular, we introduce new constraints that restrict search to executions of the approximation algorithm. Finally, we report experimental data demonstrating that this model significantly outperforms the two reference models."
  },
  "aaai2020_main_spanastochasticprojectedapproximatenewtonmethod": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " SPAN: A Stochastic Projected Approximate Newton Method ",
    "authors": [
      "Xunpeng Huang",
      "Xianfeng Liang",
      "Zhengyang Liu",
      "Lei Li",
      "Yue Yu",
      "Yitan Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5511",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5511/5367",
    "published": "2020-02",
    "summary": "Second-order optimization methods have desirable convergence properties. However, the exact Newton method requires expensive computation for the Hessian and its inverse. In this paper, we propose SPAN, a novel approximate and fast Newton method. SPAN computes the inverse of the Hessian matrix via low-rank approximation and stochastic Hessian-vector products. Our experiments on multiple benchmark datasets demonstrate that SPAN outperforms existing first-order and second-order optimization methods in terms of the convergence wall-clock time. Furthermore, we provide a theoretical analysis of the per-iteration complexity, the approximation error, and the convergence rate. Both the theoretical analysis and experimental results show that our proposed method achieves a better trade-off between the convergence rate and the per-iteration efficiency."
  },
  "aaai2020_main_modellingdiversityofsolutions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Modelling Diversity of Solutions ",
    "authors": [
      "Linnea Ingmar",
      "Maria Garcia de la Banda",
      "Peter J. Stuckey",
      "Guido Tack"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5512",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5512/5368",
    "published": "2020-02",
    "summary": " For many combinatorial problems, finding a single solution is not enough. This is clearly the case for multi-objective optimization problems, as they have no single \u201cbest solution\u201d and, thus, it is useful to find a representation of the non-dominated solutions (the Pareto frontier). However, it also applies to single objective optimization problems, where one may be interested in finding several (close to) optimal solutions that illustrate some form of diversity. The same applies to satisfaction problems. This is because models usually idealize the problem in some way, and a diverse pool of solutions may provide a better choice with respect to considerations that are omitted or simplified in the model. This paper describes a general framework for finding k diverse solutions to a combinatorial problem (be it satisfaction, single-objective or multi-objective), various approaches to solve problems in the framework, their implementations, and an experimental evaluation of their practicality."
  },
  "aaai2020_main_incrementalsymmetrybreakingconstraintsforgraphsearchproblems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Incremental Symmetry Breaking Constraints for Graph Search Problems ",
    "authors": [
      "Avraham Itzhakov",
      "Michael Codish"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5513",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5513/5369",
    "published": "2020-02",
    "summary": " This paper introduces incremental symmetry breaking constraints for graph search problems which are complete and compact. We show that these constraints can be computed incrementally: A symmetry breaking constraint for order n graphs can be extended to one for order n + 1 graphs. Moreover, these constraints induce a special property on their canonical solutions: An order n canonical graph contains a canonical subgraph on the first k vertices for every 1 \u2264 k \u2264 n. This facilitates a \u201cgenerate and extend\u201d paradigm for parallel graph search problem solving: To solve a graph search problem \u03c6 on order n graphs, first generate the canonical graphs of some order k < n. Then, compute canonical solutions for \u03c6 by extending, in parallel, each canonical order k graph together with suitable symmetry breaking constraints. The contribution is that the proposed symmetry breaking constraints enable us to extend the order k canonical graphs to order n canonical solutions. We demonstrate our approach through its application on two hard graph search problems."
  },
  "aaai2020_main_findingmostcompatiblephylogenetictreesovermulti-statecharacters": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Finding Most Compatible Phylogenetic Trees over Multi-State Characters ",
    "authors": [
      "Tuukka Korhonen",
      "Matti J\u00e4rvisalo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5514",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5514/5370",
    "published": "2020-02",
    "summary": "The reconstruction of the evolutionary tree of a set of species based on qualitative attributes is a central problem in phylogenetics. In the NP-hard perfect phylogeny problem the input is a set of taxa (species) and characters (attributes) on them, and the task is to find an evolutionary tree that describes the evolution of the taxa so that each character state evolves only once. However, in practical situations a perfect phylogeny rarely exists, motivating the maximum compatibility problem of finding the largest subset of characters admitting a perfect phylogeny. Various declarative approaches, based on applying integer programming (IP), answer set programming (ASP) and pseudo-Boolean optimization (PBO) solvers, have been proposed for maximum compatibility. In this work we develop a new hybrid approach to solving maximum compatibility for multi-state characters, making use of both declarative optimization techniques (specifically maximum satisfiability, MaxSAT) and an adaptation of the Bouchitt'e-Todinca approach to triangulation-based graph optimization problems. Empirically our approach outperforms in scalability the earlier proposed approaches w.r.t. various parameters underlying the problem."
  },
  "aaai2020_main_fouriersatafourierexpansion-basedalgebraicframeworkforsolvinghybridbooleanconstraints": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " FourierSAT: A Fourier Expansion-Based Algebraic Framework for Solving Hybrid Boolean Constraints ",
    "authors": [
      "Anastasios Kyrillidis",
      "Anshumali Shrivastava",
      "Moshe Vardi",
      "Zhiwei Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5515",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5515/5371",
    "published": "2020-02",
    "summary": "The Boolean SATisfiability problem (SAT) is of central importance in computer science. Although SAT is known to be NP-complete, progress on the engineering side\u2014especially that of Conflict-Driven Clause Learning (CDCL) and Local Search SAT solvers\u2014has been remarkable. Yet, while SAT solvers, aimed at solving industrial-scale benchmarks in Conjunctive Normal Form (CNF), have become quite mature, SAT solvers that are effective on other types of constraints (e.g., cardinality constraints and XORs) are less well-studied; a general approach to handling non-CNF constraints is still lacking. In addition, previous work indicated that for specific classes of benchmarks, the running time of extant SAT solvers depends heavily on properties of the formula and details of encoding, instead of the scale of the benchmarks, which adds uncertainty to expectations of running time."
  },
  "aaai2020_main_augmentingthepowerof(partial)maxsatresolutionwithextension": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Augmenting the Power of (Partial) MaxSat Resolution with Extension ",
    "authors": [
      "Javier Larrosa",
      "Emma Rollon"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5516",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5516/5372",
    "published": "2020-02",
    "summary": "The refutation power of SAT and MaxSAT resolution is challenged by problems like the soft and hard Pigeon Hole Problem PHP for which short refutations do not exist. In this paper we augment the MaxSAT resolution proof system with an extension rule. The new proof system MaxResE is sound and complete, and more powerful than plain MaxSAT resolution, since it can refute the soft and hard PHP in polynomial time. We show that MaxResE refutations actually subtract lower bounds from the objective function encoded by the formulas. The resulting formula is the residual after the lower bound extraction. We experimentally show that the residual of the soft PHP (once its necessary cost of 1 has been efficiently subtracted with MaxResE) is a concise, easy to solve, satisfiable problem."
  },
  "aaai2020_main_solvingsetcoveranddominatingsetviamaximumsatisfiability": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Solving Set Cover and Dominating Set via Maximum Satisfiability ",
    "authors": [
      "Zhendong Lei",
      "Shaowei Cai"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5517",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5517/5373",
    "published": "2020-02",
    "summary": "The Set Covering Problem (SCP) and Dominating Set Problem (DSP) are NP-hard and have many real world applications. SCP and DSP can be encoded into Maximum Satisfiability (MaxSAT) naturally and the resulting instances share a special structure. In this paper, we develop an efficient local search solver for MaxSAT instances of this kind. Our algorithm contains three phrase: construction, local search and recovery. In construction phrase, we simplify the instance by three reduction rules and construct an initial solution by a greedy heuristic. The initial solution is improved during the local search phrase, which exploits the feature of such instances in the scoring function and the variable selection heuristic. Finally, the corresponding solution of original instance is recovered in the recovery phrase. Experiment results on a broad range of large scale instances of SCP and DSP show that our algorithm significantly outperforms state of the art solvers for SCP, DSP and MaxSAT."
  },
  "aaai2020_main_findinggoodsubtreesforconstraintoptimizationproblemsusingfrequentpatternmining": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Finding Good Subtrees for Constraint Optimization Problems Using Frequent Pattern Mining ",
    "authors": [
      "Hongbo Li",
      "Jimmy Lee",
      "He Mi",
      "Minghao Yin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5518",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5518/5374",
    "published": "2020-02",
    "summary": "Making good decisions at the top of a search tree is important for finding good solutions early in constraint optimization. In this paper, we propose a method employing frequent pattern mining (FPM), a classic datamining technique, to find good subtrees for solving constraint optimization problems. We demonstrate that applying FPM in a small number of random high-quality feasible solutions enables us to identify subtrees containing optimal solutions in more than 55% of problem instances for four real world benchmark problems. The method works as a plugin that can be combined with any search strategy for branch-and-bound search. Exploring the identified subtrees first, the method brings substantial improvements for four efficient search strategies in both total runtime and runtime of finding optimal solutions."
  },
  "aaai2020_main_aneffectivehardthresholdingmethodbasedonstochasticvariancereductionfornonconvexsparselearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Effective Hard Thresholding Method Based on Stochastic Variance Reduction for Nonconvex Sparse Learning ",
    "authors": [
      "Guannan Liang",
      "Qianqian Tong",
      "Chunjiang Zhu",
      "Jinbo Bi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5519",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5519/5375",
    "published": "2020-02",
    "summary": "We propose a hard thresholding method based on stochastically controlled stochastic gradients (SCSG-HT) to solve a family of sparsity-constrained empirical risk minimization problems. The SCSG-HT uses batch gradients where batch size is pre-determined by the desirable precision tolerance rather than full gradients to reduce the variance in stochastic gradients. It also employs the geometric distribution to determine the number of loops per epoch. We prove that, similar to the latest methods based on stochastic gradient descent or stochastic variance reduction methods, SCSG-HT enjoys a linear convergence rate. However, SCSG-HT now has a strong guarantee to recover the optimal sparse estimator. The computational complexity of SCSG-HT is independent of sample size n when n is larger than 1/\u03b5, which enhances the scalability to massive-scale problems. Empirical results demonstrate that SCSG-HT outperforms several competitors and decreases the objective value the most with the same computational costs."
  },
  "aaai2020_main_acceleratingcolumngenerationviaflexibledualoptimalinequalitieswithapplicationtoentityresolution": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Accelerating Column Generation via Flexible Dual Optimal Inequalities with Application to Entity Resolution ",
    "authors": [
      "Vishnu Suresh Lokhande",
      "Shaofei Wang",
      "Maneesh Singh",
      "Julian Yarkony"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5520",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5520/5376",
    "published": "2020-02",
    "summary": "In this paper, we introduce a new optimization approach to Entity Resolution. Traditional approaches tackle entity resolution with hierarchical clustering, which does not benefit from a formal optimization formulation. In contrast, we model entity resolution as correlation-clustering, which we treat as a weighted set-packing problem and write as an integer linear program (ILP). In this case, sources in the input data correspond to elements and entities in output data correspond to sets/clusters. We tackle optimization of weighted set packing by relaxing integrality in our ILP formulation. The set of potential sets/clusters can not be explicitly enumerated, thus motivating optimization via column generation. In addition to the novel formulation, we also introduce new dual optimal inequalities (DOI), that we call flexible dual optimal inequalities, which tightly lower-bound dual variables during optimization and accelerate column generation. We apply our formulation to entity resolution (also called de-duplication of records), and achieve state-of-the-art accuracy on two popular benchmark datasets. Our F-DOI can be extended to other weighted set-packing problems."
  },
  "aaai2020_main_smartpredict-and-optimizeforhardcombinatorialoptimizationproblems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Smart Predict-and-Optimize for Hard Combinatorial Optimization Problems ",
    "authors": [
      "Jayanta Mandi",
      "Emir Demirovi?",
      "Peter J. Stuckey",
      "Tias Guns"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5521",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5521/5377",
    "published": "2020-02",
    "summary": "Combinatorial optimization assumes that all parameters of the optimization problem, e.g. the weights in the objective function, are fixed. Often, these weights are mere estimates and increasingly machine learning techniques are used to for their estimation. Recently, Smart Predict and Optimize (SPO) has been proposed for problems with a linear objective function over the predictions, more specifically linear programming problems. It takes the regret of the predictions on the linear problem into account, by repeatedly solving it during learning. We investigate the use of SPO to solve more realistic discrete optimization problems. The main challenge is the repeated solving of the optimization problem. To this end, we investigate ways to relax the problem as well as warm-starting the learning and the solving. Our results show that even for discrete problems it often suffices to train by solving the relaxation in the SPO loss. Furthermore, this approach outperforms the state-of-the-art approach of Wilder, Dilkina, and Tambe. We experiment with weighted knapsack problems as well as complex scheduling problems, and show for the first time that a predict-and-optimize approach can successfully be used on large-scale combinatorial optimization problems."
  },
  "aaai2020_main_grammarfilteringforsyntax-guidedsynthesis": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Grammar Filtering for Syntax-Guided Synthesis ",
    "authors": [
      "Kairo Morton",
      "William Hallahan",
      "Elven Shum",
      "Ruzica Piskac",
      "Mark Santolucito"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5522",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5522/5378",
    "published": "2020-02",
    "summary": "Programming-by-example (PBE) is a synthesis paradigm that allows users to generate functions by simply providing input-output examples. While a promising interaction paradigm, synthesis is still too slow for realtime interaction and more widespread adoption. Existing approaches to PBE synthesis have used automated reasoning tools, such as SMT solvers, as well as works applying machine learning techniques. At its core, the automated reasoning approach relies on highly domain specific knowledge of programming languages. On the other hand, the machine learning approaches utilize the fact that when working with program code, it is possible to generate arbitrarily large training datasets. In this work, we propose a system for using machine learning in tandem with automated reasoning techniques to solve Syntax Guided Synthesis (SyGuS) style PBE problems. By preprocessing SyGuS PBE problems with a neural network, we can use a data driven approach to reduce the size of the search space, then allow automated reasoning-based solvers to more quickly find a solution analytically. Our system is able to run atop existing SyGuS PBE synthesis tools, decreasing the runtime of the winner of the 2019 SyGuS Competition for the PBE Strings track by 47.65% to outperform all of the competing tools."
  },
  "aaai2020_main_d-spider-sfoadecentralizedoptimizationalgorithmwithfasterconvergenceratefornonconvexproblems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " D-SPIDER-SFO: A Decentralized Optimization Algorithm with Faster Convergence Rate for Nonconvex Problems ",
    "authors": [
      "Taoxing Pan",
      "Jun Liu",
      "Jie Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5523",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5523/5379",
    "published": "2020-02",
    "summary": " Decentralized optimization algorithms have attracted intensive interests recently, as it has a balanced communication pattern, especially when solving large-scale machine learning problems. Stochastic Path Integrated Differential Estimator Stochastic First-Order method (SPIDER-SFO) nearly achieves the algorithmic lower bound in certain regimes for nonconvex problems. However, whether we can find a decentralized algorithm which achieves a similar convergence rate to SPIDER-SFO is still unclear. To tackle this problem, we propose a decentralized variant of SPIDER-SFO, called decentralized SPIDER-SFO (D-SPIDER-SFO). We show that D-SPIDER-SFO achieves a similar gradient computation cost\u2014that is, O(\u03b5\u22123) for finding an \u03f5-approximate first-order stationary point\u2014to its centralized counterpart. To the best of our knowledge, D-SPIDER-SFO achieves the state-of-the-art performance for solving nonconvex optimization problems on decentralized networks in terms of the computational cost. Experiments on different network configurations demonstrate the efficiency of the proposed method."
  },
  "aaai2020_main_estimatingthedensityofstatesofbooleansatisfiabilityproblemsonclassicalandquantumcomputingplatforms": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Estimating the Density of States of Boolean Satisfiability Problems on Classical and Quantum Computing Platforms ",
    "authors": [
      "Tuhin Sahai",
      "Anurag Mishra",
      "Jose Miguel Pasini",
      "Susmit Jha"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5524",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5524/5380",
    "published": "2020-02",
    "summary": "Given a Boolean formula \u03d5(x) in conjunctive normal form (CNF), the density of states counts the number of variable assignments that violate exactly e clauses, for all values of e. Thus, the density of states is a histogram of the number of unsatisfied clauses over all possible assignments. This computation generalizes both maximum-satisfiability (MAX-SAT) and model counting problems and not only provides insight into the entire solution space, but also yields a measure for the hardness of the problem instance. Consequently, in real-world scenarios, this problem is typically infeasible even when using state-of-the-art algorithms. While finding an exact answer to this problem is a computationally intensive task, we propose a novel approach for estimating density of states based on the concentration of measure inequalities. The methodology results in a quadratic unconstrained binary optimization (QUBO), which is particularly amenable to quantum annealing-based solutions. We present the overall approach and compare results from the D-Wave quantum annealer against the best-known classical algorithms such as the Hamze-de Freitas-Selby (HFS) algorithm and satisfiability modulo theory (SMT) solvers."
  },
  "aaai2020_main_efficientalgorithmsforgeneratingprovablynear-optimalclusterdescriptorsforexplainability": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Efficient Algorithms for Generating Provably Near-Optimal Cluster Descriptors for Explainability ",
    "authors": [
      "Prathyush Sambaturu",
      "Aparna Gupta",
      "Ian Davidson",
      "S. S. Ravi",
      "Anil Vullikanti",
      "Andrew Warren"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5525",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5525/5381",
    "published": "2020-02",
    "summary": "Improving the explainability of the results from machine learning methods has become an important research goal. Here, we study the problem of making clusters more interpretable by extending a recent approach of [Davidson et al., NeurIPS 2018] for constructing succinct representations for clusters. Given a set of objects S, a partition \u03c0 of S (into clusters), and a universe T of tags such that each element in S is associated with a subset of tags, the goal is to find a representative set of tags for each cluster such that those sets are pairwise-disjoint and the total size of all the representatives is minimized. Since this problem is NP-hard in general, we develop approximation algorithms with provable performance guarantees for the problem. We also show applications to explain clusters from datasets, including clusters of genomic sequences that represent different threat levels."
  },
  "aaai2020_main_probabilisticinferenceforpredicateconstraintsatisfaction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Probabilistic Inference for Predicate Constraint Satisfaction ",
    "authors": [
      "Yuki Satake",
      "Hiroshi Unno",
      "Hinata Yanagi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5526",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5526/5382",
    "published": "2020-02",
    "summary": "In this paper, we present a novel constraint solving method for a class of predicate Constraint Satisfaction Problems (pCSP) where each constraint is represented by an arbitrary clause of first-order predicate logic over predicate variables. The class of pCSP properly subsumes the well-studied class of Constrained Horn Clauses (CHCs) where each constraint is restricted to a Horn clause. The class of CHCs has been widely applied to verification of linear-time safety properties of programs in different paradigms. In this paper, we show that pCSP further widens the applicability to verification of branching-time safety properties of programs that exhibit finitely-branching non-determinism. Solving pCSP (and CHCs) however is challenging because the search space of solutions is often very large (or unbounded), high-dimensional, and non-smooth. To address these challenges, our method naturally combines techniques studied separately in different literatures: counterexample guided inductive synthesis (CEGIS) and probabilistic inference in graphical models. We have implemented the presented method and obtained promising results on existing benchmarks as well as new ones that are beyond the scope of existing CHC solvers."
  },
  "aaai2020_main_hardexamplesforcommonvariabledecisionheuristics": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Hard Examples for Common Variable Decision Heuristics ",
    "authors": [
      "Marc Vinyals"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5527",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5527/5383",
    "published": "2020-02",
    "summary": "The CDCL algorithm for SAT is equivalent to the resolution proof system under a few assumptions, one of them being an optimal non-deterministic procedure for choosing the next variable to branch on. In practice this task is left to a variable decision heuristic, and since the so-called VSIDS decision heuristic is considered an integral part of CDCL, whether CDCL with a VSIDS-like heuristic is also equivalent to resolution remained a significant open question."
  },
  "aaai2020_main_multiplegraphmatchingandclusteringviadecayedpairwisematchingcomposition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multiple Graph Matching and Clustering via Decayed Pairwise Matching Composition ",
    "authors": [
      "Tianzhe Wang",
      "Zetian Jiang",
      "Junchi Yan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5528",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5528/5384",
    "published": "2020-02",
    "summary": "Jointly matching of multiple graphs is challenging and recently has been an active topic in machine learning and computer vision. State-of-the-art methods have been devised, however, to our best knowledge there is no effective mechanism that can explicitly deal with the matching of a mixture of graphs belonging to multiple clusters, e.g., a collection of bikes and bottles. Seeing its practical importance, we propose a novel approach for multiple graph matching and clustering. Firstly, for the traditional multi-graph matching setting, we devise a composition scheme based on a tree structure, which can be seen as in the between of two strong multi-graph matching solvers, i.e., MatchOpt (Yan et al. 2015a) and CAO (Yan et al. 2016a). In particular, it can be more robust than MatchOpt against a set of diverse graphs and more efficient than CAO. Then we further extend the algorithm to the multiple graph matching and clustering setting, by adopting a decaying technique along the composition path, to discount the meaningless matching between graphs in different clusters. Experimental results show the proposed methods achieve excellent trade-off on the traditional multi-graph matching case, and outperform in both matching and clustering accuracy, as well as time efficiency."
  },
  "aaai2020_main_constructingminimalperfecthashfunctionsusingsattechnology": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Constructing Minimal Perfect Hash Functions Using SAT Technology ",
    "authors": [
      "Sean Weaver",
      "Marijn Heule"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5529",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5529/5385",
    "published": "2020-02",
    "summary": "Minimal perfect hash functions (MPHFs) are used to provide efficient access to values of large dictionaries (sets of key-value pairs). Discovering new algorithms for building MPHFs is an area of active research, especially from the perspective of storage efficiency. The information-theoretic limit for MPHFs is 1/ln 2 \u2248 1.44 bits per key. The current best practical algorithms range between 2 and 4 bits per key. In this article, we propose two SAT-based constructions of MPHFs. Our first construction yields MPHFs near the information-theoretic limit. For this construction, current state-of-the-art SAT solvers can handle instances where the dictionaries contain up to 40 elements, thereby outperforming the existing (brute-force) methods. Our second construction uses XORSAT filters to realize a practical approach with long-term storage of approximately 1.83 bits per key."
  },
  "aaai2020_main_explainingpropagatorsforstringeditdistanceconstraints": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Explaining Propagators for String Edit Distance Constraints ",
    "authors": [
      "Felix Winter",
      "Nysret Musliu",
      "Peter Stuckey"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5530",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5530/5386",
    "published": "2020-02",
    "summary": "The computation of string similarity measures has been thoroughly studied in the scientific literature and has applications in a wide variety of different areas. One of the most widely used measures is the so called string edit distance which captures the number of required edit operations to transform a string into another given string. Although polynomial time algorithms are known for calculating the edit distance between two strings, there also exist NP-hard problems from practical applications like scheduling or computational biology that constrain the minimum edit distance between arrays of decision variables. In this work, we propose a novel global constraint to formulate restrictions on the minimum edit distance for such problems. Furthermore, we describe a propagation algorithm and investigate an explanation strategy for an edit distance constraint propagator that can be incorporated into state of the art lazy clause generation solvers. Experimental results show that the proposed propagator is able to significantly improve the performance of existing exact methods regarding solution quality and computation speed for benchmark problems from the literature."
  },
  "aaai2020_main_deepneuralnetworkapproximateddynamicprogrammingforcombinatorialoptimization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Neural Network Approximated Dynamic Programming for Combinatorial Optimization ",
    "authors": [
      "Shenghe Xu",
      "Shivendra S. Panwar",
      "Murali Kodialam",
      "T.V. Lakshman"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5531",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5531/5387",
    "published": "2020-02",
    "summary": "In this paper, we propose a general framework for combining deep neural networks (DNNs) with dynamic programming to solve combinatorial optimization problems. For problems that can be broken into smaller subproblems and solved by dynamic programming, we train a set of neural networks to replace value or policy functions at each decision step. Two variants of the neural network approximated dynamic programming (NDP) methods are proposed; in the value-based NDP method, the networks learn to estimate the value of each choice at the corresponding step, while in the policy-based NDP method the DNNs only estimate the best decision at each step. The training procedure of the NDP starts from the smallest problem size and a new DNN for the next size is trained to cooperate with previous DNNs. After all the DNNs are trained, the networks are fine-tuned together to further improve overall performance. We test NDP on the linear sum assignment problem, the traveling salesman problem and the talent scheduling problem. Experimental results show that NDP can achieve considerable computation time reduction on hard problems with reasonable performance loss. In general, NDP can be applied to reducible combinatorial optimization problems for the purpose of computation time reduction."
  },
  "aaai2020_main_generatinginteractiveworldswithtext": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generating Interactive Worlds with Text ",
    "authors": [
      "Angela Fan",
      "Jack Urbanek",
      "Pratik Ringshia",
      "Emily Dinan",
      "Emma Qian",
      "Siddharth Karamcheti",
      "Shrimai Prabhumoye",
      "Douwe Kiela",
      "Tim Rocktaschel",
      "Arthur Szlam",
      "Jason Weston"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5532",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5532/5388",
    "published": "2020-02",
    "summary": "Procedurally generating cohesive and interesting game environments is challenging and time-consuming. In order for the relationships between the game elements to be natural, common-sense has to be encoded into arrangement of the elements. In this work, we investigate a machine learning approach for world creation using content from the multi-player text adventure game environment LIGHT (Urbanek et al. 2019). We introduce neural network based models to compositionally arrange locations, characters, and objects into a coherent whole. In addition to creating worlds based on existing elements, our models can generate new game content. Humans can also leverage our models to interactively aid in worldbuilding. We show that the game environments created with our approach are cohesive, diverse, and preferred by human evaluators compared to other machine learning based world construction algorithms."
  },
  "aaai2020_main_deepreinforcementlearningforgeneralgameplaying": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Reinforcement Learning for General Game Playing ",
    "authors": [
      "Adrian Goldwaser",
      "Michael Thielscher"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5533",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5533/5389",
    "published": "2020-02",
    "summary": "General Game Playing agents are required to play games they have never seen before simply by looking at a formal description of the rules of the game at runtime. Previous successful agents have been based on search with generic heuristics, with almost no work done into using machine learning. Recent advances in deep reinforcement learning have shown it to be successful in some two-player zero-sum board games such as Chess and Go. This work applies deep reinforcement learning to General Game Playing, extending the AlphaZero algorithm and finds that it can provide competitive results."
  },
  "aaai2020_main_narrativeplanningmodelacquisitionfromtextsummariesanddescriptions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Narrative Planning Model Acquisition from Text Summaries and Descriptions ",
    "authors": [
      "Thomas Hayton",
      "Julie Porteous",
      "Joao Ferreira",
      "Alan Lindsay"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5534",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5534/5390",
    "published": "2020-02",
    "summary": "AI Planning has been shown to be a useful approach for the generation of narrative in interactive entertainment systems and games. However, the creation of the underlying narrative domain models is challenging: the well documented AI planning modelling bottleneck is further compounded by the need for authors, who tend to be non-technical, to create content. We seek to support authors in this task by allowing natural language (NL) plot synopses to be used as a starting point from which planning domain models can be automatically acquired. We present a solution which analyses input NL text summaries, and builds structured representations from which a pddl model is output (fully automated or author in-the-loop). We introduce a novel sieve-based approach to pronoun resolution that demonstrates consistently high performance across domains. In the paper we focus on authoring of narrative planning models for use in interactive entertainment systems and games. We show that our approach exhibits comprehensive detection of both actions and objects in the system-extracted domain models, in combination with significant improvement in the accuracy of pronoun resolution due to the use of contextual object information. Our results and an expert user assessment show that our approach enables a reduction in authoring effort required to generate baseline narrative domain models from which variants can be built."
  },
  "aaai2020_main_fet-ganfontandeffecttransferviak-shotadaptiveinstancenormalization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " FET-GAN: Font and Effect Transfer via K-shot Adaptive Instance Normalization ",
    "authors": [
      "Wei Li",
      "Yongxing He",
      "Yanwei Qi",
      "Zejian Li",
      "Yongchuan Tang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5535",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5535/5391",
    "published": "2020-02",
    "summary": "Text effect transfer aims at learning the mapping between text visual effects while maintaining the text content. While remarkably successful, existing methods have limited robustness in font transfer and weak generalization ability to unseen effects. To address these problems, we propose FET-GAN, a novel end-to-end framework to implement visual effects transfer with font variation among multiple text effects domains. Our model achieves remarkable results both on arbitrary effect transfer between texts and effect translation from text to graphic objects. By a few-shot fine-tuning strategy, FET-GAN can generalize the transfer of the pre-trained model to the new effect. Through extensive experimental validation and comparison, our model advances the state-of-the-art in the text effect transfer task. Besides, we have collected a font dataset including 100 fonts of more than 800 Chinese and English characters. Based on this dataset, we demonstrated the generalization ability of our model by the application that complements the font library automatically by few-shot samples. This application is significant in reducing the labor cost for the font designer."
  },
  "aaai2020_main_acharacter-centricneuralmodelforautomatedstorygeneration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Character-Centric Neural Model for Automated Story Generation ",
    "authors": [
      "Danyang Liu",
      "Juntao Li",
      "Meng-Hsuan Yu",
      "Ziming Huang",
      "Gongshen Liu",
      "Dongyan Zhao",
      "Rui Yan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5536",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5536/5392",
    "published": "2020-02",
    "summary": "Automated story generation is a challenging task which aims to automatically generate convincing stories composed of successive plots correlated with consistent characters. Most recent generation models are built upon advanced neural networks, e.g., variational autoencoder, generative adversarial network, convolutional sequence to sequence model. Although these models have achieved prompting results on learning linguistic patterns, very few methods consider the attributes and prior knowledge of the story genre, especially from the perspectives of explainability and consistency. To fill this gap, we propose a character-centric neural storytelling model, where a story is created encircling the given character, i.e., each part of a story is conditioned on a given character and corresponded context environment. In this way, we explicitly capture the character information and the relations between plots and characters to improve explainability and consistency. Experimental results on open dataset indicate that our model yields meaningful improvements over several strong baselines on both human and automatic evaluations."
  },
  "aaai2020_main_fastandrobustface-to-parametertranslationforgamecharacterauto-creation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fast and Robust Face-to-Parameter Translation for Game Character Auto-Creation ",
    "authors": [
      "Tianyang Shi",
      "Zhengxia Zuo",
      "Yi Yuan",
      "Changjie Fan",
      "Tianyang Shi",
      "Zhengxia Zuo",
      "Yi Yuan",
      "Changjie Fan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5537",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5537/5393",
    "published": "2020-02",
    "summary": "With the rapid development of Role-Playing Games (RPGs), players are now allowed to edit the facial appearance of their in-game characters with their preferences rather than using default templates. This paper proposes a game character auto-creation framework that generates in-game characters according to a player's input face photo. Different from the previous methods that are designed based on neural style transfer or monocular 3D face reconstruction, we re-formulate the character auto-creation process in a different point of view: by predicting a large set of physically meaningful facial parameters under a self-supervised learning paradigm. Instead of updating facial parameters iteratively at the input end of the renderer as suggested by previous methods, which are time-consuming, we introduce a facial parameter translator so that the creation can be done efficiently through a single forward propagation from the face embeddings to parameters, with a considerable 1000x computational speedup. Despite its high efficiency, the interactivity is preserved in our method where users are allowed to optionally fine-tune the facial parameters on our creation according to their needs. Our approach also shows better robustness than previous methods, especially for those photos with head-pose variance. Comparison results and ablation analysis on seven public face verification datasets suggest the effectiveness of our method."
  },
  "aaai2020_main_draftandeditautomaticstorytellingthroughmulti-passhierarchicalconditionalvariationalautoencoder": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Draft and Edit: Automatic Storytelling Through Multi-Pass Hierarchical Conditional Variational Autoencoder ",
    "authors": [
      "Meng-Hsuan Yu",
      "Juntao Li",
      "Danyang Liu",
      "Dongyan Zhao",
      "Rui Yan",
      "Bo Tang",
      "Haisong Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5538",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5538/5394",
    "published": "2020-02",
    "summary": "Automatic Storytelling has consistently been a challenging area in the field of natural language processing. Despite considerable achievements have been made, the gap between automatically generated stories and human-written stories is still significant. Moreover, the limitations of existing automatic storytelling methods are obvious, e.g., the consistency of content, wording diversity. In this paper, we proposed a multi-pass hierarchical conditional variational autoencoder model to overcome the challenges and limitations in existing automatic storytelling models. While the conditional variational autoencoder (CVAE) model has been employed to generate diversified content, the hierarchical structure and multi-pass editing scheme allow the story to create more consistent content. We conduct extensive experiments on the ROCStories Dataset. The results verified the validity and effectiveness of our proposed model and yields substantial improvement over the existing state-of-the-art approaches."
  },
  "aaai2020_main_distance-basedequilibriainnormal-formgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Distance-Based Equilibria in Normal-Form Games ",
    "authors": [
      "Erman Acar",
      "Reshef Meir"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5540",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5540/5396",
    "published": "2020-02",
    "summary": "We propose a simple uncertainty modification for the agent model in normal-form games; at any given strategy profile, the agent can access only a set of \u201cpossible profiles\u201d that are within a certain distance from the actual action profile. We investigate the various instantiations in which the agent chooses her strategy using well-known rationales e.g., considering the worst case, or trying to minimize the regret, to cope with such uncertainty. Any such modification in the behavioral model naturally induces a corresponding notion of equilibrium; a distance-based equilibrium. We characterize the relationships between the various equilibria, and also their connections to well-known existing solution concepts such as Trembling-hand perfection. Furthermore, we deliver existence results, and show that for some class of games, such solution concepts can actually lead to better outcomes."
  },
  "aaai2020_main_swapstabilityinschellinggamesongraphs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Swap Stability in Schelling Games on Graphs ",
    "authors": [
      "Aishwarya Agarwal",
      "Edith Elkind",
      "Jiarui Gan",
      "Alexandros Voudouris"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5541",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5541/5397",
    "published": "2020-02",
    "summary": "We study a recently introduced class of strategic games that is motivated by and generalizes Schelling's well-known residential segregation model. These games are played on undirected graphs, with the set of agents partitioned into multiple types; each agent either occupies a node of the graph and never moves away or aims to maximize the fraction of her neighbors who are of her own type. We consider a variant of this model that we call swap Schelling games, where the number of agents is equal to the number of nodes of the graph, and agents may swap positions with other agents to increase their utility. We study the existence, computational complexity and quality of equilibrium assignments in these games, both from a social welfare perspective and from a diversity perspective."
  },
  "aaai2020_main_theimpactofselfishnessinhypergraphhedonicgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " The Impact of Selfishness in Hypergraph Hedonic Games ",
    "authors": [
      "Alessandro Aloisio",
      "Michele Flammini",
      "Cosimo Vinci"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5542",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5542/5398",
    "published": "2020-02",
    "summary": "We consider a class of coalition formation games that can be succinctly represented by means of hypergraphs and properly generalizes symmetric additively separable hedonic games. More precisely, an instance of hypegraph hedonic game consists of a weighted hypergraph, in which each agent is associated to a distinct node and her utility for being in a given coalition is equal to the sum of the weights of all the hyperedges included in the coalition. We study the performance of stable outcomes in such games, investigating the degradation of their social welfare under two different metrics, the -Nash price of anarchyk and -core price of anarchyk, where k is the maximum size of a deviating coalition. Such prices are defined as the worst-case ratio between the optimal social welfare and the social welfare obtained when the agents reach an outcome satisfying the respective stability criteria. We provide asymptotically tight upper and lower bounds on the values of these metrics for several classes of hypergraph hedonic games, parametrized according to the integer k, the hypergraph arity r and the number of agents n. Furthermore, we show that the problem of computing the exact value of such prices for a given instance is computationally hard, even in case of non-negative hyperedge weights."
  },
  "aaai2020_main_multiagentevaluationmechanisms": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multiagent Evaluation Mechanisms ",
    "authors": [
      "Tal Alon",
      "Magdalen Dobson",
      "Ariel Procaccia",
      "Inbal Talgam-Cohen",
      "Jamie Tucker-Foltz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5543",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5543/5399",
    "published": "2020-02",
    "summary": "We consider settings where agents are evaluated based on observed features, and assume they seek to achieve feature values that bring about good evaluations. Our goal is to craft evaluation mechanisms that incentivize the agents to invest effort in desirable actions; a notable application is the design of course grading schemes. Previous work has studied this problem in the case of a single agent. By contrast, we investigate the general, multi-agent model, and provide a complete characterization of its computational complexity."
  },
  "aaai2020_main_peekingbehindtheordinalcurtainimprovingdistortionviacardinalqueries": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Peeking Behind the Ordinal Curtain: Improving Distortion via Cardinal Queries ",
    "authors": [
      "Georgios Amanatidis",
      "Georgios Birmpas",
      "Aris Filos-Ratsikas",
      "Alexandros Voudouris"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5544",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5544/5400",
    "published": "2020-02",
    "summary": "The notion of distortion was introduced by Procaccia and Rosenschein (2006) to quantify the inefficiency of using only ordinal information when trying to maximize the social welfare. Since then, this research area has flourished and bounds on the distortion have been obtained for a wide variety of fundamental scenarios. However, the vast majority of the existing literature is focused on the case where nothing is known beyond the ordinal preferences of the agents over the alternatives. In this paper, we take a more expressive approach, and consider mechanisms that are allowed to further ask a few cardinal queries in order to gain partial access to the underlying values that the agents have for the alternatives. With this extra power, we design new deterministic mechanisms that achieve significantly improved distortion bounds and outperform the best-known randomized ordinal mechanisms. We draw an almost complete picture of the number of queries required to achieve specific distortion bounds."
  },
  "aaai2020_main_multiplebirdswithonestonebeating1/2forefxandgmmsviaenvycycleelimination": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multiple Birds with One Stone: Beating 1/2 for EFX and GMMS via Envy Cycle Elimination ",
    "authors": [
      "Georgios Amanatidis",
      "Evangelos Markakis",
      "Apostolos Ntokos"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5545",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5545/5401",
    "published": "2020-02",
    "summary": "Several relaxations of envy-freeness, tailored to fair division in settings with indivisible goods, have been introduced within the last decade. Due to the lack of general existence results for most of these concepts, great attention has been paid to establishing approximation guarantees. In this work, we propose a simple algorithm that is universally fair in the sense that it returns allocations that have good approximation guarantees with respect to four such fairness notions at once. In particular, this is the first algorithm achieving a (\u03c6\u22121)-approximation of envy-freeness up to any good (EFX) and a 2/\u03c6+2 -approximation of groupwise maximin share fairness (GMMS), where \u03c6 is the golden ratio. The best known approximation factor, in polynomial time, for either one of these fairness notions prior to this work was 1/2. Moreover, the returned allocation achieves envy-freeness up to one good (EF1) and a 2/3-approximation of pairwise maximin share fairness (PMMS). While EFX is our primary focus, we also exhibit how to fine-tune our algorithm and improve further the guarantees for GMMS or PMMS."
  },
  "aaai2020_main_all-paybiddinggamesongraphs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " All-Pay Bidding Games on Graphs ",
    "authors": [
      "Guy Avni",
      "Rasmus Ibsen-Jensen",
      "Josef Tkadlec"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5546",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5546/5402",
    "published": "2020-02",
    "summary": "In this paper we introduce and study all-pay bidding games, a class of two player, zero-sum games on graphs. The game proceeds as follows. We place a token on some vertex in the graph and assign budgets to the two players. Each turn, each player submits a sealed legal bid (non-negative and below their remaining budget), which is deducted from their budget and the highest bidder moves the token onto an adjacent vertex. The game ends once a sink is reached, and Player 1 pays Player 2 the outcome that is associated with the sink. The players attempt to maximize their expected outcome. Our games model settings where effort (of no inherent value) needs to be invested in an ongoing and stateful manner. On the negative side, we show that even in simple games on DAGs, optimal strategies may require a distribution over bids with infinite support. A central quantity in bidding games is the ratio of the players budgets. On the positive side, we show a simple FPTAS for DAGs, that, for each budget ratio, outputs an approximation for the optimal strategy for that ratio. We also implement it, show that it performs well, and suggests interesting properties of these games. Then, given an outcome c, we show an algorithm for finding the necessary and sufficient initial ratio for guaranteeing outcome c with probability 1 and a strategy ensuring such. Finally, while the general case has not previously been studied, solving the specific game in which Player 1 wins iff he wins the first two auctions, has been long stated as an open question, which we solve."
  },
  "aaai2020_main_facilitylocationproblemwithcapacityconstraintsalgorithmicandmechanismdesignperspectives": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Facility Location Problem with Capacity Constraints: Algorithmic and Mechanism Design Perspectives ",
    "authors": [
      "Haris Aziz",
      "Hau Chan",
      "Barton Lee",
      "Bo Li",
      "Toby Walsh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5547",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5547/5403",
    "published": "2020-02",
    "summary": "We consider the facility location problem in the one-dimensional setting where each facility can serve a limited number of agents from the algorithmic and mechanism design perspectives. From the algorithmic perspective, we prove that the corresponding optimization problem, where the goal is to locate facilities to minimize either the total cost to all agents or the maximum cost of any agent is NP-hard. However, we show that the problem is fixed-parameter tractable, and the optimal solution can be computed in polynomial time whenever the number of facilities is bounded, or when all facilities have identical capacities. We then consider the problem from a mechanism design perspective where the agents are strategic and need not reveal their true locations. We show that several natural mechanisms studied in the uncapacitated setting either lose strategyproofness or a bound on the solution quality %on the returned solution for the total or maximum cost objective. We then propose new mechanisms that are strategyproof and achieve approximation guarantees that almost match the lower bounds."
  },
  "aaai2020_main_fairdivisionofmixeddivisibleandindivisiblegoods": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fair Division of Mixed Divisible and Indivisible Goods ",
    "authors": [
      "Xiaohui Bei",
      "Zihao Li",
      "Jinyan Liu",
      "Shengxin Liu",
      "Xinhang Lu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5548",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5548/5404",
    "published": "2020-02",
    "summary": " We study the problem of fair division when the resources contain both divisible and indivisible goods. Classic fairness notions such as envy-freeness (EF) and envy-freeness up to one good (EF1) cannot be directly applied to the mixed goods setting. In this work, we propose a new fairness notion envy-freeness for mixed goods (EFM), which is a direct generalization of both EF and EF1 to the mixed goods setting. We prove that an EFM allocation always exists for any number of agents. We also propose efficient algorithms to compute an EFM allocation for two agents and for n agents with piecewise linear valuations over the divisible goods. Finally, we relax the envy-free requirement, instead asking for \u03f5-envy-freeness for mixed goods (\u03f5-EFM), and present an algorithm that finds an \u03f5-EFM allocation in time polynomial in the number of agents, the number of indivisible goods, and 1/\u03f5."
  },
  "aaai2020_main_individual-basedstabilityinhedonicdiversitygames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Individual-Based Stability in Hedonic Diversity Games ",
    "authors": [
      "Niclas Boehmer",
      "Edith Elkind"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5549",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5549/5405",
    "published": "2020-02",
    "summary": "In hedonic diversity games (HDGs), recently introduced by Bredereck, Elkind, and Igarashi (2019), each agent belongs to one of two classes (men and women, vegetarians and meat-eaters, junior and senior researchers), and agents' preferences over coalitions are determined by the fraction of agents from their class in each coalition. Bredereck et al.show that while an HDG may fail to have a Nash stable (NS) or a core stable (CS) outcome, every HDG in which all agents have single-peaked preferences admits an individually stable (IS) outcome, which can be computed in polynomial time. In this work, we extend and strengthen these results in several ways. First, we establish that the problem of deciding if an HDG has an NS outcome is NP-complete, but admits an XP algorithm with respect to the size of the smaller class. Second, we show that, in fact, all HDGs admit IS outcomes that can be computed in polynomial time; our algorithm for finding such outcomes is considerably simpler than that of Bredereck et al. We also consider two ways of generalizing the model of Bredereck et al. to k \u2265 2 classes. We complement our theoretical results by empirical analysis, comparing the IS outcomes found by our algorithm, the algorithm of Bredereck et al. and a natural better-response dynamics."
  },
  "aaai2020_main_adaptingstablematchingstoevolvingpreferences": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adapting Stable Matchings to Evolving Preferences ",
    "authors": [
      "Robert Bredereck",
      "Jiehua Chen",
      "Du\u0161an Knop",
      "Junjie Luo",
      "Rolf Niedermeier"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5550",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5550/5406",
    "published": "2020-02",
    "summary": "Adaptivity to changing environments and constraints is key to success in modern society. We address this by proposing \u201cincrementalized versions\u201d of Stable Marriage and Stable Roommates. That is, we try to answer the following question: for both problems, what is the computational cost of adapting an existing stable matching after some of the preferences of the agents have changed. While doing so, we also model the constraint that the new stable matching shall be not too different from the old one. After formalizing these incremental versions, we provide a fairly comprehensive picture of the computational complexity landscape of Incremental Stable Marriage and Incremental Stable Roommates. To this end, we exploit the parameters \u201cdegree of change\u201d both in the input (difference between old and new preference profile) and in the output (difference between old and new stable matching). We obtain both hardness and tractability results, in particular showing a fixed-parameter tractability result with respect to the parameter \u201cdistance between old and new stable matching\u201d."
  },
  "aaai2020_main_parameterizedalgorithmsforfindingacollectivesetofitems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Parameterized Algorithms for Finding a Collective Set of Items ",
    "authors": [
      "Robert Bredereck",
      "Piotr Faliszewski",
      "Andrzej Kaczmarczyk",
      "Du\u0161an Knop",
      "Rolf Niedermeier"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5551",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5551/5407",
    "published": "2020-02",
    "summary": " We extend the work of Skowron et al. (AIJ, 2016) by considering the parameterized complexity of the following problem. We are given a set of items and a set of agents, where each agent assigns an integer utility value to each item. The goal is to find a set of k items that these agents would collectively use. For each such collective set of items, each agent provides a score that can be described using an OWA (ordered weighted average) operator and we seek a set with the highest total score. We focus on the parameterization by the number of agents and we find numerous fixed-parameter tractability results (however, we also find some W[1]-hardness results). It turns out that most of our algorithms even apply to the setting where each agent has an integer weight."
  },
  "aaai2020_main_electingsuccessivecommitteescomplexityandalgorithms": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Electing Successive Committees: Complexity and Algorithms ",
    "authors": [
      "Robert Bredereck",
      "Andrzej Kaczmarczyk",
      "Rolf Niedermeier"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5552",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5552/5408",
    "published": "2020-02",
    "summary": " We introduce successive committees elections. The point is that our new model additionally takes into account that \u201ccommittee members\u201d shall have a short term of office possibly over a consecutive time period (e.g., to limit the influence of elitist power cartels or to keep the social costs of overloading committees as small as possible) but at the same time overly frequent elections are to be avoided (e.g., for the sake of long-term planning). Thus, given voter preferences over a set of candidates, a desired committee size, a number of committees to be elected, and an upper bound on the number of committees that each candidate can participate in, the goal is to find a \u201cbest possible\u201d series of committees representing the electorate."
  },
  "aaai2020_main_approval-basedapportionment": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Approval-Based Apportionment ",
    "authors": [
      "Markus Brill",
      "Paul G\u00f6lz",
      "Dominik Peters",
      "Ulrike Schmidt-Kraepelin",
      "Kai Wilker"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5553",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5553/5409",
    "published": "2020-02",
    "summary": "In the apportionment problem, a fixed number of seats must be distributed among parties in proportion to the number of voters supporting each party. We study a generalization of this setting, in which voters cast approval ballots over parties, such that each voter can support multiple parties. This approval-based apportionment setting generalizes traditional apportionment and is a natural restriction of approval-based multiwinner elections, where approval ballots range over individual candidates. Using techniques from both apportionment and multiwinner elections, we are able to provide representation guarantees that are currently out of reach in the general setting of multiwinner elections: First, we show that core-stable committees are guaranteed to exist and can be found in polynomial time. Second, we demonstrate that extended justified representation is compatible with committee monotonicity."
  },
  "aaai2020_main_refiningtournamentsolutionsviamarginofvictory": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Refining Tournament Solutions via Margin of Victory ",
    "authors": [
      "Markus Brill",
      "Ulrike Schmidt-Kraepelin",
      "Warut Suksompong"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5554",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5554/5410",
    "published": "2020-02",
    "summary": "Tournament solutions are frequently used to select winners from a set of alternatives based on pairwise comparisons between alternatives. Prior work has shown that several common tournament solutions tend to select large winner sets and therefore have low discriminative power. In this paper, we propose a general framework for refining tournament solutions. In order to distinguish between winning alternatives, and also between non-winning ones, we introduce the notion of margin of victory (MoV) for tournament solutions. MoV is a robustness measure for individual alternatives: For winners, the MoV captures the distance from dropping out of the winner set, and for non-winners, the distance from entering the set. In each case, distance is measured in terms of which pairwise comparisons would have to be reversed in order to achieve the desired outcome. For common tournament solutions, including the top cycle, the uncovered set, and the Banks set, we determine the complexity of computing the MoV and provide worst-case bounds on the MoV for both winners and non-winners. Our results can also be viewed from the perspective of bribery and manipulation."
  },
  "aaai2020_main_persuadingvotersitseasytowhisper,itshardtospeakloud": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Persuading Voters: It's Easy to Whisper, It's Hard to Speak Loud ",
    "authors": [
      "Matteo Castiglioni",
      "Andrea Celli",
      "Nicola Gatti"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5555",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5555/5411",
    "published": "2020-02",
    "summary": " We focus on the following natural question: is it possible to influence the outcome of a voting process through the strategic provision of information to voters who update their beliefs rationally? We investigate whether it is computationally tractable to design a signaling scheme maximizing the probability with which the sender's preferred candidate is elected. We resort to the model recently introduced by Arieli and Babichenko (2019) (i.e., without inter-agent externalities), and focus on, as illustrative examples, k-voting rules and plurality voting. There is a sharp contrast between the case in which private signals are allowed and the more restrictive setting in which only public signals are allowed. In the former, we show that an optimal signaling scheme can be computed efficiently both under a k-voting rule and plurality voting. In establishing these results, we provide two contributions applicable to general settings beyond voting. Specifically, we extend a well-known result by Dughmi and Xu (2017) to more general settings and prove that, when the sender's utility function is anonymous, computing an optimal signaling scheme is fixed-parameter tractable in the number of receivers' actions. In the public signaling case, we show that the sender's optimal expected return cannot be approximated to within any factor under a k-voting rule. This negative result easily extends to plurality voting and problems where utility functions are anonymous."
  },
  "aaai2020_main_electioncontrolinsocialnetworksviaedgeadditionorremoval": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Election Control in Social Networks via Edge Addition or Removal ",
    "authors": [
      "Matteo Castiglioni",
      "Diodato Ferraioli",
      "Nicola Gatti"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5556",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5556/5412",
    "published": "2020-02",
    "summary": "We focus on the scenario in which messages pro and/or against one or multiple candidates are spread through a social network in order to affect the votes of the receivers. Several results are known in the literature when the manipulator can make seeding by buying influencers. In this paper, instead, we assume the set of influencers and their messages to be given, and we ask whether a manipulator (e.g., the platform) can alter the outcome of the election by adding or removing edges in the social network. We study a wide range of cases distinguishing for the number of candidates or for the kind of messages spread over the network. We provide a positive result, showing that, except for trivial cases, manipulation is not affordable, the optimization problem being hard even if the manipulator has an unlimited budget (i.e., he can add or remove as many edges as desired). Furthermore, we prove that our hardness results still hold in a reoptimization variant, where the manipulator already knows an optimal solution to the problem and needs to compute a new solution once a local modification occurs (e.g., in bandit scenarios where estimations related to random variables change over time)."
  },
  "aaai2020_main_privatebayesianpersuasionwithsequentialgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Private Bayesian Persuasion with Sequential Games ",
    "authors": [
      "Andrea Celli",
      "Stefano Coniglio",
      "Nicola Gatti"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5557",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5557/5413",
    "published": "2020-02",
    "summary": "We study an information-structure design problem (a.k.a. a persuasion problem) with a single sender and multiple receivers with actions of a priori unknown types, independently drawn from action-specific marginal probability distributions. As in the standard Bayesian persuasion model, the sender has access to additional information regarding the action types, which she can exploit when committing to a (noisy) signaling scheme through which she sends a private signal to each receiver. The novelty of our model is in considering the much more expressive case in which the receivers interact in a sequential game with imperfect information, with utilities depending on the game outcome and the realized action types. After formalizing the notions of ex ante and ex interim persuasiveness (which differ by the time at which the receivers commit to following the sender's signaling scheme), we investigate the continuous optimization problem of computing a signaling scheme which maximizes the sender's expected revenue. We show that computing an optimal ex ante persuasive signaling scheme is NP-hard when there are three or more receivers. Instead, in contrast with previous hardness results for ex interim persuasion, we show that, for games with two receivers, an optimal ex ante persuasive signaling scheme can be computed in polynomial time thanks to the novel algorithm we propose, based on the ellipsoid method."
  },
  "aaai2020_main_favorite-candidatevotingforeliminatingtheleastpopularcandidateinametricspace": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Favorite-Candidate Voting for Eliminating the Least Popular Candidate in a Metric Space ",
    "authors": [
      "Xujin Chen",
      "Minming Li",
      "Chenhao Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5558",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5558/5414",
    "published": "2020-02",
    "summary": "We study single-candidate voting embedded in a metric space, where both voters and candidates are points in the space, and the distances between voters and candidates specify the voters' preferences over candidates. In the voting, each voter is asked to submit her favorite candidate. Given the collection of favorite candidates, a mechanism for eliminating the least popular candidate finds a committee containing all candidates but the one to be eliminated."
  },
  "aaai2020_main_manipulatingdistrictstowinelectionsfine-grainedcomplexity": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Manipulating Districts to Win Elections: Fine-Grained Complexity ",
    "authors": [
      "Eduard Eiben",
      "Fedor Fomin",
      "Fahad Panolan",
      "Kirill Simonov"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5559",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5559/5415",
    "published": "2020-02",
    "summary": "Gerrymandering is a practice of manipulating district boundaries and locations in order to achieve a political advantage for a particular party. Lewenberg, Lev, and Rosenschein [AAMAS 2017] initiated the algorithmic study of a geographically-based manipulation problem, where voters must vote at the ballot box closest to them. In this variant of gerrymandering, for a given set of possible locations of ballot boxes and known political preferences of n voters, the task is to identify locations for k boxes out of m possible locations to guarantee victory of a certain party in at least \u2113 districts. Here integers k and \u2113 are some selected parameter."
  },
  "aaai2020_main_onswapconvexityofvotingrules": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On Swap Convexity of Voting Rules ",
    "authors": [
      "Svetlana Obraztsova",
      "Edith Elkind",
      "Piotr Faliszewski"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5560",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5560/5416",
    "published": "2020-02",
    "summary": " Obraztsova et al. (2013) have recently proposed an intriguing convexity axiom for voting rules. This axiom imposes conditions on the shape of the sets of elections with a given candidate as a winner. However, this new axiom is both too weak and too strong: it is too weak because it defines a set to be convex if for any two elements of the set some shortest path between them lies within the set, whereas the standard definition of convexity requires all shortest paths between two elements to lie within the set, and it is too strong because common voting rules do not satisfy this axiom. In this paper, we (1) propose several families of voting rules that are convex in the sense of Obraztsova et al.; (2) put forward a weaker notion of convexity that is satisfied by most common voting rules; (3) prove impossibility results for a variant of this definition that considers all, rather than some shortest paths."
  },
  "aaai2020_main_analysisofone-to-onematchingmechanismsviasatsolvingimpossibilitiesforuniversalaxioms": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Analysis of One-to-One Matching Mechanisms via SAT Solving: Impossibilities for Universal Axioms ",
    "authors": [
      "Ulle Endriss"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5561",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5561/5417",
    "published": "2020-02",
    "summary": "We develop a powerful approach that makes modern SAT solving techniques available as a tool to support the axiomatic analysis of economic matching mechanisms. Our central result is a preservation theorem, establishing sufficient conditions under which the possibility of designing a matching mechanism meeting certain axiomatic requirements for a given number of agents carries over to all scenarios with strictly fewer agents. This allows us to obtain general results about matching by verifying claims for specific instances using a SAT solver. We use our approach to automatically derive elementary proofs for two new impossibility theorems: (i) a strong form of Roth's classical result regarding the impossibility of designing mechanisms that are both stable and strategyproof and (ii) a result establishing the impossibility of guaranteeing stability while also respecting a basic notion of cross-group fairness (so-called gender-indifference)."
  },
  "aaai2020_main_iterativedelegationsinliquiddemocracywithrestrictedpreferences": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Iterative Delegations in Liquid Democracy with Restricted Preferences ",
    "authors": [
      "Bruno Escoffier",
      "Hugo Gilbert",
      "Ad\u00e8le Pass-Lanneau"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5562",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5562/5418",
    "published": "2020-02",
    "summary": "Liquid democracy is a collective decision making paradigm which lies between direct and representative democracy. One main feature of liquid democracy is that voters can delegate their votes in a transitive manner so that: A delegates to B and B delegates to C leads to A delegates to C. Unfortunately, because voters' preferences over delegates may be conflicting, this process may not converge. There may not even exist a stable state (also called equilibrium). In this paper, we investigate the stability of the delegation process in liquid democracy when voters have restricted types of preference on the agent representing them (e.g., single-peaked preferences). We show that various natural structures of preference guarantee the existence of an equilibrium and we obtain both tractability and hardness results for the problem of computing several equilibria with some desirable properties."
  },
  "aaai2020_main_coarsecorrelationinextensive-formgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Coarse Correlation in Extensive-Form Games ",
    "authors": [
      "Gabriele Farina",
      "Tommaso Bianchi",
      "Tuomas Sandholm"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5563",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5563/5419",
    "published": "2020-02",
    "summary": " Coarse correlation models strategic interactions of rational agents complemented by a correlation device which is a mediator that can recommend behavior but not enforce it. Despite being a classical concept in the theory of normal-form games since 1978, not much is known about the merits of coarse correlation in extensive-form settings. In this paper, we consider two instantiations of the idea of coarse correlation in extensive-form games: normal-form coarse-correlated equilibrium (NFCCE), already defined in the literature, and extensive-form coarse-correlated equilibrium (EFCCE), a new solution concept that we introduce. We show that EFCCEs are a subset of NFCCEs and a superset of the related extensive-form correlated equilibria. We also show that, in n-player extensive-form games, social-welfare-maximizing EFCCEs and NFCCEs are bilinear saddle points, and give new efficient algorithms for the special case of two-player games with no chance moves. Experimentally, our proposed algorithm for NFCCE is two to four orders of magnitude faster than the prior state of the art. "
  },
  "aaai2020_main_designingcommitteesformitigatingbiases": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Designing Committees for Mitigating Biases ",
    "authors": [
      "Michal Feldman",
      "Yishay Mansour",
      "Noam Nisan",
      "Sigal Oren",
      "Moshe Tennenholtz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5564",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5564/5420",
    "published": "2020-02",
    "summary": "It is widely observed that individuals prefer to interact with others who are more similar to them (this phenomenon is termed homophily). This similarity manifests itself in various ways such as beliefs, values and education. Thus, it should not come as a surprise that when people make hiring choices, for example, their similarity to the candidate plays a role in their choice. In this paper, we suggest that putting the decision in the hands of a committee instead of a single person can reduce this bias."
  },
  "aaai2020_main_strategyproofmechanismsforfriendsandenemiesgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Strategyproof Mechanisms for Friends and Enemies Games ",
    "authors": [
      "Michele Flammini",
      "Bojana Kodric",
      "Giovanna Varricchio"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5565",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5565/5421",
    "published": "2020-02",
    "summary": "We investigate strategyproof mechanisms for Friends and Enemies Games, a subclass of Hedonic Games in which every agent classifies any other one as a friend or as an enemy. In this setting, we consider the two classical scenarios proposed in the literature, called Friends Appreciation (FA) and Enemies Aversion (EA). Roughly speaking, in the former each agent gives priority to the number of friends in her coalition, while in the latter to the number of enemies."
  },
  "aaai2020_main_preventingarbitragefromcollusionwhenelicitingprobabilities": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Preventing Arbitrage from Collusion When Eliciting Probabilities ",
    "authors": [
      "Rupert Freeman",
      "David M. Pennock",
      "Dominik Peters",
      "Bo Waggoner"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5566",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5566/5422",
    "published": "2020-02",
    "summary": " We consider the design of mechanisms to elicit probabilistic forecasts when agents are strategic and may collude with one another. Chun and Shachter (2011) have shown that when agents may form coalitions, many known mechanisms for elicitation permit arbitrage, allowing the coalition members to guarantee themselves higher payments by misreporting their beliefs. We consider two approaches to protect against colluding agents. First, we present a novel strictly proper mechanism that does not admit arbitrage provided that the reports of the agents are bounded away from 0 and 1, a common assumption in many settings. Second, we discover strictly arbitrage-free mechanisms that satisfy an intermediate guarantee between weak and strict properness."
  },
  "aaai2020_main_vcgundersybil(false-name)attacks-abayesiananalysis": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " VCG under Sybil (False-Name) Attacks - A Bayesian Analysis ",
    "authors": [
      "Yotam Gafni",
      "Ron Lavi",
      "Moshe Tennenholtz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5567",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5567/5423",
    "published": "2020-02",
    "summary": "VCG is a classical combinatorial auction that maximizes social welfare. However, while the standard single-item Vickrey auction is false-name-proof, a major failure of multi-item VCG is its vulnerability to false-name attacks. This occurs already in the natural bare minimum model in which there are two identical items and bidders are single-minded. Previous solutions to this challenge focused on developing alternative mechanisms that compromise social welfare. We re-visit the VCG auction vulnerability and consider the bidder behavior in Bayesian settings. In service of that we introduce a novel notion, termed the granularity threshold, that characterizes VCG Bayesian resilience to false-name attacks as a function of the bidder type distribution. Using this notion we show a large class of cases in which VCG indeed obtains Bayesian resilience for the two-item single-minded setting."
  },
  "aaai2020_main_biddinginsmartgridpdastheory,analysisandstrategy": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bidding in Smart Grid PDAs: Theory, Analysis and Strategy ",
    "authors": [
      "Susobhan Ghosh",
      "Sujit Gujar",
      "Praveen Paruchuri",
      "Easwar Subramanian",
      "Sanjay Bhat"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5568",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5568/5424",
    "published": "2020-02",
    "summary": "Periodic Double Auctions (PDAs) are commonly used in the real world for trading, e.g. in stock markets to determine stock opening prices, and energy markets to trade energy in order to balance net demand in smart grids, involving trillions of dollars in the process. A bidder, participating in such PDAs, has to plan for bids in the current auction as well as for the future auctions, which highlights the necessity of good bidding strategies. In this paper, we perform an equilibrium analysis of single unit single-shot double auctions with a certain clearing price and payment rule, which we refer to as ACPR, and find it intractable to analyze as number of participating agents increase. We further derive the best response for a bidder with complete information in a single-shot double auction with ACPR. Leveraging the theory developed for single-shot double auction and taking the PowerTAC wholesale market PDA as our testbed, we proceed by modeling the PDA of PowerTAC as an MDP. We propose a novel bidding strategy, namely MDPLCPBS. We empirically show that MDPLCPBS follows the equilibrium strategy for double auctions that we previously analyze. In addition, we benchmark our strategy against the baseline and the state-of-the-art bidding strategies for the PowerTAC wholesale market PDAs, and show that MDPLCPBS outperforms most of them consistently."
  },
  "aaai2020_main_beyondpairwisecomparisonsinsocialchoiceasetwisekemenyaggregationproblem": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Beyond Pairwise Comparisons in Social Choice: A Setwise Kemeny Aggregation Problem ",
    "authors": [
      "Hugo Gilbert",
      "Tom Portoleau",
      "Olivier Spanjaard"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5569",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5569/5425",
    "published": "2020-02",
    "summary": "In this paper, we advocate the use of setwise contests for aggregating a set of input rankings into an output ranking. We propose a generalization of the Kemeny rule where one minimizes the number of k-wise disagreements instead of pairwise disagreements (one counts 1 disagreement each time the top choice in a subset of alternatives of cardinality at most k differs between an input ranking and the output ranking). After an algorithmic study of this k-wise Kemeny aggregation problem, we introduce a k-wise counterpart of the majority graph. It reveals useful to divide the aggregation problem into several sub-problems. We conclude with numerical tests."
  },
  "aaai2020_main_contiguouscakecuttinghardnessresultsandapproximationalgorithms": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Contiguous Cake Cutting: Hardness Results and Approximation Algorithms ",
    "authors": [
      "Paul W. Goldberg",
      "Alexandros Hollender",
      "Warut Suksompong"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5570",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5570/5426",
    "published": "2020-02",
    "summary": "We study the fair allocation of a cake, which serves as a metaphor for a divisible resource, under the requirement that each agent should receive a contiguous piece of the cake. While it is known that no finite envy-free algorithm exists in this setting, we exhibit efficient algorithms that produce allocations with low envy among the agents. We then establish NP-hardness results for various decision problems on the existence of envy-free allocations, such as when we fix the ordering of the agents or constrain the positions of certain cuts. In addition, we consider a discretized setting where indivisible items lie on a line and show a number of hardness results strengthening those from prior work."
  },
  "aaai2020_main_stronglybudgetbalancedauctionsformulti-sidedmarkets": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Strongly Budget Balanced Auctions for Multi-Sided Markets ",
    "authors": [
      "Rica Gonen",
      "Erel Segal-Halevi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5571",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5571/5427",
    "published": "2020-02",
    "summary": "In two-sided markets, Myerson and Satterthwaite's impossibility theorem states that one can not maximize the gain-from-trade while also satisfying truthfulness, individual-rationality and no deficit. Attempts have been made to circumvent Myerson and Satterthwaite's result by attaining approximately-maximum gain-from-trade: the double-sided auctions of McAfee (1992) is truthful and has no deficit, and the one by Segal-Halevi et al. (2016) additionally has no surplus \u2014 it is strongly-budget-balanced. They consider two categories of agents \u2014 buyers and sellers, where each trade set is composed of a single buyer and a single seller."
  },
  "aaai2020_main_thecomplexityofcomputingmaximinshareallocationsongraphs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " The Complexity of Computing Maximin Share Allocations on Graphs ",
    "authors": [
      "Gianluigi Greco",
      "Francesco Scarcello"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5572",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5572/5428",
    "published": "2020-02",
    "summary": "Maximin share is a compelling notion of fairness proposed by Buddish as a relaxation of more traditional concepts for fair allocations of indivisible goods. In this paper we consider this notion within a setting where bundles of goods must induce connected subsets over an underlying graph. This setting received much attention in earlier literature, and our study answers a number of questions that were left open. First, we show that computing maximin share allocations is F\u03942P-complete, even when focusing on consistent scenarios, that is, where such allocations are a-priori guaranteed to exist. Moreover, the problem remains intractable if all agents have the same type, i.e., have the same utility functions, and if either the values returned by the utility functions are polynomially bounded, or the underlying graphs have a low degree of cyclicity (more precisely, have bounded treewidth). However, if these conditions hold all together, then computing maximin share allocations (or checking that none exists) becomes tractable. The result is established via machineries based on logspace alternating machines that use partial representations of connected bundles, which are interesting in their own."
  },
  "aaai2020_main_fairdivisionthroughinformationwithholding": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fair Division Through Information Withholding ",
    "authors": [
      "Hadi Hosseini",
      "Sujoy Sikdar",
      "Rohit Vaish",
      "Hejun Wang",
      "Lirong Xia"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5573",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5573/5429",
    "published": "2020-02",
    "summary": " Envy-freeness up to one good (EF1) is a well-studied fairness notion for indivisible goods that addresses pairwise envy by the removal of at most one good. In the worst case, each pair of agents might require the (hypothetical) removal of a different good, resulting in a weak aggregate guarantee. We study allocations that are nearly envy-free in aggregate, and define a novel fairness notion based on information withholding. Under this notion, an agent can withhold (or hide) some of the goods in its bundle and reveal the remaining goods to the other agents. We observe that in practice, envy-freeness can be achieved by withholding only a small number of goods overall. We show that finding allocations that withhold an optimal number of goods is computationally hard even for highly restricted classes of valuations. In contrast to the worst-case results, our experiments on synthetic and real-world preference data show that existing algorithms for finding EF1 allocations withhold a close-to-optimal amount of information."
  },
  "aaai2020_main_modelandreinforcementlearningformarkovgameswithriskpreferences": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Model and Reinforcement Learning for Markov Games with Risk Preferences ",
    "authors": [
      "Wenjie Huang",
      "Viet Hai Pham",
      "William Benjamin Haskell"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5574",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5574/5430",
    "published": "2020-02",
    "summary": " We motivate and propose a new model for non-cooperative Markov game which considers the interactions of risk-aware players. This model characterizes the time-consistent dynamic \u201crisk\u201d from both stochastic state transitions (inherent to the game) and randomized mixed strategies (due to all other players). An appropriate risk-aware equilibrium concept is proposed and the existence of such equilibria is demonstrated in stationary strategies by an application of Kakutani's fixed point theorem. We further propose a simulation-based Q-learning type algorithm for risk-aware equilibrium computation. This algorithm works with a special form of minimax risk measures which can naturally be written as saddle-point stochastic optimization problems, and covers many widely investigated risk measures. Finally, the almost sure convergence of this simulation-based algorithm to an equilibrium is demonstrated under some mild conditions. Our numerical experiments on a two player queuing game validate the properties of our model and algorithm, and demonstrate their worth and applicability in real life competitive decision-making."
  },
  "aaai2020_main_asimple,fast,andsafemediatorforcongestionmanagement": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Simple, Fast, and Safe Mediator for Congestion Management ",
    "authors": [
      "Kei Ikegami",
      "Kyohei Okumura",
      "Takumi Yoshikawa"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5575",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5575/5431",
    "published": "2020-02",
    "summary": "Congestion is a severe problem in cities. A large population with little information about each other's preferences hardly reaches equilibrium and causes unexpected congestion. Controlling such congestion requires us to collect information dispersed in the market and to coordinate actions among agents. We aim to design a mediator that a) induces a game with high social welfare in equilibrium, b) computes an equilibrium efficiently, c) works without common prior, and d) performs well even when only some of the agents in the market use the mediator. We propose a mediator based on a version of best response dynamics (BRD). We prove that, in a simple setting with two resources, \u201cgood behavior\u201d (reporting truthfully and following the recommendation) forms an (approximate) ex-post Nash equilibrium in the mediated game; in the equilibrium, the welfare is close to the first-best when preferences diverge enough. Furthermore, under a certain behavioral assumption, those who are not using the mediator can always enjoy non-negative payoff gain by joining it even without the full participation of others. Additionally, our experimental results suggest that such results remain valid for more general settings."
  },
  "aaai2020_main_repeatedmultimarketcontactwithprivatemonitoringabelief-freeapproach": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Repeated Multimarket Contact with Private Monitoring: A Belief-Free Approach ",
    "authors": [
      "Atsushi Iwasaki",
      "Tadashi Sekiguchi",
      "Shun Yamamoto",
      "Makoto Yokoo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5576",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5576/5432",
    "published": "2020-02",
    "summary": "This paper studies repeated games where two players play multiple duopolistic games simultaneously (multimarket contact). A key assumption is that each player receives a noisy and private signal about the other's actions (private monitoring or observation errors). There has been no game-theoretic support that multimarket contact facilitates collusion or not, in the sense that more collusive equilibria in terms of per-market profits exist than those under a benchmark case of one market. An equilibrium candidate under the benchmark case is belief-free strategies. We are the first to construct a non-trivial class of strategies that exhibits the effect of multimarket contact from the perspectives of simplicity and mild punishment. Strategies must be simple because firms in a cartel must coordinate each other with no communication. Punishment must be mild to an extent that it does not hurt even the minimum required profits in the cartel. We thus focus on two-state automaton strategies such that the players are cooperative in at least one market even when he or she punishes a traitor. Furthermore, we identify an additional condition (partial indifference), under which the collusive equilibrium yields the optimal payoff."
  },
  "aaai2020_main_amultiarmedbanditbasedincentivemechanismforasubsetselectionofcustomersfordemandresponseinsmartgrids": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Multiarmed Bandit Based Incentive Mechanism for a Subset Selection of Customers for Demand Response in Smart Grids ",
    "authors": [
      "Jain Shweta",
      "Gujar Sujit"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5577",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5577/5433",
    "published": "2020-02",
    "summary": "Demand response is a crucial tool to maintain the stability of the smart grids. With the upcoming research trends in the area of electricity markets, it has become a possibility to design a dynamic pricing system, and consumers are made aware of what they are going to pay. Though the dynamic pricing system (pricing based on the total demand a distributor company is facing) seems to be one possible solution, the current dynamic pricing approaches are either too complex for a consumer to understand or are too naive leading to inefficiencies in the system (either consumer side or distributor side). Due to these limitations, the recent literature is focusing on the approach to provide incentives to the consumers to reduce the electricity, especially in peak hours. For each round, the goal is to select a subset of consumers to whom the distributor should offer incentives so as to minimize the loss which comprises of cost of buying the electricity from the market, uncertainties at consumer end, and cost incurred to the consumers to reduce the electricity which is a private information to the consumers. Due to the uncertainties in the loss function (arising from renewable energy resources as well as consumption needs), traditional auction theory-based incentives face manipulation challenges. Towards this, we propose a novel combinatorial multi-armed bandit (MAB) algorithm, which we refer to as \\namemab\\ to learn the uncertainties along with an auction to elicit true costs incurred by the consumers. We prove that our mechanism is regret optimal and is incentive compatible. We further demonstrate efficacy of our algorithms via simulations."
  },
  "aaai2020_main_double-oraclesamplingmethodforstackelbergequilibriumapproximationingeneral-sumextensive-formgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Double-Oracle Sampling Method for Stackelberg Equilibrium Approximation in General-Sum Extensive-Form Games ",
    "authors": [
      "Jan Karwowski",
      "Jacek Ma\u0144dziuk"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5578",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5578/5434",
    "published": "2020-02",
    "summary": "The paper presents a new method for approximating Strong Stackelberg Equilibrium in general-sum sequential games with imperfect information and perfect recall. The proposed approach is generic as it does not rely on any specific properties of a particular game model. The method is based on iterative interleaving of the two following phases: (1) guided Monte Carlo Tree Search sampling of the Follower's strategy space and (2) building the Leader's behavior strategy tree for which the sampled Follower's strategy is an optimal response. The above solution scheme is evaluated with respect to expected Leader's utility and time requirements on three sets of interception games with variable characteristics, played on graphs. A comparison with three state-of-the-art MILP/LP-based methods shows that in vast majority of test cases proposed simulation-based approach leads to optimal Leader's strategies, while excelling the competitive methods in terms of better time scalability and lower memory requirements."
  },
  "aaai2020_main_strategy-proofandnon-wastefulmulti-unitauctionviasocialnetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Strategy-Proof and Non-Wasteful Multi-Unit Auction via Social Network ",
    "authors": [
      "Takehiro Kawasaki",
      "Nathanael Barrot",
      "Seiji Takanashi",
      "Taiki Todo",
      "Makoto Yokoo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5579",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5579/5435",
    "published": "2020-02",
    "summary": "Auctions via social network, pioneered by Li et al. (2017), have been attracting considerable attention in the literature of mechanism design for auctions. However, no known mechanism has satisfied strategy-proofness, non-deficit, non-wastefulness, and individual rationality for the multi-unit unit-demand auction, except for some na\u00efve ones. In this paper, we first propose a mechanism that satisfies all the above properties. We then make a comprehensive comparison with two na\u00efve mechanisms, showing that the proposed mechanism dominates them in social surplus, seller's revenue, and incentive of buyers for truth-telling. We also analyze the characteristics of the social surplus and the revenue achieved by the proposed mechanism, including the constant approximability of the worst-case efficiency loss and the complexity of optimizing revenue from the seller's perspective."
  },
  "aaai2020_main_onthemax-minfairstochasticallocationofindivisiblegoods": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On the Max-Min Fair Stochastic Allocation of Indivisible Goods ",
    "authors": [
      "Yasushi Kawase",
      "Hanna Sumita"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5580",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5580/5436",
    "published": "2020-02",
    "summary": "We study the problem of fairly allocating a set of indivisible goods to risk-neutral agents in a stochastic setting. We propose an (approximation) algorithm to find a stochastic allocation that maximizes the minimum utility among the agents. The algorithm runs by repeatedly finding an (approximate) allocation to maximize the total virtual utility of the agents. This implies that the problem is solvable in polynomial time when the utilities are gross-substitutes (which is a subclass of submodular). When the utilities are submodular, we can find a (1 \u2212 1/e)-approximate solution for the problem and this is best possible unless P=NP. We also extend the problem where a stochastic allocation must satisfy the (ex ante) envy-freeness. Under this condition, we demonstrate that the problem is NP-hard even when every agent has an additive utility with a matroid constraint (which is a subclass of gross-substitutes). Furthermore, we propose a polynomial-time algorithm for the setting with a restriction that the matroid constraint is common to all agents."
  },
  "aaai2020_main_ananalysisframeworkformetricvotingbasedonlpduality": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Analysis Framework for Metric Voting based on LP Duality ",
    "authors": [
      "David Kempe"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5581",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5581/5437",
    "published": "2020-02",
    "summary": "Distortion-based analysis has established itself as a fruitful framework for comparing voting mechanisms. m voters and n candidates are jointly embedded in an (unknown) metric space, and the voters submit rankings of candidates by non-decreasing distance from themselves. Based on the submitted rankings, the social choice rule chooses a winning candidate; the quality of the winner is the sum of the (unknown) distances to the voters. The rule's choice will in general be suboptimal, and the worst-case ratio between the cost of its chosen candidate and the optimal candidate is called the rule's distortion. It was shown in prior work that every deterministic rule has distortion at least 3, while the Copeland rule and related rules guarantee distortion at most 5; a very recent result gave a rule with distortion 2 + \u221a5 \u2248 4.236."
  },
  "aaai2020_main_communication,distortion,andrandomnessinmetricvoting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Communication, Distortion, and Randomness in Metric Voting ",
    "authors": [
      "David Kempe"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5582",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5582/5438",
    "published": "2020-02",
    "summary": "In distortion-based analysis of social choice rules over metric spaces, voters and candidates are jointly embedded in a metric space. Voters rank candidates by non-decreasing distance. The mechanism, receiving only this ordinal (comparison) information, must select a candidate approximately minimizing the sum of distances from all voters to the chosen candidate. It is known that while the Copeland rule and related rules guarantee distortion at most 5, the distortion of many other standard voting rules, such as Plurality, Veto, or k-approval, grows unboundedly in the number n of candidates."
  },
  "aaai2020_main_informationelicitationmechanismsforstatisticalestimation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Information Elicitation Mechanisms for Statistical Estimation ",
    "authors": [
      "Yuqing Kong",
      "Grant Schoenebeck",
      "Biaoshuai Tao",
      "Fang-Yi Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5583",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5583/5439",
    "published": "2020-02",
    "summary": "We study learning statistical properties from strategic agents with private information. In this problem, agents must be incentivized to truthfully reveal their information even when it cannot be directly verified. Moreover, the information reported by the agents must be aggregated into a statistical estimate. We study two fundamental statistical properties: estimating the mean of an unknown Gaussian, and linear regression with Gaussian error. The information of each agent is one point in a Euclidean space."
  },
  "aaai2020_main_perpetualvotingfairnessinlong-termdecisionmaking": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Perpetual Voting: Fairness in Long-Term Decision Making ",
    "authors": [
      "Martin Lackner"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5584",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5584/5440",
    "published": "2020-02",
    "summary": "In this paper we introduce a new voting formalism to support long-term collective decision making: perpetual voting rules. These are voting rules that take the history of previous decisions into account. Due to this additional information, perpetual voting rules may offer temporal fairness guarantees that cannot be achieved in singular decisions. In particular, such rules may enable minorities to have a fair (proportional) influence on the decision process and thus foster long-term participation of minorities. This paper explores the proposed voting rules via an axiomatic analysis as well as a quantitative evaluation by computer simulations. We identify two perpetual voting rules as particularly recommendable in long-term collective decision making."
  },
  "aaai2020_main_defendingwithsharedresourcesonanetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Defending with Shared Resources on a Network ",
    "authors": [
      "Minming Li",
      "Long Tran-Thanh",
      "Xiaowei Wu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5585",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5585/5441",
    "published": "2020-02",
    "summary": " In this paper we consider a defending problem on a network. In the model, the defender holds a total defending resource of R, which can be distributed to the nodes of the network. The defending resource allocated to a node can be shared by its neighbors. There is a weight associated with every edge that represents the efficiency defending resources are shared between neighboring nodes. We consider the setting when each attack can affect not only the target node, but its neighbors as well. Assuming that nodes in the network have different treasures to defend and different defending requirements, the defender aims at allocating the defending resource to the nodes to minimize the loss due to attack. We give polynomial time exact algorithms for two important special cases of the network defending problem. For the case when an attack can only affect the target node, we present an LP-based exact algorithm. For the case when defending resources cannot be shared, we present a max-flow-based exact algorithm. We show that the general problem is NP-hard, and we give a 2-approximation algorithm based on LP-rounding. Moreover, by giving a matching lower bound of 2 on the integrality gap on the LP relaxation, we show that our rounding is tight."
  },
  "aaai2020_main_structurelearningforapproximatesolutionofmany-playergames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Structure Learning for Approximate Solution of Many-Player Games ",
    "authors": [
      "Zun Li",
      "Michael Wellman"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5586",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5586/5442",
    "published": "2020-02",
    "summary": "Games with many players are difficult to solve or even specify without adopting structural assumptions that enable representation in compact form. Such structure is generally not given and will not hold exactly for particular games of interest. We introduce an iterative structure-learning approach to search for approximate solutions of many-player games, assuming only black-box simulation access to noisy payoff samples. Our first algorithm, K-Roles, exploits symmetry by learning a role assignment for players of the game through unsupervised learning (clustering) methods. Our second algorithm, G3L, seeks sparsity by greedy search over local interactions to learn a graphical game model. Both algorithms use supervised learning (regression) to fit payoff values to the learned structures, in compact representations that facilitate equilibrium calculation. We experimentally demonstrate the efficacy of both methods in reaching quality solutions and uncovering hidden structure, on both perfectly and approximately structured game instances."
  },
  "aaai2020_main_adaptivequantitativetradinganimitativedeepreinforcementlearningapproach": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adaptive Quantitative Trading: An Imitative Deep Reinforcement Learning Approach ",
    "authors": [
      "Yang Liu",
      "Qi Liu",
      "Hongke Zhao",
      "Zhen Pan",
      "Chuanren Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5587",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5587/5443",
    "published": "2020-02",
    "summary": "In recent years, considerable efforts have been devoted to developing AI techniques for finance research and applications. For instance, AI techniques (e.g., machine learning) can help traders in quantitative trading (QT) by automating two tasks: market condition recognition and trading strategies execution. However, existing methods in QT face challenges such as representing noisy high-frequent financial data and finding the balance between exploration and exploitation of the trading agent with AI techniques. To address the challenges, we propose an adaptive trading model, namely iRDPG, to automatically develop QT strategies by an intelligent trading agent. Our model is enhanced by deep reinforcement learning (DRL) and imitation learning techniques. Specifically, considering the noisy financial data, we formulate the QT process as a Partially Observable Markov Decision Process (POMDP). Also, we introduce imitation learning to leverage classical trading strategies useful to balance between exploration and exploitation. For better simulation, we train our trading agent in the real financial market using minute-frequent data. Experimental results demonstrate that our model can extract robust market features and be adaptive in different markets."
  },
  "aaai2020_main_limitationsofincentivecompatibilityondiscretetypespaces": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Limitations of Incentive Compatibility on Discrete Type Spaces ",
    "authors": [
      "Taylor Lundy",
      "Hu Fu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5588",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5588/5444",
    "published": "2020-02",
    "summary": "In the design of incentive compatible mechanisms, a common approach is to enforce incentive compatibility as constraints in programs that optimize over feasible mechanisms. Such constraints are often imposed on sparsified representations of the type spaces, such as their discretizations or samples, in order for the program to be manageable. In this work, we explore limitations of this approach, by studying whether all dominant strategy incentive compatible mechanisms on a set T of discrete types can be extended to the convex hull of T."
  },
  "aaai2020_main_mechanismdesignwithpredictedtaskrevenueforbikesharingsystems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Mechanism Design with Predicted Task Revenue for Bike Sharing Systems ",
    "authors": [
      "Hongtao Lv",
      "Chaoli Zhang",
      "Zhenzhe Zheng",
      "Tie Luo",
      "Fan Wu",
      "Guihai Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5589",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5589/5445",
    "published": "2020-02",
    "summary": "Bike sharing systems have been widely deployed around the world in recent years. A core problem in such systems is to reposition the bikes so that the distribution of bike supply is reshaped to better match the dynamic bike demand. When the bike-sharing company or platform is able to predict the revenue of each reposition task based on historic data, an additional constraint is to cap the payment for each task below its predicted revenue. In this paper, we propose an incentive mechanism called TruPreTar to incentivize users to park bicycles at locations desired by the platform toward rebalancing supply and demand. TruPreTar possesses four important economic and computational properties such as truthfulness and budget feasibility. Furthermore, we prove that even when the payment budget is tight, the total revenue still exceeds or equals the budget. Otherwise, TruPreTar achieves 2-approximation as compared to the optimal (revenue-maximizing) solution, which is close to the lower bound of at least \u221a2 that we also prove. Using an industrial dataset obtained from a large bike-sharing company, our experiments show that TruPreTar is effective in rebalancing bike supply and demand and, as a result, generates high revenue that outperforms several benchmark mechanisms."
  },
  "aaai2020_main_liftingpreferencesoveralternativestopreferencesoversetsofalternativesthecomplexityofrecognizingdesirablefamiliesofsets": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Lifting Preferences over Alternatives to Preferences over Sets of Alternatives: The Complexity of Recognizing Desirable Families of Sets ",
    "authors": [
      "Jan Maly"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5590",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5590/5446",
    "published": "2020-02",
    "summary": "The problem of lifting a preference order on a set of objects to a preference order on a family of subsets of this set is a fundamental problem with a wide variety of applications in AI. The process is often guided by axioms postulating properties the lifted order should have. Well-known impossibility results by Kannai and Peleg and by Barber\u00e0 and Pattanaik tell us that some desirable axioms \u2013 namely dominance and (strict) independence \u2013 are not jointly satisfiable for any linear order on the objects if all non-empty sets of objects are to be ordered. On the other hand, if not all non-empty sets of objects are to be ordered, the axioms are jointly satisfiable for all linear orders on the objects for some families of sets. Such families are very important for applications as they allow for the use of lifted orders, for example, in combinatorial voting. In this paper, we determine the computational complexity of recognizing such families. We show that it is \u03a02p-complete to decide for a given family of subsets whether dominance and independence or dominance and strict independence are jointly satisfiable for all linear orders on the objects if the lifted order needs to be total. Furthermore, we show that the problem remains coNP-complete if the lifted order can be incomplete. Additionally, we show that the complexity of these problem can increase exponentially if the family of sets is not given explicitly but via a succinct domain restriction."
  },
  "aaai2020_main_theeffectivenessofpeerpredictioninlong-termforecasting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " The Effectiveness of Peer Prediction in Long-Term Forecasting ",
    "authors": [
      "Mandal Debmalya",
      "Radanovi\u0107 Goran",
      "Parkes David"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5591",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5591/5447",
    "published": "2020-02",
    "summary": ""
  },
  "aaai2020_main_thesurprisingpowerofhidinginformationinfacilitylocation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " The Surprising Power of Hiding Information in Facility Location ",
    "authors": [
      "Safwan Hossain",
      "Evi Micha",
      "Nisarg Shah"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5592",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5592/5448",
    "published": "2020-02",
    "summary": "Facility location is the problem of locating a public facility based on the preferences of multiple agents. In the classic framework, where each agent holds a single location on a line and can misreport it, strategyproof mechanisms for choosing the location of the facility are well-understood."
  },
  "aaai2020_main_canwepredicttheelectionoutcomefromsampledvotes?": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Can We Predict the Election Outcome from Sampled Votes? ",
    "authors": [
      "Evi Micha",
      "Nisarg Shah"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5593",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5593/5449",
    "published": "2020-02",
    "summary": " In the standard model of voting, it is assumed that a voting rule observes the ranked preferences of each individual over a set of alternatives and makes a collective decision. In practice, however, not every individual votes. Is it possible to make a good collective decision for a group given the preferences of only a few of its members? We propose a framework in which we are given the ranked preferences of k out of n individuals sampled from a distribution, and the goal is to predict what a given voting rule would output if applied on the underlying preferences of all n individuals. We focus on the family of positional scoring rules, derive a strong negative result when the underlying preferences can be arbitrary, and discover interesting phenomena when they are generated from a known distribution."
  },
  "aaai2020_main_priceoffairnessinbudgetdivisionandprobabilisticsocialchoice": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Price of Fairness in Budget Division and Probabilistic Social Choice ",
    "authors": [
      "Marcin Michorzewski",
      "Dominik Peters",
      "Piotr Skowron"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5594",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5594/5450",
    "published": "2020-02",
    "summary": "A group of agents needs to divide a divisible common resource (such as a monetary budget) among several uses or projects. We assume that agents have approval preferences over projects, and their utility is the fraction of the budget spent on approved projects. If we maximize utilitarian social welfare, the entire budget will be spent on a single popular project, even if a substantial fraction of the agents disapprove it. This violates the individual fair share axiom (IFS) which requires that for each agent, at least 1/n of the budget is spent on approved projects. We study the price of imposing such fairness axioms on utilitarian social welfare. We show that no division rule satisfying IFS can guarantee to achieve more than an O(1/\u221am) fraction of maximum utilitarian welfare, in the worst case. However, imposing stronger group fairness conditions (such as the core) does not come with an increased price, since both the conditional utilitarian rule and the Nash rule match this bound and guarantee an \u038f(1/\u221am) fraction. The same guarantee is attained by the rule under which the spending on a project is proportional to its approval score. We also study a family of rules interpolating between the utilitarian and the Nash rule, quantifying a trade-off between welfare and group fairness. An experimental analysis by sampling using several probabilistic models shows that the conditional utilitarian rule achieves very high welfare on average."
  },
  "aaai2020_main_robustmarketequilibriawithuncertainpreferences": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Robust Market Equilibria with Uncertain Preferences ",
    "authors": [
      "Riley Murray",
      "Christian Kroer",
      "Alex Peysakhovich",
      "Parikshit Shah"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5595",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5595/5451",
    "published": "2020-02",
    "summary": "The problem of allocating scarce items to individuals is an important practical question in market design. An increasingly popular set of mechanisms for this task uses the concept of market equilibrium: individuals report their preferences, have a budget of real or fake currency, and a set of prices for items and allocations is computed that sets demand equal to supply. An important real world issue with such mechanisms is that individual valuations are often only imperfectly known. In this paper, we show how concepts from classical market equilibrium can be extended to reflect such uncertainty. We show that in linear, divisible Fisher markets a robust market equilibrium (RME) always exists; this also holds in settings where buyers may retain unspent money. We provide theoretical analysis of the allocative properties of RME in terms of envy and regret. Though RME are hard to compute for general uncertainty sets, we consider some natural and tractable uncertainty sets which lead to well behaved formulations of the problem that can be solved via modern convex programming methods. Finally, we show that very mild uncertainty about valuations can cause RME allocations to outperform those which take estimates as having no underlying uncertainty."
  },
  "aaai2020_main_practicalfrank\u2013wolfemethodwithdecisiondiagramsforcomputingwardropequilibriumofcombinatorialcongestiongames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Practical Frank\u2013Wolfe Method with Decision Diagrams for Computing Wardrop Equilibrium of Combinatorial Congestion Games ",
    "authors": [
      "Kengo Nakamura",
      "Shinsaku Sakaue",
      "Norihito Yasuda"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5596",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5596/5452",
    "published": "2020-02",
    "summary": "Computation of equilibria for congestion games has been an important research subject. In many realistic scenarios, each strategy of congestion games is given by a combination of elements that satisfies certain constraints; such games are called combinatorial congestion games. For example, given a road network with some toll roads, each strategy of routing games is a path (a combination of edges) whose total toll satisfies a certain budget constraint. Generally, given a ground set of n elements, the set of all such strategies, called the strategy set, can be large exponentially in n, and it often has complicated structures; these issues make equilibrium computation very hard. In this paper, we propose a practical algorithm for such hard equilibrium computation problems. We use data structures, called zero-suppressed binary decision diagrams (ZDDs), to compactly represent strategy sets, and we develop a Frank\u2013Wolfe-style iterative equilibrium computation algorithm whose per-iteration complexity is linear in the size of the ZDD representation. We prove that an \u03f5-approximate Wardrop equilibrium can be computed in O(poly(n)/\u03f5) iterations, and we improve the result to O(poly(n) log \u03f5\u22121) for some special cases. Experiments confirm the practical utility of our method."
  },
  "aaai2020_main_balancingthetradeoffbetweenprofitandfairnessinrideshareplatformsduringhigh-demandhours": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Balancing the Tradeoff between Profit and Fairness in Rideshare Platforms during High-Demand Hours ",
    "authors": [
      "Vedant Nanda",
      "Pan Xu",
      "Karthik Abhinav Sankararaman",
      "John Dickerson",
      "Aravind Srinivasan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5597",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5597/5453",
    "published": "2020-02",
    "summary": "Rideshare platforms, when assigning requests to drivers, tend to maximize profit for the system and/or minimize waiting time for riders. Such platforms can exacerbate biases that drivers may have over certain types of requests. We consider the case of peak hours when the demand for rides is more than the supply of drivers. Drivers are well aware of their advantage during the peak hours and can choose to be selective about which rides to accept. Moreover, if in such a scenario, the assignment of requests to drivers (by the platform) is made only to maximize profit and/or minimize wait time for riders, requests of a certain type (e.g., from a non-popular pickup location, or to a non-popular drop-off location) might never be assigned to a driver. Such a system can be highly unfair to riders. However, increasing fairness might come at a cost of the overall profit made by the rideshare platform. To balance these conflicting goals, we present a flexible, non-adaptive algorithm, NAdap, that allows the platform designer to control the profit and fairness of the system via parameters \u03b1 and \u03b2 respectively. We model the matching problem as an online bipartite matching where the set of drivers is offline and requests arrive online. Upon the arrival of a request, we use NAdap to assign it to a driver (the driver might then choose to accept or reject it) or reject the request. We formalize the measures of profit and fairness in our setting and show that by using NAdap, the competitive ratios for profit and fairness measures would be no worse than \u03b1/e and \u03b2/e respectively. Extensive experimental results on both real-world and synthetic datasets confirm the validity of our theoretical lower bounds. Additionally, they show that NAdap under some choice of (\u03b1, \u03b2) can beat two natural heuristics, Greedy and Uniform, on both fairness and profit. Code is available at: https://github.com/nvedant07/rideshare-fairness-peak/."
  },
  "aaai2020_main_comparingelectionmethodswhereeachvoterranksonlyfewcandidates": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Comparing Election Methods Where Each Voter Ranks Only Few Candidates ",
    "authors": [
      "Matthias Bentert",
      "Piotr Skowron"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5598",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5598/5454",
    "published": "2020-02",
    "summary": "Election rules are formal processes that aggregate voters' preferences, typically to select a single winning candidate. Most of the election rules studied in the literature require the voters to rank the candidates from the most to the least preferred one. This method of eliciting preferences is impractical when the number of candidates to be ranked is large. We ask how well certain election rules (focusing on positional scoring rules and the Minimax rule) can be approximated from partial preferences collected through one of the following procedures: (i) randomized\u2014we ask each voter to rank a random subset of \u2113 candidates, and (ii) deterministic\u2014we ask each voter to provide a ranking of her \u2113 most preferred candidates (the \u2113-truncated ballot). We establish theoretical bounds on the approximation ratios and complement our theoretical analysis with computer simulations. We find that it is usually better to use the randomized approach."
  },
  "aaai2020_main_solvingonlinethreatscreeninggamesusingconstrainedactionspacereinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Solving Online Threat Screening Games using Constrained Action Space Reinforcement Learning ",
    "authors": [
      "Sanket Shah",
      "Sinha Arunesh",
      "Varakantham Pradeep",
      "Perrault Andrew",
      "Tambe Milind"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5599",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5599/5455",
    "published": "2020-02",
    "summary": "Large-scale screening for potential threats with limited resources and capacity for screening is a problem of interest at airports, seaports, and other ports of entry. Adversaries can observe screening procedures and arrive at a time when there will be gaps in screening due to limited resource capacities. To capture this game between ports and adversaries, this problem has been previously represented as a Stackelberg game, referred to as a Threat Screening Game (TSG). Given the significant complexity associated with solving TSGs and uncertainty in arrivals of customers, existing work has assumed that screenees arrive and are allocated security resources at the beginning of the time-window. In practice, screenees such as airport passengers arrive in bursts correlated with flight time and are not bound by fixed time-windows. To address this, we propose an online threat screening model in which the screening strategy is determined adaptively as a passenger arrives while satisfying a hard bound on acceptable risk of not screening a threat. To solve the online problem, we first reformulate it as a Markov Decision Process (MDP) in which the hard bound on risk translates to a constraint on the action space and then solve the resultant MDP using Deep Reinforcement Learning (DRL). To this end, we provide a novel way to efficiently enforce linear inequality constraints on the action output in DRL. We show that our solution allows us to significantly reduce screenee wait time without compromising on the risk."
  },
  "aaai2020_main_reinforcementmechanismdesignwithapplicationstodynamicpricinginsponsoredsearchauctions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reinforcement Mechanism Design: With Applications to Dynamic Pricing in Sponsored Search Auctions ",
    "authors": [
      "Weiran Shen",
      "Binghui Peng",
      "Hanpeng Liu",
      "Michael Zhang",
      "Ruohan Qian",
      "Yan Hong",
      "Zhi Guo",
      "Zongyao Ding",
      "Pengjun Lu",
      "Pingzhong Tang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5600",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5600/5456",
    "published": "2020-02",
    "summary": "In many social systems in which individuals and organizations interact with each other, there can be no easy laws to govern the rules of the environment, and agents' payoffs are often influenced by other agents' actions. We examine such a social system in the setting of sponsored search auctions and tackle the search engine's dynamic pricing problem by combining the tools from both mechanism design and the AI domain. In this setting, the environment not only changes over time, but also behaves strategically. Over repeated interactions with bidders, the search engine can dynamically change the reserve prices and determine the optimal strategy that maximizes the profit. We first train a buyer behavior model, with a real bidding data set from a major search engine, that predicts bids given information disclosed by the search engine and the bidders' performance data from previous rounds. We then formulate the dynamic pricing problem as an MDP and apply a reinforcement-based algorithm that optimizes reserve prices over time. Experiments demonstrate that our model outperforms static optimization strategies including the ones that are currently in use as well as several other dynamic ones."
  },
  "aaai2020_main_complexityofcomputingtheshapleyvalueingameswithexternalities": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Complexity of Computing the Shapley Value in Games with Externalities ",
    "authors": [
      "Oskar Skibski"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5601",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5601/5457",
    "published": "2020-02",
    "summary": "We study the complexity of computing the Shapley value in games with externalities. We focus on two representations based on marginal contribution nets (embedded MC-nets and weighted MC-nets) and five extensions of the Shapley value to games with externalities. Our results show that while weighted MC-nets are more concise than embedded MC-nets, they have slightly worse computational properties when it comes to computing the Shapley value: two out of five extensions can be computed in polynomial time for embedded MC-nets and only one for weighted MC-nets."
  },
  "aaai2020_main_pathplanningproblemswithsideobservations\u2014whencolonelsplayhide-and-seek": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Path Planning Problems with Side Observations\u2014When Colonels Play Hide-and-Seek ",
    "authors": [
      "Dong Quan Vu",
      "Patrick Loiseau",
      "Alonso Silva",
      "Long Tran-Thanh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5602",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5602/5458",
    "published": "2020-02",
    "summary": "Resource allocation games such as the famous Colonel Blotto (CB) and Hide-and-Seek (HS) games are often used to model a large variety of practical problems, but only in their one-shot versions. Indeed, due to their extremely large strategy space, it remains an open question how one can efficiently learn in these games. In this work, we show that the online CB and HS games can be cast as path planning problems with side-observations (SOPPP): at each stage, a learner chooses a path on a directed acyclic graph and suffers the sum of losses that are adversarially assigned to the corresponding edges; and she then receives semi-bandit feedback with side-observations (i.e., she observes the losses on the chosen edges plus some others). We propose a novel algorithm, Exp3-OE, the first-of-its-kind with guaranteed efficient running time for SOPPP without requiring any auxiliary oracle. We provide an expected-regret bound of Exp3-OE in SOPPP matching the order of the best benchmark in the literature. Moreover, we introduce additional assumptions on the observability model under which we can further improve the regret bounds of Exp3-OE. We illustrate the benefit of using Exp3-OE in SOPPP by applying it to the online CB and HS games."
  },
  "aaai2020_main_multi-typeresourceallocationwithpartialpreferences": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Type Resource Allocation with Partial Preferences ",
    "authors": [
      "Haibin Wang",
      "Sujoy Sikdar",
      "Xiaoxi Guo",
      "Lirong Xia",
      "Yongzhi Cao",
      "Hanpin Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5603",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5603/5459",
    "published": "2020-02",
    "summary": "We propose multi-type probabilistic serial (MPS) and multi-type random priority (MRP) as extensions of the well-known PS and RP mechanisms to the multi-type resource allocation problems (MTRAs) with partial preferences. In our setting, there are multiple types of divisible items, and a group of agents who have partial order preferences over bundles consisting of one item of each type. We show that for the unrestricted domain of partial order preferences, no mechanism satisfies both sd-efficiency and sd-envy-freeness. Notwithstanding this impossibility result, our main message is positive: When agents' preferences are represented by acyclic CP-nets, MPS satisfies sd-efficiency, sd-envy-freeness, ordinal fairness, and upper invariance, while MRP satisfies ex-post-efficiency, sd-strategyproofness, and upper invariance, recovering the properties of PS and RP. Besides, we propose a hybrid mechanism, multi-type general dictatorship (MGD), combining the ideas of MPS and MRP, which satisfies sd-efficiency, equal treatment of equals and decomposability under the unrestricted domain of partial order preferences."
  },
  "aaai2020_main_niceinvinciblestrategyfortheaverage-payoffipd": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Nice Invincible Strategy for the Average-Payoff IPD ",
    "authors": [
      "Shiheng Wang",
      "Fangzhen Lin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5604",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5604/5460",
    "published": "2020-02",
    "summary": "The Iterated Prisoner's Dilemma (IPD) is a well-known benchmark for studying the long term behaviours of rational agents. Many well-known strategies have been studied, from the simple tit-for-tat (TFT) to more involved ones like zero determinant and extortionate strategies studied recently by Press and Dyson. In this paper, we consider what we call invincible strategies. These are ones that will never lose against any other strategy in terms of average payoff in the limit. We provide a simple characterization of this class of strategies, and show that invincible strategies can also be nice. We discuss its relationship with some important strategies and generalize our results to some typical repeated 2x2 games. It's known that experimentally, nice strategies like the TFT and extortionate ones can act as catalysts for the evolution of cooperation. Our experiments show that this is also the case for some invincible strategies that are neither nice nor extortionate."
  },
  "aaai2020_main_boundedincentivesinmanipulatingtheprobabilisticserialrule": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bounded Incentives in Manipulating the Probabilistic Serial Rule ",
    "authors": [
      "Zihe Wang",
      "Zhide Wei",
      "Jie Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5605",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5605/5461",
    "published": "2020-02",
    "summary": "The Probabilistic Serial mechanism is well-known for its desirable fairness and efficiency properties. It is one of the most prominent protocols for the random assignment problem. However, Probabilistic Serial is not incentive-compatible, thereby these desirable properties only hold for the agents' declared preferences, rather than their genuine preferences. A substantial utility gain through strategic behaviors would trigger self-interested agents to manipulate the mechanism and would subvert the very foundation of adopting the mechanism in practice. In this paper, we characterize the extent to which an individual agent can increase its utility by strategic manipulation. We show that the incentive ratio of the mechanism is 3/2. That is, no agent can misreport its preferences such that its utility becomes more than 1.5 times of what it is when reports truthfully. This ratio is a worst-case guarantee by allowing an agent to have complete information about other agents' reports and to figure out the best response strategy even if it is computationally intractable in general. To complement this worst-case study, we further evaluate an agent's utility gain on average by experiments. The experiments show that an agent' incentive in manipulating the rule is very limited. These results shed some light on the robustness of Probabilistic Serial against strategic manipulation, which is one step further than knowing that it is not incentive-compatible."
  },
  "aaai2020_main_deeplearning\u2014powerediterativecombinatorialauctions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Learning\u2014Powered Iterative Combinatorial Auctions ",
    "authors": [
      "Jakob Weissteiner",
      "Sven Seuken"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5606",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5606/5462",
    "published": "2020-02",
    "summary": "In this paper, we study the design of deep learning-powered iterative combinatorial auctions (ICAs). We build on prior work where preference elicitation was done via kernelized support vector regressions (SVRs). However, the SVR-based approach has limitations because it requires solving a machine learning (ML)-based winner determination problem (WDP). With expressive kernels (like gaussians), the ML-based WDP cannot be solved for large domains. While linear or quadratic kernels have better computational scalability, these kernels have limited expressiveness. In this work, we address these shortcomings by using deep neural networks (DNNs) instead of SVRs. We first show how the DNN-based WDP can be reformulated into a mixed integer program (MIP). Second, we experimentally compare the prediction performance of DNNs against SVRs. Third, we present experimental evaluations in two medium-sized domains which show that even ICAs based on relatively small-sized DNNs lead to higher economic efficiency than ICAs based on kernelized SVRs. Finally, we show that our DNN-powered ICA also scales well to very large CA domains."
  },
  "aaai2020_main_amulti-unitprofitcompetitivemechanismforcellulartrafficoffloading": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Multi-Unit Profit Competitive Mechanism for Cellular Traffic Offloading ",
    "authors": [
      "Jun Wu",
      "Yu Qiao",
      "Lei Zhang",
      "Chongjun Wang",
      "Meilin Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5607",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5607/5463",
    "published": "2020-02",
    "summary": "Cellular traffic offloading is nowadays an important problem in mobile networking. We model it as a procurement problem where each agent sells multi-units of a homogeneous item with privately known capacity and unit cost, and the auctioneer's demand valuation function is symmetric submodular. Based on the framework of random sampling and profit extraction, we aim to design a prior-free mechanism which guarantees a profit competitive to the omniscient single-price auction. However, the symmetric submodular demand valuation function and 2-parameter setting present new challenges. By adopting the highest feasible clear price, we successfully design a truthful profit extractor, and then we propose a mechanism which is proved to be truthful, individually rational and constant-factor competitive in a fixed market."
  },
  "aaai2020_main_algorithmsformanipulatingsequentialallocation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Algorithms for Manipulating Sequential Allocation ",
    "authors": [
      "Mingyu Xiao",
      "Jiaxing Ling"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5608",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5608/5464",
    "published": "2020-02",
    "summary": " Sequential allocation is a simple and widely studied mechanism to allocate indivisible items in turns to agents according to a pre-specified picking sequence of agents. At each turn, the current agent in the picking sequence picks its most preferred item among all items having not been allocated yet. This problem is well-known to be not strategyproof, i.e., an agent may get more utility by reporting an untruthful preference ranking of items. It arises the problem: how to find the best response of an agent? It is known that this problem is polynomially solvable for only two agents and NP-complete for an arbitrary number of agents. The computational complexity of this problem with three agents was left as an open problem. In this paper, we give a novel algorithm that solves the problem in polynomial time for each fixed number of agents. We also show that an agent can always get at least half of its optimal utility by simply using its truthful preference as the response."
  },
  "aaai2020_main_computingequilibriainbinarynetworkedpublicgoodsgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Computing Equilibria in Binary Networked Public Goods Games ",
    "authors": [
      "Sixie Yu",
      "Kai Zhou",
      "Jeffrey Brantingham",
      "Yevgeniy Vorobeychik"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5609",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5609/5465",
    "published": "2020-02",
    "summary": " Public goods games study the incentives of individuals to contribute to a public good and their behaviors in equilibria. In this paper, we examine a specific type of public goods game where players are networked and each has binary actions, and focus on the algorithmic aspects of such games. First, we show that checking the existence of a pure-strategy Nash equilibrium is NP-complete. We then identify tractable instances based on restrictions of either utility functions or of the underlying graphical structure. In certain cases, we also show that we can efficiently compute a socially optimal Nash equilibrium. Finally, we propose a heuristic approach for computing approximate equilibria in general binary networked public goods games, and experimentally demonstrate its effectiveness. Due to space limitation, some proofs are deferred to the extended version1."
  },
  "aaai2020_main_computingteam-maxminequilibriainzero-summultiplayerextensive-formgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Computing Team-Maxmin Equilibria in Zero-Sum Multiplayer Extensive-Form Games ",
    "authors": [
      "Youzhi Zhang",
      "Bo An"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5610",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5610/5466",
    "published": "2020-02",
    "summary": " The study of finding the equilibrium for multiplayer games is challenging. This paper focuses on computing Team-Maxmin Equilibria (TMEs) in zero-sum multiplayer Extensive-Form Games (EFGs), which describes the optimal strategies for a team of players who share the same goal but they take actions independently against an adversary. TMEs can capture many realistic scenarios, including: 1) a team of players play against a target player in poker games; and 2) defense resources schedule and patrol independently in security games. However, the study of efficiently finding TMEs within any given accuracy in EFGs is almost completely unexplored. To fill this gap, we first study the inefficiency caused by computing the equilibrium where team players correlate their strategies and then transforming it into the mixed strategy profile of the team and show that this inefficiency can be arbitrarily large. Second, to efficiently solve the non-convex program for finding TMEs directly, we develop the Associated Recursive Asynchronous Multiparametric Disaggregation Technique (ARAMDT) to approximate multilinear terms in the program with two novel techniques: 1) an asynchronous precision method to reduce the number of constraints and variables for approximation by using different precision levels to approximate these terms; and 2) an associated constraint method to reduce the feasible solution space of the mixed-integer linear program resulting from ARAMDT by exploiting the relation between these terms. Third, we develop a novel iterative algorithm to efficiently compute TMEs within any given accuracy based on ARAMDT. Our algorithm is orders of magnitude faster than baselines in the experimental evaluation."
  },
  "aaai2020_main_aunifyingviewonindividualboundsandheuristicinaccuraciesinbidirectionalsearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Unifying View on Individual Bounds and Heuristic Inaccuracies in Bidirectional Search ",
    "authors": [
      "Vidal Alc\u00e1zar",
      "Pat Riddle",
      "Mike Barley"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5611",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5611/5467",
    "published": "2020-02",
    "summary": "In the past few years, new very successful bidirectional heuristic search algorithms have been proposed. Their key novelty is a lower bound on the cost of a solution that includes information from the g values in both directions. Kaindl and Kainz (1997) proposed measuring how inaccurate a heuristic is while expanding nodes in the opposite direction, and using this information to raise the f value of the evaluated nodes. However, this comes with a set of disadvantages and remains yet to be exploited to its full potential. Additionally, Sadhukhan (2013) presented BAE\u2217, a bidirectional best-first search algorithm based on the accumulated heuristic inaccuracy along a path. However, no complete comparison in regards to other bidirectional algorithms has yet been done, neither theoretical nor empirical. In this paper we define individual bounds within the lower-bound framework and show how both Kaindl and Kainz's and Sadhukhan's methods can be generalized thus creating new bounds. This overcomes previous shortcomings and allows newer algorithms to benefit from these techniques as well. Experimental results show a substantial improvement, up to an order of magnitude in the number of necessarily-expanded nodes compared to state-of-the-art near-optimal algorithms in common benchmarks."
  },
  "aaai2020_main_aninteractiveregret-basedgeneticalgorithmforsolvingmulti-objectivecombinatorialoptimizationproblems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Interactive Regret-Based Genetic Algorithm for Solving Multi-Objective Combinatorial Optimization Problems ",
    "authors": [
      "Nawal Benabbou",
      "Cassandre Leroy",
      "Thibaut Lust"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5612",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5612/5468",
    "published": "2020-02",
    "summary": "We propose a new approach consisting in combining genetic algorithms and regret-based incremental preference elicitation for solving multi-objective combinatorial optimization problems with unknown preferences. For the purpose of elicitation, we assume that the decision maker's preferences can be represented by a parameterized scalarizing function but the parameters are initially not known. Instead, the parameter imprecision is progressively reduced by asking preference queries to the decision maker during the search to help identify the best solutions within a population. Our algorithm, called RIGA, can be applied to any multi-objective combinatorial optimization problem provided that the scalarizing function is linear in its parameters and that a (near-)optimal solution can be efficiently determined when preferences are known. Moreover, RIGA runs in polynomial time while asking no more than a polynomial number of queries. For the multi-objective traveling salesman problem, we provide numerical results showing its practical efficiency in terms of number of queries, computation time and gap to optimality."
  },
  "aaai2020_main_localsearchwithdynamic-thresholdconfigurationcheckingandincrementalneighborhoodupdatingformaximumk-plexproblem": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Local Search with Dynamic-Threshold Configuration Checking and Incremental Neighborhood Updating for Maximum k-plex Problem ",
    "authors": [
      "Peilin Chen",
      "Hai Wan",
      "Shaowei Cai",
      "Jia Li",
      "Haicheng Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5613",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5613/5469",
    "published": "2020-02",
    "summary": "The Maximum k-plex Problem is an important combinatorial optimization problem with increasingly wide applications. In this paper, we propose a novel strategy, named Dynamic-threshold Configuration Checking (DCC), to reduce the cycling problem of local search. Due to the complicated neighborhood relations, all the previous local search algorithms for this problem spend a large amount of time in identifying feasible neighbors in each step. To further improve the performance on dense and challenging instances, we propose Double-attributes Incremental Neighborhood Updating (DINU) scheme which reduces the worst-case time complexity per iteration from O(|V|\u22c5\u0394G) to O(k \u00b7 \u0394G\u203e). Based on DCC strategy and DINU scheme, we develop a local search algorithm named DCCplex. According to the experiment result, DCCplex shows promising result on DIMACS and BHOSLIB benchmark as well as real-world massive graphs. Especially, DCCplex updates the lower bound of the maximum k-plex for most dense and challenging instances."
  },
  "aaai2020_main_envelope-basedapproachestoreal-timeheuristicsearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Envelope-Based Approaches to Real-Time Heuristic Search ",
    "authors": [
      "Kevin Gall",
      "Bence Cserna",
      "Wheeler Ruml"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5614",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5614/5470",
    "published": "2020-02",
    "summary": "In real-time heuristic search, the planner must return the next action for the agent within a pre-specified time bound. Many algorithms for this setting are \u2018agent-centered\u2019 in that, at every iteration, they only expand states near the agent's current state, discarding the search frontier afterwards. In this paper, we investigate the alternative paradigm in which the search expands a single ever-growing envelope of states. Previous work on envelope-based methods restricts the agent to move along the generated search tree. We propose a more flexible approach in which an auxiliary search is performed within the envelope to guide the agent toward a promising frontier node. Experimental results indicate that intra-envelope search is beneficial in state spaces that are highly interconnected, such as those for grid pathfinding."
  },
  "aaai2020_main_runtimeanalysisofsomaticcontiguoushypermutationoperatorsinmoea/dframework": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Runtime Analysis of Somatic Contiguous Hypermutation Operators in MOEA/D Framework ",
    "authors": [
      "Zhengxin Huang",
      "Yuren Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5615",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5615/5471",
    "published": "2020-02",
    "summary": "Somatic contiguous hypermutation (CHM) operators are important variation operators in artificial immune systems. The few existing theoretical studies are only concerned with understanding the optimization behavior of CHM operators on solving single-objective optimization problems. The MOEA/D framework is one of the most popular strategies for solving multi-objective optimization problems (MOPs). In this paper, we present a runtime analysis of using two CHM operators in MOEA/D framework for solving five benchmark MOPs, including four bi-objective and one many-objective problems. Our analyses show that the expected runtimes of CHM operators on the four bi-objective problems are better than or as good as that of the well-studied standard bit mutation operator. Moreover, using CHM operators in MOEA/D framework can improve the best known upper bound on the many-objective problem by a factor of n. This paper provides insight into understanding the optimization behavior of CHM operators in the well-known MOEA/D framework, and indicates that using the CHM operator in MOEA/D framework is a promising method for handling MOPs."
  },
  "aaai2020_main_learningtooptimizevariationalquantumcircuitstosolvecombinatorialproblems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Optimize Variational Quantum Circuits to Solve Combinatorial Problems ",
    "authors": [
      "Sami Khairy",
      "Ruslan Shaydulin",
      "Lukasz Cincio",
      "Yuri Alexeev",
      "Prasanna Balaprakash"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5616",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5616/5472",
    "published": "2020-02",
    "summary": "Quantum computing is a computational paradigm with the potential to outperform classical methods for a variety of problems. Proposed recently, the Quantum Approximate Optimization Algorithm (QAOA) is considered as one of the leading candidates for demonstrating quantum advantage in the near term. QAOA is a variational hybrid quantum-classical algorithm for approximately solving combinatorial optimization problems. The quality of the solution obtained by QAOA for a given problem instance depends on the performance of the classical optimizer used to optimize the variational parameters. In this paper, we formulate the problem of finding optimal QAOA parameters as a learning task in which the knowledge gained from solving training instances can be leveraged to find high-quality solutions for unseen test instances. To this end, we develop two machine-learning-based approaches. Our first approach adopts a reinforcement learning (RL) framework to learn a policy network to optimize QAOA circuits. Our second approach adopts a kernel density estimation (KDE) technique to learn a generative model of optimal QAOA parameters. In both approaches, the training procedure is performed on small-sized problem instances that can be simulated on a classical computer; yet the learned RL policy and the generative model can be used to efficiently solve larger problems. Extensive simulations using the IBM Qiskit Aer quantum circuit simulator demonstrate that our proposed RL- and KDE-based approaches reduce the optimality gap by factors up to 30.15 when compared with other commonly used off-the-shelf optimizers."
  },
  "aaai2020_main_howthedurationofthelearningperiodaffectstheperformanceofrandomgradientselectionhyper-heuristics": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " How the Duration of the Learning Period Affects the Performance of Random Gradient Selection Hyper-Heuristics ",
    "authors": [
      "Andrei Lissovoi",
      "Pietro Oliveto",
      "John Alasdair Warwicker"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5617",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5617/5473",
    "published": "2020-02",
    "summary": "Recent analyses have shown that a random gradient hyper-heuristic (HH) using randomised local search (RLSk) low-level heuristics with different neighbourhood sizes k can optimise the unimodal benchmark function LeadingOnes in the best expected time achievable with the available heuristics, if sufficiently long learning periods \u03c4 are employed. In this paper, we examine the impact of the learning period on the performance of the hyper-heuristic for standard unimodal benchmark functions with different characteristics: Ridge, where the HH has to learn that RLS1 is always the best low-level heuristic, and OneMax, where different low-level heuristics are preferable in different areas of the search space. We rigorously prove that super-linear learning periods \u03c4 are required for the HH to achieve optimal expected runtime for Ridge. Conversely, a sub-logarithmic learning period is the best static choice for OneMax, while using super-linear values for \u03c4 increases the expected runtime above the asymptotic unary unbiased black box complexity of the problem. We prove that a random gradient HH which automatically adapts the learning period throughout the run has optimal asymptotic expected runtime for both OneMax and Ridge. Additionally, we show experimentally that it outperforms any static learning period for realistic problem sizes."
  },
  "aaai2020_main_onperformanceestimationinautomaticalgorithmconfiguration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On Performance Estimation in Automatic Algorithm Configuration ",
    "authors": [
      "Shengcai Liu",
      "Ke Tang",
      "Yunwei Lei",
      "Xin Yao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5618",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5618/5474",
    "published": "2020-02",
    "summary": "Over the last decade, research on automated parameter tuning, often referred to as automatic algorithm configuration (AAC), has made significant progress. Although the usefulness of such tools has been widely recognized in real world applications, the theoretical foundations of AAC are still very weak. This paper addresses this gap by studying the performance estimation problem in AAC. More specifically, this paper first proves the universal best performance estimator in a practical setting, and then establishes theoretical bounds on the estimation error, i.e., the difference between the training performance and the true performance for a parameter configuration, considering finite and infinite configuration spaces respectively. These findings were verified in extensive experiments conducted on four algorithm configuration scenarios involving different problem domains. Moreover, insights for enhancing existing AAC methods are also identified."
  },
  "aaai2020_main_alearningbasedbranchandboundformaximumcommonsubgraphrelatedproblems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Learning Based Branch and Bound for Maximum Common Subgraph Related Problems ",
    "authors": [
      "Yanli Liu",
      "Chu-Min Li",
      "Hua Jiang",
      "Kun He"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5619",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5619/5475",
    "published": "2020-02",
    "summary": "The performance of a branch-and-bound (BnB) algorithm for maximum common subgraph (MCS) problem and its related problems, like maximum common connected subgraph (MCCS) and induced Subgraph Isomorphism (SI), crucially depends on the branching heuristic. We propose a branching heuristic inspired from reinforcement learning with a goal of reaching a tree leaf as early as possible to greatly reduce the search tree size. Experimental results show that the proposed heuristic consistently and significantly improves the current best BnB algorithm for the MCS, MCCS and SI problems. An analysis is carried out to give insight on why and how reinforcement learning is useful in the new branching heuristic."
  },
  "aaai2020_main_cakewalksampling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Cakewalk Sampling ",
    "authors": [
      "Uri Patish",
      "Shimon Ullman"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5620",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5620/5476",
    "published": "2020-02",
    "summary": "We study the task of finding good local optima in combinatorial optimization problems. Although combinatorial optimization is NP-hard in general, locally optimal solutions are frequently used in practice. Local search methods however typically converge to a limited set of optima that depend on their initialization. Sampling methods on the other hand can access any valid solution, and thus can be used either directly or alongside methods of the former type as a way for finding good local optima. Since the effectiveness of this strategy depends on the sampling distribution, we derive a robust learning algorithm that adapts sampling distributions towards good local optima of arbitrary objective functions. As a first use case, we empirically study the efficiency in which sampling methods can recover locally maximal cliques in undirected graphs. Not only do we show how our adaptive sampler outperforms related methods, we also show how it can even approach the performance of established clique algorithms. As a second use case, we consider how greedy algorithms can be combined with our adaptive sampler, and we demonstrate how this leads to superior performance in k-medoid clustering. Together, these findings suggest that our adaptive sampler can provide an effective strategy to combinatorial optimization problems that arise in practice."
  },
  "aaai2020_main_subsetselectionbyparetooptimizationwithrecombination": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Subset Selection by Pareto Optimization with Recombination ",
    "authors": [
      "Chao Qian",
      "Chao Bian",
      "Chao Feng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5621",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5621/5477",
    "published": "2020-02",
    "summary": "Subset selection, i.e., to select a limited number of items optimizing some given objective function, is a fundamental problem with various applications such as unsupervised feature selection and sparse regression. By employing a multi-objective evolutionary algorithm (EA) with mutation only to optimize the given objective function and minimize the number of selected items simultaneously, the recently proposed POSS algorithm achieves state-of-the-art performance for subset selection. In this paper, we propose the PORSS algorithm by incorporating recombination, a characterizing feature of EAs, into POSS. We prove that PORSS can achieve the optimal polynomial-time approximation guarantee as POSS when the objective function is monotone, and can find an optimal solution efficiently in some cases whereas POSS cannot. Extensive experiments on unsupervised feature selection and sparse regression show the superiority of PORSS over POSS. Our analysis also theoretically discloses that recombination from diverse solutions can be more likely than mutation alone to generate various variations, thereby leading to better exploration; this may be of independent interest for understanding the influence of recombination."
  },
  "aaai2020_main_asymptoticriskofb\u00e9ziersimplexfitting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Asymptotic Risk of B\u00e9zier Simplex Fitting ",
    "authors": [
      "Akinori Tanaka",
      "Akiyoshi Sannai",
      "Ken Kobayashi",
      "Naoki Hamada"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5622",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5622/5478",
    "published": "2020-02",
    "summary": "The B'ezier simplex fitting is a novel data modeling technique which utilizes geometric structures of data to approximate the Pareto set of multi-objective optimization problems. There are two fitting methods based on different sampling strategies. The inductive skeleton fitting employs a stratified subsampling from skeletons of a simplex, whereas the all-at-once fitting uses a non-stratified sampling which treats a simplex as a single object. In this paper, we analyze the asymptotic risks of those B'ezier simplex fitting methods and derive the optimal subsample ratio for the inductive skeleton fitting. It is shown that the inductive skeleton fitting with the optimal ratio has a smaller risk when the degree of a B'ezier simplex is less than three. Those results are verified numerically under small to moderate sample sizes. In addition, we provide two complementary applications of our theory: a generalized location problem and a multi-objective hyper-parameter tuning of the group lasso. The former can be represented by a B'ezier simplex of degree two where the inductive skeleton fitting outperforms. The latter can be represented by a B'ezier simplex of degree three where the all-at-once fitting gets an advantage."
  },
  "aaai2020_main_tradingconvergenceratewithcomputationalbudgetinhighdimensionalbayesianoptimization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Trading Convergence Rate with Computational Budget in High Dimensional Bayesian Optimization ",
    "authors": [
      "Hung Tran-The",
      "Sunil Gupta",
      "Santu Rana",
      "Svetha Venkatesh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5623",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5623/5479",
    "published": "2020-02",
    "summary": "Scaling Bayesian optimisation (BO) to high-dimensional search spaces is a active and open research problems particularly when no assumptions are made on function structure. The main reason is that at each iteration, BO requires to find global maximisation of acquisition function, which itself is a non-convex optimization problem in the original search space. With growing dimensions, the computational budget for this maximisation gets increasingly short leading to inaccurate solution of the maximisation. This inaccuracy adversely affects both the convergence and the efficiency of BO. We propose a novel approach where the acquisition function only requires maximisation on a discrete set of low dimensional subspaces embedded in the original high-dimensional search space. Our method is free of any low dimensional structure assumption on the function unlike many recent high-dimensional BO methods. Optimising acquisition function in low dimensional subspaces allows our method to obtain accurate solutions within limited computational budget. We show that in spite of this convenience, our algorithm remains convergent. In particular, cumulative regret of our algorithm only grows sub-linearly with the number of iterations. More importantly, as evident from our regret bounds, our algorithm provides a way to trade the convergence rate with the number of subspaces used in the optimisation. Finally, when the number of subspaces is \"sufficiently large\", our algorithm's cumulative regret is at most O*(\u221aT\u03b3T) as opposed to O*(\u221aDT\u03b3T) for the GP-UCB of Srinivas et al. (2012), reducing a crucial factor \u221aD where D being the dimensional number of input space. We perform empirical experiments to evaluate our method extensively, showing that its sample efficiency is better than the existing methods for many optimisation problems involving dimensions up to 5000."
  },
  "aaai2020_main_reductionandlocalsearchforweightedgraphcoloringproblem": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reduction and Local Search for Weighted Graph Coloring Problem ",
    "authors": [
      "Yiyuan Wang",
      "Shaowei Cai",
      "Shiwei Pan",
      "Ximing Li",
      "Monghao Yin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5624",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5624/5480",
    "published": "2020-02",
    "summary": "The weighted graph coloring problem (WGCP) is an important extension of the graph coloring problem (GCP) with wide applications. Compared to GCP, where numerous methods have been developed and even massive graphs with millions of vertices can be solved well, fewer works have been done for WGCP, and no solution is available for solving WGCP for massive graphs. This paper explores techniques for solving WGCP, including a lower bound and a reduction rule based on clique sampling, and a local search algorithm based on two selection rules and a new variant of configuration checking. This results in our algorithm RedLS (Reduction plus Local Search). Experiments are conducted to compare RedLS with the state-of-the-art algorithms on massive graphs as well as conventional benchmarks studied in previous works. RedLS exhibits very good performance and robustness. It significantly outperforms previous algorithms on all benchmarks."
  },
  "aaai2020_main_enumeratingmaximalk-plexeswithworst-casetimeguarantee": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Enumerating Maximal k-Plexes with Worst-Case Time Guarantee ",
    "authors": [
      "Yi Zhou",
      "Jingwei Xu",
      "Zhenyu Guo",
      "Mingyu Xiao",
      "Yan Jin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5625",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5625/5481",
    "published": "2020-02",
    "summary": "The problem of enumerating all maximal cliques in a graph is a key primitive in a variety of real-world applications such as community detection and so on. However, in practice, communities are rarely formed as cliques due to data noise. Hence, k-plex, a subgraph in which any vertex is adjacent to all but at most k vertices, is introduced as a relaxation of clique. In this paper, we investigate the problem of enumerating all maximal k-plexes and present FaPlexen, an enumeration algorithm which integrates the \u201cpivot\u201d heuristic and new branching schemes. To our best knowledge, for the first time, FaPlexen lists all maximal k-plexes with provably worst-case running time O(n2\u03b3n) in a graph with n vertices, where \u03b3 < 2. Then, we propose another algorithm CommuPlex which non-trivially extends FaPlexen to find all maximal k-plexes of prescribed size for community detection in massive real-life networks. We finally carry out experiments on both real and synthetic graphs and demonstrate that our algorithms run much faster than the state-of-the-art algorithms."
  },
  "aaai2020_main_ahuman-ailoopapproachforjointkeyworddiscoveryandexpectationestimationinmicroposteventdetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Human-AI Loop Approach for Joint Keyword Discovery and Expectation Estimation in Micropost Event Detection ",
    "authors": [
      "Akansha Bhardwaj",
      "Jie Yang",
      "Philippe Cudr\u00e9-Mauroux"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5626",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5626/5482",
    "published": "2020-02",
    "summary": "Microblogging platforms such as Twitter are increasingly being used in event detection. Existing approaches mainly use machine learning models and rely on event-related keywords to collect the data for model training. These approaches make strong assumptions on the distribution of the relevant microposts containing the keyword \u2013 referred to as the expectation of the distribution \u2013 and use it as a posterior regularization parameter during model training. Such approaches are, however, limited as they fail to reliably estimate the informativeness of a keyword and its expectation for model training. This paper introduces a Human-AI loop approach to jointly discover informative keywords for model training while estimating their expectation. Our approach iteratively leverages the crowd to estimate both keyword-specific expectation and the disagreement between the crowd and the model in order to discover new keywords that are most beneficial for model training. These keywords and their expectation not only improve the resulting performance but also make the model training process more transparent. We empirically demonstrate the merits of our approach, both in terms of accuracy and interpretability, on multiple real-world datasets and show that our approach improves the state of the art by 24.3%."
  },
  "aaai2020_main_justaskaninteractivelearningframeworkforvisionandlanguagenavigation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Just Ask: An Interactive Learning Framework for Vision and Language Navigation ",
    "authors": [
      "Ta-Chung Chi",
      "Minmin Shen",
      "Mihail Eric",
      "Seokhwan Kim",
      "Dilek Hakkani-tur"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5627",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5627/5483",
    "published": "2020-02",
    "summary": "In the vision and language navigation task (Anderson et al. 2018), the agent may encounter ambiguous situations that are hard to interpret by just relying on visual information and natural language instructions. We propose an interactive learning framework to endow the agent with the ability to ask for users' help in such situations. As part of this framework, we investigate multiple learning approaches for the agent with different levels of complexity. The simplest model-confusion-based method lets the agent ask questions based on its confusion, relying on the predefined confidence threshold of a next action prediction model. To build on this confusion-based method, the agent is expected to demonstrate more sophisticated reasoning such that it discovers the timing and locations to interact with a human. We achieve this goal using reinforcement learning (RL) with a proposed reward shaping term, which enables the agent to ask questions only when necessary. The success rate can be boosted by at least 15% with only one question asked on average during the navigation. Furthermore, we show that the RL agent is capable of adjusting dynamically to noisy human responses. Finally, we design a continual learning strategy, which can be viewed as a data augmentation method, for the agent to improve further utilizing its interaction history with a human. We demonstrate the proposed strategy is substantially more realistic and data-efficient compared to previously proposed pre-exploration techniques."
  },
  "aaai2020_main_aframeworkforengineeringhuman/agentteamingsystems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Framework for Engineering Human/Agent Teaming Systems ",
    "authors": [
      "Rick Evertsz",
      "John Thangarajah"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5629",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5629/5485",
    "published": "2020-02",
    "summary": "The increasing capabilities of autonomous systems offer the potential for more effective teaming with humans. Effective human/agent teaming is facilitated by a mutual understanding of the team objective and how that objective is decomposed into team roles. This paper presents a framework for engineering human/agent teams that delineates the key human/agent teaming components, using TDF-T diagrams to design the agents/teams and then present contextualised team cognition to the human team members at runtime. Our hypothesis is that this facilitates effective human/agent teaming by enhancing the human's understanding of their role in the team and their coordination requirements. To evaluate this hypothesis we conducted a study with human participants using our user interface for the StarCraft strategy game, which presents pertinent, instantiated TDF-T diagrams to the human at runtime. The performance of human participants in the study indicates that their ability to work in concert with the non-player characters in the game is significantly enhanced by the timely presentation of a diagrammatic representation of team cognition."
  },
  "aaai2020_main_whatisityoureallywantofme?generalizedrewardlearningwithbiasedbeliefsaboutdomaindynamics": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " What Is It You Really Want of Me? Generalized Reward Learning with Biased Beliefs about Domain Dynamics ",
    "authors": [
      "Ze Gong",
      "Yu Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5630",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5630/5486",
    "published": "2020-02",
    "summary": "Reward learning as a method for inferring human intent and preferences has been studied extensively. Prior approaches make an implicit assumption that the human maintains a correct belief about the robot's domain dynamics. However, this may not always hold since the human's belief may be biased, which can ultimately lead to a misguided estimation of the human's intent and preferences, which is often derived from human feedback on the robot's behaviors. In this paper, we remove this restrictive assumption by considering that the human may have an inaccurate understanding of the robot. We propose a method called Generalized Reward Learning with biased beliefs about domain dynamics (GeReL) to infer both the reward function and human's belief about the robot in a Bayesian setting based on human ratings. Due to the complex forms of the posteriors, we formulate it as a variational inference problem to infer the posteriors of the parameters that govern the reward function and human's belief about the robot simultaneously. We evaluate our method in a simulated domain and with a user study where the user has a bias based on the robot's appearances. The results show that our method can recover the true human preferences while subject to such biased beliefs, in contrast to prior approaches that could have misinterpreted them completely."
  },
  "aaai2020_main_explainablereinforcementlearningthroughacausallens": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Explainable Reinforcement Learning through a Causal Lens ",
    "authors": [
      "Prashan Madumal",
      "Tim Miller",
      "Liz Sonenberg",
      "Frank Vetere"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5631",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5631/5487",
    "published": "2020-02",
    "summary": "Prominent theories in cognitive science propose that humans understand and represent the knowledge of the world through causal relationships. In making sense of the world, we build causal models in our mind to encode cause-effect relations of events and use these to explain why new events happen by referring to counterfactuals \u2014 things that did not happen. In this paper, we use causal models to derive causal explanations of the behaviour of model-free reinforcement learning agents. We present an approach that learns a structural causal model during reinforcement learning and encodes causal relationships between variables of interest. This model is then used to generate explanations of behaviour based on counterfactual analysis of the causal model. We computationally evaluate the model in 6 domains and measure performance and task prediction accuracy. We report on a study with 120 participants who observe agents playing a real-time strategy game (Starcraft II) and then receive explanations of the agents' behaviour. We investigate: 1) participants' understanding gained by explanations through task prediction; 2) explanation satisfaction and 3) trust. Our results show that causal model explanations perform better on these measures compared to two other baseline explanation models."
  },
  "aaai2020_main_relativeattributingpropagationinterpretingthecomparativecontributionsofindividualunitsindeepneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Relative Attributing Propagation: Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks ",
    "authors": [
      "Woo-Jeoung Nam",
      "Shir Gur",
      "Jaesik Choi",
      "Lior Wolf",
      "Seong-Whan Lee"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5632",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5632/5488",
    "published": "2020-02",
    "summary": "As Deep Neural Networks (DNNs) have demonstrated superhuman performance in a variety of fields, there is an increasing interest in understanding the complex internal mechanisms of DNNs. In this paper, we propose Relative Attributing Propagation (RAP), which decomposes the output predictions of DNNs with a new perspective of separating the relevant (positive) and irrelevant (negative) attributions according to the relative influence between the layers. The relevance of each neuron is identified with respect to its degree of contribution, separated into positive and negative, while preserving the conservation rule. Considering the relevance assigned to neurons in terms of relative priority, RAP allows each neuron to be assigned with a bi-polar importance score concerning the output: from highly relevant to highly irrelevant. Therefore, our method makes it possible to interpret DNNs with much clearer and attentive visualizations of the separated attributions than the conventional explaining methods. To verify that the attributions propagated by RAP correctly account for each meaning, we utilize the evaluation metrics: (i) Outside-inside relevance ratio, (ii) Segmentation mIOU and (iii) Region perturbation. In all experiments and metrics, we present a sizable gap in comparison to the existing literature."
  },
  "aaai2020_main_human-machinecollaborationforfastlandcovermapping": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Human-Machine Collaboration for Fast Land Cover Mapping ",
    "authors": [
      "Caleb Robinson",
      "Anthony Ortiz",
      "Kolya Malkin",
      "Blake Elias",
      "Andi Peng",
      "Dan Morris",
      "Bistra Dilkina",
      "Nebojsa Jojic"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5633",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5633/5489",
    "published": "2020-02",
    "summary": "We propose incorporating human labelers in a model fine-tuning system that provides immediate user feedback. In our framework, human labelers can interactively query model predictions on unlabeled data, choose which data to label, and see the resulting effect on the model's predictions. This bi-directional feedback loop allows humans to learn how the model responds to new data. We implement this framework for fine-tuning high-resolution land cover segmentation models and compare human-selected points to points selected using standard active learning methods. Specifically, we fine-tune a deep neural network \u2013 trained to segment high-resolution aerial imagery into different land cover classes in Maryland, USA \u2013 to a new spatial area in New York, USA using both our human-in-the-loop method and traditional active learning methods. The tight loop in our proposed system turns the algorithm and the human operator into a hybrid system that can produce land cover maps of large areas more efficiently than the traditional workflows. Our framework has applications in machine learning settings where there is a practically limitless supply of unlabeled data, of which only a small fraction can feasibly be labeled through human efforts, such as geospatial and medical image-based applications."
  },
  "aaai2020_main_hierarchicalexpertise-levelmodelingforuserspecificrobot-behaviorexplanations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Hierarchical Expertise-Level Modeling for User Specific Robot-Behavior Explanations ",
    "authors": [
      "Sarath Sreedharan",
      "Tathagata Chakraborti",
      "Christian Muise",
      "Subbarao Kambhampati"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5634",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5634/5490",
    "published": "2020-02",
    "summary": "In this work, we present a new planning formalism called Expectation-Aware planning for decision making with humans in the loop where the human's expectations about an agent may differ from the agent's own model. We show how this formulation allows agents to not only leverage existing strategies for handling model differences like explanations (Chakraborti et al. 2017) and explicability (Kulkarni et al. 2019), but can also exhibit novel behaviors that are generated through the combination of these different strategies. Our formulation also reveals a deep connection to existing approaches in epistemic planning. Specifically, we show how we can leverage classical planning compilations for epistemic planning to solve Expectation-Aware planning problems. To the best of our knowledge, the proposed formulation is the first complete solution to planning with diverging user expectations that is amenable to a classical planning compilation while successfully combining previous works on explanation and explicability. We empirically show how our approach provides a computational advantage over our earlier approaches that rely on search in the space of models."
  },
  "aaai2020_main_corpus-levelend-to-endexplorationforinteractivesystems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Corpus-Level End-to-End Exploration for Interactive Systems",
    "authors": [
      "Zhiwen Tang",
      "Grace Hui Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5635",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5635/5491",
    "published": "2020-02",
    "summary": "A core interest in building Artificial Intelligence (AI) agents is to let them interact with and assist humans. One example is Dynamic Search (DS), which models the process that a human works with a search engine agent to accomplish a complex and goal-oriented task. Early DS agents using Reinforcement Learning (RL) have only achieved limited success for (1) their lack of direct control over which documents to return and (2) the difficulty to recover from wrong search trajectories. In this paper, we present a novel corpus-level end-to-end exploration (CE3) method to address these issues. In our method, an entire text corpus is compressed into a global low-dimensional representation, which enables the agent to gain access to the full state and action spaces, including the under-explored areas. We also propose a new form of retrieval function, whose linear approximation allows end-to-end manipulation of documents. Experiments on the Text REtrieval Conference (TREC) Dynamic Domain (DD) Track show that CE3 outperforms the state-of-the-art DS systems."
  },
  "aaai2020_main_learningtointeractivelylearnandassist": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Interactively Learn and Assist ",
    "authors": [
      "Mark Woodward",
      "Chelsea Finn",
      "Karol Hausman"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5636",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5636/5492",
    "published": "2020-02",
    "summary": "When deploying autonomous agents in the real world, we need effective ways of communicating objectives to them. Traditional skill learning has revolved around reinforcement and imitation learning, each with rigid constraints on the format of information exchanged between the human and the agent. While scalar rewards carry little information, demonstrations require significant effort to provide and may carry more information than is necessary. Furthermore, rewards and demonstrations are often defined and collected before training begins, when the human is most uncertain about what information would help the agent. In contrast, when humans communicate objectives with each other, they make use of a large vocabulary of informative behaviors, including non-verbal communication, and often communicate throughout learning, responding to observed behavior. In this way, humans communicate intent with minimal effort. In this paper, we propose such interactive learning as an alternative to reward or demonstration-driven learning. To accomplish this, we introduce a multi-agent training framework that enables an agent to learn from another agent who knows the current task. Through a series of experiments, we demonstrate the emergence of a variety of interactive learning behaviors, including information-sharing, information-seeking, and question-answering. Most importantly, we find that our approach produces an agent that is capable of learning interactively from a human user, without a set of explicit demonstrations or a reward function, and achieving significantly better performance cooperatively with a human than a human performing the task alone."
  },
  "aaai2020_main_cg-gananinteractiveevolutionarygan-basedapproachforfacialcompositegeneration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " CG-GAN: An Interactive Evolutionary GAN-Based Approach for Facial Composite Generation ",
    "authors": [
      "Nicola Zaltron",
      "Luisa Zurlo",
      "Sebastian Risi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5637",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5637/5493",
    "published": "2020-02",
    "summary": "Facial composites are graphical representations of an eyewitness's memory of a face. Many digital systems are available for the creation of such composites but are either unable to reproduce features unless previously designed or do not allow holistic changes to the image. In this paper, we improve the efficiency of composite creation by removing the reliance on expert knowledge and letting the system learn to represent faces from examples. The novel approach, Composite Generating GAN (CG-GAN), applies generative and evolutionary computation to allow casual users to easily create facial composites. Specifically, CG-GAN utilizes the generator network of a pg-GAN to create high-resolution human faces. Users are provided with several functions to interactively breed and edit faces. CG-GAN offers a novel way of generating and handling static and animated photo-realistic facial composites, with the possibility of combining multiple representations of the same perpetrator, generated by different eyewitnesses."
  },
  "aaai2020_main_queryingtofindasafepolicyunderuncertainsafetyconstraintsinmarkovdecisionprocesses": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Querying to Find a Safe Policy under Uncertain Safety Constraints in Markov Decision Processes ",
    "authors": [
      "Shun Zhang",
      "Edmund Durfee",
      "Satinder Singh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5638",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5638/5494",
    "published": "2020-02",
    "summary": "An autonomous agent acting on behalf of a human user has the potential of causing side-effects that surprise the user in unsafe ways. When the agent cannot formulate a policy with only side-effects it knows are safe, it needs to selectively query the user about whether other useful side-effects are safe. Our goal is an algorithm that queries about as few potential side-effects as possible to find a safe policy, or to prove that none exists. We extend prior work on irreducible infeasible sets to also handle our problem's complication that a constraint to avoid a side-effect cannot be relaxed without user permission. By proving that our objectives are also adaptive submodular, we devise a querying algorithm that we empirically show finds nearly-optimal queries with much less computation than a guaranteed-optimal approach, and outperforms competing approximate approaches."
  },
  "aaai2020_main_cocoxgeneratingconceptualandcounterfactualexplanationsviafault-lines": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " CoCoX: Generating Conceptual and Counterfactual Explanations via Fault-Lines ",
    "authors": [
      "Arjun Akula",
      "Shuai Wang",
      "Song-Chun Zhu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5643",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5643/5499",
    "published": "2020-02",
    "summary": "We present CoCoX (short for Conceptual and Counterfactual Explanations), a model for explaining decisions made by a deep convolutional neural network (CNN). In Cognitive Psychology, the factors (or semantic-level features) that humans zoom in on when they imagine an alternative to a model prediction are often referred to as fault-lines. Motivated by this, our CoCoX model explains decisions made by a CNN using fault-lines. Specifically, given an input image I for which a CNN classification model M predicts class cpred, our fault-line based explanation identifies the minimal semantic-level features (e.g., stripes on zebra, pointed ears of dog), referred to as explainable concepts, that need to be added to or deleted from I in order to alter the classification category of I by M to another specified class calt. We argue that, due to the conceptual and counterfactual nature of fault-lines, our CoCoX explanations are practical and more natural for both expert and non-expert users to understand the internal workings of complex deep learning models. Extensive quantitative and qualitative experiments verify our hypotheses, showing that CoCoX significantly outperforms the state-of-the-art explainable AI models. Our implementation is available at https://github.com/arjunakula/CoCoX"
  },
  "aaai2020_main_towardsawarenessofhumanrelationalstrategiesinvirtualagents": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Awareness of Human Relational Strategies in Virtual Agents ",
    "authors": [
      "Ian Beaver",
      "Cynthia Freeman",
      "Abdullah Mueen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5644",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5644/5500",
    "published": "2020-02",
    "summary": "As Intelligent Virtual Agents (IVAs) increase in adoption and further emulate human personalities, we are interested in how humans apply relational strategies to them compared to other humans in a service environment. Human-computer data from three live customer service IVAs was collected, and annotators marked all text that was deemed unnecessary to the determination of user intention as well as the presence of multiple intents. After merging the selections of multiple annotators, a second round of annotation determined the classes of relational language present in the unnecessary sections such as Greetings, Backstory, Justification, Gratitude, Rants, or Expressing Emotions. We compare the usage of such language in human-human service interactions. We show that removal of this language from task-based inputs has a positive effect by both an increase in confidence and improvement in responses, as evaluated by humans, demonstrating the need for IVAs to anticipate relational language injection. This work provides a methodology to identify relational segments and a baseline of human performance in this task as well as laying the groundwork for IVAs to reciprocate relational strategies in order to improve their believeability."
  },
  "aaai2020_main_regressionunderhumanassistance": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Regression under Human Assistance ",
    "authors": [
      "Abir De",
      "Paramita Koley",
      "Niloy Ganguly",
      "Manuel Gomez-Rodriguez"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5645",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5645/5501",
    "published": "2020-02",
    "summary": "Decisions are increasingly taken by both humans and machine learning models. However, machine learning models are currently trained for full automation\u2014they are not aware that some of the decisions may still be taken by humans. In this paper, we take a first step towards the development of machine learning models that are optimized to operate under different automation levels. More specifically, we first introduce the problem of ridge regression under human assistance and show that it is NP-hard. Then, we derive an alternative representation of the corresponding objective function as a difference of nondecreasing submodular functions. Building on this representation, we further show that the objective is nondecreasing and satisfies \u03b1-submodularity, a recently introduced notion of approximate submodularity. These properties allow a simple and efficient greedy algorithm to enjoy approximation guarantees at solving the problem. Experiments on synthetic and real-world data from two important applications\u2014medical diagnosis and content moderation\u2014demonstrate that the greedy algorithm beats several competitive baselines."
  },
  "aaai2020_main_mimamonetintegratingmicro-andmacro-motionforvideoemotionrecognition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MIMAMO Net: Integrating Micro- and Macro-Motion for Video Emotion Recognition ",
    "authors": [
      "Didan Deng",
      "Zhaokang Chen",
      "Yuqian Zhou",
      "Bertram Shi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5646",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5646/5502",
    "published": "2020-02",
    "summary": "Spatial-temporal feature learning is of vital importance for video emotion recognition. Previous deep network structures often focused on macro-motion which extends over long time scales, e.g., on the order of seconds. We believe integrating structures capturing information about both micro- and macro-motion will benefit emotion prediction, because human perceive both micro- and macro-expressions. In this paper, we propose to combine micro- and macro-motion features to improve video emotion recognition with a two-stream recurrent network, named MIMAMO (Micro-Macro-Motion) Net. Specifically, smaller and shorter micro-motions are analyzed by a two-stream network, while larger and more sustained macro-motions can be well captured by a subsequent recurrent network. Assigning specific interpretations to the roles of different parts of the network enables us to make choice of parameters based on prior knowledge: choices that turn out to be optimal. One of the important innovations in our model is the use of interframe phase differences rather than optical flow as input to the temporal stream. Compared with the optical flow, phase differences require less computation and are more robust to illumination changes. Our proposed network achieves state of the art performance on two video emotion datasets, the OMG emotion dataset and the Aff-Wild dataset. The most significant gains are for arousal prediction, for which motion information is intuitively more informative. Source code is available at https://github.com/wtomin/MIMAMO-Net."
  },
  "aaai2020_main_conditionalgenerativeneuraldecodingwithstructuredcnnfeatureprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Conditional Generative Neural Decoding with Structured CNN Feature Prediction ",
    "authors": [
      "Changde Du",
      "Changying Du",
      "Lijie Huang",
      "Huiguang He"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5647",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5647/5503",
    "published": "2020-02",
    "summary": "Decoding visual contents from human brain activity is a challenging task with great scientific value. Two main facts that hinder existing methods from producing satisfactory results are 1) typically small paired training data; 2) under-exploitation of the structural information underlying the data. In this paper, we present a novel conditional deep generative neural decoding approach with structured intermediate feature prediction. Specifically, our approach first decodes the brain activity to the multilayer intermediate features of a pretrained convolutional neural network (CNN) with a structured multi-output regression (SMR) model, and then inverts the decoded CNN features to the visual images with an introspective conditional generation (ICG) model. The proposed SMR model can simultaneously leverage the covariance structures underlying the brain activities, the CNN features and the prediction tasks to improve the decoding accuracy and interpretability. Further, our ICG model can 1) leverage abundant unpaired images to augment the training data; 2) self-evaluate the quality of its conditionally generated images; and 3) adversarially improve itself without extra discriminator. Experimental results show that our approach yields state-of-the-art visual reconstructions from brain activities."
  },
  "aaai2020_main_gaspingforutility": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " GaSPing for Utility ",
    "authors": [
      "Mengyang Gu",
      "Debarun Bhattacharjya",
      "Dharmashankar Subramanian"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5648",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5648/5504",
    "published": "2020-02",
    "summary": "High-consequence decisions often require a detailed investigation of a decision maker's preferences, as represented by a utility function. Inferring a decision maker's utility function through assessments typically involves an elicitation phase where the decision maker responds to a series of elicitation queries, followed by an estimation phase where the state-of-the-art for direct elicitation approaches in practice is to either fit responses to a parametric form or perform linear interpolation. We introduce a Bayesian nonparametric method involving Gaussian stochastic processes for estimating a utility function from direct elicitation responses. Advantages include the flexibility to fit a large class of functions, favorable theoretical properties, and a fully probabilistic view of the decision maker's preference properties including risk attitude. Through extensive simulation experiments as well as two real datasets from management science, we demonstrate that the proposed approach results in better function fitting."
  },
  "aaai2020_main_harnessinggansforzero-shotlearningofnewclassesinvisualspeechrecognition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Harnessing GANs for Zero-Shot Learning of New Classes in Visual Speech Recognition ",
    "authors": [
      "Yaman Kumar",
      "Dhruva Sahrawat",
      "Shubham Maheshwari",
      "Debanjan Mahata",
      "Amanda Stent",
      "Yifang Yin",
      "Rajiv Ratn Shah",
      "Roger Zimmermann"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5649",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5649/5505",
    "published": "2020-02",
    "summary": "Visual Speech Recognition (VSR) is the process of recognizing or interpreting speech by watching the lip movements of the speaker. Recent machine learning based approaches model VSR as a classification problem; however, the scarcity of training data leads to error-prone systems with very low accuracies in predicting unseen classes. To solve this problem, we present a novel approach to zero-shot learning by generating new classes using Generative Adversarial Networks (GANs), and show how the addition of unseen class samples increases the accuracy of a VSR system by a significant margin of 27% and allows it to handle speaker-independent out-of-vocabulary phrases. We also show that our models are language agnostic and therefore capable of seamlessly generating, using English training data, videos for a new language (Hindi). To the best of our knowledge, this is the first work to show empirical evidence of the use of GANs for generating training samples of unseen classes in the domain of VSR, hence facilitating zero-shot learning. We make the added videos for new classes publicly available along with our code1."
  },
  "aaai2020_main_graph-baseddecodingmodelforfunctionalalignmentofunalignedfmridata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Graph-Based Decoding Model for Functional Alignment of Unaligned fMRI Data ",
    "authors": [
      "Weida Li",
      "Mingxia Liu",
      "Fang Chen",
      "Daoqiang Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5650",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5650/5506",
    "published": "2020-02",
    "summary": "Aggregating multi-subject functional magnetic resonance imaging (fMRI) data is indispensable for generating valid and general inferences from patterns distributed across human brains. The disparities in anatomical structures and functional topographies of human brains warrant aligning fMRI data across subjects. However, the existing functional alignment methods cannot handle well various kinds of fMRI datasets today, especially when they are not temporally-aligned, i.e., some of the subjects probably lack the responses to some stimuli, or different subjects might follow different sequences of stimuli. In this paper, a cross-subject graph that depicts the (dis)similarities between samples across subjects is used as a priori for developing a more flexible framework that suits an assortment of fMRI datasets. However, the high dimension of fMRI data and the use of multiple subjects makes the crude framework time-consuming or unpractical. To address this issue, we further regularize the framework, so that a novel feasible kernel-based optimization, which permits non-linear feature extraction, could be theoretically developed. Specifically, a low-dimension assumption is imposed on each new feature space to avoid overfitting caused by the high-spatial-low-temporal resolution of fMRI data. Experimental results on five datasets suggest that the proposed method is not only superior to several state-of-the-art methods on temporally-aligned fMRI data, but also suitable for dealing with temporally-unaligned fMRI data."
  },
  "aaai2020_main_multi-sourcedomainadaptationforvisualsentimentclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Source Domain Adaptation for Visual Sentiment Classification ",
    "authors": [
      "Chuang Lin",
      "Sicheng Zhao",
      "Lei Meng",
      "Tat-Seng Chua"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5651",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5651/5507",
    "published": "2020-02",
    "summary": "Existing domain adaptation methods on visual sentiment classification typically are investigated under the single-source scenario, where the knowledge learned from a source domain of sufficient labeled data is transferred to the target domain of loosely labeled or unlabeled data. However, in practice, data from a single source domain usually have a limited volume and can hardly cover the characteristics of the target domain. In this paper, we propose a novel multi-source domain adaptation (MDA) method, termed Multi-source Sentiment Generative Adversarial Network (MSGAN), for visual sentiment classification. To handle data from multiple source domains, it learns to find a unified sentiment latent space where data from both the source and target domains share a similar distribution. This is achieved via cycle consistent adversarial learning in an end-to-end manner. Extensive experiments conducted on four benchmark datasets demonstrate that MSGAN significantly outperforms the state-of-the-art MDA approaches for visual sentiment classification."
  },
  "aaai2020_main_learninggraphconvolutionalnetworkforskeleton-basedhumanactionrecognitionbyneuralsearching": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Graph Convolutional Network for Skeleton-Based Human Action Recognition by Neural Searching ",
    "authors": [
      "Wei Peng",
      "Xiaopeng Hong",
      "Haoyu Chen",
      "Guoying Zhao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5652",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5652/5508",
    "published": "2020-02",
    "summary": "Human action recognition from skeleton data, fuelled by the Graph Convolutional Network (GCN) with its powerful capability of modeling non-Euclidean data, has attracted lots of attention. However, many existing GCNs provide a pre-defined graph structure and share it through the entire network, which can loss implicit joint correlations especially for the higher-level features. Besides, the mainstream spectral GCN is approximated by one-order hop such that higher-order connections are not well involved. All of these require huge efforts to design a better GCN architecture. To address these problems, we turn to Neural Architecture Search (NAS) and propose the first automatically designed GCN for this task. Specifically, we explore the spatial-temporal correlations between nodes and build a search space with multiple dynamic graph modules. Besides, we introduce multiple-hop modules and expect to break the limitation of representational capacity caused by one-order approximation. Moreover, a corresponding sampling- and memory-efficient evolution strategy is proposed to search in this space. The resulted architecture proves the effectiveness of the higher-order approximation and the layer-wise dynamic graph modules. To evaluate the performance of the searched model, we conduct extensive experiments on two very large scale skeleton-based action recognition datasets. The results show that our model gets the state-of-the-art results in term of given metrics."
  },
  "aaai2020_main_ucf-staralargescalestillimagedatasetforunderstandinghumanactions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " UCF-STAR: A Large Scale Still Image Dataset for Understanding Human Actions ",
    "authors": [
      "Marjaneh Safaei",
      "Pooyan Balouchian",
      "Hassan Foroosh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5653",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5653/5509",
    "published": "2020-02",
    "summary": "Action recognition in still images poses a great challenge due to (i) fewer available training data, (ii) absence of temporal information. To address the first challenge, we introduce a dataset for STill image Action Recognition (STAR), containing over $1M$ images across 50 different human body-motion action categories. UCF-STAR is the largest dataset in the literature for action recognition in still images. The key characteristics of UCF-STAR include (1) focusing on human body-motion rather than relatively static human-object interaction categories, (2) collecting images from the wild to benefit from a varied set of action representations, (3) appending multiple human-annotated labels per image rather than just the action label, and (4) inclusion of rich, structured and multi-modal set of metadata for each image. This departs from existing datasets, which typically provide single annotation in a smaller number of images and categories, with no metadata. UCF-STAR exposes the intrinsic difficulty of action recognition through its realistic scene and action complexity. To benchmark and demonstrate the benefits of UCF-STAR as a large-scale dataset, and to show the role of \u201clatent\u201d motion information in recognizing human actions in still images, we present a novel approach relying on predicting temporal information, yielding higher accuracy on 5 widely-used datasets."
  },
  "aaai2020_main_towardssociallyresponsibleaicognitivebias-awaremulti-objectivelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Socially Responsible AI: Cognitive Bias-Aware Multi-Objective Learning ",
    "authors": [
      "Procheta Sen",
      "Debasis Ganguly"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5654",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5654/5510",
    "published": "2020-02",
    "summary": "Human society had a long history of suffering from cognitive biases leading to social prejudices and mass injustice. The prevalent existence of cognitive biases in large volumes of historical data can pose a threat of being manifested as unethical and seemingly inhumane predictions as outputs of AI systems trained on such data. To alleviate this problem, we propose a bias-aware multi-objective learning framework that given a set of identity attributes (e.g. gender, ethnicity etc.) and a subset of sensitive categories of the possible classes of prediction outputs, learns to reduce the frequency of predicting certain combinations of them, e.g. predicting stereotypes such as \u2018most blacks use abusive language\u2019, or \u2018fear is a virtue of women\u2019. Our experiments conducted on an emotion prediction task with balanced class priors shows that a set of baseline bias-agnostic models exhibit cognitive biases with respect to gender, such as women are prone to be afraid whereas men are more prone to be angry. In contrast, our proposed bias-aware multi-objective learning methodology is shown to reduce such biases in the predictid emotions."
  },
  "aaai2020_main_reinforcinganimagecaptiongeneratorusingoff-linehumanfeedback": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reinforcing an Image Caption Generator Using Off-Line Human Feedback ",
    "authors": [
      "Paul Hongsuck Seo",
      "Piyush Sharma",
      "Tomer Levinboim",
      "Bohyung Han",
      "Radu Soricut"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5655",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5655/5511",
    "published": "2020-02",
    "summary": "Human ratings are currently the most accurate way to assess the quality of an image captioning model, yet most often the only used outcome of an expensive human rating evaluation is a few overall statistics over the evaluation dataset. In this paper, we show that the signal from instance-level human caption ratings can be leveraged to improve captioning models, even when the amount of caption ratings is several orders of magnitude less than the caption training data. We employ a policy gradient method to maximize the human ratings as rewards in an off-policy reinforcement learning setting, where policy gradients are estimated by samples from a distribution that focuses on the captions in a caption ratings dataset. Our empirical evidence indicates that the proposed method learns to generalize the human raters' judgments to a previously unseen set of images, as judged by a different set of human judges, and additionally on a different, multi-dimensional side-by-side human evaluation procedure."
  },
  "aaai2020_main_instance-adaptivegraphforeegemotionrecognition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Instance-Adaptive Graph for EEG Emotion Recognition ",
    "authors": [
      "Tengfei Song",
      "Suyuan Liu",
      "Wenming Zheng",
      "Yuan Zong",
      "Zhen Cui"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5656",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5656/5512",
    "published": "2020-02",
    "summary": "To tackle the individual differences and characterize the dynamic relationships among different EEG regions for EEG emotion recognition, in this paper, we propose a novel instance-adaptive graph method (IAG), which employs a more flexible way to construct graphic connections so as to present different graphic representations determined by different input instances. To fit the different EEG pattern, we employ an additional branch to characterize the intrinsic dynamic relationships between different EEG channels. To give a more precise graphic representation, we design the multi-level and multi-graph convolutional operation and the graph coarsening. Furthermore, we present a type of sparse graphic representation to extract more discriminative features. Experiments on two widely-used EEG emotion recognition datasets are conducted to evaluate the proposed model and the experimental results show that our method achieves the state-of-the-art performance."
  },
  "aaai2020_main_variationalpathwayreasoningforeegemotionrecognition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Variational Pathway Reasoning for EEG Emotion Recognition ",
    "authors": [
      "Tong Zhang",
      "Zhen Cui",
      "Chunyan Xu",
      "Wenming Zheng",
      "Jian Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5657",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5657/5513",
    "published": "2020-02",
    "summary": "Research on human emotion cognition revealed that connections and pathways exist between spatially-adjacent and functional-related areas during emotion expression (Adolphs 2002a; Bullmore and Sporns 2009). Deeply inspired by this mechanism, we propose a heuristic Variational Pathway Reasoning (VPR) method to deal with EEG-based emotion recognition. We introduce random walk to generate a large number of candidate pathways along electrodes. To encode each pathway, the dynamic sequence model is further used to learn between-electrode dependencies. The encoded pathways around each electrode are aggregated to produce a pseudo maximum-energy pathway, which consists of the most important pair-wise connections. To find those most salient connections, we propose a sparse variational scaling (SVS) module to learn scaling factors of pseudo pathways by using the Bayesian probabilistic process and sparsity constraint, where the former endows good generalization ability while the latter favors adaptive pathway selection. Finally, the salient pathways from those candidates are jointly decided by the pseudo pathways and scaling factors. Extensive experiments on EEG emotion recognition demonstrate that the proposed VPR is superior to those state-of-the-art methods, and could find some interesting pathways w.r.t. different emotions."
  },
  "aaai2020_main_crowd-assisteddisastersceneassessmentwithhuman-aiinteractiveattention": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Crowd-Assisted Disaster Scene Assessment with Human-AI Interactive Attention ",
    "authors": [
      "Daniel (Yue) Zhang",
      "Yifeng Huang",
      "Yang Zhang",
      "Dong Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5658",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5658/5514",
    "published": "2020-02",
    "summary": "The recent advances of mobile sensing and artificial intelligence (AI) have brought new revolutions in disaster response applications. One example is disaster scene assessment (DSA) which leverages computer vision techniques to assess the level of damage severity of the disaster events from images provided by eyewitnesses on social media. The assessment results are critical in prioritizing the rescue operations of the response teams. While AI algorithms can significantly reduce the detection time and manual labeling cost in such applications, their performance often falls short of the desired accuracy. Our work is motivated by the emergence of crowdsourcing platforms (e.g., Amazon Mechanic Turk, Waze) that provide unprecedented opportunities for acquiring human intelligence for AI applications. In this paper, we develop an interactive Disaster Scene Assessment (iDSA) scheme that allows AI algorithms to directly interact with humans to identify the salient regions of the disaster images in DSA applications. We also develop new incentive designs and active learning techniques to ensure reliable, timely, and cost-efficient responses from the crowdsourcing platforms. Our evaluation results on real-world case studies during Nepal and Ecuador earthquake events demonstrate that iDSA can significantly outperform state-of-the-art baselines in accurately assessing the damage of disaster scenes."
  },
  "aaai2020_main_bar\u2014areinforcementlearningagentforbounding-boxautomatedrefinement": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " BAR \u2014 A Reinforcement Learning Agent for Bounding-Box Automated Refinement ",
    "authors": [
      "Morgane Ayle",
      "Jimmy Tekli",
      "Julia El-Zini",
      "Boulos El-Asmar",
      "Mariette Awad"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5639",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5639/5495",
    "published": "2020-02",
    "summary": "Research has shown that deep neural networks are able to help and assist human workers throughout the industrial sector via different computer vision applications. However, such data-driven learning approaches require a very large number of labeled training images in order to generalize well and achieve high accuracies that meet industry standards. Gathering and labeling large amounts of images is both expensive and time consuming, specifically for industrial use-cases. In this work, we introduce BAR (Bounding-box Automated Refinement), a reinforcement learning agent that learns to correct inaccurate bounding-boxes that are weakly generated by certain detection methods, or wrongly annotated by a human, using either an offline training method with Deep Reinforcement Learning (BAR-DRL), or an online one using Contextual Bandits (BAR-CB). Our agent limits the human intervention to correcting or verifying a subset of bounding-boxes instead of re-drawing new ones. Results on a car industry-related dataset and on the PASCAL VOC dataset show a consistent increase of up to 0.28 in the Intersection-over-Union of bounding-boxes with their desired ground-truths, while saving 30%-82% of human intervention time in either correcting or re-drawing inaccurate proposals."
  },
  "aaai2020_main_cost-accuracyawareadaptivelabelingforactivelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Cost-Accuracy Aware Adaptive Labeling for Active Learning ",
    "authors": [
      "Ruijiang Gao",
      "Maytal Saar-Tsechansky"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5640",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5640/5496",
    "published": "2020-02",
    "summary": "Conventional active learning algorithms assume a single labeler that produces noiseless label at a given, fixed cost, and aim to achieve the best generalization performance for given classifier under a budget constraint. However, in many real settings, different labelers have different labeling costs and can yield different labeling accuracies. Moreover, a given labeler may exhibit different labeling accuracies for different instances. This setting can be referred to as active learning with diverse labelers with varying costs and accuracies, and it arises in many important real settings. It is therefore beneficial to understand how to effectively trade-off between labeling accuracy for different instances, labeling costs, as well as the informativeness of training instances, so as to achieve the best generalization performance at the lowest labeling cost. In this paper, we propose a new algorithm for selecting instances, labelers (and their corresponding costs and labeling accuracies), that employs generalization bound of learning with label noise to select informative instances and labelers so as to achieve higher generalization accuracy at a lower cost. Our proposed algorithm demonstrates state-of-the-art performance on five UCI and a real crowdsourcing dataset."
  },
  "aaai2020_main_hirepeerimpartialpeer-assessedhiringatscaleinexpertcrowdsourcingmarkets": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " HirePeer: Impartial Peer-Assessed Hiring at Scale in Expert Crowdsourcing Markets ",
    "authors": [
      "Yasmine Kotturi",
      "Anson Kahng",
      "Ariel Procaccia",
      "Chinmay Kulkarni"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5641",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5641/5497",
    "published": "2020-02",
    "summary": "Expert crowdsourcing (e.g., Upwork.com) provides promising benefits such as productivity improvements for employers, and flexible working arrangements for workers. Yet to realize these benefits, a key persistent challenge is effective hiring at scale. Current approaches, such as reputation systems and standardized competency tests, develop weaknesses such as score inflation over time, thus degrading market quality. This paper presents HirePeer, a novel alternative approach to hiring at scale that leverages peer assessment to elicit honest assessments of fellow workers' job application materials, which it then aggregates using an impartial ranking algorithm. This paper reports on three studies that investigate both the costs and the benefits to workers and employers of impartial peer-assessed hiring. We find, to solicit honest assessments, algorithms must be communicated in terms of their impartial effects. Second, in practice, peer assessment is highly accurate, and impartial rank aggregation algorithms incur a small accuracy cost for their impartiality guarantee. Third, workers report finding peer-assessed hiring useful for receiving targeted feedback on their job materials."
  },
  "aaai2020_main_fine-grainedmachineteachingwithattentionmodeling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fine-Grained Machine Teaching with Attention Modeling ",
    "authors": [
      "Jiacheng Liu",
      "Xiaofeng Hou",
      "Feilong Tang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5642",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5642/5498",
    "published": "2020-02",
    "summary": "The state-of-the-art machine teaching techniques overestimate the ability of learners in grasping a complex concept. On one side, since a complicated concept always contains multiple fine-grained concepts, students can only grasp parts of them during a practical teaching process. On the other side, because a single teaching sample contains unequal information in terms of various fine-grained concepts, learners accept them at different levels. Thus, with more and more complicated dataset, it is challenging for us to rethink the machine teaching frameworks. In this work, we propose a new machine teaching framework called Attentive Machine Teaching (AMT). Specifically, we argue that a complicated concept always consists of multiple features, which we call fine-grained concepts. We define attention to represent the learning level of a learner in studying a fine-grained concept. Afterwards, we propose AMT, an adaptive teaching framework to construct the personalized optimal teaching dataset for learners. During each iteration, we estimate the workers' ability with Graph Neural Network (GNN) and select the best sample using a pool-based searching approach. For corroborating our theoretical findings, we conduct extensive experiments with both synthetic datasets and real datasets. Our experimental results verify the effectiveness of AMT algorithms."
  },
  "aaai2020_main_learningandreasoningforrobotsequentialdecisionmakingunderuncertainty": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning and Reasoning for Robot Sequential Decision Making under Uncertainty ",
    "authors": [
      "Saeid Amiri",
      "Mohammad Shokrolah Shirazi",
      "Shiqi Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5659",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5659/5515",
    "published": "2020-02",
    "summary": "Robots frequently face complex tasks that require more than one action, where sequential decision-making (sdm) capabilities become necessary. The key contribution of this work is a robot sdm framework, called lcorpp, that supports the simultaneous capabilities of supervised learning for passive state estimation, automated reasoning with declarative human knowledge, and planning under uncertainty toward achieving long-term goals. In particular, we use a hybrid reasoning paradigm to refine the state estimator, and provide informative priors for the probabilistic planner. In experiments, a mobile robot is tasked with estimating human intentions using their motion trajectories, declarative contextual knowledge, and human-robot interaction (dialog-based and motion-based). Results suggest that, in efficiency and accuracy, our framework performs better than its no-learning and no-reasoning counterparts in office environment."
  },
  "aaai2020_main_queryrewritingforontology-mediatedconditionalanswers": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Query Rewriting for Ontology-Mediated Conditional Answers ",
    "authors": [
      "Medina Andresel",
      "Magdalena Ortiz",
      "Mantas Simkus"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5660",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5660/5516",
    "published": "2020-02",
    "summary": "Among many solutions for extracting useful answers from incomplete data, ontology-mediated queries (OMQs) use domain knowledge to infer missing facts. We propose an extension of OMQs that allows us to make certain assumptions\u2014for example, about parts of the data that may be unavailable at query time, or costly to query\u2014and retrieve conditional answers, that is, tuples that become certain query answers when the assumptions hold. We show that querying in this powerful formalism often has no higher worst-case complexity than in plain OMQs, and that these queries are first-order rewritable for DL-Lite\u211b. Rewritability is preserved even if we allow some use of closed predicates to combine the (partial) closed- and open-world assumptions. This is remarkable, as closed predicates are a very useful extension of OMQs, but they usually make query answering intractable in data complexity, even in very restricted settings."
  },
  "aaai2020_main_revisitingthefoundationsofabstractargumentation\u2013semanticsbasedonweakadmissibilityandweakdefense": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Revisiting the Foundations of Abstract Argumentation \u2013 Semantics Based on Weak Admissibility and Weak Defense ",
    "authors": [
      "Ringo Baumann",
      "Gerhard Brewka",
      "Markus Ulbricht"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5661",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5661/5517",
    "published": "2020-02",
    "summary": "In his seminal 1995 paper, Dung paved the way for abstract argumentation, a by now major research area in knowledge representation. He pointed out that there is a problematic issue with self-defeating arguments underlying all traditional semantics. A self-defeat occurs if an argument attacks itself either directly or indirectly via an odd attack loop, unless the loop is broken up by some argument attacking the loop from outside. Motivated by the fact that such arguments represent self-contradictory or paradoxical arguments, he asked for reasonable semantics which overcome the problem that such arguments may indeed invalidate any argument they attack. This paper tackles this problem from scratch. More precisely, instead of continuing to use previous concepts defined by Dung we provide new foundations for abstract argumentation, so-called weak admissibility and weak defense. After showing that these key concepts are compatible as in the classical case we introduce new versions of the classical Dung-style semantics including complete, preferred and grounded semantics. We provide a rigorous study of these new concepts including interrelationships as well as the relations to their Dung-style counterparts. The newly introduced semantics overcome the issue with self-defeating arguments, and they are semantically insensitive to syntactic deletions of self-attacking arguments, a special case of self-defeat."
  },
  "aaai2020_main_forgettinganargument": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Forgetting an Argument ",
    "authors": [
      "Ringo Baumann",
      "Dov Gabbay",
      "Odinaldo Rodrigues"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5662",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5662/5518",
    "published": "2020-02",
    "summary": "The notion of forgetting, as considered in the famous paper by Lin and Reiter in 1994 has been extensively studied in classical logic and more recently, in non-monotonic formalisms like logic programming. In this paper, we convey the idea of forgetting to another major AI formalism, namely Dung-style argumentation frameworks. Our approach is axiomatic-driven and not limited to any specific semantics: we propose semantical and syntactical desiderata encoding different criteria for what forgetting an argument might mean; analyze how these criteria relate to each other; and check whether the criteria can be satisfied in general. The analysis is done for a number of widely used argumentation semantics. Our investigation shows that almost all desiderata are individually satisfiable. However, combinations of semantical and/or syntactical conditions reveal a much more interesting landscape. For instance, we found that the ad hoc approach to forgetting an argument, i.e., by the syntactical removal of the argument and all of its associated attacks, is too restrictive and only compatible with the two weakest semantical desiderata. Amongst the several interesting combinations identified, we showed that one satisfies a notion of minimal change and presented an algorithm that given an AF F and argument x, constructs a suitable AF G satisfying the conditions in the combination."
  },
  "aaai2020_main_checkingchaseterminationoverontologiesofexistentialruleswithequality": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Checking Chase Termination over Ontologies of Existential Rules with Equality ",
    "authors": [
      "David Carral",
      "Jacopo Urbani"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5663",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5663/5519",
    "published": "2020-02",
    "summary": "The chase is a sound and complete algorithm for conjunctive query answering over ontologies of existential rules with equality. To enable its effective use, we can apply acyclicity notions; that is, sufficient conditions that guarantee chase termination. Unfortunately, most of these notions have only been defined for existential rule sets without equality. A proposed solution to circumvent this issue is to treat equality as an ordinary predicate with an explicit axiomatisation. We empirically show that this solution is not efficient in practice and propose an alternative approach. More precisely, we show that, if the chase terminates for any equality axiomatisation of an ontology, then it terminates for the original ontology (which may contain equality). Therefore, one can apply existing acyclicity notions to check chase termination over an axiomatisation of an ontology and then use the original ontology for reasoning. We show that, in practice, doing so results in a more efficient reasoning procedure. Furthermore, we present equality model-faithful acyclicity, a general acyclicity notion that can be directly applied to ontologies with equality."
  },
  "aaai2020_main_model-baseddiagnosiswithuncertainobservations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Model-Based Diagnosis with Uncertain Observations ",
    "authors": [
      "Dean Cazes",
      "Meir Kalech"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5664",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5664/5520",
    "published": "2020-02",
    "summary": "Classical model-based diagnosis uses a model of the system to infer diagnoses \u2013 explanations \u2013 of a given abnormal observation. In this work, we explore how to address the case where there is uncertainty over a given observation. This can happen, for example, when the observations are collected by noisy sensors, that are known to return incorrect observations with some probability. We formally define this common scenario for consistency-based and abductive models. In addition, we analyze the complexity of two complete algorithms we propose for finding all diagnoses and correctly ranking them. Finally, we propose a third algorithm that returns the most probable diagnosis without finding all possible diagnoses. Experimental evaluation shows that this third algorithm can be very effective in cases where the number of faults is small and the uncertainty over the observations is not large. If, however, all possible diagnoses are desired, then the choice between the first two algorithms depends on whether the domain's diagnosis form is abductive or consistent."
  },
  "aaai2020_main_parameregardingneuralnetworkparametersasrelationembeddingsforknowledgegraphcompletion": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ParamE: Regarding Neural Network Parameters as Relation Embeddings for Knowledge Graph Completion ",
    "authors": [
      "Feihu Che",
      "Dawei Zhang",
      "Jianhua Tao",
      "Mingyue Niu",
      "Bocheng Zhao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5665",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5665/5521",
    "published": "2020-02",
    "summary": "We study the task of learning entity and relation embeddings in knowledge graphs for predicting missing links. Previous translational models on link prediction make use of translational properties but lack enough expressiveness, while the convolution neural network based model (ConvE) takes advantage of the great nonlinearity fitting ability of neural networks but overlooks translational properties. In this paper, we propose a new knowledge graph embedding model called ParamE which can utilize the two advantages together. In ParamE, head entity embeddings, relation embeddings and tail entity embeddings are regarded as the input, parameters and output of a neural network respectively. Since parameters in networks are effective in converting input to output, taking neural network parameters as relation embeddings makes ParamE much more expressive and translational. In addition, the entity and relation embeddings in ParamE are from feature space and parameter space respectively, which is in line with the essence that entities and relations are supposed to be mapped into two different spaces. We evaluate the performances of ParamE on standard FB15k-237 and WN18RR datasets, and experiments show ParamE can significantly outperform existing state-of-the-art models, such as ConvE, SACN, RotatE and D4-STE/Gumbel."
  },
  "aaai2020_main_answeringconjunctivequerieswithinequalitiesindl-lite\u211b": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Answering Conjunctive Queries with Inequalities in DL-Lite\u211b ",
    "authors": [
      "Gianluca Cima",
      "Maurizio Lenzerini",
      "Antonella Poggi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5666",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5666/5522",
    "published": "2020-02",
    "summary": "In the context of the Description Logic DL-Lite\u211b\u2260, i.e., DL-Lite\u211b without UNA and with inequality axioms, we address the problem of adding to unions of conjunctive queries (UCQs) one of the simplest forms of negation, namely, inequality. It is well known that answering conjunctive queries with unrestricted inequalities over DL-Lite\u211b ontologies is in general undecidable. Therefore, we explore two strategies for recovering decidability, and, hopefully, tractability. Firstly, we weaken the ontology language, and consider the variant of DL-Lite\u211b\u2260 corresponding to rdfs enriched with both inequality and disjointness axioms. Secondly, we weaken the query language, by preventing inequalities to be applied to existentially quantified variables, thus obtaining the class of queries named UCQb\u2260,s. We prove that in the two cases, query answering is decidable, and we provide tight complexity bounds for the problem, both for data and combined complexity. Notably, the results show that answering UCQb\u2260,s over DL-Lite\u211b\u2260 ontologies is still in AC0 in data complexity."
  },
  "aaai2020_main_epistemicintegrityconstraintsforontology-baseddatamanagement": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Epistemic Integrity Constraints for Ontology-Based Data Management ",
    "authors": [
      "Marco Console",
      "Maurizio Lenzerini"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5667",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5667/5523",
    "published": "2020-02",
    "summary": "Ontology-based data management (OBDM) is a powerful knowledge-oriented paradigm for managing data spread over multiple heterogeneous sources. In OBDM, the data sources of an information system are handled through the reconciled view provided by an ontology, i.e., the conceptualization of the underlying domain of interest expressed in some formal language. In any information systems where the basic knowledge resides in data sources, it is of paramount importance to specify the acceptable states of such information. Usually, this is done via integrity constraints, i.e., requirements that the data must satisfy formally expressed in some specific language. However, while the semantics of integrity constraints are clear in the context of databases, the presence of inferred information, typical of OBDM systems, considerably complicates the matter. In this paper, we establish a novel framework for integrity constraints in the OBDM scenarios, based on the notion of knowledge state of the information system. For integrity constraints in this framework, we define a language based on epistemic logic, and study decidability and complexity of both checking satisfaction and performing different forms of static analysis on them."
  },
  "aaai2020_main_hypotheticalanswerstocontinuousqueriesoverdatastreams": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Hypothetical Answers to Continuous Queries over Data Streams ",
    "authors": [
      "Lu\u00eds Cruz-Filipe",
      "Isabel Nunes",
      "Gra\u00e7a Gaspar"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5668",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5668/5524",
    "published": "2020-02",
    "summary": "Continuous queries over data streams often delay answers until some relevant input arrives through the data stream. These delays may turn answers, when they arrive, obsolete to users who sometimes have to make decisions with no help whatsoever. Therefore, it can be useful to provide hypothetical answers \u2013 \u201cgiven the current information, it is possible that X will become true at time t\u201d \u2013 instead of no information at all."
  },
  "aaai2020_main_elgologahigh-levelprogramminglanguagewithmemoryoftheexecutionhistory": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ElGolog: A High-Level Programming Language with Memory of the Execution History ",
    "authors": [
      "Giuseppe De Giacomo",
      "Yves Lesp\u00e9rance",
      "Eugenia Ternovska"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5669",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5669/5525",
    "published": "2020-02",
    "summary": "Most programming languages only support tests that refer exclusively to the current state. This applies even to high-level programming languages based on the situation calculus such as Golog. The result is that additional variables/fluents/data structures must be introduced to track conditions that the program uses in tests to make decisions. In this paper, drawing inspiration from McCarthy's Elephant 2000, we propose an extended version of Golog, called ElGolog, that supports rich tests about the execution history, where tests are expressed in a first-order variant of two-way linear dynamic logic that uses ElGolog programs with converse. We show that in spite of rich tests, ElGolog shares key features with Golog, including a sematics based on macroexpansion into situation calculus formulas, upon which regression can still be applied. We also show that like Golog, our extended language can easily be implemented in ElGolog."
  },
  "aaai2020_main_efficientmodel-baseddiagnosisofsequentialcircuits": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Efficient Model-Based Diagnosis of Sequential Circuits ",
    "authors": [
      "Alexander Feldman",
      "Ingo Pill",
      "Franza Wotawa",
      "Ion Matei",
      "Johan de Kleer"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5670",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5670/5526",
    "published": "2020-02",
    "summary": "In Model-Based Diagnosis (MBD), we concern ourselves with the health and safety of physical and software systems. Although we often use different knowledge representations and algorithms, some tools like satisfiability (SAT) solvers and temporal logics, are used in both domains. In this paper we introduce Finite Trace Next Logic (FTNL) models of sequential circuits and propose an enhanced algorithm for computing minimal-cardinality diagnoses."
  },
  "aaai2020_main_proportionalbeliefmerging": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Proportional Belief Merging ",
    "authors": [
      "Adrian Haret",
      "Martin Lackner",
      "Andreas Pfandler",
      "Johannes P. Wallner"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5671",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5671/5527",
    "published": "2020-02",
    "summary": "In this paper we introduce proportionality to belief merging. Belief merging is a framework for aggregating information presented in the form of propositional formulas, and it generalizes many aggregation models in social choice. In our analysis, two incompatible notions of proportionality emerge: one similar to standard notions of proportionality in social choice, the other more in tune with the logic-based merging setting. Since established merging operators meet neither of these proportionality requirements, we design new proportional belief merging operators. We analyze the proposed operators against established rationality postulates, finding that current approaches to proportionality from the field of social choice are, at their core, incompatible with standard rationality postulates in belief merging. We provide characterization results that explain the underlying conflict, and provide a complexity analysis of our novel operators."
  },
  "aaai2020_main_structuraldecompositionsofepistemiclogicprograms": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Structural Decompositions of Epistemic Logic Programs ",
    "authors": [
      "Markus Hecher",
      "Michael Morak",
      "Stefan Woltran"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5672",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5672/5528",
    "published": "2020-02",
    "summary": "Epistemic logic programs (ELPs) are a popular generalization of standard Answer Set Programming (ASP) providing means for reasoning over answer sets within the language. This richer formalism comes at the price of higher computational complexity reaching up to the fourth level of the polynomial hierarchy. However, in contrast to standard ASP, dedicated investigations towards tractability have not been undertaken yet. In this paper, we give first results in this direction and show that central ELP problems can be solved in linear time for ELPs exhibiting structural properties in terms of bounded treewidth. We also provide a full dynamic programming algorithm that adheres to these bounds. Finally, we show that applying treewidth to a novel dependency structure\u2014given in terms of epistemic literals\u2014allows to bound the number of ASP solver calls in typical ELP solving procedures."
  },
  "aaai2020_main_goingdeepgraphconvolutionalladder-shapenetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Going Deep: Graph Convolutional Ladder-Shape Networks ",
    "authors": [
      "Ruiqi Hu",
      "Shirui Pan",
      "Guodong Long",
      "Qinghua Lu",
      "Liming Zhu",
      "Jing Jiang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5673",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5673/5529",
    "published": "2020-02",
    "summary": "Neighborhood aggregation algorithms like spectral graph convolutional networks (GCNs) formulate graph convolutions as a symmetric Laplacian smoothing operation to aggregate the feature information of one node with that of its neighbors. While they have achieved great success in semi-supervised node classification on graphs, current approaches suffer from the over-smoothing problem when the depth of the neural networks increases, which always leads to a noticeable degradation of performance. To solve this problem, we present graph convolutional ladder-shape networks (GCLN), a novel graph neural network architecture that transmits messages from shallow layers to deeper layers to overcome the over-smoothing problem and dramatically extend the scale of the neural networks with improved performance. We have validated the effectiveness of proposed GCLN at a node-wise level with a semi-supervised task (node classification) and an unsupervised task (node clustering), and at a graph-wise level with graph classification by applying a differentiable pooling operation. The proposed GCLN outperforms original GCNs, deep GCNs and other state-of-the-art GCN-based models for all three tasks, which were designed from various perspectives on six real-world benchmark data sets."
  },
  "aaai2020_main_aggregationofperspectivesusingtheconstellationsapproachtoprobabilisticargumentation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Aggregation of Perspectives Using the Constellations Approach to Probabilistic Argumentation ",
    "authors": [
      "Anthony Hunter",
      "Kawsar Noor"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5674",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5674/5530",
    "published": "2020-02",
    "summary": "In the constellations approach to probabilistic argumentation, there is a probability distribution over the subgraphs of an argument graph, and this can be used to represent the uncertainty in the structure of the argument graph. In this paper, we consider how we can construct this probability distribution from data. We provide a language for data based on perspectives (opinions) on the structure of the graph, and we introduce a framework (based on general properties and some specific proposals) for aggregating these perspectives, and as a result obtaining a probability distribution that best reflects these perspectives. This can be used in applications such as summarizing collections of online reviews and combining conflicting reports."
  },
  "aaai2020_main_leastgeneralgeneralizationsindescriptionlogicverificationandexistence": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Least General Generalizations in Description Logic: Verification and Existence ",
    "authors": [
      "Jean Christoph Jung",
      "Carsten Lutz",
      "Frank Wolter"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5675",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5675/5531",
    "published": "2020-02",
    "summary": "We study two forms of least general generalizations in description logic, the least common subsumer (LCS) and most specific concept (MSC). While the LCS generalizes from examples that take the form of concepts, the MSC generalizes from individuals in data. Our focus is on the complexity of existence and verification, the latter meaning to decide whether a candidate concept is the LCS or MSC. We consider cases with and without a background TBox and a target signature. Our results range from coNP-complete for LCS and MSC verification in the description logic \u03b5\u2112 without TBoxes to undecidability of LCS and MSC verification and existence in \u03b5\u2112I with TBoxes. To obtain results in the presence of a TBox, we establish a close link between the problems studied in this paper and concept learning from positive and negative examples. We also give a way to regain decidability in \u03b5\u2112I with TBoxes and study single example MSC as a special case."
  },
  "aaai2020_main_complexityandexpressivepowerofdisjunctionandnegationinlimitdatalog": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Complexity and Expressive Power of Disjunction and Negation in Limit Datalog ",
    "authors": [
      "Mark Kaminski",
      "Bernardo Cuenca Grau",
      "Egor V. Kostylev",
      "Ian Horrocks"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5676",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5676/5532",
    "published": "2020-02",
    "summary": "Limit Datalog is a fragment of Datalog\u2124\u2014the extension of Datalog with arithmetic functions over the integers\u2014which has been proposed as a declarative language suitable for capturing data analysis tasks. In limit Datalog programs, all intensional predicates with a numeric argument are limit predicates that keep maximal (or minimal) bounds on numeric values. Furthermore, to ensure decidability of reasoning, limit Datalog imposes a linearity condition restricting the use of multiplication in rules. In this paper, we study the complexity and expressive power of limit Datalog programs extended with disjunction in the heads of rules and non-monotonic negation under the stable model semantics. We show that allowing for unrestricted use of negation leads to undecidability of reasoning. Decidability can be restored by stratifying the use of negation over predicates carrying numeric values. We show that the resulting language is \u03a02EXP -complete in combined complexity and that it captures \u03a02P over ordered structures in the sense of descriptive complexity.We also provide a study of several fragments of this language: we show that the complexity and expressive power of the full language are already reached for disjunction-free programs; furthermore, we show that semi-positive disjunctive programs are coNEXPcomplete and that they capture coNP."
  },
  "aaai2020_main_logicsforsizeswithunionorintersection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Logics for Sizes with Union or Intersection ",
    "authors": [
      "Caleb Kisby",
      "Saul Blanco",
      "Alex Kruckman",
      "Lawrence Moss"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5677",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5677/5533",
    "published": "2020-02",
    "summary": "This paper presents the most basic logics for reasoning about the sizes of sets that admit either the union of terms or the intersection of terms. That is, our logics handle assertions All x y and AtLeast x y, where x and y are built up from basic terms by either unions or intersections. We present a sound, complete, and polynomial-time decidable proof system for these logics. An immediate consequence of our work is the completeness of the logic additionally permitting More x y. The logics considered here may be viewed as efficient fragments of two logics which appear in the literature: Boolean Algebra with Presburger Arithmetic and the Logic of Comparative Cardinality."
  },
  "aaai2020_main_fastlasscalableinductivelogicprogrammingincorporatingdomain-specificoptimisationcriteria": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " FastLAS: Scalable Inductive Logic Programming Incorporating Domain-Specific Optimisation Criteria ",
    "authors": [
      "Mark Law",
      "Alessandra Russo",
      "Elisa Bertino",
      "Krysia Broda",
      "Jorge Lobo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5678",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5678/5534",
    "published": "2020-02",
    "summary": "Inductive Logic Programming (ILP) systems aim to find a set of logical rules, called a hypothesis, that explain a set of examples. In cases where many such hypotheses exist, ILP systems often bias towards shorter solutions, leading to highly general rules being learned. In some application domains like security and access control policies, this bias may not be desirable, as when data is sparse more specific rules that guarantee tighter security should be preferred. This paper presents a new general notion of a scoring function over hypotheses that allows a user to express domain-specific optimisation criteria. This is incorporated into a new ILP system, called FastLAS, that takes as input a learning task and a customised scoring function, and computes an optimal solution with respect to the given scoring function. We evaluate the accuracy of FastLAS over real-world datasets for access control policies and show that varying the scoring function allows a user to target domain-specific performance metrics. We also compare FastLAS to state-of-the-art ILP systems, using the standard ILP bias for shorter solutions, and demonstrate that FastLAS is significantly faster and more scalable."
  },
  "aaai2020_main_automaticverificationoflivenesspropertiesinthesituationcalculus": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Automatic Verification of Liveness Properties in the Situation Calculus ",
    "authors": [
      "Jian Li",
      "Yongmei Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5679",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5679/5535",
    "published": "2020-02",
    "summary": "In dynamic systems, liveness properties concern whether something good will eventually happen. Examples of liveness properties are termination of programs and goal achievability. In this paper, we consider the following theorem-proving problem: given an action theory and a goal, check whether the goal is achievable in every model of the action theory. We make the assumption that there are finitely many non-number objects. We propose to use mathematical induction to address this problem: we identify a natural number feature and prove by mathematical induction that for any values of the feature, the goal is achievable. Both the basis and induction steps are verified using first-order theorem provers. We propose a simple method to identify potential features which are the number of objects satisfying a certain formula by generating small models of the action theory and calling a classical planner to achieve the goal. We also propose to regress the goal via different actions and then verify whether the resulting goals are achievable. We implemented the proposed method and experimented with the blocks world domain and a number of other domains from the literature. Experimental results showed that most goals can be verified within a reasonable amount of time."
  },
  "aaai2020_main_pathrankingwithattentiontotypehierarchies": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Path Ranking with Attention to Type Hierarchies ",
    "authors": [
      "Weiyu Liu",
      "Angel Daruna",
      "Zsolt Kira",
      "Sonia Chernova"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5680",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5680/5536",
    "published": "2020-02",
    "summary": "The objective of the knowledge base completion problem is to infer missing information from existing facts in a knowledge base. Prior work has demonstrated the effectiveness of path-ranking based methods, which solve the problem by discovering observable patterns in knowledge graphs, consisting of nodes representing entities and edges representing relations. However, these patterns either lack accuracy because they rely solely on relations or cannot easily generalize due to the direct use of specific entity information. We introduce Attentive Path Ranking, a novel path pattern representation that leverages type hierarchies of entities to both avoid ambiguity and maintain generalization. Then, we present an end-to-end trained attention-based RNN model to discover the new path patterns from data. Experiments conducted on benchmark knowledge base completion datasets WN18RR and FB15k-237 demonstrate that the proposed model outperforms existing methods on the fact prediction task by statistically significant margins of 26% and 10%, respectively. Furthermore, quantitative and qualitative analyses show that the path patterns balance between generalization and discrimination."
  },
  "aaai2020_main_k-bertenablinglanguagerepresentationwithknowledgegraph": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " K-BERT: Enabling Language Representation with Knowledge Graph ",
    "authors": [
      "Weijie Liu",
      "Peng Zhou",
      "Zhe Zhao",
      "Zhiruo Wang",
      "Qi Ju",
      "Haotang Deng",
      "Ping Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5681",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5681/5537",
    "published": "2020-02",
    "summary": "Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by being equipped with a KG without pre-training by itself because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts."
  },
  "aaai2020_main_explanationsforinconsistency-tolerantqueryansweringunderexistentialrules": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Explanations for Inconsistency-Tolerant Query Answering under Existential Rules ",
    "authors": [
      "Thomas Lukasiewicz",
      "Enrico Malizia",
      "Cristian Molinaro"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5682",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5682/5538",
    "published": "2020-02",
    "summary": "Querying inconsistent knowledge bases is a problem that has attracted a great deal of interest over the last decades. While several semantics of query answering have been proposed, and their complexity is rather well-understood, little attention has been paid to the problem of explaining query answers. Explainability has recently become a prominent problem in different areas of AI. In particular, explaining query answers allows users to understand not only what is entailed by an inconsistent knowledge base, but also why. In this paper, we address the problem of explaining query answers for existential rules under three popular inconsistency-tolerant semantics, namely, the ABox repair, the intersection of repairs, and the intersection of closed repairs semantics. We provide a thorough complexity analysis for a wide range of existential rule languages and for different complexity measures."
  },
  "aaai2020_main_resilientlogicprogramsanswersetprogramschallengedbyontologies": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Resilient Logic Programs: Answer Set Programs Challenged by Ontologies ",
    "authors": [
      "Sanja Lukumbuzya",
      "Magdalena Ortiz",
      "Mantas \u0161imkus"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5683",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5683/5539",
    "published": "2020-02",
    "summary": "We introduce resilient logic programs (RLPs) that couple a non-monotonic logic program and a first-order (FO) theory or description logic (DL) ontology. Unlike previous hybrid languages, where the interaction between the program and the theory is limited to consistency or query entailment tests, in RLPs answer sets must be \u2018resilient\u2019 to the models of the theory, allowing non-output predicates of the program to respond differently to different models. RLPs can elegantly express \u2203\u2200\u2203-QBFs, disjunctive ASP, and configuration problems under incompleteness of information. RLPs are decidable when a couple of natural assumptions are made: (i) satisfiability of FO theories in the presence of closed predicates is decidable, and (ii) rules are safe in the style of the well-known DL-safeness. We further show that a large fragment of such RLPs can be translated into standard (disjunctive) ASP, for which efficient implementations exist. For RLPs with theories expressed in DLs, we use a novel relaxation of safeness that safeguards rules via predicates whose extensions can be inferred to have a finite bound. We present several complexity results for the case where ontologies are written in some standard DLs."
  },
  "aaai2020_main_commonsenseknowledgebasecompletionwithstructuralandsemanticcontext": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Commonsense Knowledge Base Completion with Structural and Semantic Context ",
    "authors": [
      "Chaitanya Malaviya",
      "Chandra Bhagavatula",
      "Antoine Bosselut",
      "Yejin Choi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5684",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5684/5540",
    "published": "2020-02",
    "summary": "Automatic KB completion for commonsense knowledge graphs (e.g., ATOMIC and ConceptNet) poses unique challenges compared to the much studied conventional knowledge bases (e.g., Freebase). Commonsense knowledge graphs use free-form text to represent nodes, resulting in orders of magnitude more nodes compared to conventional KBs ( \u223c18x more nodes in ATOMIC compared to Freebase (FB15K-237)). Importantly, this implies significantly sparser graph structures \u2014 a major challenge for existing KB completion methods that assume densely connected graphs over a relatively smaller set of nodes."
  },
  "aaai2020_main_blameworthinessinsecuritygames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Blameworthiness in Security Games ",
    "authors": [
      "Pavel Naumov",
      "Jia Tao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5685",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5685/5541",
    "published": "2020-02",
    "summary": "Security games are an example of a successful real-world application of game theory. The paper defines blameworthiness of the defender and the attacker in security games using the principle of alternative possibilities and provides a sound and complete logical system for reasoning about blameworthiness in such games. Two of the axioms of this system capture the asymmetry of information in security games."
  },
  "aaai2020_main_decidingacceptanceinincompleteargumentationframeworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deciding Acceptance in Incomplete Argumentation Frameworks ",
    "authors": [
      "Andreas Niskanen",
      "Daniel Neugebauer",
      "Matti J\u00e4rvisalo",
      "J\u00f6rg Rothe"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5686",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5686/5542",
    "published": "2020-02",
    "summary": "Expressing incomplete knowledge in abstract argumentation frameworks (AFs) through incomplete AFs has recently received noticeable attention. However, algorithmic aspects of deciding acceptance in incomplete AFs are still under-developed. We address this current shortcoming by developing algorithms for NP-hard and coNP-hard variants of acceptance problems over incomplete AFs via harnessing Boolean satisfiability (SAT) solvers. Focusing on nonempty conflict-free or admissible sets and on stable extensions, we also provide new complexity results for a refined variant of skeptical acceptance in incomplete AFs, ranging from polynomial-time computability to hardness for the second level of the polynomial hierarchy. Furthermore, central to the proposed SAT-based counterexample-guided abstraction refinement approach for the second-level problem variants, we establish conditions for redundant atomic changes to incomplete AFs from the perspective of preserving extensions. We show empirically that the resulting SAT-based approach for incomplete AFs scales at least as well as existing SAT-based approaches to deciding acceptance in AFs."
  },
  "aaai2020_main_rule-guidedcompositionalrepresentationlearningonknowledgegraphs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Rule-Guided Compositional Representation Learning on Knowledge Graphs ",
    "authors": [
      "Guanglin Niu",
      "Yongfei Zhang",
      "Bo Li",
      "Peng Cui",
      "Si Liu",
      "Jingyang Li",
      "Xiaowei Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5687",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5687/5543",
    "published": "2020-02",
    "summary": "Representation learning on a knowledge graph (KG) is to embed entities and relations of a KG into low-dimensional continuous vector spaces. Early KG embedding methods only pay attention to structured information encoded in triples, which would cause limited performance due to the structure sparseness of KGs. Some recent attempts consider paths information to expand the structure of KGs but lack explainability in the process of obtaining the path representations. In this paper, we propose a novel Rule and Path-based Joint Embedding (RPJE) scheme, which takes full advantage of the explainability and accuracy of logic rules, the generalization of KG embedding as well as the supplementary semantic structure of paths. Specifically, logic rules of different lengths (the number of relations in rule body) in the form of Horn clauses are first mined from the KG and elaborately encoded for representation learning. Then, the rules of length 2 are applied to compose paths accurately while the rules of length 1 are explicitly employed to create semantic associations among relations and constrain relation embeddings. Moreover, the confidence level of each rule is also considered in optimization to guarantee the availability of applying the rule to representation learning. Extensive experimental results illustrate that RPJE outperforms other state-of-the-art baselines on KG completion task, which also demonstrate the superiority of utilizing logic rules as well as paths for improving the accuracy and explainability of representation learning."
  },
  "aaai2020_main_learningqueryinseparable\u03b5\u2112\u210bontologies": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Query Inseparable \u03b5\u2112\u210b Ontologies ",
    "authors": [
      "Ana Ozaki",
      "Cosimo Persia",
      "Andrea Mazzullo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5688",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5688/5544",
    "published": "2020-02",
    "summary": "We investigate the complexity of learning query inseparable \u03b5\u2112\u210b ontologies in a variant of Angluin's exact learning model. Given a fixed data instance A* and a query language \ud835\udcac, we are interested in computing an ontology \u210b that entails the same queries as a target ontology \ud835\udcaf on A*, that is, \u210b and \ud835\udcaf are inseparable w.r.t. A* and \ud835\udcac. The learner is allowed to pose two kinds of questions. The first is \u2018Does (\ud835\udcaf,A)\u22a8 q?\u2019, with A an arbitrary data instance and q and query in \ud835\udcac. An oracle replies this question with \u2018yes\u2019 or \u2018no\u2019. In the second, the learner asks \u2018Are \u210b and \ud835\udcaf inseparable w.r.t. A* and \ud835\udcac?\u2019. If so, the learning process finishes, otherwise, the learner receives (A*,q) with q \u2208 \ud835\udcac, (\ud835\udcaf,A*) |= q and (\u210b,A*) \u22ad q (or vice-versa). Then, we analyse conditions in which query inseparability is preserved if A* changes. Finally, we consider the PAC learning model and a setting where the algorithms learn from a batch of classified data, limiting interactions with the oracles."
  },
  "aaai2020_main_graphrepresentationsforhigher-orderlogicandtheoremproving": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Graph Representations for Higher-Order Logic and Theorem Proving ",
    "authors": [
      "Aditya Paliwal",
      "Sarah Loos",
      "Markus Rabe",
      "Kshitij Bansal",
      "Christian Szegedy"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5689",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5689/5545",
    "published": "2020-02",
    "summary": "This paper presents the first use of graph neural networks (GNNs) for higher-order proof search and demonstrates that GNNs can improve upon state-of-the-art results in this domain. Interactive, higher-order theorem provers allow for the formalization of most mathematical theories and have been shown to pose a significant challenge for deep learning. Higher-order logic is highly expressive and, even though it is well-structured with a clearly defined grammar and semantics, there still remains no well-established method to convert formulas into graph-based representations. In this paper, we consider several graphical representations of higher-order logic and evaluate them against the HOList benchmark for higher-order theorem proving."
  },
  "aaai2020_main_relatednessandtbox-drivenrulelearninginlargeknowledgebases": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Relatedness and TBox-Driven Rule Learning in Large Knowledge Bases ",
    "authors": [
      "Giuseppe Pirr\u00f2"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5690",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5690/5546",
    "published": "2020-02",
    "summary": "We present RARL, an approach to discover rules of the form body \u21d2 head in large knowledge bases (KBs) that typically include a set of terminological facts (TBox) and a set of TBox-compliant assertional facts (ABox). RARL's main intuition is to learn rules by leveraging TBox-information and the semantic relatedness between the predicate(s) in the atoms of the body and the predicate in the head. RARL uses an efficient relatedness-driven TBox traversal algorithm, which given an input rule head, generates the set of most semantically related candidate rule bodies. Then, rule confidence is computed in the ABox based on a set of positive and negative examples. Decoupling candidate generation and rule quality assessment offers greater flexibility than previous work."
  },
  "aaai2020_main_aframeworkformeasuringinformationasymmetry": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Framework for Measuring Information Asymmetry ",
    "authors": [
      "Yakoub Salhi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5691",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5691/5547",
    "published": "2020-02",
    "summary": "Information asymmetry occurs when an imbalance of knowledge exists between two parties, such as a buyer and a seller, a regulator and an operator, and an employer and an employee. It is a key concept in several domains, in particular, in economics. We propose in this work a general logic-based framework for measuring the information asymmetry between two parties. A situation of information asymmetry is represented by a knowledge base and a set of questions. We define the notion of information asymmetry measure through rationality postulates. We further introduce a syntactic concept, called minimal question subset (MQS), to take into consideration the fact that answering some questions allows avoiding others. This concept is used for defining rationality postulates and measures. Finally, we propose a method for computing the MQSes of a given situation of information asymmetry."
  },
  "aaai2020_main_adversarialdeepnetworkembeddingforcross-networknodeclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adversarial Deep Network Embedding for Cross-Network Node Classification ",
    "authors": [
      "Xiao Shen",
      "Quanyu Dai",
      "Fu-lai Chung",
      "Wei Lu",
      "Kup-Sze Choi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5692",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5692/5548",
    "published": "2020-02",
    "summary": "In this paper, the task of cross-network node classification, which leverages the abundant labeled nodes from a source network to help classify unlabeled nodes in a target network, is studied. The existing domain adaptation algorithms generally fail to model the network structural information, and the current network embedding models mainly focus on single-network applications. Thus, both of them cannot be directly applied to solve the cross-network node classification problem. This motivates us to propose an adversarial cross-network deep network embedding (ACDNE) model to integrate adversarial domain adaptation with deep network embedding so as to learn network-invariant node representations that can also well preserve the network structural information. In ACDNE, the deep network embedding module utilizes two feature extractors to jointly preserve attributed affinity and topological proximities between nodes. In addition, a node classifier is incorporated to make node representations label-discriminative. Moreover, an adversarial domain adaptation technique is employed to make node representations network-invariant. Extensive experimental results demonstrate that the proposed ACDNE model achieves the state-of-the-art performance in cross-network node classification."
  },
  "aaai2020_main_contextualparametergenerationforknowledgegraphlinkprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Contextual Parameter Generation for Knowledge Graph Link Prediction ",
    "authors": [
      "George Stoica",
      "Otilia Stretcu",
      "Emmanouil Antonios Platanios",
      "Tom Mitchell",
      "Barnab\u00e1s P\u00f3czos"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5693",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5693/5549",
    "published": "2020-02",
    "summary": "We consider the task of knowledge graph link prediction. Given a question consisting of a source entity and a relation (e.g., Shakespeare and BornIn), the objective is to predict the most likely answer entity (e.g., England). Recent approaches tackle this problem by learning entity and relation embeddings. However, they often constrain the relationship between these embeddings to be additive (i.e., the embeddings are concatenated and then processed by a sequence of linear functions and element-wise non-linearities). We show that this type of interaction significantly limits representational power. For example, such models cannot handle cases where a different projection of the source entity is used for each relation. We propose to use contextual parameter generation to address this limitation. More specifically, we treat relations as the context in which source entities are processed to produce predictions, by using relation embeddings to generate the parameters of a model operating over source entity embeddings. This allows models to represent more complex interactions between entities and relations. We apply our method on two existing link prediction methods, including the current state-of-the-art, resulting in significant performance gains and establishing a new state-of-the-art for this task. These gains are achieved while also reducing convergence time by up to 28 times."
  },
  "aaai2020_main_interacteimprovingconvolution-basedknowledgegraphembeddingsbyincreasingfeatureinteractions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " InteractE: Improving Convolution-Based Knowledge Graph Embeddings by Increasing Feature Interactions ",
    "authors": [
      "Shikhar Vashishth",
      "Soumya Sanyal",
      "Vikram Nitin",
      "Nilesh Agrawal",
      "Partha Talukdar"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5694",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5694/5550",
    "published": "2020-02",
    "summary": "Most existing knowledge graphs suffer from incompleteness, which can be alleviated by inferring missing links based on known facts. One popular way to accomplish this is to generate low-dimensional embeddings of entities and relations, and use these to make inferences. ConvE, a recently proposed approach, applies convolutional filters on 2D reshapings of entity and relation embeddings in order to capture rich interactions between their components. However, the number of interactions that ConvE can capture is limited. In this paper, we analyze how increasing the number of these interactions affects link prediction performance, and utilize our observations to propose InteractE. InteractE is based on three key ideas \u2013 feature permutation, a novel feature reshaping, and circular convolution. Through extensive experiments, we find that InteractE outperforms state-of-the-art convolutional link prediction baselines on FB15k-237. Further, InteractE achieves an MRR score that is 9%, 7.5%, and 23% better than ConvE on the FB15k-237, WN18RR and YAGO3-10 datasets respectively. The results validate our central hypothesis \u2013 that increasing feature interaction is beneficial to link prediction performance. We make the source code of InteractE available to encourage reproducible research."
  },
  "aaai2020_main_queryansweringwithguardedexistentialrulesunderstablemodelsemantics": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Query Answering with Guarded Existential Rules under Stable Model Semantics ",
    "authors": [
      "Hai Wan",
      "Guohui Xiao",
      "Chenglin Wang",
      "Xianqiao Liu",
      "Junhong Chen",
      "Zhe Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5695",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5695/5551",
    "published": "2020-02",
    "summary": "In this paper, we study the problem of query answering with guarded existential rules (also called GNTGDs) under stable model semantics. Our goal is to use existing answer set programming (ASP) solvers. However, ASP solvers handle only finitely-ground logic programs while the program translated from GNTGDs by Skolemization is not in general. To address this challenge, we introduce two novel notions of (1) guarded instantiation forest to describe the instantiation of GNTGDs and (2) prime block to characterize the repeated infinitely-ground program translated from GNTGDs. Using these notions, we prove that the ground termination problem for GNTGDs is decidable. We also devise an algorithm for query answering with GNTGDs using ASP solvers. We have implemented our approach in a prototype system. The evaluation over a set of benchmarks shows encouraging results."
  },
  "aaai2020_main_cotsaeco-trainingofstructureandattributeembeddingsforentityalignment": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " COTSAE: CO-Training of Structure and Attribute Embeddings for Entity Alignment ",
    "authors": [
      "Kai Yang",
      "Shaoqin Liu",
      "Junfeng Zhao",
      "Yasha Wang",
      "Bing Xie"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5696",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5696/5552",
    "published": "2020-02",
    "summary": "Entity alignment is a fundamental and vital task in Knowledge Graph (KG) construction and fusion. Previous works mainly focus on capturing the structural semantics of entities by learning the entity embeddings on the relational triples and pre-aligned \"seed entities\". Some works also seek to incorporate the attribute information to assist refining the entity embeddings. However, there are still many problems not considered, which dramatically limits the utilization of attribute information in the entity alignment. Different KGs may have lots of different attribute types, and even the same attribute may have diverse data structures and value granularities. Most importantly, attributes may have various \"contributions\" to the entity alignment. To solve these problems, we propose COTSAE that combines the structure and attribute information of entities by co-training two embedding learning components, respectively. We also propose a joint attention method in our model to learn the attentions of attribute types and values cooperatively. We verified our COTSAE on several datasets from real-world KGs, and the results showed that it is significantly better than the latest entity alignment methods. The structure and attribute information can complement each other and both contribute to performance improvement."
  },
  "aaai2020_main_ranking-basedsemanticsforsetsofattackingarguments": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Ranking-Based Semantics for Sets of Attacking Arguments ",
    "authors": [
      "Bruno Yun",
      "Srdjan Vesic",
      "Madalina Croitoru"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5697",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5697/5553",
    "published": "2020-02",
    "summary": "Argumentation is a process of evaluating and comparing sets of arguments. Ranking-based semantics received a lot of attention recently. All of the semantics introduced so far are applicable to binary attack relations. In this paper, we study a more general case when sets of arguments can jointly attack an argument. We generalise existing postulates for ranking-based semantics to fit this framework, define a general variant of h-categoriser, prove that it converges for every argumentation framework and study the postulates it satisfies. We also study the link between binary and hypergraph version of h-categoriser."
  },
  "aaai2020_main_few-shotknowledgegraphcompletion": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Few-Shot Knowledge Graph Completion ",
    "authors": [
      "Chuxu Zhang",
      "Huaxiu Yao",
      "Chao Huang",
      "Meng Jiang",
      "Zhenhui Li",
      "Nitesh V. Chawla"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5698",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5698/5554",
    "published": "2020-02",
    "summary": "Knowledge graphs (KGs) serve as useful resources for various natural language processing applications. Previous KG completion approaches require a large number of training instances (i.e., head-tail entity pairs) for every relation. The real case is that for most of the relations, very few entity pairs are available. Existing work of one-shot learning limits method generalizability for few-shot scenarios and does not fully use the supervisory information; however, few-shot KG completion has not been well studied yet. In this work, we propose a novel few-shot relation learning model (FSRL) that aims at discovering facts of new relations with few-shot references. FSRL can effectively capture knowledge from heterogeneous graph structure, aggregate representations of few-shot references, and match similar entity pairs of reference set for every relation. Extensive experiments on two public datasets demonstrate that FSRL outperforms the state-of-the-art."
  },
  "aaai2020_main_towardsuniversallanguagesfortractableontologymediatedqueryanswering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Universal Languages for Tractable Ontology Mediated Query Answering ",
    "authors": [
      "Heng Zhang",
      "Yan Zhang",
      "Jia-Huai You",
      "Zhiyong Feng",
      "Guifei Jiang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5699",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5699/5555",
    "published": "2020-02",
    "summary": "An ontology language for ontology mediated query answering (OMQA-language) is universal for a family of OMQA-languages if it is the most expressive one among this family. In this paper, we focus on three families of tractable OMQA-languages, including first-order rewritable languages and languages whose data complexity of the query answering is in AC0 or PTIME. On the negative side, we prove that there is, in general, no universal language for each of these families of languages. On the positive side, we propose a novel property, the locality, to approximate the first-order rewritability, and show that there exists a language of disjunctive embedded dependencies that is universal for the family of OMQA-languages with locality. All of these results apply to OMQA with query languages such as conjunctive queries, unions of conjunctive queries and acyclic conjunctive queries."
  },
  "aaai2020_main_ontheexpressivityofaskqueriesinsparql": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On the Expressivity of ASK Queries in SPARQL ",
    "authors": [
      "Xiaowang Zhang",
      "Jan Van den Bussche",
      "Kewen Wang",
      "Heng Zhang",
      "Xuanxing Yang",
      "Zhiyong Feng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5700",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5700/5556",
    "published": "2020-02",
    "summary": "As a major query type in SPARQL, ASK queries are boolean queries and have found applications in several domains such as semantic SPARQL optimization. This paper is a first systematic study of the relative expressive power of various fragments of ASK queries in SPARQL. Among many new results, a surprising one is that the operator UNION is redundant for ASK queries. The results in this paper as a whole paint a rich picture for the expressivity of fragments of ASK queries with the four basic operators of SPARQL 1.0 possibly together with a negation. The work in this paper provides a guideline for future SPARQL query optimization and implementation."
  },
  "aaai2020_main_learninghierarchy-awareknowledgegraphembeddingsforlinkprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction ",
    "authors": [
      "Zhanqiu Zhang",
      "Jianyu Cai",
      "Yongdong Zhang",
      "Jie Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5701",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5701/5557",
    "published": "2020-02",
    "summary": "Knowledge graph embedding, which aims to represent entities and relations as low dimensional vectors (or matrices, tensors, etc.), has been shown to be a powerful technique for predicting missing links in knowledge graphs. Existing knowledge graph embedding models mainly focus on modeling relation patterns such as symmetry/antisymmetry, inversion, and composition. However, many existing approaches fail to model semantic hierarchies, which are common in real-world applications. To address this challenge, we propose a novel knowledge graph embedding model\u2014namely, Hierarchy-Aware Knowledge Graph Embedding (HAKE)\u2014which maps entities into the polar coordinate system. HAKE is inspired by the fact that concentric circles in the polar coordinate system can naturally reflect the hierarchy. Specifically, the radial coordinate aims to model entities at different levels of the hierarchy, and entities with smaller radii are expected to be at higher levels; the angular coordinate aims to distinguish entities at the same level of the hierarchy, and these entities are expected to have roughly the same radii but different angles. Experiments demonstrate that HAKE can effectively model the semantic hierarchies in knowledge graphs, and significantly outperforms existing state-of-the-art methods on benchmark datasets for the link prediction task."
  },
  "aaai2020_main_apracticalapproachtoforgettingindescriptionlogicswithnominals": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Practical Approach to Forgetting in Description Logics with Nominals ",
    "authors": [
      "Yizheng Zhao",
      "Renate Schmidt",
      "Yuejie Wang",
      "Xuanming Zhang",
      "Hao Feng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5702",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5702/5558",
    "published": "2020-02",
    "summary": "This paper investigates the problem of forgetting in description logics with nominals. In particular, we develop a practical method for forgetting concept and role names from ontologies specified in the description logic ALCO, extending the basic ALC with nominals. The method always terminates, and is sound in the sense that the forgetting solution computed by the method has the same logical consequences with the original ontology. The method is so far the only approach to deductive forgetting in description logics with nominals. An evaluation of a prototype implementation shows that the method achieves a significant speed-up and notably better success rates than the Lethe tool which performs deductive forgetting for ALC-ontologies. Compared to Fame, a semantic forgetting tool for ALCOIH-ontologies, better success rates are attained. From the perspective of ontology engineering this is very useful, as it provides ontology curators with a powerful tool to produce views of ontologies."
  },
  "aaai2020_main_decidingthelooselyguardedfragmentandqueryingitshornfragmentusingresolution": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deciding the Loosely Guarded Fragment and Querying Its Horn Fragment Using Resolution ",
    "authors": [
      "Sen Zheng",
      "Renate Schmidt"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5703",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5703/5559",
    "published": "2020-02",
    "summary": "We consider the following query answering problem: Given a Boolean conjunctive query and a theory in the Horn loosely guarded fragment, the aim is to determine whether the query is entailed by the theory. In this paper, we present a resolution decision procedure for the loosely guarded fragment, and use such a procedure to answer Boolean conjunctive queries against the Horn loosely guarded fragment. The Horn loosely guarded fragment subsumes classes of rules that are prevalent in ontology-based query answering, such as Horn ALCHOI and guarded existential rules. Additionally, we identify star queries and cloud queries, which using our procedure, can be answered against the loosely guarded fragment."
  },
  "aaai2020_main_ltl\u0192synthesiswithfairnessandstabilityassumptions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " LTL\u0192 Synthesis with Fairness and Stability Assumptions ",
    "authors": [
      "Shufang Zhu",
      "Giuseppe De Giacomo",
      "Geguang Pu",
      "Moshe Y. Vardi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5704",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5704/5560",
    "published": "2020-02",
    "summary": "In synthesis, assumptions are constraints on the environment that rule out certain environment behaviors. A key observation here is that even if we consider systems with LTL\u0192 goals on finite traces, environment assumptions need to be expressed over infinite traces, since accomplishing the agent goals may require an unbounded number of environment action. To solve synthesis with respect to finite-trace LTL\u0192 goals under infinite-trace assumptions, we could reduce the problem to LTL synthesis. Unfortunately, while synthesis in LTL\u0192 and in LTL have the same worst-case complexity (both 2EXPTIME-complete), the algorithms available for LTL synthesis are much more difficult in practice than those for LTL\u0192 synthesis. In this work we show that in interesting cases we can avoid such a detour to LTL synthesis and keep the simplicity of LTL\u0192 synthesis. Specifically, we develop a BDD-based fixpoint-based technique for handling basic forms of fairness and of stability assumptions. We show, empirically, that this technique performs much better than standard LTL synthesis."
  },
  "aaai2020_main_learningtoreasonleveragingneuralnetworksforapproximatednfcounting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Reason: Leveraging Neural Networks for Approximate DNF Counting ",
    "authors": [
      "Ralph Abboud",
      "Ismail Ceylan",
      "Thomas Lukasiewicz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5705",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5705/5561",
    "published": "2020-02",
    "summary": "Weighted model counting (WMC) has emerged as a prevalent approach for probabilistic inference. In its most general form, WMC is #P-hard. Weighted DNF counting (weighted #DNF) is a special case, where approximations with probabilistic guarantees are obtained in O(nm), where n denotes the number of variables, and m the number of clauses of the input DNF, but this is not scalable in practice. In this paper, we propose a neural model counting approach for weighted #DNF that combines approximate model counting with deep learning, and accurately approximates model counts in linear time when width is bounded. We conduct experiments to validate our method, and show that our model learns and generalizes very well to large-scale #DNF instances."
  },
  "aaai2020_main_quantizedcompressivesamplingofstochasticgradientsforefficientcommunicationindistributeddeeplearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Quantized Compressive Sampling of Stochastic Gradients for Efficient Communication in Distributed Deep Learning ",
    "authors": [
      "Afshin Abdi",
      "Faramarz Fekri"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5706",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5706/5562",
    "published": "2020-02",
    "summary": "In distributed training of deep models, the transmission volume of stochastic gradients (SG) imposes a bottleneck in scaling up the number of processing nodes. On the other hand, the existing methods for compression of SGs have two major drawbacks. First, due to the increase in the overall variance of the compressed SG, the hyperparameters of the learning algorithm must be readjusted to ensure the convergence of the training. Further, the convergence rate of the resulting algorithm still would be adversely affected. Second, for those approaches for which the compressed SG values are biased, there is no guarantee for the learning convergence and thus an error feedback is often required. We propose Quantized Compressive Sampling (QCS) of SG that addresses the above two issues while achieving an arbitrarily large compression gain. We introduce two variants of the algorithm: Unbiased-QCS and MMSE-QCS and show their superior performance w.r.t. other approaches. Specifically, we show that for the same number of communication bits, the convergence rate is improved by a factor of 2 relative to state of the art. Next, we propose to improve the convergence rate of the distributed training algorithm via a weighted error feedback. Specifically, we develop and analyze a method to both control the overall variance of the compressed SG and prevent the staleness of the updates. Finally, through simulations, we validate our theoretical results and establish the superior performance of the proposed SG compression in the distributed training of deep models. Our simulations also demonstrate that our proposed compression method expands substantially the region of step-size values for which the learning algorithm converges."
  },
  "aaai2020_main_indirectstochasticgradientquantizationanditsapplicationindistributeddeeplearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Indirect Stochastic Gradient Quantization and Its Application in Distributed Deep Learning ",
    "authors": [
      "Afshin Abdi",
      "Faramarz Fekri"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5707",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5707/5563",
    "published": "2020-02",
    "summary": "Transmitting the gradients or model parameters is a critical bottleneck in distributed training of large models. To mitigate this issue, we propose an indirect quantization and compression of stochastic gradients (SG) via factorization. The gist of the idea is that, in contrast to the direct compression methods, we focus on the factors in SGs, i.e., the forward and backward signals in the backpropagation algorithm. We observe that these factors are correlated and generally sparse in most deep models. This gives rise to rethinking of the approaches for quantization and compression of gradients with the ultimate goal of minimizing the error in the final computed gradients subject to the desired communication constraints. We have proposed and theoretically analyzed different indirect SG quantization (ISGQ) methods. The proposed ISGQ reduces the reconstruction error in SGs compared to the direct quantization methods with the same number of quantization bits. Moreover, it can achieve compression gains of more than 100, while the existing traditional quantization schemes can achieve compression ratio of at most 32 (quantizing to 1 bit). Further, for a fixed total batch-size, the required transmission bit-rate per worker decreases in ISGQ as the number of workers increases."
  },
  "aaai2020_main_image-adaptiveganbasedreconstruction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Image-Adaptive GAN Based Reconstruction ",
    "authors": [
      "Shady Abu Hussein",
      "Tom Tirer",
      "Raja Giryes"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5708",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5708/5564",
    "published": "2020-02",
    "summary": "In the recent years, there has been a significant improvement in the quality of samples produced by (deep) generative models such as variational auto-encoders and generative adversarial networks. However, the representation capabilities of these methods still do not capture the full distribution for complex classes of images, such as human faces. This deficiency has been clearly observed in previous works that use pre-trained generative models to solve imaging inverse problems. In this paper, we suggest to mitigate the limited representation capabilities of generators by making them image-adaptive and enforcing compliance of the restoration with the observations via back-projections. We empirically demonstrate the advantages of our proposed approach for image super-resolution and compressed sensing."
  },
  "aaai2020_main_degandata-enrichingganforretrievingrepresentativesamplesfromatrainedclassifier": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DeGAN: Data-Enriching GAN for Retrieving Representative Samples from a Trained Classifier ",
    "authors": [
      "Sravanti Addepalli",
      "Gaurav Kumar Nayak",
      "Anirban Chakraborty",
      "Venkatesh Babu Radhakrishnan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5709",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5709/5565",
    "published": "2020-02",
    "summary": "In this era of digital information explosion, an abundance of data from numerous modalities is being generated as well as archived everyday. However, most problems associated with training Deep Neural Networks still revolve around lack of data that is rich enough for a given task. Data is required not only for training an initial model, but also for future learning tasks such as Model Compression and Incremental Learning. A diverse dataset may be used for training an initial model, but it may not be feasible to store it throughout the product life cycle due to data privacy issues or memory constraints. We propose to bridge the gap between the abundance of available data and lack of relevant data, for the future learning tasks of a given trained network. We use the available data, that may be an imbalanced subset of the original training dataset, or a related domain dataset, to retrieve representative samples from a trained classifier, using a novel Data-enriching GAN (DeGAN) framework. We demonstrate that data from a related domain can be leveraged to achieve state-of-the-art performance for the tasks of Data-free Knowledge Distillation and Incremental Learning on benchmark datasets. We further demonstrate that our proposed framework can enrich any data, even from unrelated domains, to make it more useful for the future learning tasks of a given network."
  },
  "aaai2020_main_boundsandcomplexityresultsforlearningcoalition-basedinteractionfunctionsinnetworkedsocialsystems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bounds and Complexity Results for Learning Coalition-Based Interaction Functions in Networked Social Systems ",
    "authors": [
      "Abhijin Adiga",
      "Chris Kuhlman",
      "Madhav Marathe",
      "S. Ravi",
      "Daniel Rosenkranz",
      "Richard Stearns",
      "Anil Vullikanti"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5710",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5710/5566",
    "published": "2020-02",
    "summary": "Using a discrete dynamical system model for a networked social system, we consider the problem of learning a class of local interaction functions in such networks. Our focus is on learning local functions which are based on pairwise disjoint coalitions formed from the neighborhood of each node. Our work considers both active query and PAC learning models. We establish bounds on the number of queries needed to learn the local functions under both models. We also establish a complexity result regarding efficient consistent learners for such functions. Our experimental results on synthetic and real social networks demonstrate how the number of queries depends on the structure of the underlying network and number of coalitions."
  },
  "aaai2020_main_learningoptimaldecisiontreesusingcachingbranch-and-boundsearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Optimal Decision Trees Using Caching Branch-and-Bound Search ",
    "authors": [
      "Ga\u00ebl Aglin",
      "Siegfried Nijssen",
      "Pierre Schaus"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5711",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5711/5567",
    "published": "2020-02",
    "summary": "Several recent publications have studied the use of Mixed Integer Programming (MIP) for finding an optimal decision tree, that is, the best decision tree under formal requirements on accuracy, fairness or interpretability of the predictive model. These publications used MIP to deal with the hard computational challenge of finding such trees. In this paper, we introduce a new efficient algorithm, DL8.5, for finding optimal decision trees, based on the use of itemset mining techniques. We show that this new approach outperforms earlier approaches with several orders of magnitude, for both numerical and discrete data, and is generic as well. The key idea underlying this new approach is the use of a cache of itemsets in combination with branch-and-bound search; this new type of cache also stores results for parts of the search space that have been traversed partially."
  },
  "aaai2020_main_detectingsemanticanomalies": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Detecting Semantic Anomalies ",
    "authors": [
      "Faruk Ahmed",
      "Aaron Courville"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5712",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5712/5568",
    "published": "2020-02",
    "summary": "We critically appraise the recent interest in out-of-distribution (OOD) detection and question the practical relevance of existing benchmarks. While the currently prevalent trend is to consider different datasets as OOD, we argue that out-distributions of practical interest are ones where the distinction is semantic in nature for a specified context, and that evaluative tasks should reflect this more closely. Assuming a context of object recognition, we recommend a set of benchmarks, motivated by practical applications. We make progress on these benchmarks by exploring a multi-task learning based approach, showing that auxiliary objectives for improved semantic awareness result in improved semantic anomaly detection, with accompanying generalization benefits."
  },
  "aaai2020_main_exactandefficientinferenceforcollectiveflowdiffusionmodelviaminimumconvexcostflowalgorithm": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Exact and Efficient Inference for Collective Flow Diffusion Model via Minimum Convex Cost Flow Algorithm ",
    "authors": [
      "Yasunori Akagi",
      "Takuya Nishimura",
      "Yusuke Tanaka",
      "Takeshi Kurashima",
      "Hiroyuki Toda"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5713",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5713/5569",
    "published": "2020-02",
    "summary": "Collective Flow Diffusion Model (CFDM) is a general framework to find the hidden movements underlying aggregated population data. The key procedure in CFDM analysis is MAP inference of hidden variables. Unfortunately, existing approaches fail to offer exact MAP inferences, only approximate versions, and take a lot of computation time when applied to large scale problems. In this paper, we propose an exact and efficient method for MAP inference in CFDM. Our key idea is formulating the MAP inference problem as a combinatorial optimization problem called Minimum Convex Cost Flow Problem (C-MCFP) with no approximation or continuous relaxation. On the basis of this formulation, we propose an efficient inference method that employs the C-MCFP algorithm as a subroutine. Our experiments on synthetic and real datasets show that the proposed method is effective both in single MAP inference and people flow estimation with EM algorithm."
  },
  "aaai2020_main_pursuitoflow-rankmodelsoftime-varyingmatricesrobusttosparseandmeasurementnoise": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Pursuit of Low-Rank Models of Time-Varying Matrices Robust to Sparse and Measurement Noise ",
    "authors": [
      "Albert Akhriev",
      "Jakub Marecek",
      "Andrea Simonetto"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5714",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5714/5570",
    "published": "2020-02",
    "summary": "In tracking of time-varying low-rank models of time-varying matrices, we present a method robust to both uniformly-distributed measurement noise and arbitrarily-distributed \u201csparse\u201d noise. In theory, we bound the tracking error. In practice, our use of randomised coordinate descent is scalable and allows for encouraging results on changedetection.net, a benchmark."
  },
  "aaai2020_main_animplicitformofkrasulinask-pcaupdatewithouttheorthonormalityconstraint": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Implicit Form of Krasulina's k-PCA Update without the Orthonormality Constraint ",
    "authors": [
      "Ehsan Amid",
      "Manfred K. Warmuth"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5715",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5715/5571",
    "published": "2020-02",
    "summary": "We shed new insights on the two commonly used updates for the online k-PCA problem, namely, Krasulina's and Oja's updates. We show that Krasulina's update corresponds to a projected gradient descent step on the Stiefel manifold of orthonormal k-frames, while Oja's update amounts to a gradient descent step using the unprojected gradient. Following these observations, we derive a more implicit form of Krasulina's k-PCA update, i.e. a version that uses the information of the future gradient as much as possible. Most interestingly, our implicit Krasulina update avoids the costly QR-decomposition step by bypassing the orthonormality constraint. A related update, called the Sanger's rule, can be seen as an explicit approximation of our implicit update. We show that the new update in fact corresponds to an online EM step applied to a probabilistic k-PCA model. The probabilistic view of the update allows us to combine multiple models in a distributed setting. We show experimentally that the implicit Krasulina update yields superior convergence while being significantly faster. We also give strong evidence that the new update can benefit from parallelism and is more stable w.r.t. tuning of the learning rate."
  },
  "aaai2020_main_krigingconvolutionalnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Kriging Convolutional Networks ",
    "authors": [
      "Gabriel Appleby",
      "Linfeng Liu",
      "Li-Ping Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5716",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5716/5572",
    "published": "2020-02",
    "summary": "Spatial interpolation is a class of estimation problems where locations with known values are used to estimate values at other locations, with an emphasis on harnessing spatial locality and trends. Traditional kriging methods have strong Gaussian assumptions, and as a result, often fail to capture complexities within the data. Inspired by the recent progress of graph neural networks, we introduce Kriging Convolutional Networks (KCN), a method of combining advantages of Graph Neural Networks (GNN) and kriging. Compared to standard GNNs, KCNs make direct use of neighboring observations when generating predictions. KCNs also contain the kriging method as a specific configuration. Empirically, we show that this model outperforms GNNs and kriging in several applications."
  },
  "aaai2020_main_efficientinferenceofoptimaldecisiontrees": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Efficient Inference of Optimal Decision Trees ",
    "authors": [
      "Florent Avellaneda"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5717",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5717/5573",
    "published": "2020-02",
    "summary": "Inferring a decision tree from a given dataset is a classic problem in machine learning. This problem consists of building, from a labelled dataset, a tree where each node corresponds to a class and a path between the tree root and a leaf corresponds to a conjunction of features to be satisfied in this class. Following the principle of parsimony, we want to infer a minimal tree consistent with the dataset. Unfortunately, inferring an optimal decision tree is NP-complete for several definitions of optimality. For this reason, the majority of existing approaches rely on heuristics, and the few existing exact approaches do not work on large datasets. In this paper, we propose a novel approach for inferring an optimal decision tree with a minimum depth based on the incremental generation of Boolean formulas. The experimental results indicate that it scales sufficiently well and the time it takes to run grows slowly with the size of datasets."
  },
  "aaai2020_main_fewshotnetworkcompressionviacrossdistillation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Few Shot Network Compression via Cross Distillation ",
    "authors": [
      "Haoli Bai",
      "Jiaxiang Wu",
      "Irwin King",
      "Michael Lyu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5718",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5718/5574",
    "published": "2020-02",
    "summary": "Model compression has been widely adopted to obtain light-weighted deep neural networks. Most prevalent methods, however, require fine-tuning with sufficient training data to ensure accuracy, which could be challenged by privacy and security issues. As a compromise between privacy and performance, in this paper we investigate few shot network compression: given few samples per class, how can we effectively compress the network with negligible performance drop? The core challenge of few shot network compression lies in high estimation errors from the original network during inference, since the compressed network can easily over-fits on the few training instances. The estimation errors could propagate and accumulate layer-wisely and finally deteriorate the network output. To address the problem, we propose cross distillation, a novel layer-wise knowledge distillation approach. By interweaving hidden layers of teacher and student network, layer-wisely accumulated estimation errors can be effectively reduced. The proposed method offers a general framework compatible with prevalent network compression techniques such as pruning. Extensive experiments n benchmark datasets demonstrate that cross distillation can significantly improve the student network's accuracy when only a few training instances are available."
  },
  "aaai2020_main_athree-leveloptimizationmodelfornonlinearlyseparableclustering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Three-Level Optimization Model for Nonlinearly Separable Clustering ",
    "authors": [
      "Liang Bai",
      "Jiye Liang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5719",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5719/5575",
    "published": "2020-02",
    "summary": "Due to the complex structure of the real-world data, nonlinearly separable clustering is one of popular and widely studied clustering problems. Currently, various types of algorithms, such as kernel k-means, spectral clustering and density clustering, have been developed to solve this problem. However, it is difficult for them to balance the efficiency and effectiveness of clustering, which limits their real applications. To get rid of the deficiency, we propose a three-level optimization model for nonlinearly separable clustering which divides the clustering problem into three sub-problems: a linearly separable clustering on the object set, a nonlinearly separable clustering on the cluster set and an ensemble clustering on the partition set. An iterative algorithm is proposed to solve the optimization problem. The proposed algorithm can use low computational cost to effectively recognize nonlinearly separable clusters. The performance of this algorithm has been studied on synthetical and real data sets. Comparisons with other nonlinearly separable clustering algorithms illustrate the efficiency and effectiveness of the proposed algorithm."
  },
  "aaai2020_main_learning-basedefficientgraphsimilaritycomputationviamulti-scaleconvolutionalsetmatching": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning-Based Efficient Graph Similarity Computation via Multi-Scale Convolutional Set Matching ",
    "authors": [
      "Yunsheng Bai",
      "Hao Ding",
      "Ken Gu",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5720",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5720/5576",
    "published": "2020-02",
    "summary": "Graph similarity computation is one of the core operations in many graph-based applications, such as graph similarity search, graph database analysis, graph clustering, etc. Since computing the exact distance/similarity between two graphs is typically NP-hard, a series of approximate methods have been proposed with a trade-off between accuracy and speed. Recently, several data-driven approaches based on neural networks have been proposed, most of which model the graph-graph similarity as the inner product of their graph-level representations, with different techniques proposed for generating one embedding per graph. However, using one fixed-dimensional embedding per graph may fail to fully capture graphs in varying sizes and link structures\u2014a limitation that is especially problematic for the task of graph similarity computation, where the goal is to find the fine-grained difference between two graphs. In this paper, we address the problem of graph similarity computation from another perspective, by directly matching two sets of node embeddings without the need to use fixed-dimensional vectors to represent whole graphs for their similarity computation. The model, Graph-Sim, achieves the state-of-the-art performance on four real-world graph datasets under six out of eight settings (here we count a specific dataset and metric combination as one setting), compared to existing popular methods for approximate Graph Edit Distance (GED) and Maximum Common Subgraph (MCS) computation."
  },
  "aaai2020_main_learningtooptimizecomputationalresourcesfrugaltrainingwithgeneralizationguarantees": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Optimize Computational Resources: Frugal Training with Generalization Guarantees ",
    "authors": [
      "Maria-Florina Balcan",
      "Tuomas Sandholm",
      "Ellen Vitercik"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5721",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5721/5577",
    "published": "2020-02",
    "summary": "Algorithms typically come with tunable parameters that have a considerable impact on the computational resources they consume. Too often, practitioners must hand-tune the parameters, a tedious and error-prone task. A recent line of research provides algorithms that return nearly-optimal parameters from within a finite set. These algorithms can be used when the parameter space is infinite by providing as input a random sample of parameters. This data-independent discretization, however, might miss pockets of nearly-optimal parameters: prior research has presented scenarios where the only viable parameters lie within an arbitrarily small region. We provide an algorithm that learns a finite set of promising parameters from within an infinite set. Our algorithm can help compile a configuration portfolio, or it can be used to select the input to a configuration algorithm for finite parameter spaces. Our approach applies to any configuration problem that satisfies a simple yet ubiquitous structure: the algorithm's performance is a piecewise constant function of its parameters. Prior research has exhibited this structure in domains from integer programming to clustering."
  },
  "aaai2020_main_scalableattentivesentencepairmodelingviadistilledsentenceembedding": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Scalable Attentive Sentence Pair Modeling via Distilled Sentence Embedding ",
    "authors": [
      "Oren Barkan",
      "Noam Razin",
      "Itzik Malkiel",
      "Ori Katz",
      "Avi Caciularu",
      "Noam Koenigstein"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5722",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5722/5578",
    "published": "2020-02",
    "summary": "Recent state-of-the-art natural language understanding models, such as BERT and XLNet, score a pair of sentences (A and B) using multiple cross-attention operations \u2013 a process in which each word in sentence A attends to all words in sentence B and vice versa. As a result, computing the similarity between a query sentence and a set of candidate sentences, requires the propagation of all query-candidate sentence-pairs throughout a stack of cross-attention layers. This exhaustive process becomes computationally prohibitive when the number of candidate sentences is large. In contrast, sentence embedding techniques learn a sentence-to-vector mapping and compute the similarity between the sentence vectors via simple elementary operations. In this paper, we introduce Distilled Sentence Embedding (DSE) \u2013 a model that is based on knowledge distillation from cross-attentive models, focusing on sentence-pair tasks. The outline of DSE is as follows: Given a cross-attentive teacher model (e.g. a fine-tuned BERT), we train a sentence embedding based student model to reconstruct the sentence-pair scores obtained by the teacher model. We empirically demonstrate the effectiveness of DSE on five GLUE sentence-pair tasks. DSE significantly outperforms several ELMO variants and other sentence embedding methods, while accelerating computation of the query-candidate sentence-pairs similarities by several orders of magnitude, with an average relative degradation of 4.6% compared to BERT. Furthermore, we show that DSE produces sentence embeddings that reach state-of-the-art performance on universal sentence representation benchmarks. Our code is made publicly available at https://github.com/microsoft/Distilled-Sentence-Embedding."
  },
  "aaai2020_main_midasmicrocluster-baseddetectorofanomaliesinedgestreams": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Midas: Microcluster-Based Detector of Anomalies in Edge Streams ",
    "authors": [
      "Siddharth Bhatia",
      "Bryan Hooi",
      "Minji Yoon",
      "Kijung Shin",
      "Christos Faloutsos"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5724",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5724/5580",
    "published": "2020-02",
    "summary": "Given a stream of graph edges from a dynamic graph, how can we assign anomaly scores to edges in an online manner, for the purpose of detecting unusual behavior, using constant time and memory? Existing approaches aim to detect individually surprising edges. In this work, we propose Midas, which focuses on detecting microcluster anomalies, or suddenly arriving groups of suspiciously similar edges, such as lockstep behavior, including denial of service attacks in network traffic data. Midas has the following properties: (a) it detects microcluster anomalies while providing theoretical guarantees about its false positive probability; (b) it is online, thus processing each edge in constant time and constant memory, and also processes the data 108\u2013505 times faster than state-of-the-art approaches; (c) it provides 46%-52% higher accuracy (in terms of AUC) than state-of-the-art approaches."
  },
  "aaai2020_main_exploratorycombinatorialoptimizationwithreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Exploratory Combinatorial Optimization with Reinforcement Learning ",
    "authors": [
      "Thomas Barrett",
      "William Clements",
      "Jakob Foerster",
      "Alex Lvovsky"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5723",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5723/5579",
    "published": "2020-02",
    "summary": "Many real-world problems can be reduced to combinatorial optimization on a graph, where the subset or ordering of vertices that maximize some objective function must be found. With such tasks often NP-hard and analytically intractable, reinforcement learning (RL) has shown promise as a framework with which efficient heuristic methods to tackle these problems can be learned. Previous works construct the solution subset incrementally, adding one element at a time, however, the irreversible nature of this approach prevents the agent from revising its earlier decisions, which may be necessary given the complexity of the optimization task. We instead propose that the agent should seek to continuously improve the solution by learning to explore at test time. Our approach of exploratory combinatorial optimization (ECO-DQN) is, in principle, applicable to any combinatorial problem that can be defined on a graph. Experimentally, we show our method to produce state-of-the-art RL performance on the Maximum Cut problem. Moreover, because ECO-DQN can start from any arbitrary configuration, it can be combined with other search methods to further improve performance, which we demonstrate using a simple random search."
  },
  "aaai2020_main_event-drivencontinuoustimebayesiannetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Event-Driven Continuous Time Bayesian Networks ",
    "authors": [
      "Debarun Bhattacharjya",
      "Karthikeyan Shanmugam",
      "Tian Gao",
      "Nicholas Mattei",
      "Kush Varshney",
      "Dharmashankar Subramanian"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5725",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5725/5581",
    "published": "2020-02",
    "summary": "We introduce a novel event-driven continuous time Bayesian network (ECTBN) representation to model situations where a system's state variables could be influenced by occurrences of events of various types. In this way, the model parameters and graphical structure capture not only potential \u201ccausal\u201d dynamics of system evolution but also the influence of event occurrences that may be interventions. We propose a greedy search procedure for structure learning based on the BIC score for a special class of ECTBNs, showing that it is asymptotically consistent and also effective for limited data. We demonstrate the power of the representation by applying it to model paths out of poverty for clients of CityLink Center, an integrated social service provider in Cincinnati, USA. Here the ECTBN formulation captures the effect of classes/counseling sessions on an individual's life outcome areas such as education, transportation, employment and financial education."
  },
  "aaai2020_main_anefficientevolutionaryalgorithmforsubsetselectionwithgeneralcostconstraints": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Efficient Evolutionary Algorithm for Subset Selection with General Cost Constraints ",
    "authors": [
      "Chao Bian",
      "Chao Feng",
      "Chao Qian",
      "Yang Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5726",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5726/5582",
    "published": "2020-02",
    "summary": "In this paper, we study the problem of selecting a subset from a ground set to maximize a monotone objective function f such that a monotone cost function c is bounded by an upper limit. State-of-the-art algorithms include the generalized greedy algorithm and POMC. The former is an efficient fixed time algorithm, but the performance is limited by the greedy nature. The latter is an anytime algorithm that can find better subsets using more time, but without any polynomial-time approximation guarantee. In this paper, we propose a new anytime algorithm EAMC, which employs a simple evolutionary algorithm to optimize a surrogate objective integrating f and c. We prove that EAMC achieves the best known approximation guarantee in polynomial expected running time. Experimental results on the applications of maximum coverage, influence maximization and sensor placement show the excellent performance of EAMC."
  },
  "aaai2020_main_astochasticderivative-freeoptimizationmethodwithimportancesamplingtheoryandlearningtocontrol": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Stochastic Derivative-Free Optimization Method with Importance Sampling: Theory and Learning to Control ",
    "authors": [
      "Adel Bibi",
      "El Houcine Bergou",
      "Ozan Sener",
      "Bernard Ghanem",
      "Peter Richtarik"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5727",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5727/5583",
    "published": "2020-02",
    "summary": "We consider the problem of unconstrained minimization of a smooth objective function in \u211dn in a setting where only function evaluations are possible. While importance sampling is one of the most popular techniques used by machine learning practitioners to accelerate the convergence of their models when applicable, there is not much existing theory for this acceleration in the derivative-free setting. In this paper, we propose the first derivative free optimization method with importance sampling and derive new improved complexity results on non-convex, convex and strongly convex functions. We conduct extensive experiments on various synthetic and real LIBSVM datasets confirming our theoretical results. We test our method on a collection of continuous control tasks on MuJoCo environments with varying difficulty. Experiments show that our algorithm is practical for high dimensional continuous control problems where importance sampling results in a significant sample complexity improvement."
  },
  "aaai2020_main_proximaldistilledevolutionaryreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Proximal Distilled Evolutionary Reinforcement Learning ",
    "authors": [
      "Cristian Bodnar",
      "Ben Day",
      "Pietro Li\u00f3"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5728",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5728/5584",
    "published": "2020-02",
    "summary": "Reinforcement Learning (RL) has achieved impressive performance in many complex environments due to the integration with Deep Neural Networks (DNNs). At the same time, Genetic Algorithms (GAs), often seen as a competing approach to RL, had limited success in scaling up to the DNNs required to solve challenging tasks. Contrary to this dichotomic view, in the physical world, evolution and learning are complementary processes that continuously interact. The recently proposed Evolutionary Reinforcement Learning (ERL) framework has demonstrated mutual benefits to performance when combining the two methods. However, ERL has not fully addressed the scalability problem of GAs. In this paper, we show that this problem is rooted in an unfortunate combination of a simple genetic encoding for DNNs and the use of traditional biologically-inspired variation operators. When applied to these encodings, the standard operators are destructive and cause catastrophic forgetting of the traits the networks acquired. We propose a novel algorithm called Proximal Distilled Evolutionary Reinforcement Learning (PDERL) that is characterised by a hierarchical integration between evolution and learning. The main innovation of PDERL is the use of learning-based variation operators that compensate for the simplicity of the genetic representation. Unlike traditional operators, our proposals meet the functional requirements of variation operators when applied on directly-encoded DNNs. We evaluate PDERL in five robot locomotion settings from the OpenAI gym. Our method outperforms ERL, as well as two state-of-the-art RL algorithms, PPO and TD3, in all tested environments."
  },
  "aaai2020_main_efficientverificationofrelu-basedneuralnetworksviadependencyanalysis": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Efficient Verification of ReLU-Based Neural Networks via Dependency Analysis ",
    "authors": [
      "Elena Botoeva",
      "Panagiotis Kouvaros",
      "Jan Kronqvist",
      "Alessio Lomuscio",
      "Ruth Misener"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5729",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5729/5585",
    "published": "2020-02",
    "summary": "We introduce an efficient method for the verification of ReLU-based feed-forward neural networks. We derive an automated procedure that exploits dependency relations between the ReLU nodes, thereby pruning the search tree that needs to be considered by MILP-based formulations of the verification problem. We augment the resulting algorithm with methods for input domain splitting and symbolic interval propagation. We present Venus, the resulting verification toolkit, and evaluate it on the ACAS collision avoidance networks and models trained on the MNIST and CIFAR-10 datasets. The experimental results obtained indicate considerable gains over the present state-of-the-art tools."
  },
  "aaai2020_main_information-theoreticunderstandingofpopulationriskimprovementwithmodelcompression": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Information-Theoretic Understanding of Population Risk Improvement with Model Compression ",
    "authors": [
      "Yuheng Bu",
      "Weihao Gao",
      "Shaofeng Zou",
      "Venugopal Veeravalli"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5730",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5730/5586",
    "published": "2020-02",
    "summary": "We show that model compression can improve the population risk of a pre-trained model, by studying the tradeoff between the decrease in the generalization error and the increase in the empirical risk with model compression. We first prove that model compression reduces an information-theoretic bound on the generalization error; this allows for an interpretation of model compression as a regularization technique to avoid overfitting. We then characterize the increase in empirical risk with model compression using rate distortion theory. These results imply that the population risk could be improved by model compression if the decrease in generalization error exceeds the increase in empirical risk. We show through a linear regression example that such a decrease in population risk due to model compression is indeed possible. Our theoretical results further suggest that the Hessian-weighted K-means clustering compression approach can be improved by regularizing the distance between the clustering centers. We provide experiments with neural networks to support our theoretical assertions."
  },
  "aaai2020_main_amulti-scaleapproachforgraphlinkprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Multi-Scale Approach for Graph Link Prediction ",
    "authors": [
      "Lei Cai",
      "Shuiwang Ji"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5731",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5731/5587",
    "published": "2020-02",
    "summary": "Deep models can be made scale-invariant when trained with multi-scale information. Images can be easily made multi-scale, given their grid-like structures. Extending this to generic graphs poses major challenges. For example, in link prediction tasks, inputs are represented as graphs consisting of nodes and edges. Currently, the state-of-the-art model for link prediction uses supervised heuristic learning, which learns graph structure features centered on two target nodes. It then learns graph neural networks to predict the existence of links based on graph structure features. Thus, the performance of link prediction models highly depends on graph structure features. In this work, we propose a novel node aggregation method that can transform the enclosing subgraph into different scales and preserve the relationship between two target nodes for link prediction. A theory for analyzing the information loss during the re-scaling procedure is also provided. Graphs in different scales can provide scale-invariant information, which enables graph neural networks to learn invariant features and improve link prediction performance. Our experimental results on 14 datasets from different areas demonstrate that our proposed method outperforms the state-of-the-art methods by employing multi-scale graphs without additional parameters."
  },
  "aaai2020_main_deterministicvalue-policygradients": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deterministic Value-Policy Gradients ",
    "authors": [
      "Qingpeng Cai",
      "Ling Pan",
      "Pingzhong Tang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5732",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5732/5588",
    "published": "2020-02",
    "summary": "Reinforcement learning algorithms such as the deep deterministic policy gradient algorithm (DDPG) has been widely used in continuous control tasks. However, the model-free DDPG algorithm suffers from high sample complexity. In this paper we consider the deterministic value gradients to improve the sample efficiency of deep reinforcement learning algorithms. Previous works consider deterministic value gradients with the finite horizon, but it is too myopic compared with infinite horizon. We firstly give a theoretical guarantee of the existence of the value gradients in this infinite setting. Based on this theoretical guarantee, we propose a class of the deterministic value gradient algorithm (DVG) with infinite horizon, and different rollout steps of the analytical gradients by the learned model trade off between the variance of the value gradients and the model bias. Furthermore, to better combine the model-based deterministic value gradient estimators with the model-free deterministic policy gradient estimator, we propose the deterministic value-policy gradient (DVPG) algorithm. We finally conduct extensive experiments comparing DVPG with state-of-the-art methods on several standard continuous control benchmarks. Results demonstrate that DVPG substantially outperforms other baselines."
  },
  "aaai2020_main_predictingpropositionalsatisfiabilityviaend-to-endlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Predicting Propositional Satisfiability via End-to-End Learning ",
    "authors": [
      "Chris Cameron",
      "Rex Chen",
      "Jason Hartford",
      "Kevin Leyton-Brown"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5733",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5733/5589",
    "published": "2020-02",
    "summary": "Strangely enough, it is possible to use machine learning models to predict the satisfiability status of hard SAT problems with accuracy considerably higher than random guessing. Existing methods have relied on extensive, manual feature engineering and computationally complex features (e.g., based on linear programming relaxations). We show for the first time that even better performance can be achieved by end-to-end learning methods \u2014 i.e., models that map directly from raw problem inputs to predictions and take only linear time to evaluate. Our work leverages deep network models which capture a key invariance exhibited by SAT problems: satisfiability status is unaffected by reordering variables and clauses. We showed that end-to-end learning with deep networks can outperform previous work on random 3-SAT problems at the solubility phase transition, where: (1) exactly 50% of problems are satisfiable; and (2) empirical runtimes of known solution methods scale exponentially with problem size (e.g., we achieved 84% prediction accuracy on 600-variable problems, which take hours to solve with state-of-the-art methods). We also showed that deep networks can generalize across problem sizes (e.g., a network trained only on 100-variable problems, which typically take about 10 ms to solve, achieved 81% accuracy on 600-variable problems)."
  },
  "aaai2020_main_activeordinalqueryingfortuplewisesimilaritylearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Active Ordinal Querying for Tuplewise Similarity Learning ",
    "authors": [
      "Gregory Canal",
      "Stefano Fenu",
      "Christopher Rozell"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5734",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5734/5590",
    "published": "2020-02",
    "summary": "Many machine learning tasks such as clustering, classification, and dataset search benefit from embedding data points in a space where distances reflect notions of relative similarity as perceived by humans. A common way to construct such an embedding is to request triplet similarity queries to an oracle, comparing two objects with respect to a reference. This work generalizes triplet queries to tuple queries of arbitrary size that ask an oracle to rank multiple objects against a reference, and introduces an efficient and robust adaptive selection method called InfoTuple that uses a novel approach to mutual information maximization. We show that the performance of InfoTuple at various tuple sizes exceeds that of the state-of-the-art adaptive triplet selection method on synthetic tests and new human response datasets, and empirically demonstrate the significant gains in efficiency and query consistency achieved by querying larger tuples instead of triplets."
  },
  "aaai2020_main_fatigue-awarebanditsfordependentclickmodels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fatigue-Aware Bandits for Dependent Click Models ",
    "authors": [
      "Junyu Cao",
      "Wei Sun",
      "Zuo-Jun (Max) Shen",
      "Markus Ettl"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5735",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5735/5591",
    "published": "2020-02",
    "summary": "As recommender systems send a massive amount of content to keep users engaged, users may experience fatigue which is contributed by 1) an overexposure to irrelevant content, 2) boredom from seeing too many similar recommendations. To address this problem, we consider an online learning setting where a platform learns a policy to recommend content that takes user fatigue into account. We propose an extension of the Dependent Click Model (DCM) to describe users' behavior. We stipulate that for each piece of content, its attractiveness to a user depends on its intrinsic relevance and a discount factor which measures how many similar contents have been shown. Users view the recommended content sequentially and click on the ones that they find attractive. Users may leave the platform at any time, and the probability of exiting is higher when they do not like the content. Based on user's feedback, the platform learns the relevance of the underlying content as well as the discounting effect due to content fatigue. We refer to this learning task as \u201cfatigue-aware DCM Bandit\u201d problem. We consider two learning scenarios depending on whether the discounting effect is known. For each scenario, we propose a learning algorithm which simultaneously explores and exploits, and characterize its regret bound."
  },
  "aaai2020_main_generalizationerrorboundsofgradientdescentforlearningover-parameterizeddeeprelunetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generalization Error Bounds of Gradient Descent for Learning Over-Parameterized Deep ReLU Networks ",
    "authors": [
      "Yuan Cao",
      "Quanquan Gu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5736",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5736/5592",
    "published": "2020-02",
    "summary": "Empirical studies show that gradient-based methods can learn deep neural networks (DNNs) with very good generalization performance in the over-parameterization regime, where DNNs can easily fit a random labeling of the training data. Very recently, a line of work explains in theory that with over-parameterization and proper random initialization, gradient-based methods can find the global minima of the training loss for DNNs. However, existing generalization error bounds are unable to explain the good generalization performance of over-parameterized DNNs. The major limitation of most existing generalization bounds is that they are based on uniform convergence and are independent of the training algorithm. In this work, we derive an algorithm-dependent generalization error bound for deep ReLU networks, and show that under certain assumptions on the data distribution, gradient descent (GD) with proper random initialization is able to train a sufficiently over-parameterized DNN to achieve arbitrarily small generalization error. Our work sheds light on explaining the good generalization performance of over-parameterized deep neural networks."
  },
  "aaai2020_main_exponentialfamilygraphembeddings": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Exponential Family Graph Embeddings ",
    "authors": [
      "Abdulkadir Celikkanat",
      "Fragkiskos D. Malliaros"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5737",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5737/5593",
    "published": "2020-02",
    "summary": "Representing networks in a low dimensional latent space is a crucial task with many interesting applications in graph learning problems, such as link prediction and node classification. A widely applied network representation learning paradigm is based on the combination of random walks for sampling context nodes and the traditional Skip-Gram model to capture center-context node relationships. In this paper, we emphasize on exponential family distributions to capture rich interaction patterns between nodes in random walk sequences. We introduce the generic exponential family graph embedding model, that generalizes random walk-based network representation learning techniques to exponential family conditional distributions. We study three particular instances of this model, analyzing their properties and showing their relationship to existing unsupervised learning models. Our experimental evaluation on real-world datasets demonstrates that the proposed techniques outperform well-known baseline methods in two downstream machine learning tasks."
  },
  "aaai2020_main_askingtherightquestionstotherightusersactivelearningwithimperfectoracles": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Asking the Right Questions to the Right Users: Active Learning with Imperfect Oracles ",
    "authors": [
      "Shayok Chakraborty"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5738",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5738/5594",
    "published": "2020-02",
    "summary": "Active learning algorithms automatically identify the salient and exemplar samples from large amounts of unlabeled data and tremendously reduce human annotation effort in inducing a machine learning model. In a traditional active learning setup, the labeling oracles are assumed to be infallible, that is, they always provide correct answers (in terms of class labels) to the queried unlabeled instances. However, in real-world applications, oracles are often imperfect and provide incorrect label annotations. Oracles also have diverse expertise and while they may be noisy, certain oracles may provide accurate annotations to certain specific instances. In this paper, we propose a novel framework to address the challenging problem of active learning in the presence of multiple imperfect oracles. We pose the optimal sample and oracle selection as a constrained optimization problem and derive a linear programming relaxation to select a batch of (sample-oracle) pairs, which can potentially augment maximal information to the underlying classification model. Our extensive empirical studies on 9 challenging datasets (from a variety of application domains) corroborate the usefulness of our framework over competing baselines."
  },
  "aaai2020_main_lifelonglearningwithachangingactionset": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Lifelong Learning with a Changing Action Set ",
    "authors": [
      "Yash Chandak",
      "Georgios Theocharous",
      "Chris Nota",
      "Philip Thomas"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5739",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5739/5595",
    "published": "2020-02",
    "summary": "In many real-world sequential decision making problems, the number of available actions (decisions) can vary over time. While problems like catastrophic forgetting, changing transition dynamics, changing rewards functions, etc. have been well-studied in the lifelong learning literature, the setting where the size of the action set changes remains unaddressed. In this paper, we present first steps towards developing an algorithm that autonomously adapts to an action set whose size changes over time. To tackle this open problem, we break it into two problems that can be solved iteratively: inferring the underlying, unknown, structure in the space of actions and optimizing a policy that leverages this structure. We demonstrate the efficiency of this approach on large-scale real-world lifelong learning problems."
  },
  "aaai2020_main_reinforcementlearningwhenallactionsarenotalwaysavailable": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reinforcement Learning When All Actions Are Not Always Available ",
    "authors": [
      "Yash Chandak",
      "Georgios Theocharous",
      "Blossom Metevier",
      "Philip Thomas"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5740",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5740/5596",
    "published": "2020-02",
    "summary": "The Markov decision process (MDP) formulation used to model many real-world sequential decision making problems does not efficiently capture the setting where the set of available decisions (actions) at each time step is stochastic. Recently, the stochastic action set Markov decision process (SAS-MDP) formulation has been proposed, which better captures the concept of a stochastic action set. In this paper we argue that existing RL algorithms for SAS-MDPs can suffer from potential divergence issues, and present new policy gradient algorithms for SAS-MDPs that incorporate variance reduction techniques unique to this setting, and provide conditions for their convergence. We conclude with experiments that demonstrate the practicality of our approaches on tasks inspired by real-life use cases wherein the action set is stochastic."
  },
  "aaai2020_main_arestrictedblack-boxadversarialframeworktowardsattackinggraphembeddingmodels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Restricted Black-Box Adversarial Framework Towards Attacking Graph Embedding Models ",
    "authors": [
      "Heng Chang",
      "Yu Rong",
      "Tingyang Xu",
      "Wenbing Huang",
      "Honglei Zhang",
      "Peng Cui",
      "Wenwu Zhu",
      "Junzhou Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5741",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5741/5597",
    "published": "2020-02",
    "summary": "With the great success of graph embedding model on both academic and industry area, the robustness of graph embedding against adversarial attack inevitably becomes a central problem in graph learning domain. Regardless of the fruitful progress, most of the current works perform the attack in a white-box fashion: they need to access the model predictions and labels to construct their adversarial loss. However, the inaccessibility of model predictions in real systems makes the white-box attack impractical to real graph learning system. This paper promotes current frameworks in a more general and flexible sense \u2013 we demand to attack various kinds of graph embedding model with black-box driven. To this end, we begin by investigating the theoretical connections between graph signal processing and graph embedding models in a principled way and formulate the graph embedding model as a general graph signal process with corresponding graph filter. As such, a generalized adversarial attacker: GF-Attack is constructed by the graph filter and feature matrix. Instead of accessing any knowledge of the target classifiers used in graph embedding, GF-Attack performs the attack only on the graph filter in a black-box attack fashion. To validate the generalization of GF-Attack, we construct the attacker on four popular graph embedding models. Extensive experimental results validate the effectiveness of our attacker on several benchmark datasets. Particularly by using our attack, even small graph perturbations like one-edge flip is able to consistently make a strong attack in performance to different graph embedding models."
  },
  "aaai2020_main_robustdataprogrammingwithprecision-guidedlabelingfunctions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Robust Data Programming with Precision-guided Labeling Functions ",
    "authors": [
      "Oishik Chatterjee",
      "Ganesh Ramakrishnan",
      "Sunita Sarawagi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5742",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5742/5598",
    "published": "2020-02",
    "summary": "Scarcity of labeled data is a bottleneck for supervised learning models. A paradigm that has evolved for dealing with this problem is data programming. An existing data programming paradigm allows human supervision to be provided as a set of discrete labeling functions (LF) that output possibly noisy labels to input instances and a generative model for consolidating the weak labels. We enhance and generalize this paradigm by supporting functions that output a continuous score (instead of a hard label) that noisily correlates with labels. We show across five applications that continuous LFs are more natural to program and lead to improved recall. We also show that accuracy of existing generative models is unstable with respect to initialization, training epochs, and learning rates. We give control to the data programmer to guide the training process by providing intuitive quality guides with each LF. We propose an elegant method of incorporating these guides into the generative model. Our overall method, called CAGE, makes the data programming paradigm more reliable than other tricks based on initialization, sign-penalties, or soft-accuracy constraints."
  },
  "aaai2020_main_anewensembleadversarialattackpoweredbylong-termgradientmemories": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A New Ensemble Adversarial Attack Powered by Long-Term Gradient Memories ",
    "authors": [
      "Zhaohui Che",
      "Ali Borji",
      "Guangtao Zhai",
      "Suiyi Ling",
      "Jing Li",
      "Patrick Le Callet"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5743",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5743/5599",
    "published": "2020-02",
    "summary": "Deep neural networks are vulnerable to adversarial attacks. More importantly, some adversarial examples crafted against an ensemble of pre-trained source models can transfer to other new target models, thus pose a security threat to black-box applications (when the attackers have no access to the target models). Despite adopting diverse architectures and parameters, source and target models often share similar decision boundaries. Therefore, if an adversary is capable of fooling several source models concurrently, it can potentially capture intrinsic transferable adversarial information that may allow it to fool a broad class of other black-box target models. Current ensemble attacks, however, only consider a limited number of source models to craft an adversary, and obtain poor transferability. In this paper, we propose a novel black-box attack, dubbed Serial-Mini-Batch-Ensemble-Attack (SMBEA). SMBEA divides a large number of pre-trained source models into several mini-batches. For each single batch, we design 3 new ensemble strategies to improve the intra-batch transferability. Besides, we propose a new algorithm that recursively accumulates the \u201clong-term\u201d gradient memories of the previous batch to the following batch. This way, the learned adversarial information can be preserved and the inter-batch transferability can be improved. Experiments indicate that our method outperforms state-of-the-art ensemble attacks over multiple pixel-to-pixel vision tasks including image translation and salient region prediction. Our method successfully fools two online black-box saliency prediction systems including DeepGaze-II (Kummerer 2017) and SALICON (Huang et al. 2017). Finally, we also contribute a new repository to promote the research on adversarial attack and defense over pixel-to-pixel tasks: https://github.com/CZHQuality/AAA-Pix2pix."
  },
  "aaai2020_main_towardathousandlightsdecentralizeddeepreinforcementlearningforlarge-scaletrafficsignalcontrol": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Toward A Thousand Lights: Decentralized Deep Reinforcement Learning for Large-Scale Traffic Signal Control ",
    "authors": [
      "Chacha Chen",
      "Hua Wei",
      "Nan Xu",
      "Guanjie Zheng",
      "Ming Yang",
      "Yuanhao Xiong",
      "Kai Xu",
      "Zhenhui Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5744",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5744/5600",
    "published": "2020-02",
    "summary": "Traffic congestion plagues cities around the world. Recent years have witnessed an unprecedented trend in applying reinforcement learning for traffic signal control. However, the primary challenge is to control and coordinate traffic lights in large-scale urban networks. No one has ever tested RL models on a network of more than a thousand traffic lights. In this paper, we tackle the problem of multi-intersection traffic signal control, especially for large-scale networks, based on RL techniques and transportation theories. This problem is quite difficult because there are challenges such as scalability, signal coordination, data feasibility, etc. To address these challenges, we (1) design our RL agents utilizing \u2018pressure\u2019 concept to achieve signal coordination in region-level; (2) show that implicit coordination could be achieved by individual control agents with well-crafted reward design thus reducing the dimensionality; and (3) conduct extensive experiments on multiple scenarios, including a real-world scenario with 2510 traffic lights in Manhattan, New York City 1 2."
  },
  "aaai2020_main_hommhigher-ordermomentmatchingforunsuperviseddomainadaptation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " HoMM: Higher-Order Moment Matching for Unsupervised Domain Adaptation ",
    "authors": [
      "Chao Chen",
      "Zhihang Fu",
      "Zhihong Chen",
      "Sheng Jin",
      "Zhaowei Cheng",
      "Xinyu Jin",
      "Xian-sheng Hua"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5745",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5745/5601",
    "published": "2020-02",
    "summary": "Minimizing the discrepancy of feature distributions between different domains is one of the most promising directions in unsupervised domain adaptation. From the perspective of moment matching, most existing discrepancy-based methods are designed to match the second-order or lower moments, which however, have limited expression of statistical characteristic for non-Gaussian distributions. In this work, we propose a Higher-order Moment Matching (HoMM) method, and further extend the HoMM into reproducing kernel Hilbert spaces (RKHS). In particular, our proposed HoMM can perform arbitrary-order moment matching, we show that the first-order HoMM is equivalent to Maximum Mean Discrepancy (MMD) and the second-order HoMM is equivalent to Correlation Alignment (CORAL). Moreover, HoMM (order\u2265 3) is expected to perform fine-grained domain alignment as higher-order statistics can approximate more complex, non-Gaussian distributions. Besides, we also exploit the pseudo-labeled target samples to learn discriminative representations in the target domain, which further improves the transfer performance. Extensive experiments are conducted, showing that our proposed HoMM consistently outperforms the existing moment matching methods by a large margin. Codes are available at https://github.com/chenchao666/HoMM-Master"
  },
  "aaai2020_main_onlineknowledgedistillationwithdiversepeers": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Online Knowledge Distillation with Diverse Peers ",
    "authors": [
      "Defang Chen",
      "Jian-Ping Mei",
      "Can Wang",
      "Yan Feng",
      "Chun Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5746",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5746/5602",
    "published": "2020-02",
    "summary": "Distillation is an effective knowledge-transfer technique that uses predicted distributions of a powerful teacher model as soft targets to train a less-parameterized student model. A pre-trained high capacity teacher, however, is not always available. Recently proposed online variants use the aggregated intermediate predictions of multiple student models as targets to train each student model. Although group-derived targets give a good recipe for teacher-free distillation, group members are homogenized quickly with simple aggregation functions, leading to early saturated solutions. In this work, we propose Online Knowledge Distillation with Diverse peers (OKDDip), which performs two-level distillation during training with multiple auxiliary peers and one group leader. In the first-level distillation, each auxiliary peer holds an individual set of aggregation weights generated with an attention-based mechanism to derive its own targets from predictions of other auxiliary peers. Learning from distinct target distributions helps to boost peer diversity for effectiveness of group-based distillation. The second-level distillation is performed to transfer the knowledge in the ensemble of auxiliary peers further to the group leader, i.e., the model used for inference. Experimental results show that the proposed framework consistently gives better performance than state-of-the-art approaches without sacrificing training or inference complexity, demonstrating the effectiveness of the proposed two-level distillation framework."
  },
  "aaai2020_main_measuringandrelievingtheover-smoothingproblemforgraphneuralnetworksfromthetopologicalview": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Measuring and Relieving the Over-Smoothing Problem for Graph Neural Networks from the Topological View ",
    "authors": [
      "Deli Chen",
      "Yankai Lin",
      "Wei Li",
      "Peng Li",
      "Jie Zhou",
      "Xu Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5747",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5747/5603",
    "published": "2020-02",
    "summary": "Graph Neural Networks (GNNs) have achieved promising performance on a wide range of graph-based tasks. Despite their success, one severe limitation of GNNs is the over-smoothing issue (indistinguishable representations of nodes in different classes). In this work, we present a systematic and quantitative study on the over-smoothing issue of GNNs. First, we introduce two quantitative metrics, MAD and MADGap, to measure the smoothness and over-smoothness of the graph nodes representations, respectively. Then, we verify that smoothing is the nature of GNNs and the critical factor leading to over-smoothness is the low information-to-noise ratio of the message received by the nodes, which is partially determined by the graph topology. Finally, we propose two methods to alleviate the over-smoothing issue from the topological view: (1) MADReg which adds a MADGap-based regularizer to the training objective; (2) AdaEdge which optimizes the graph topology based on the model predictions. Extensive experiments on 7 widely-used graph datasets with 10 typical GNN models show that the two proposed methods are effective for relieving the over-smoothing issue, thus improving the performance of various GNN models."
  },
  "aaai2020_main_ecgadvgeneratingadversarialelectrocardiogramtomisguidearrhythmiaclassificationsystem": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ECGadv: Generating Adversarial Electrocardiogram to Misguide Arrhythmia Classification System ",
    "authors": [
      "Huangxun Chen",
      "Chenyu Huang",
      "Qianyi Huang",
      "Qian Zhang",
      "Wei Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5748",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5748/5604",
    "published": "2020-02",
    "summary": "Deep neural networks (DNNs)-powered Electrocardiogram (ECG) diagnosis systems recently achieve promising progress to take over tedious examinations by cardiologists. However, their vulnerability to adversarial attacks still lack comprehensive investigation. The existing attacks in image domain could not be directly applicable due to the distinct properties of ECGs in visualization and dynamic properties. Thus, this paper takes a step to thoroughly explore adversarial attacks on the DNN-powered ECG diagnosis system. We analyze the properties of ECGs to design effective attacks schemes under two attacks models respectively. Our results demonstrate the blind spots of DNN-powered diagnosis systems under adversarial attacks, which calls attention to adequate countermeasures."
  },
  "aaai2020_main_ls-treemodelinterpretationwhenthedataarelinguistic": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " LS-Tree: Model Interpretation When the Data Are Linguistic ",
    "authors": [
      "Jianbo Chen",
      "Michael Jordan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5749",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5749/5605",
    "published": "2020-02",
    "summary": "We study the problem of interpreting trained classification models in the setting of linguistic data sets. Leveraging a parse tree, we propose to assign least-squares-based importance scores to each word of an instance by exploiting syntactic constituency structure. We establish an axiomatic characterization of these importance scores by relating them to the Banzhaf value in coalitional game theory. Based on these importance scores, we develop a principled method for detecting and quantifying interactions between words in a sentence. We demonstrate that the proposed method can aid in interpretability and diagnostics for several widely-used language models."
  },
  "aaai2020_main_generativeadversarialnetworksforvideo-to-videodomainadaptation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generative Adversarial Networks for Video-to-Video Domain Adaptation ",
    "authors": [
      "Jiawei Chen",
      "Yuexiang Li",
      "Kai Ma",
      "Yefeng Zheng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5750",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5750/5606",
    "published": "2020-02",
    "summary": "Endoscopic videos from multicentres often have different imaging conditions, e.g., color and illumination, which make the models trained on one domain usually fail to generalize well to another. Domain adaptation is one of the potential solutions to address the problem. However, few of existing works focused on the translation of video-based data. In this work, we propose a novel generative adversarial network (GAN), namely VideoGAN, to transfer the video-based data across different domains. As the frames of a video may have similar content and imaging conditions, the proposed VideoGAN has an X-shape generator to preserve the intra-video consistency during translation. Furthermore, a loss function, namely color histogram loss, is proposed to tune the color distribution of each translated frame. Two colonoscopic datasets from different centres, i.e., CVC-Clinic and ETIS-Larib, are adopted to evaluate the performance of domain adaptation of our VideoGAN. Experimental results demonstrate that the adapted colonoscopic video generated by our VideoGAN can significantly boost the segmentation accuracy, i.e., an improvement of 5%, of colorectal polyps on multicentre datasets. As our VideoGAN is a general network architecture, we also evaluate its performance with the CamVid driving video dataset on the cloudy-to-sunny translation task. Comprehensive experiments show that the domain gap could be substantially narrowed down by our VideoGAN."
  },
  "aaai2020_main_fastadaptivelyweightedmatrixfactorizationforrecommendationwithimplicitfeedback": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fast Adaptively Weighted Matrix Factorization for Recommendation with Implicit Feedback ",
    "authors": [
      "Jiawei Chen",
      "Can Wang",
      "Sheng Zhou",
      "Qihao Shi",
      "Jingbang Chen",
      "Yan Feng",
      "Chun Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5751",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5751/5607",
    "published": "2020-02",
    "summary": "Recommendation from implicit feedback is a highly challenging task due to the lack of the reliable observed negative data. A popular and effective approach for implicit recommendation is to treat unobserved data as negative but downweight their confidence. Naturally, how to assign confidence weights and how to handle the large number of the unobserved data are two key problems for implicit recommendation models. However, existing methods either pursuit fast learning by manually assigning simple confidence weights, which lacks flexibility and may create empirical bias in evaluating user's preference; or adaptively infer personalized confidence weights but suffer from low efficiency."
  },
  "aaai2020_main_variationalmetricscalingformetric-basedmeta-learning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Variational Metric Scaling for Metric-Based Meta-Learning ",
    "authors": [
      "Jiaxin Chen",
      "Li-ming Zhan",
      "Xiao-Ming Wu",
      "Fu-lai Chung"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5752",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5752/5608",
    "published": "2020-02",
    "summary": "Metric-based meta-learning has attracted a lot of attention due to its effectiveness and efficiency in few-shot learning. Recent studies show that metric scaling plays a crucial role in the performance of metric-based meta-learning algorithms. However, there still lacks a principled method for learning the metric scaling parameter automatically. In this paper, we recast metric-based meta-learning from a Bayesian perspective and develop a variational metric scaling framework for learning a proper metric scaling parameter. Firstly, we propose a stochastic variational method to learn a single global scaling parameter. To better fit the embedding space to a given data distribution, we extend our method to learn a dimensional scaling vector to transform the embedding space. Furthermore, to learn task-specific embeddings, we generate task-dependent dimensional scaling vectors with amortized variational inference. Our method is end-to-end without any pre-training and can be used as a simple plug-and-play module for existing metric-based meta-algorithms. Experiments on miniImageNet show that our methods can be used to consistently improve the performance of existing metric-based meta-algorithms including prototypical networks and TADAM."
  },
  "aaai2020_main_afrank-wolfeframeworkforefficientandeffectiveadversarialattacks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks ",
    "authors": [
      "Jinghui Chen",
      "Dongruo Zhou",
      "Jinfeng Yi",
      "Quanquan Gu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5753",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5753/5609",
    "published": "2020-02",
    "summary": "Depending on how much information an adversary can access to, adversarial attacks can be classified as white-box attack and black-box attack. For white-box attack, optimization-based attack algorithms such as projected gradient descent (PGD) can achieve relatively high attack success rates within moderate iterates. However, they tend to generate adversarial examples near or upon the boundary of the perturbation set, resulting in large distortion. Furthermore, their corresponding black-box attack algorithms also suffer from high query complexities, thereby limiting their practical usefulness. In this paper, we focus on the problem of developing efficient and effective optimization-based adversarial attack algorithms. In particular, we propose a novel adversarial attack framework for both white-box and black-box settings based on a variant of Frank-Wolfe algorithm. We show in theory that the proposed attack algorithms are efficient with an O(1/\u221aT) convergence rate. The empirical results of attacking the ImageNet and MNIST datasets also verify the efficiency and effectiveness of the proposed algorithms. More specifically, our proposed algorithms attain the best attack performances in both white-box and black-box attacks among all baselines, and are more time and query efficient than the state-of-the-art."
  },
  "aaai2020_main_weaklysuperviseddisentanglementbypairwisesimilarities": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Weakly Supervised Disentanglement by Pairwise Similarities ",
    "authors": [
      "Junxiang Chen",
      "Kayhan Batmanghelich"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5754",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5754/5610",
    "published": "2020-02",
    "summary": "Recently, researches related to unsupervised disentanglement learning with deep generative models have gained substantial popularity. However, without introducing supervision, there is no guarantee that the factors of interest can be successfully recovered (Locatello et al. 2018). Motivated by a real-world problem, we propose a setting where the user introduces weak supervision by providing similarities between instances based on a factor to be disentangled. The similarity is provided as either a binary (yes/no) or real-valued label describing whether a pair of instances are similar or not. We propose a new method for weakly supervised disentanglement of latent variables within the framework of Variational Autoencoder. Experimental results demonstrate that utilizing weak supervision improves the performance of the disentanglement method substantially."
  },
  "aaai2020_main_outlierdetectionensemblewithembeddedfeatureselection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Outlier Detection Ensemble with Embedded Feature Selection ",
    "authors": [
      "Li Cheng",
      "Yijie Wang",
      "Xinwang Liu",
      "Bin Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5755",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5755/5611",
    "published": "2020-02",
    "summary": "Feature selection places an important role in improving the performance of outlier detection, especially for noisy data. Existing methods usually perform feature selection and outlier scoring separately, which would select feature subsets that may not optimally serve for outlier detection, leading to unsatisfying performance. In this paper, we propose an outlier detection ensemble framework with embedded feature selection (ODEFS), to address this issue. Specifically, for each random sub-sampling based learning component, ODEFS unifies feature selection and outlier detection into a pairwise ranking formulation to learn feature subsets that are tailored for the outlier detection method. Moreover, we adopt the thresholded self-paced learning to simultaneously optimize feature selection and example selection, which is helpful to improve the reliability of the training set. After that, we design an alternate algorithm with proved convergence to solve the resultant optimization problem. In addition, we analyze the generalization error bound of the proposed framework, which provides theoretical guarantee on the method and insightful practical guidance. Comprehensive experimental results on 12 real-world datasets from diverse domains validate the superiority of the proposed ODEFS."
  },
  "aaai2020_main_multi-viewclusteringinlatentembeddingspace": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-View Clustering in Latent Embedding Space ",
    "authors": [
      "Man-Sheng Chen",
      "Ling Huang",
      "Chang-Dong Wang",
      "Dong Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5756",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5756/5612",
    "published": "2020-02",
    "summary": "Previous multi-view clustering algorithms mostly partition the multi-view data in their original feature space, the efficacy of which heavily and implicitly relies on the quality of the original feature presentation. In light of this, this paper proposes a novel approach termed Multi-view Clustering in Latent Embedding Space (MCLES), which is able to cluster the multi-view data in a learned latent embedding space while simultaneously learning the global structure and the cluster indicator matrix in a unified optimization framework. Specifically, in our framework, a latent embedding representation is firstly discovered which can effectively exploit the complementary information from different views. The global structure learning is then performed based on the learned latent embedding representation. Further, the cluster indicator matrix can be acquired directly with the learned global structure. An alternating optimization scheme is introduced to solve the optimization problem. Extensive experiments conducted on several real-world multi-view datasets have demonstrated the superiority of our approach."
  },
  "aaai2020_main_adversarial-learnedlossfordomainadaptation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adversarial-Learned Loss for Domain Adaptation ",
    "authors": [
      "Minghao Chen",
      "Shuai Zhao",
      "Haifeng Liu",
      "Deng Cai"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5757",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5757/5613",
    "published": "2020-02",
    "summary": "Recently, remarkable progress has been made in learning transferable representation across domains. Previous works in domain adaptation are majorly based on two techniques: domain-adversarial learning and self-training. However, domain-adversarial learning only aligns feature distributions between domains but does not consider whether the target features are discriminative. On the other hand, self-training utilizes the model predictions to enhance the discrimination of target features, but it is unable to explicitly align domain distributions. In order to combine the strengths of these two methods, we propose a novel method called Adversarial-Learned Loss for Domain Adaptation (ALDA). We first analyze the pseudo-label method, a typical self-training method. Nevertheless, there is a gap between pseudo-labels and the ground truth, which can cause incorrect training. Thus we introduce the confusion matrix, which is learned through an adversarial manner in ALDA, to reduce the gap and align the feature distributions. Finally, a new loss function is auto-constructed from the learned confusion matrix, which serves as the loss for unlabeled target samples. Our ALDA outperforms state-of-the-art approaches in four standard domain adaptation datasets. Our code is available at https://github.com/ZJULearning/ALDA."
  },
  "aaai2020_main_multi-rangeattentivebicomponentgraphconvolutionalnetworkfortrafficforecasting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting ",
    "authors": [
      "Weiqi Chen",
      "Ling Chen",
      "Yu Xie",
      "Wei Cao",
      "Yusong Gao",
      "Xiaojie Feng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5758",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5758/5614",
    "published": "2020-02",
    "summary": "Traffic forecasting is of great importance to transportation management and public safety, and very challenging due to the complicated spatial-temporal dependency and essential uncertainty brought about by the road network and traffic conditions. Latest studies mainly focus on modeling the spatial dependency by utilizing graph convolutional networks (GCNs) throughout a fixed weighted graph. However, edges, i.e., the correlations between pair-wise nodes, are much more complicated and interact with each other. In this paper, we propose the Multi-Range Attentive Bicomponent GCN (MRA-BGCN), a novel deep learning model for traffic forecasting. We first build the node-wise graph according to the road network distance and the edge-wise graph according to various edge interaction patterns. Then, we implement the interactions of both nodes and edges using bicomponent graph convolution. The multi-range attention mechanism is introduced to aggregate information in different neighborhood ranges and automatically learn the importance of different ranges. Extensive experiments on two real-world road network traffic datasets, METR-LA and PEMS-BAY, show that our MRA-BGCN achieves the state-of-the-art results."
  },
  "aaai2020_main_autodaldistributedactivelearningwithautomatichyperparameterselection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AutoDAL: Distributed Active Learning with Automatic Hyperparameter Selection ",
    "authors": [
      "Xu Chen",
      "Brett Wujek"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5759",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5759/5615",
    "published": "2020-02",
    "summary": "Automated machine learning (AutoML) strives to establish an appropriate machine learning model for any dataset automatically with minimal human intervention. Although extensive research has been conducted on AutoML, most of it has focused on supervised learning. Research of automated semi-supervised learning and active learning algorithms is still limited. Implementation becomes more challenging when the algorithm is designed for a distributed computing environment. With this as motivation, we propose a novel automated learning system for distributed active learning (AutoDAL) to address these challenges. First, automated graph-based semi-supervised learning is conducted by aggregating the proposed cost functions from different compute nodes in a distributed manner. Subsequently, automated active learning is addressed by jointly optimizing hyperparameters in both the classification and query selection stages leveraging the graph loss minimization and entropy regularization. Moreover, we propose an efficient distributed active learning algorithm which is scalable for big data by first partitioning the unlabeled data and replicating the labeled data to different worker nodes in the classification stage, and then aggregating the data in the controller in the query selection stage. The proposed AutoDAL algorithm is applied to multiple benchmark datasets and a real-world electrocardiogram (ECG) dataset for classification. We demonstrate that the proposed AutoDAL algorithm is capable of achieving significantly better performance compared to several state-of-the-art AutoML approaches and active learning algorithms."
  },
  "aaai2020_main_optimalattackagainstautoregressivemodelsbymanipulatingtheenvironment": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Optimal Attack against Autoregressive Models by Manipulating the Environment ",
    "authors": [
      "Yiding Chen",
      "Xiaojin Zhu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5760",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5760/5616",
    "published": "2020-02",
    "summary": "We describe an optimal adversarial attack formulation against autoregressive time series forecast using Linear Quadratic Regulator (LQR). In this threat model, the environment evolves according to a dynamical system; an autoregressive model observes the current environment state and predicts its future values; an attacker has the ability to modify the environment state in order to manipulate future autoregressive forecasts. The attacker's goal is to force autoregressive forecasts into tracking a target trajectory while minimizing its attack expenditure. In the white-box setting where the attacker knows the environment and forecast models, we present the optimal attack using LQR for linear models, and Model Predictive Control (MPC) for nonlinear models. In the black-box setting, we combine system identification and MPC. Experiments demonstrate the effectiveness of our attacks."
  },
  "aaai2020_main_multi-viewpartialmulti-labellearningwithgraph-baseddisambiguation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-View Partial Multi-Label Learning with Graph-Based Disambiguation ",
    "authors": [
      "Ze-Sen Chen",
      "Xuan Wu",
      "Qing-Guo Chen",
      "Yao Hu",
      "Min-Ling Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5761",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5761/5617",
    "published": "2020-02",
    "summary": "In multi-view multi-label learning (MVML), each training example is represented by different feature vectors and associated with multiple labels simultaneously. Nonetheless, the labeling quality of training examples is tend to be affected by annotation noises. In this paper, the problem of multi-view partial multi-label learning (MVPML) is studied, where the set of associated labels are assumed to be candidate ones and only partially valid. To solve the MVPML problem, a two-stage graph-based disambiguation approach is proposed. Firstly, the ground-truth labels of each training example are estimated by disambiguating the candidate labels with fused similarity graph. After that, the predictive model for each label is learned from embedding features generated from disambiguation-guided clustering analysis. Extensive experimental studies clearly validate the effectiveness of the proposed approach in solving the MVPML problem."
  },
  "aaai2020_main_compressedself-attentionfordeepmetriclearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Compressed Self-Attention for Deep Metric Learning ",
    "authors": [
      "Ziye Chen",
      "Mingming Gong",
      "Yanwu Xu",
      "Chaohui Wang",
      "Kun Zhang",
      "Bo Du"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5762",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5762/5618",
    "published": "2020-02",
    "summary": "In this paper, we aim to enhance self-attention (SA) mechanism for deep metric learning in visual perception, by capturing richer contextual dependencies in visual data. To this end, we propose a novel module, named compressed self-attention (CSA), which significantly reduces the computation and memory cost with a neglectable decrease in accuracy with respect to the original SA mechanism, thanks to the following two characteristics: i) it only needs to compute a small number of base attention maps for a small number of base feature vectors; and ii) the output at each spatial location can be simply obtained by an adaptive weighted average of the outputs calculated from the base attention maps. The high computational efficiency of CSA enables the application to high-resolution shallow layers in convolutional neural networks with little additional cost. In addition, CSA makes it practical to further partition the feature maps into groups along the channel dimension and compute attention maps for features in each group separately, thus increasing the diversity of long-range dependencies and accordingly boosting the accuracy. We evaluate the performance of CSA via extensive experiments on two metric learning tasks: person re-identification and local descriptor learning. Qualitative and quantitative comparisons with latest methods demonstrate the significance of CSA in this topic."
  },
  "aaai2020_main_semi-supervisedlearningunderclassdistributionmismatch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Semi-Supervised Learning under Class Distribution Mismatch ",
    "authors": [
      "Yanbei Chen",
      "Xiatian Zhu",
      "Wei Li",
      "Shaogang Gong"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5763",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5763/5619",
    "published": "2020-02",
    "summary": "Semi-supervised learning (SSL) aims to avoid the need for collecting prohibitively expensive labelled training data. Whilst demonstrating impressive performance boost, existing SSL methods artificially assume that small labelled data and large unlabelled data are drawn from the same class distribution. In a more realistic scenario with class distribution mismatch between the two sets, they often suffer severe performance degradation due to error propagation introduced by irrelevant unlabelled samples. Our work addresses this under-studied and realistic SSL problem by a novel algorithm named Uncertainty-Aware Self-Distillation (UASD). Specifically, UASD produces soft targets that avoid catastrophic error propagation, and empower learning effectively from unconstrained unlabelled data with out-of-distribution (OOD) samples. This is based on joint Self-Distillation and OOD filtering in a unified formulation. Without bells and whistles, UASD significantly outperforms six state-of-the-art methods in more realistic SSL under class distribution mismatch on three popular image classification datasets: CIFAR10, CIFAR100, and TinyImageNet."
  },
  "aaai2020_main_instanasinstance-awareneuralarchitecturesearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " InstaNAS: Instance-Aware Neural Architecture Search ",
    "authors": [
      "An-Chieh Cheng",
      "Chieh Hubert Lin",
      "Da-Cheng Juan",
      "Wei Wei",
      "Min Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5764",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5764/5620",
    "published": "2020-02",
    "summary": "Conventional Neural Architecture Search (NAS) aims at finding a single architecture that achieves the best performance, which usually optimizes task related learning objectives such as accuracy. However, a single architecture may not be representative enough for the whole dataset with high diversity and variety. Intuitively, electing domain-expert architectures that are proficient in domain-specific features can further benefit architecture related objectives such as latency. In this paper, we propose InstaNAS\u2014an instance-aware NAS framework\u2014that employs a controller trained to search for a \u201cdistribution of architectures\u201d instead of a single architecture; This allows the model to use sophisticated architectures for the difficult samples, which usually comes with large architecture related cost, and shallow architectures for those easy samples. During the inference phase, the controller assigns each of the unseen input samples with a domain expert architecture that can achieve high accuracy with customized inference costs. Experiments within a search space inspired by MobileNetV2 show InstaNAS can achieve up to 48.8% latency reduction without compromising accuracy on a series of datasets against MobileNetV2."
  },
  "aaai2020_main_distillingportablegenerativeadversarialnetworksforimagetranslation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Distilling Portable Generative Adversarial Networks for Image Translation ",
    "authors": [
      "Hanting Chen",
      "Yunhe Wang",
      "Han Shu",
      "Changyuan Wen",
      "Chunjing Xu",
      "Boxin Shi",
      "Chao Xu",
      "Chang Xu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5765",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5765/5621",
    "published": "2020-02",
    "summary": "Despite Generative Adversarial Networks (GANs) have been widely used in various image-to-image translation tasks, they can be hardly applied on mobile devices due to their heavy computation and storage cost. Traditional network compression methods focus on visually recognition tasks, but never deal with generation tasks. Inspired by knowledge distillation, a student generator of fewer parameters is trained by inheriting the low-level and high-level information from the original heavy teacher generator. To promote the capability of student generator, we include a student discriminator to measure the distances between real images, and images generated by student and teacher generators. An adversarial learning process is therefore established to optimize student generator and student discriminator. Qualitative and quantitative analysis by conducting experiments on benchmark datasets demonstrate that the proposed method can learn portable generative models with strong performance."
  },
  "aaai2020_main_towardsbetterforecastingbyfusingnearanddistantfuturevisions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Better Forecasting by Fusing Near and Distant Future Visions ",
    "authors": [
      "Jiezhu Cheng",
      "Kaizhu Huang",
      "Zibin Zheng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5766",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5766/5622",
    "published": "2020-02",
    "summary": "Multivariate time series forecasting is an important yet challenging problem in machine learning. Most existing approaches only forecast the series value of one future moment, ignoring the interactions between predictions of future moments with different temporal distance. Such a deficiency probably prevents the model from getting enough information about the future, thus limiting the forecasting accuracy. To address this problem, we propose Multi-Level Construal Neural Network (MLCNN), a novel multi-task deep learning framework. Inspired by the Construal Level Theory of psychology, this model aims to improve the predictive performance by fusing forecasting information (i.e., future visions) of different future time. We first use the Convolution Neural Network to extract multi-level abstract representations of the raw data for near and distant future predictions. We then model the interplay between multiple predictive tasks and fuse their future visions through a modified Encoder-Decoder architecture. Finally, we combine traditional Autoregression model with the neural network to solve the scale insensitive problem. Experiments on three real-world datasets show that our method achieves statistically significant improvements compared to the most state-of-the-art baseline methods, with average 4.59% reduction on RMSE metric and average 6.87% reduction on MAE metric."
  },
  "aaai2020_main_seq2sickevaluatingtherobustnessofsequence-to-sequencemodelswithadversarialexamples": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples ",
    "authors": [
      "Minhao Cheng",
      "Jinfeng Yi",
      "Pin-Yu Chen",
      "Huan Zhang",
      "Cho-Jui Hsieh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5767",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5767/5623",
    "published": "2020-02",
    "summary": "Crafting adversarial examples has become an important technique to evaluate the robustness of deep neural networks (DNNs). However, most existing works focus on attacking the image classification problem since its input space is continuous and output space is finite. In this paper, we study the much more challenging problem of crafting adversarial examples for sequence-to-sequence (seq2seq) models, whose inputs are discrete text strings and outputs have an almost infinite number of possibilities. To address the challenges caused by the discrete input space, we propose a projected gradient method combined with group lasso and gradient regularization. To handle the almost infinite output space, we design some novel loss functions to conduct non-overlapping attack and targeted keyword attack. We apply our algorithm to machine translation and text summarization tasks, and verify the effectiveness of the proposed algorithm: by changing less than 3 words, we can make seq2seq model to produce desired outputs with high success rates. We also use an external sentiment classifier to verify the property of preserving semantic meanings for our generated adversarial examples. On the other hand, we recognize that, compared with the well-evaluated CNN-based classifiers, seq2seq models are intrinsically more robust to adversarial attacks."
  },
  "aaai2020_main_adaptivefactorizationnetworklearningadaptive-orderfeatureinteractions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adaptive Factorization Network: Learning Adaptive-Order Feature Interactions ",
    "authors": [
      "Weiyu Cheng",
      "Yanyan Shen",
      "Linpeng Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5768",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5768/5624",
    "published": "2020-02",
    "summary": "Various factorization-based methods have been proposed to leverage second-order, or higher-order cross features for boosting the performance of predictive models. They generally enumerate all the cross features under a predefined maximum order, and then identify useful feature interactions through model training, which suffer from two drawbacks. First, they have to make a trade-off between the expressiveness of higher-order cross features and the computational cost, resulting in suboptimal predictions. Second, enumerating all the cross features, including irrelevant ones, may introduce noisy feature combinations that degrade model performance. In this work, we propose the Adaptive Factorization Network (AFN), a new model that learns arbitrary-order cross features adaptively from data. The core of AFN is a logarithmic transformation layer that converts the power of each feature in a feature combination into the coefficient to be learned. The experimental results on four real datasets demonstrate the superior predictive performance of AFN against the state-of-the-arts."
  },
  "aaai2020_main_time2graphrevisitingtimeseriesmodelingwithdynamicshapelets": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets ",
    "authors": [
      "Ziqiang Cheng",
      "Yang Yang",
      "Wei Wang",
      "Wenjie Hu",
      "Yueting Zhuang",
      "Guojie Song"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5769",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5769/5625",
    "published": "2020-02",
    "summary": "Time series modeling has attracted extensive research efforts; however, achieving both reliable efficiency and interpretability from a unified model still remains a challenging problem. Among the literature, shapelets offer interpretable and explanatory insights in the classification tasks, while most existing works ignore the differing representative power at different time slices, as well as (more importantly) the evolution pattern of shapelets. In this paper, we propose to extract time-aware shapelets by designing a two-level timing factor. Moreover, we define and construct the shapelet evolution graph, which captures how shapelets evolve over time and can be incorporated into the time series embeddings by graph embedding algorithms. To validate whether the representations obtained in this way can be applied effectively in various scenarios, we conduct experiments based on three public time series datasets, and two real-world datasets from different domains. Experimental results clearly show the improvements achieved by our approach compared with 16 state-of-the-art baselines."
  },
  "aaai2020_main_suspicion-freeadversarialattacksonclusteringalgorithms": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Suspicion-Free Adversarial Attacks on Clustering Algorithms ",
    "authors": [
      "Anshuman Chhabra",
      "Abhishek Roy",
      "Prasant Mohapatra"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5770",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5770/5626",
    "published": "2020-02",
    "summary": "Clustering algorithms are used in a large number of applications and play an important role in modern machine learning\u2013 yet, adversarial attacks on clustering algorithms seem to be broadly overlooked unlike supervised learning. In this paper, we seek to bridge this gap by proposing a black-box adversarial attack for clustering models for linearly separable clusters. Our attack works by perturbing a single sample close to the decision boundary, which leads to the misclustering of multiple unperturbed samples, named spill-over adversarial samples. We theoretically show the existence of such adversarial samples for the K-Means clustering. Our attack is especially strong as (1) we ensure the perturbed sample is not an outlier, hence not detectable, and (2) the exact metric used for clustering is not known to the attacker. We theoretically justify that the attack can indeed be successful without the knowledge of the true metric. We conclude by providing empirical results on a number of datasets, and clustering algorithms. To the best of our knowledge, this is the first work that generates spill-over adversarial samples without the knowledge of the true metric ensuring that the perturbed sample is not an outlier, and theoretically proves the above."
  },
  "aaai2020_main_ageneralapproachtofairnesswithoptimaltransport": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A General Approach to Fairness with Optimal Transport ",
    "authors": [
      "Chiappa Silvia",
      "Jiang Ray",
      "Stepleton Tom",
      "Pacchiano Aldo",
      "Jiang Heinrich",
      "Aslanides John"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5771",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5771/5627",
    "published": "2020-02",
    "summary": "We propose a general approach to fairness based on transporting distributions corresponding to different sensitive attributes to a common distribution. We use optimal transport theory to derive target distributions and methods that allow us to achieve fairness with minimal changes to the unfair model. Our approach is applicable to both classification and regression problems, can enforce different notions of fairness, and enable us to achieve a Pareto-optimal trade-off between accuracy and fairness. We demonstrate that it outperforms previous approaches in several benchmark fairness datasets."
  },
  "aaai2020_main_activelearninginthegeometricblockmodel": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Active Learning in the Geometric Block Model ",
    "authors": [
      "Eli Chien",
      "Antonia Tulino",
      "Jaime Llorca"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5772",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5772/5628",
    "published": "2020-02",
    "summary": "The geometric block model is a recently proposed generative model for random graphs that is able to capture the inherent geometric properties of many community detection problems, providing more accurate characterizations of practical community structures compared with the popular stochastic block model. Galhotra et al. recently proposed a motif-counting algorithm for unsupervised community detection in the geometric block model that is proved to be near-optimal. They also characterized the regimes of the model parameters for which the proposed algorithm can achieve exact recovery. In this work, we initiate the study of active learning in the geometric block model. That is, we are interested in the problem of exactly recovering the community structure of random graphs following the geometric block model under arbitrary model parameters, by possibly querying the labels of a limited number of chosen nodes. We propose two active learning algorithms that combine the use of motif-counting with two different label query policies. Our main contribution is to show that sampling the labels of a vanishingly small fraction of nodes (sub-linear in the total number of nodes) is sufficient to achieve exact recovery in the regimes under which the state-of-the-art unsupervised method fails. We validate the superior performance of our algorithms via numerical simulations on both real and synthetic datasets."
  },
  "aaai2020_main_deepmixedeffectmodelusinggaussianprocessesapersonalizedandreliablepredictionforhealthcare": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Mixed Effect Model Using Gaussian Processes: A Personalized and Reliable Prediction for Healthcare ",
    "authors": [
      "Ingyo Chung",
      "Saehoon Kim",
      "Juho Lee",
      "Kwang Joon Kim",
      "Sung Ju Hwang",
      "Eunho Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5773",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5773/5629",
    "published": "2020-02",
    "summary": "We present a personalized and reliable prediction model for healthcare, which can provide individually tailored medical services such as diagnosis, disease treatment, and prevention. Our proposed framework targets at making personalized and reliable predictions from time-series data, such as Electronic Health Records (EHR), by modeling two complementary components: i) a shared component that captures global trend across diverse patients and ii) a patient-specific component that models idiosyncratic variability for each patient. To this end, we propose a composite model of a deep neural network to learn complex global trends from the large number of patients, and Gaussian Processes (GP) to probabilistically model individual time-series given relatively small number of visits per patient. We evaluate our model on diverse and heterogeneous tasks from EHR datasets and show practical advantages over standard time-series deep models such as pure Recurrent Neural Network (RNN)."
  },
  "aaai2020_main_aconstraint-basedapproachtolearningandexplanation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Constraint-Based Approach to Learning and Explanation ",
    "authors": [
      "Gabriele Ciravegna",
      "Francesco Giannini",
      "Stefano Melacci",
      "Marco Maggini",
      "Marco Gori"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5774",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5774/5630",
    "published": "2020-02",
    "summary": "In the last few years we have seen a remarkable progress from the cultivation of the idea of expressing domain knowledge by the mathematical notion of constraint. However, the progress has mostly involved the process of providing consistent solutions with a given set of constraints, whereas learning \u201cnew\u201d constraints, that express new knowledge, is still an open challenge. In this paper we propose a novel approach to learning of constraints which is based on information theoretic principles. The basic idea consists in maximizing the transfer of information between task functions and a set of learnable constraints, implemented using neural networks subject to L1 regularization. This process leads to the unsupervised development of new constraints that are fulfilled in different sub-portions of the input domain. In addition, we define a simple procedure that can explain the behaviour of the newly devised constraints in terms of First-Order Logic formulas, thus extracting novel knowledge on the relationships between the original tasks. An experimental evaluation is provided to support the proposed approach, in which we also explore the regularization effects introduced by the proposed Information-Based Learning of Constraint (IBLC) algorithm."
  },
  "aaai2020_main_representingclosedtransformationpathsinencodednetworklatentspace": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Representing Closed Transformation Paths in Encoded Network Latent Space ",
    "authors": [
      "Marissa Connor",
      "Christopher Rozell"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5775",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5775/5631",
    "published": "2020-02",
    "summary": "Deep generative networks have been widely used for learning mappings from a low-dimensional latent space to a high-dimensional data space. In many cases, data transformations are defined by linear paths in this latent space. However, the Euclidean structure of the latent space may be a poor match for the underlying latent structure in the data. In this work, we incorporate a generative manifold model into the latent space of an autoencoder in order to learn the low-dimensional manifold structure from the data and adapt the latent space to accommodate this structure. In particular, we focus on applications in which the data has closed transformation paths which extend from a starting point and return to nearly the same point. Through experiments on data with natural closed transformation paths, we show that this model introduces the ability to learn the latent dynamics of complex systems, generate transformation paths, and classify samples that belong on the same transformation path."
  },
  "aaai2020_main_forgettingtolearnlogicprograms": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Forgetting to Learn Logic Programs ",
    "authors": [
      "Andrew Cropper"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5776",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5776/5632",
    "published": "2020-02",
    "summary": "Most program induction approaches require predefined, often hand-engineered, background knowledge (BK). To overcome this limitation, we explore methods to automatically acquire BK through multi-task learning. In this approach, a learner adds learned programs to its BK so that they can be reused to help learn other programs. To improve learning performance, we explore the idea of forgetting, where a learner can additionally remove programs from its BK. We consider forgetting in an inductive logic programming (ILP) setting. We show that forgetting can significantly reduce both the size of the hypothesis space and the sample complexity of an ILP learner. We introduce Forgetgol, a multi-task ILP learner which supports forgetting. We experimentally compare Forgetgol against approaches that either remember or forget everything. Our experimental results show that Forgetgol outperforms the alternative approaches when learning from over 10,000 tasks."
  },
  "aaai2020_main_exploitingspatialinvarianceforscalableunsupervisedobjecttracking": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Exploiting Spatial Invariance for Scalable Unsupervised Object Tracking ",
    "authors": [
      "Eric Crawford",
      "Joelle Pineau"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5777",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5777/5633",
    "published": "2020-02",
    "summary": "The ability to detect and track objects in the visual world is a crucial skill for any intelligent agent, as it is a necessary precursor to any object-level reasoning process. Moreover, it is important that agents learn to track objects without supervision (i.e. without access to annotated training videos) since this will allow agents to begin operating in new environments with minimal human assistance. The task of learning to discover and track objects in videos, which we call unsupervised object tracking, has grown in prominence in recent years; however, most architectures that address it still struggle to deal with large scenes containing many objects. In the current work, we propose an architecture that scales well to the large-scene, many-object setting by employing spatially invariant computations (convolutions and spatial attention) and representations (a spatially local object specification scheme). In a series of experiments, we demonstrate a number of attractive features of our architecture; most notably, that it outperforms competing methods at tracking objects in cluttered scenes with many objects, and that it can generalize well to videos that are larger and/or contain more objects than videos encountered during training."
  },
  "aaai2020_main_labelerrorcorrectionandgenerationthroughlabelrelationships": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Label Error Correction and Generation through Label Relationships ",
    "authors": [
      "Zijun Cui",
      "Yong Zhang",
      "Qiang Ji"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5778",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5778/5634",
    "published": "2020-02",
    "summary": "For multi-label supervised learning, the quality of the label annotation is important. However, for many real world multi-label classification applications, label annotations often lack quality, in particular when label annotation requires special expertise, such as annotating fine-grained labels. The relationships among labels, on other hand, are usually stable and robust to errors. For this reason, we propose to capture and leverage label relationships at different levels to improve fine-grained label annotation quality and to generate labels. Two levels of labels, including object-level labels and property-level labels, are considered. The object-level labels characterize object category based on its overall appearance, while the property-level labels describe specific local object properties. A Bayesian network (BN) is learned to capture the relationships among the multiple labels at the two levels. A MAP inference is then performed to identify the most stable and consistent label relationships and they are then used to improve data annotations for the same dataset and to generate labels for a new dataset. Experimental evaluations on six benchmark databases for two different tasks (facial action unit and object attribute classification) demonstrate the effectiveness of the proposed method in improving data annotation and in generating effective new labels."
  },
  "aaai2020_main_ataleoftwo-timescalereinforcementlearningwiththetightestfinite-timebound": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Tale of Two-Timescale Reinforcement Learning with the Tightest Finite-Time Bound ",
    "authors": [
      "Gal Dalal",
      "Balazs Szorenyi",
      "Gugan Thoppe"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5779",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5779/5635",
    "published": "2020-02",
    "summary": "Policy evaluation in reinforcement learning is often conducted using two-timescale stochastic approximation, which results in various gradient temporal difference methods such as GTD(0), GTD2, and TDC. Here, we provide convergence rate bounds for this suite of algorithms. Algorithms such as these have two iterates, \u03b8n and wn, which are updated using two distinct stepsize sequences, \u03b1n and \u03b2n, respectively. Assuming \u03b1n = n\u03b1\u2212 and \u03b2n = n\u03b2\u2212 with 1 > \u03b1 > \u03b2 > 0, we show that, with high probability, the two iterates converge to their respective solutions \u03b8* and w* at rates given by \u2225\u03b8n - \u03b8*\u2225 = \u00d5(n/2\u03b1\u2212) and \u2225wn - w*\u2225 = \u00d5(n/2\u03b2\u2212); here, \u00d5 hides logarithmic terms. Via comparable lower bounds, we show that these bounds are, in fact, tight. To the best of our knowledge, ours is the first finite-time analysis which achieves these rates. While it was known that the two timescale components decouple asymptotically, our results depict this phenomenon more explicitly by showing that it in fact happens from some finite time onwards. Lastly, compared to existing works, our result applies to a broader family of stepsizes, including non-square summable ones."
  },
  "aaai2020_main_explainabledatadecompositions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Explainable Data Decompositions ",
    "authors": [
      "Sebastian Dalleiger",
      "Jilles Vreeken"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5780",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5780/5636",
    "published": "2020-02",
    "summary": "Our goal is to discover the components of a dataset, characterize why we deem these components, explain how these components are different from each other, as well as identify what properties they share among each other. As is usual, we consider regions in the data to be components if they show significantly different distributions. What is not usual, however, is that we parameterize these distributions with patterns that are informative for one or more components. We do so because these patterns allow us to characterize what is going on in our data as well as explain our decomposition."
  },
  "aaai2020_main_askip-connectedevolvingrecurrentneuralnetworkfordatastreamclassificationunderlabellatencyscenario": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Skip-Connected Evolving Recurrent Neural Network for Data Stream Classification under Label Latency Scenario ",
    "authors": [
      "Monidipa Das",
      "Mahardhika Pratama",
      "Jie Zhang",
      "Yew Soon Ong"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5781",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5781/5637",
    "published": "2020-02",
    "summary": "Stream classification models for non-stationary environments often assume the immediate availability of data labels. However, in a practical scenario, it is quite natural that the data labels are available only after some temporal lag. This paper explores how a stream classifier model can be made adaptive to such label latency scenario. We propose SkipE-RNN, a self-evolutionary recurrent neural network with dynamically evolving skipped-recurrent-connection for the best utilization of previously observed label information while classifying the current data. When the data label is unavailable, SkipE-RNN uses an auto-learned mapping function to find the best match from the already known data labels and updates the network parameter accordingly. Later, upon availability of true data label, if the previously mapped label is found to be incorrect, SkipE-RNN employs a regularization technique along with the parameter updating process, so as to penalize the model. In addition, SkipE-RNN has inborn power of self-adjusting the network capacity by growing/pruning hidden nodes to cope with the evolving nature of data stream. Rigorous empirical evaluations using synthetic as well as real-world datasets reveal effectiveness of SkipE-RNN in both finitely delayed and infinitely delayed data label scenarios."
  },
  "aaai2020_main_dnnsaslayersofcooperatingclassifiers": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DNNs as Layers of Cooperating Classifiers ",
    "authors": [
      "Marelie Davel",
      "Marthinus Theunissen",
      "Arnold Pretorius",
      "Etienne Barnard"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5782",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5782/5638",
    "published": "2020-02",
    "summary": "A robust theoretical framework that can describe and predict the generalization ability of DNNs in general circumstances remains elusive. Classical attempts have produced complexity metrics that rely heavily on global measures of compactness and capacity with little investigation into the effects of sub-component collaboration. We demonstrate intriguing regularities in the activation patterns of the hidden nodes within fully-connected feedforward networks. By tracing the origin of these patterns, we show how such networks can be viewed as the combination of two information processing systems: one continuous and one discrete. We describe how these two systems arise naturally from the gradient-based optimization process, and demonstrate the classification ability of the two systems, individually and in collaboration. This perspective on DNN classification offers a novel way to think about generalization, in which different subsets of the training data are used to train distinct classifiers; those classifiers are then combined to perform the classification task, and their consistency is crucial for accurate classification."
  },
  "aaai2020_main_makingexistingclusteringsfaireralgorithms,complexityresultsandinsights": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Making Existing Clusterings Fairer: Algorithms, Complexity Results and Insights ",
    "authors": [
      "Ian Davidson",
      "S.S Ravi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5783",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5783/5639",
    "published": "2020-02",
    "summary": "We explore the area of fairness in clustering from the different perspective of modifying clusterings from existing algorithms to make them fairer whilst retaining their quality. We formulate the minimal cluster modification for fairness (MCMF) problem where the input is a given partitional clustering and the goal is to minimally change it so that the clustering is still of good quality and fairer. We show using an intricate case analysis that for a single protected variable, the problem is efficiently solvable (i.e., in the class P) by proving that the constraint matrix for an integer linear programming (ILP) formulation is totally unimodular (TU). Interestingly, we show that even for a single protected variable, the addition of simple pairwise guidance (to say ensure individual level fairness) makes the MCMF problem computationally intractable (i.e., NP-hard). Experimental results on Twitter, Census and NYT data sets show that our methods can modify existing clusterings for data sets in excess of 100,000 instances within minutes on laptops and find as fair but higher quality clusterings than fair by design clustering algorithms."
  },
  "aaai2020_main_fixed-horizontemporaldifferencemethodsforstablereinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fixed-Horizon Temporal Difference Methods for Stable Reinforcement Learning ",
    "authors": [
      "Kristopher De Asis",
      "Alan Chan",
      "Silviu Pitis",
      "Richard Sutton",
      "Daniel Graves"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5784",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5784/5640",
    "published": "2020-02",
    "summary": "We explore fixed-horizon temporal difference (TD) methods, reinforcement learning algorithms for a new kind of value function that predicts the sum of rewards over a fixed number of future time steps. To learn the value function for horizon h, these algorithms bootstrap from the value function for horizon h\u22121, or some shorter horizon. Because no value function bootstraps from itself, fixed-horizon methods are immune to the stability problems that plague other off-policy TD methods using function approximation (also known as \u201cthe deadly triad\u201d). Although fixed-horizon methods require the storage of additional value functions, this gives the agent additional predictive power, while the added complexity can be substantially reduced via parallel updates, shared weights, and n-step bootstrapping. We show how to use fixed-horizon value functions to solve reinforcement learning problems competitively with methods such as Q-learning that learn conventional value functions. We also prove convergence of fixed-horizon temporal difference methods with linear and general function approximation. Taken together, our results establish fixed-horizon TD methods as a viable new way of avoiding the stability problems of the deadly triad."
  },
  "aaai2020_main_capsuleroutingviavariationalbayes": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Capsule Routing via Variational Bayes ",
    "authors": [
      "Fabio De Sousa Ribeiro",
      "Georgios Leontidis",
      "Stefanos Kollias"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5785",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5785/5641",
    "published": "2020-02",
    "summary": "Capsule networks are a recently proposed type of neural network shown to outperform alternatives in challenging shape recognition tasks. In capsule networks, scalar neurons are replaced with capsule vectors or matrices, whose entries represent different properties of objects. The relationships between objects and their parts are learned via trainable viewpoint-invariant transformation matrices, and the presence of a given object is decided by the level of agreement among votes from its parts. This interaction occurs between capsule layers and is a process called routing-by-agreement. In this paper, we propose a new capsule routing algorithm derived from Variational Bayes for fitting a mixture of transforming gaussians, and show it is possible transform our capsule network into a Capsule-VAE. Our Bayesian approach addresses some of the inherent weaknesses of MLE based models such as the variance-collapse by modelling uncertainty over capsule pose parameters. We outperform the state-of-the-art on smallNORB using \u224350% fewer capsules than previously reported, achieve competitive performances on CIFAR-10, Fashion-MNIST, SVHN, and demonstrate significant improvement in MNIST to affNIST generalisation over previous works.1"
  },
  "aaai2020_main_systemidentificationwithtime-awareneuralsequencemodels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " System Identification with Time-Aware Neural Sequence Models ",
    "authors": [
      "Thomas Demeester"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5786",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5786/5642",
    "published": "2020-02",
    "summary": "Established recurrent neural networks are well-suited to solve a wide variety of prediction tasks involving discrete sequences. However, they do not perform as well in the task of dynamical system identification, when dealing with observations from continuous variables that are unevenly sampled in time, for example due to missing observations. We show how such neural sequence models can be adapted to deal with variable step sizes in a natural way. In particular, we introduce a \u2018time-aware\u2019 and stationary extension of existing models (including the Gated Recurrent Unit) that allows them to deal with unevenly sampled system observations by adapting to the observation times, while facilitating higher-order temporal behavior. We discuss the properties and demonstrate the validity of the proposed approach, based on samples from two industrial input/output processes."
  },
  "aaai2020_main_reinforcingneuralnetworkstabilitywithattractordynamics": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reinforcing Neural Network Stability with Attractor Dynamics ",
    "authors": [
      "Hanming Deng",
      "Yang Hua",
      "Tao Song",
      "Zhengui Xue",
      "Ruhui Ma",
      "Neil Robertson",
      "Haibing Guan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5787",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5787/5643",
    "published": "2020-02",
    "summary": "Recent approaches interpret deep neural works (DNNs) as dynamical systems, drawing the connection between stability in forward propagation and generalization of DNNs. In this paper, we take a step further to be the first to reinforce this stability of DNNs without changing their original structure and verify the impact of the reinforced stability on the network representation from various aspects. More specifically, we reinforce stability by modeling attractor dynamics of a DNN and propose relu-max attractor network (RMAN), a light-weight module readily to be deployed on state-of-the-art ResNet-like networks. RMAN is only needed during training so as to modify a ResNet's attractor dynamics by minimizing an energy function together with the loss of the original learning task. Through intensive experiments, we show that RMAN-modified attractor dynamics bring a more structured representation space to ResNet and its variants, and more importantly improve the generalization ability of ResNet-like networks in supervised tasks due to reinforced stability."
  },
  "aaai2020_main_optimizingdiscretespacesviaexpensiveevaluationsalearningtosearchframework": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Optimizing Discrete Spaces via Expensive Evaluations: A Learning to Search Framework ",
    "authors": [
      "Aryan Deshwal",
      "Syrine Belakaria",
      "Janardhan Rao Doppa",
      "Alan Fern"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5788",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5788/5644",
    "published": "2020-02",
    "summary": "We consider the problem of optimizing expensive black-box functions over discrete spaces (e.g., sets, sequences, graphs). The key challenge is to select a sequence of combinatorial structures to evaluate, in order to identify high-performing structures as quickly as possible. Our main contribution is to introduce and evaluate a new learning-to-search framework for this problem called L2S-DISCO. The key insight is to employ search procedures guided by control knowledge at each step to select the next structure and to improve the control knowledge as new function evaluations are observed. We provide a concrete instantiation of L2S-DISCO for local search procedure and empirically evaluate it on diverse real-world benchmarks. Results show the efficacy of L2S-DISCO over state-of-the-art algorithms in solving complex optimization problems."
  },
  "aaai2020_main_integratingoverlappingdatasetsusingbivariatecausaldiscovery": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Integrating Overlapping Datasets Using Bivariate Causal Discovery ",
    "authors": [
      "Anish Dhir",
      "Ciaran M. Lee"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5789",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5789/5645",
    "published": "2020-02",
    "summary": "Causal knowledge is vital for effective reasoning in science, as causal relations, unlike correlations, allow one to reason about the outcomes of interventions. Algorithms that can discover causal relations from observational data are based on the assumption that all variables have been jointly measured in a single dataset. In many cases this assumption fails. Previous approaches to overcoming this shortcoming devised algorithms that returned all joint causal structures consistent with the conditional independence information contained in each individual dataset. But, as conditional independence tests only determine causal structure up to Markov equivalence, the number of consistent joint structures returned by these approaches can be quite large. The last decade has seen the development of elegant algorithms for discovering causal relations beyond conditional independence, which can distinguish among Markov equivalent structures. In this work we adapt and extend these so-called bivariate causal discovery algorithms to the problem of learning consistent causal structures from multiple datasets with overlapping variables belonging to the same generating process, providing a sound and complete algorithm that outperforms previous approaches on synthetic and real data."
  },
  "aaai2020_main_improvingtherobustnessofwassersteinembeddingbyadversarialpac-bayesianlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Improving the Robustness of Wasserstein Embedding by Adversarial PAC-Bayesian Learning ",
    "authors": [
      "Daizong Ding",
      "Mi Zhang",
      "Xudong Pan",
      "Min Yang",
      "Xiangnan He"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5790",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5790/5646",
    "published": "2020-02",
    "summary": "Node embedding is a crucial task in graph analysis. Recently, several methods are proposed to embed a node as a distribution rather than a vector to capture more information. Although these methods achieved noticeable improvements, their extra complexity brings new challenges. For example, the learned representations of nodes could be sensitive to external noises on the graph and vulnerable to adversarial behaviors. In this paper, we first derive an upper bound on generalization error for Wasserstein embedding via the PAC-Bayesian theory. Based on this, we propose an algorithm called Adversarial PAC-Bayesian Learning (APBL) in order to minimize the generalization error bound. Furthermore, we provide a model called Regularized Adversarial Wasserstein Embedding Network (RAWEN) as an implementation of APBL. Besides our comprehensive analysis of the robustness of RAWEN, our work for the first time explores more kinds of embedded distributions. For evaluations, we conduct extensive experiments to demonstrate the effectiveness and robustness of our proposed embedding model compared with the state-of-the-art methods."
  },
  "aaai2020_main_gradient-awaremodel-basedpolicysearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Gradient-Aware Model-Based Policy Search ",
    "authors": [
      "Pierluca D'Oro",
      "Alberto Maria Metelli",
      "Andrea Tirinzoni",
      "Matteo Papini",
      "Marcello Restelli"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5791",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5791/5647",
    "published": "2020-02",
    "summary": "Traditional model-based reinforcement learning approaches learn a model of the environment dynamics without explicitly considering how it will be used by the agent. In the presence of misspecified model classes, this can lead to poor estimates, as some relevant available information is ignored. In this paper, we introduce a novel model-based policy search approach that exploits the knowledge of the current agent policy to learn an approximate transition model, focusing on the portions of the environment that are most relevant for policy improvement. We leverage a weighting scheme, derived from the minimization of the error on the model-based policy gradient estimator, in order to define a suitable objective function that is optimized for learning the approximate transition model. Then, we integrate this procedure into a batch policy improvement algorithm, named Gradient-Aware Model-based Policy Search (GAMPS), which iteratively learns a transition model and uses it, together with the collected trajectories, to compute the new policy parameters. Finally, we empirically validate GAMPS on benchmark domains analyzing and discussing its properties."
  },
  "aaai2020_main_fairnessinnetworkrepresentationbylatentstructuralheterogeneityinobservationaldata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fairness in Network Representation by Latent Structural Heterogeneity in Observational Data ",
    "authors": [
      "Xin Du",
      "Yulong Pei",
      "Wouter Duivesteijn",
      "Mykola Pechenizkiy"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5792",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5792/5648",
    "published": "2020-02",
    "summary": "While recent advances in machine learning put many focuses on fairness of algorithmic decision making, topics about fairness of representation, especially fairness of network representation, are still underexplored. Network representation learning learns a function mapping nodes to low-dimensional vectors. Structural properties, e.g. communities and roles, are preserved in the latent embedding space. In this paper, we argue that latent structural heterogeneity in the observational data could bias the classical network representation model. The unknown heterogeneous distribution across subgroups raises new challenges for fairness in machine learning. Pre-defined groups with sensitive attributes cannot properly tackle the potential unfairness of network representation. We propose a method which can automatically discover subgroups which are unfairly treated by the network representation model. The fairness measure we propose can evaluate complex targets with multi-degree interactions. We conduct randomly controlled experiments on synthetic datasets and verify our methods on real-world datasets. Both quantitative and quantitative results show that our method is effective to recover the fairness of network representations. Our research draws insight on how structural heterogeneity across subgroups restricted by attributes would affect the fairness of network representation learning."
  },
  "aaai2020_main_onthediscrepancybetweenthetheoreticalanalysisandpracticalimplementationsofcompressedcommunicationfordistributeddeeplearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On the Discrepancy between the Theoretical Analysis and Practical Implementations of Compressed Communication for Distributed Deep Learning ",
    "authors": [
      "Aritra Dutta",
      "El Houcine Bergou",
      "Ahmed M. Abdelmoniem",
      "Chen-Yu Ho",
      "Atal Narayan Sahu",
      "Marco Canini",
      "Panos Kalnis"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5793",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5793/5649",
    "published": "2020-02",
    "summary": "Compressed communication, in the form of sparsification or quantization of stochastic gradients, is employed to reduce communication costs in distributed data-parallel training of deep neural networks. However, there exists a discrepancy between theory and practice: while theoretical analysis of most existing compression methods assumes compression is applied to the gradients of the entire model, many practical implementations operate individually on the gradients of each layer of the model."
  },
  "aaai2020_main_aninformation-theoreticquantificationofdiscriminationwithexemptfeatures": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Information-Theoretic Quantification of Discrimination with Exempt Features ",
    "authors": [
      "Sanghamitra Dutta",
      "Praveen Venkatesh",
      "Piotr Mardziel",
      "Anupam Datta",
      "Pulkit Grover"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5794",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5794/5650",
    "published": "2020-02",
    "summary": "The needs of a business (e.g., hiring) may require the use of certain features that are critical in a way that any discrimination arising due to them should be exempted. In this work, we propose a novel information-theoretic decomposition of the total discrimination (in a counterfactual sense) into a non-exempt component, which quantifies the part of the discrimination that cannot be accounted for by the critical features, and an exempt component, which quantifies the remaining discrimination. Our decomposition enables selective removal of the non-exempt component if desired. We arrive at this decomposition through examples and counterexamples that enable us to first obtain a set of desirable properties that any measure of non-exempt discrimination should satisfy. We then demonstrate that our proposed quantification of non-exempt discrimination satisfies all of them. This decomposition leverages a body of work from information theory called Partial Information Decomposition (PID). We also obtain an impossibility result showing that no observational measure of non-exempt discrimination can satisfy all of the desired properties, which leads us to relax our goals and examine alternative observational measures that satisfy only some of these properties. We then perform a case study using one observational measure to show how one might train a model allowing for exemption of discrimination due to critical features."
  },
  "aaai2020_main_unsupervisedmetriclearningwithsyntheticexamples": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Unsupervised Metric Learning with Synthetic Examples ",
    "authors": [
      "Ujjal Kr Dutta",
      "Mehrtash Harandi",
      "C. Chandra Sekhar"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5795",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5795/5651",
    "published": "2020-02",
    "summary": "Distance Metric Learning (DML) involves learning an embedding that brings similar examples closer while moving away dissimilar ones. Existing DML approaches make use of class labels to generate constraints for metric learning. In this paper, we address the less-studied problem of learning a metric in an unsupervised manner. We do not make use of class labels, but use unlabeled data to generate adversarial, synthetic constraints for learning a metric inducing embedding. Being a measure of uncertainty, we minimize the entropy of a conditional probability to learn the metric. Our stochastic formulation scales well to large datasets, and performs competitive to existing metric learning methods."
  },
  "aaai2020_main_polynomialmatrixcompletionformissingdataimputationandtransductivelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Polynomial Matrix Completion for Missing Data Imputation and Transductive Learning ",
    "authors": [
      "Jicong Fan",
      "Yuqian Zhang",
      "Madeleine Udell"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5796",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5796/5652",
    "published": "2020-02",
    "summary": "This paper develops new methods to recover the missing entries of a high-rank or even full-rank matrix when the intrinsic dimension of the data is low compared to the ambient dimension. Specifically, we assume that the columns of a matrix are generated by polynomials acting on a low-dimensional intrinsic variable, and wish to recover the missing entries under this assumption. We show that we can identify the complete matrix of minimum intrinsic dimension by minimizing the rank of the matrix in a high dimensional feature space. We develop a new formulation of the resulting problem using the kernel trick together with a new relaxation of the rank objective, and propose an efficient optimization method. We also show how to use our methods to complete data drawn from multiple nonlinear manifolds. Comparative studies on synthetic data, subspace clustering with missing data, motion capture data recovery, and transductive learning verify the superiority of our methods over the state-of-the-art."
  },
  "aaai2020_main_distributionallyrobustcounterfactualriskminimization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Distributionally Robust Counterfactual Risk Minimization ",
    "authors": [
      "Louis Faury",
      "Ugo Tanielian",
      "Elvis Dohmatob",
      "Elena Smirnova",
      "Flavian Vasile"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5797",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5797/5653",
    "published": "2020-02",
    "summary": "This manuscript introduces the idea of using Distributionally Robust Optimization (DRO) for the Counterfactual Risk Minimization (CRM) problem. Tapping into a rich existing literature, we show that DRO is a principled tool for counterfactual decision making. We also show that well-established solutions to the CRM problem like sample variance penalization schemes are special instances of a more general DRO problem. In this unifying framework, a variety of distributionally robust counterfactual risk estimators can be constructed using various probability distances and divergences as uncertainty measures. We propose the use of Kullback-Leibler divergence as an alternative way to model uncertainty in CRM and derive a new robust counterfactual objective. In our experiments, we show that this approach outperforms the state-of-the-art on four benchmark datasets, validating the relevance of using other uncertainty measures in practical applications."
  },
  "aaai2020_main_regularizedtrainingandtightcertificationforrandomizedsmoothedclassifierwithprovablerobustness": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Regularized Training and Tight Certification for Randomized Smoothed Classifier with Provable Robustness ",
    "authors": [
      "Huijie Feng",
      "Chunpeng Wu",
      "Guoyang Chen",
      "Weifeng Zhang",
      "Yang Ning"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5798",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5798/5654",
    "published": "2020-02",
    "summary": "Recently smoothing deep neural network based classifiers via isotropic Gaussian perturbation is shown to be an effective and scalable way to provide state-of-the-art probabilistic robustness guarantee against \u21132 norm bounded adversarial perturbations. However, how to train a good base classifier that is accurate and robust when smoothed has not been fully investigated. In this work, we derive a new regularized risk, in which the regularizer can adaptively encourage the accuracy and robustness of the smoothed counterpart when training the base classifier. It is computationally efficient and can be implemented in parallel with other empirical defense methods. We discuss how to implement it under both standard (non-adversarial) and adversarial training scheme. At the same time, we also design a new certification algorithm, which can leverage the regularization effect to provide tighter robustness lower bound that holds with high probability. Our extensive experimentation demonstrates the effectiveness of the proposed training and certification approaches on CIFAR-10 and ImageNet datasets."
  },
  "aaai2020_main_privacy-preservinggaussianprocessregression\u2013amodularapproachtotheapplicationofhomomorphicencryption": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Privacy-Preserving Gaussian Process Regression \u2013 A Modular Approach to the Application of Homomorphic Encryption ",
    "authors": [
      "Peter Fenner",
      "Edward Pyzer-Knapp"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5799",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5799/5655",
    "published": "2020-02",
    "summary": "Much of machine learning relies on the use of large amounts of data to train models to make predictions. When this data comes from multiple sources, for example when evaluation of data against a machine learning model is offered as a service, there can be privacy issues and legal concerns over the sharing of data. Fully homomorphic encryption (FHE) allows data to be computed on whilst encrypted, which can provide a solution to the problem of data privacy. However, FHE is both slow and restrictive, so existing algorithms must be manipulated to make them work efficiently under the FHE paradigm. Some commonly used machine learning algorithms, such as Gaussian process regression, are poorly suited to FHE and cannot be manipulated to work both efficiently and accurately. In this paper, we show that a modular approach, which applies FHE to only the sensitive steps of a workflow that need protection, allows one party to make predictions on their data using a Gaussian process regression model built from another party's data, without either party gaining access to the other's data, in a way which is both accurate and efficient. This construction is, to our knowledge, the first example of an effectively encrypted Gaussian process."
  },
  "aaai2020_main_learningtripleembeddingsfromknowledgegraphs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Triple Embeddings from Knowledge Graphs ",
    "authors": [
      "Valeria Fionda",
      "Giuseppe Pirr\u00f2"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5800",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5800/5656",
    "published": "2020-02",
    "summary": "Graph embedding techniques allow to learn high-quality feature vectors from graph structures and are useful in a variety of tasks, from node classification to clustering. Existing approaches have only focused on learning feature vectors for the nodes and predicates in a knowledge graph. To the best of our knowledge, none of them has tackled the problem of directly learning triple embeddings. The approaches that are closer to this task have focused on homogeneous graphs involving only one type of edge and obtain edge embeddings by applying some operation (e.g., average) on the embeddings of the endpoint nodes. The goal of this paper is to introduce Triple2Vec, a new technique to directly embed knowledge graph triples. We leverage the idea of line graph of a graph and extend it to the context of knowledge graphs. We introduce an edge weighting mechanism for the line graph based on semantic proximity. Embeddings are finally generated by adopting the SkipGram model, where sentences are replaced with graph walks. We evaluate our approach on different real-world knowledge graphs and compared it with related work. We also show an application of triple embeddings in the context of user-item recommendations."
  },
  "aaai2020_main_trainingdecisiontreesasreplacementforconvolutionlayers": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Training Decision Trees as Replacement for Convolution Layers ",
    "authors": [
      "Wolfgang Fuhl",
      "Gjergji Kasneci",
      "Wolfgang Rosenstiel",
      "Enkeljda Kasneci"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5801",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5801/5657",
    "published": "2020-02",
    "summary": "We present an alternative layer to convolution layers in convolutional neural networks (CNNs). Our approach reduces the complexity of convolutions by replacing it with binary decisions. Those binary decisions are used as indexes to conditional distributions where each weight represents a leaf in a decision tree. This means that only the indices to the weights need to be determined once, thus reducing the complexity of convolutions by the depth of the output tensor. Index computation is performed by simple binary decisions that require fewer cycles compared to conventionally used multiplications. In addition, we show how convolutions can be replaced by binary decisions. These binary decisions form indices in the conditional distributions and we show how they are used to replace 2D weight matrices as well as 3D weight tensors. These new layers can be trained like convolution layers in CNNs based on the backpropagation algorithm, for which we provide a formalization. Our results on multiple publicly available data sets show that our approach performs similar to conventional neuronal networks. Beyond the formalized reduction of complexity and the improved qualitative performance, we show the runtime improvement empirically compared to convolution layers."
  },
  "aaai2020_main_inductionofsubgoalautomataforreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Induction of Subgoal Automata for Reinforcement Learning ",
    "authors": [
      "Daniel Furelos-Blanco",
      "Mark Law",
      "Alessandra Russo",
      "Krysia Broda",
      "Anders Jonsson"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5802",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5802/5658",
    "published": "2020-02",
    "summary": "In this work we present ISA, a novel approach for learning and exploiting subgoals in reinforcement learning (RL). Our method relies on inducing an automaton whose transitions are subgoals expressed as propositional formulas over a set of observable events. A state-of-the-art inductive logic programming system is used to learn the automaton from observation traces perceived by the RL agent. The reinforcement learning and automaton learning processes are interleaved: a new refined automaton is learned whenever the RL agent generates a trace not recognized by the current automaton. We evaluate ISA in several gridworld problems and show that it performs similarly to a method for which automata are given in advance. We also show that the learned automata can be exploited to speed up convergence through reward shaping and transfer learning across multiple tasks. Finally, we analyze the running time and the number of traces that ISA needs to learn an automata, and the impact that the number of observable events have on the learner's performance."
  },
  "aaai2020_main_fastanddeepgraphneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fast and Deep Graph Neural Networks ",
    "authors": [
      "Claudio Gallicchio",
      "Alessio Micheli"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5803",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5803/5659",
    "published": "2020-02",
    "summary": "We address the efficiency issue for the construction of a deep graph neural network (GNN). The approach exploits the idea of representing each input graph as a fixed point of a dynamical system (implemented through a recurrent neural network), and leverages a deep architectural organization of the recurrent units. Efficiency is gained by many aspects, including the use of small and very sparse networks, where the weights of the recurrent units are left untrained under the stability condition introduced in this work. This can be viewed as a way to study the intrinsic power of the architecture of a deep GNN, and also to provide insights for the set-up of more complex fully-trained models. Through experimental results, we show that even without training of the recurrent connections, the architecture of small deep GNN is surprisingly able to achieve or improve the state-of-the-art performance on a significant set of tasks in the field of graphs classification."
  },
  "aaai2020_main_ontheparameterizedcomplexityofclusteringincompletedataintosubspacesofsmallrank": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On the Parameterized Complexity of Clustering Incomplete Data into Subspaces of Small Rank ",
    "authors": [
      "Robert Ganian",
      "Iyad Kanj",
      "Sebastian Ordyniak",
      "Stefan Szeider"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5804",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5804/5660",
    "published": "2020-02",
    "summary": "We consider a fundamental matrix completion problem where we are given an incomplete matrix and a set of constraints modeled as a CSP instance. The goal is to complete the matrix subject to the input constraints and in such a way that the complete matrix can be clustered into few subspaces with low rank. This problem generalizes several problems in data mining and machine learning, including the problem of completing a matrix into one with minimum rank. In addition to its ubiquitous applications in machine learning, the problem has strong connections to information theory, related to binary linear codes, and variants of it have been extensively studied from that perspective. We formalize the problem mentioned above and study its classical and parameterized complexity. We draw a detailed landscape of the complexity and parameterized complexity of the problem with respect to several natural parameters that are desirably small and with respect to several well-studied CSP fragments."
  },
  "aaai2020_main_adaptiveconvolutionalrelus": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adaptive Convolutional ReLUs ",
    "authors": [
      "Hongyang Gao",
      "Lei Cai",
      "Shuiwang Ji"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5805",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5805/5661",
    "published": "2020-02",
    "summary": "Rectified linear units (ReLUs) are currently the most popular activation function used in neural networks. Although ReLUs can solve the gradient vanishing problem and accelerate training convergence, it suffers from the dying ReLU problem in which some neurons are never activated if the weights are not updated properly. In this work, we propose a novel activation function, known as the adaptive convolutional ReLU (ConvReLU), that can better mimic brain neuron activation behaviors and overcome the dying ReLU problem. With our novel parameter sharing scheme, ConvReLUs can be applied to convolution layers that allow each input neuron to be activated by different trainable thresholds without involving a large number of extra parameters. We employ the zero initialization scheme in ConvReLU to encourage trainable thresholds to be close to zero. Finally, we develop a partial replacement strategy that only replaces the ReLUs in the early layers of the network. This resolves the dying ReLU problem and retains sparse representations for linear classifiers. Experimental results demonstrate that our proposed ConvReLU has consistently better performance compared to ReLU, LeakyReLU, and PReLU. In addition, the partial replacement strategy is shown to be effective not only for our ConvReLU but also for LeakyReLU and PReLU."
  },
  "aaai2020_main_infinitylearninglearningmarkovchainsfromaggregatesteady-stateobservations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Infinity Learning: Learning Markov Chains from Aggregate Steady-State Observations ",
    "authors": [
      "Jianfei Gao",
      "Mohamed A. Zahran",
      "Amit Sheoran",
      "Sonia Fahmy",
      "Bruno Ribeiro"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5806",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5806/5662",
    "published": "2020-02",
    "summary": "We consider the task of learning a parametric Continuous Time Markov Chain (CTMC) sequence model without examples of sequences, where the training data consists entirely of aggregate steady-state statistics. Making the problem harder, we assume that the states we wish to predict are unobserved in the training data. Specifically, given a parametric model over the transition rates of a CTMC and some known transition rates, we wish to extrapolate its steady state distribution to states that are unobserved. A technical roadblock to learn a CTMC from its steady state has been that the chain rule to compute gradients will not work over the arbitrarily long sequences necessary to reach steady state \u2014from where the aggregate statistics are sampled. To overcome this optimization challenge, we propose \u221e-SGD, a principled stochastic gradient descent method that uses randomly-stopped estimators to avoid infinite sums required by the steady state computation, while learning even when only a subset of the CTMC states can be observed. We apply \u221e-SGD to a real-world testbed and synthetic experiments showcasing its accuracy, ability to extrapolate the steady state distribution to unobserved states under unobserved conditions (heavy loads, when training under light loads), and succeeding in difficult scenarios where even a tailor-made extension of existing methods fails."
  },
  "aaai2020_main_tensor-svdbasedgraphlearningformulti-viewsubspaceclustering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Tensor-SVD Based Graph Learning for Multi-View Subspace Clustering ",
    "authors": [
      "Quanxue Gao",
      "Wei Xia",
      "Zhizhen Wan",
      "Deyan Xie",
      "Pu Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5807",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5807/5663",
    "published": "2020-02",
    "summary": "Low-rank representation based on tensor-Singular Value Decomposition (t-SVD) has achieved impressive results for multi-view subspace clustering, but it does not well deal with noise and illumination changes embedded in multi-view data. The major reason is that all the singular values have the same contribution in tensor-nuclear norm based on t-SVD, which does not make sense in the existence of noise and illumination change. To improve the robustness and clustering performance, we study the weighted tensor-nuclear norm based on t-SVD and develop an efficient algorithm to optimize the weighted tensor-nuclear norm minimization (WTNNM) problem. We further apply the WTNNM algorithm to multi-view subspace clustering by exploiting the high order correlations embedded in different views. Extensive experimental results reveal that our WTNNM method is superior to several state-of-the-art multi-view subspace clustering methods in terms of performance."
  },
  "aaai2020_main_cross-modalsubspaceclusteringviadeepcanonicalcorrelationanalysis": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Cross-Modal Subspace Clustering via Deep Canonical Correlation Analysis ",
    "authors": [
      "Quanxue Gao",
      "Huanhuan Lian",
      "Qianqian Wang",
      "Gan Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5808",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5808/5664",
    "published": "2020-02",
    "summary": "For cross-modal subspace clustering, the key point is how to exploit the correlation information between cross-modal data. However, most hierarchical and structural correlation information among cross-modal data cannot be well exploited due to its high-dimensional non-linear property. To tackle this problem, in this paper, we propose an unsupervised framework named Cross-Modal Subspace Clustering via Deep Canonical Correlation Analysis (CMSC-DCCA), which incorporates the correlation constraint with a self-expressive layer to make full use of information among the inter-modal data and the intra-modal data. More specifically, the proposed model consists of three components: 1) deep canonical correlation analysis (Deep CCA) model; 2) self-expressive layer; 3) Deep CCA decoders. The Deep CCA model consists of convolutional encoders and correlation constraint. Convolutional encoders are used to obtain the latent representations of cross-modal data, while adding the correlation constraint for the latent representations can make full use of the information of the inter-modal data. Furthermore, self-expressive layer works on latent representations and constrain it perform self-expression properties, which makes the shared coefficient matrix could capture the hierarchical intra-modal correlations of each modality. Then Deep CCA decoders reconstruct data to ensure that the encoded features can preserve the structure of the original data. Experimental results on several real-world datasets demonstrate the proposed method outperforms the state-of-the-art methods."
  },
  "aaai2020_main_amulti-channelneuralgraphicaleventmodelwithnegativeevidence": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Multi-Channel Neural Graphical Event Model with Negative Evidence ",
    "authors": [
      "Tian Gao",
      "Dharmashankar Subramanian",
      "Karthikeyan Shanmugam",
      "Debarun Bhattacharjya",
      "Nicholas Mattei"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5810",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5810/5666",
    "published": "2020-02",
    "summary": "Event datasets are sequences of events of various types occurring irregularly over the time-line, and they are increasingly prevalent in numerous domains. Existing work for modeling events using conditional intensities rely on either using some underlying parametric form to capture historical dependencies, or on non-parametric models that focus primarily on tasks such as prediction. We propose a non-parametric deep neural network approach in order to estimate the underlying intensity functions. We use a novel multi-channel RNN that optimally reinforces the negative evidence of no observable events with the introduction of fake event epochs within each consecutive inter-event interval. We evaluate our method against state-of-the-art baselines on model fitting tasks as gauged by log-likelihood. Through experiments on both synthetic and real-world datasets, we find that our proposed approach outperforms existing baselines on most of the datasets studied."
  },
  "aaai2020_main_revisitingbilinearpoolingacodingperspective": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Revisiting Bilinear Pooling: A Coding Perspective ",
    "authors": [
      "Zhi Gao",
      "Yuwei Wu",
      "Xiaoxun Zhang",
      "Jindou Dai",
      "Yunde Jia",
      "Mehrtash Harandi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5811",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5811/5667",
    "published": "2020-02",
    "summary": "Bilinear pooling has achieved state-of-the-art performance on fusing features in various machine learning tasks, owning to its ability to capture complex associations between features. Despite the success, bilinear pooling suffers from redundancy and burstiness issues, mainly due to the rank-one property of the resulting representation. In this paper, we prove that bilinear pooling is indeed a similarity-based coding-pooling formulation. This establishment then enables us to devise a new feature fusion algorithm, the factorized bilinear coding (FBC) method, to overcome the drawbacks of the bilinear pooling. We show that FBC can generate compact and discriminative representations with substantially fewer parameters. Experiments on two challenging tasks, namely image classification and visual question answering, demonstrate that our method surpasses the bilinear pooling technique by a large margin."
  },
  "aaai2020_main_improvedalgorithmsforconservativeexplorationinbandits": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Improved Algorithms for Conservative Exploration in Bandits ",
    "authors": [
      "Evrard Garcelon",
      "Mohammad Ghavamzadeh",
      "Alessandro Lazaric",
      "Matteo Pirotta"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5812",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5812/5668",
    "published": "2020-02",
    "summary": "In many fields such as digital marketing, healthcare, finance, and robotics, it is common to have a well-tested and reliable baseline policy running in production (e.g., a recommender system). Nonetheless, the baseline policy is often suboptimal. In this case, it is desirable to deploy online learning algorithms (e.g., a multi-armed bandit algorithm) that interact with the system to learn a better/optimal policy under the constraint that during the learning process the performance is almost never worse than the performance of the baseline itself. In this paper, we study the conservative learning problem in the contextual linear bandit setting and introduce a novel algorithm, the Conservative Constrained LinUCB (CLUCB2). We derive regret bounds for CLUCB2 that match existing results and empirically show that it outperforms state-of-the-art conservative bandit algorithms in a number of synthetic and real-world problems. Finally, we consider a more realistic constraint where the performance is verified only at predefined checkpoints (instead of at every step) and show how this relaxed constraint favorably impacts the regret and empirical performance of CLUCB2."
  },
  "aaai2020_main_modelingdialogueswithhashcoderepresentationsanonparametricapproach": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Modeling Dialogues with Hashcode Representations: A Nonparametric Approach ",
    "authors": [
      "Sahil Garg",
      "Irina Rish",
      "Guillermo Cecchi",
      "Palash Goyal",
      "Sarik Ghazarian",
      "Shuyang Gao",
      "Greg Ver Steeg",
      "Aram Galstyan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5813",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5813/5669",
    "published": "2020-02",
    "summary": "We propose a novel dialogue modeling framework, the first-ever nonparametric kernel functions based approach for dialogue modeling, which learns hashcodes as text representations; unlike traditional deep learning models, it handles well relatively small datasets, while also scaling to large ones. We also derive a novel lower bound on mutual information, used as a model-selection criterion favoring representations with better alignment between the utterances of participants in a collaborative dialogue setting, as well as higher predictability of the generated responses. As demonstrated on three real-life datasets, including prominently psychotherapy sessions, the proposed approach significantly outperforms several state-of-art neural network based dialogue systems, both in terms of computational efficiency, reducing training time from days or weeks to hours, and the response quality, achieving an order of magnitude improvement over competitors in frequency of being chosen as the best model by human evaluators."
  },
  "aaai2020_main_reinforcementlearningwithnon-markovianrewards": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reinforcement Learning with Non-Markovian Rewards ",
    "authors": [
      "Maor Gaon",
      "Ronen Brafman"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5814",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5814/5670",
    "published": "2020-02",
    "summary": "The standard RL world model is that of a Markov Decision Process (MDP). A basic premise of MDPs is that the rewards depend on the last state and action only. Yet, many real-world rewards are non-Markovian. For example, a reward for bringing coffee only if requested earlier and not yet served, is non-Markovian if the state only records current requests and deliveries. Past work considered the problem of modeling and solving MDPs with non-Markovian rewards (NMR), but we know of no principled approaches for RL with NMR. Here, we address the problem of policy learning from experience with such rewards. We describe and evaluate empirically four combinations of the classical RL algorithm Q-learning and R-max with automata learning algorithms to obtain new RL algorithms for domains with NMR. We also prove that some of these variants converge to an optimal policy in the limit."
  },
  "aaai2020_main_diachronicembeddingfortemporalknowledgegraphcompletion": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Diachronic Embedding for Temporal Knowledge Graph Completion ",
    "authors": [
      "Rishab Goel",
      "Seyed Mehran Kazemi",
      "Marcus Brubaker",
      "Pascal Poupart"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5815",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5815/5671",
    "published": "2020-02",
    "summary": "Knowledge graphs (KGs) typically contain temporal facts indicating relationships among entities at different times. Due to their incompleteness, several approaches have been proposed to infer new facts for a KG based on the existing ones\u2013a problem known as KG completion. KG embedding approaches have proved effective for KG completion, however, they have been developed mostly for static KGs. Developing temporal KG embedding models is an increasingly important problem. In this paper, we build novel models for temporal KG completion through equipping static models with a diachronic entity embedding function which provides the characteristics of entities at any point in time. This is in contrast to the existing temporal KG embedding approaches where only static entity features are provided. The proposed embedding function is model-agnostic and can be potentially combined with any static model. We prove that combining it with SimplE, a recent model for static KG embedding, results in a fully expressive model for temporal KG completion. Our experiments indicate the superiority of our proposal compared to existing baselines."
  },
  "aaai2020_main_adversariallyrobustdistillation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adversarially Robust Distillation ",
    "authors": [
      "Micah Goldblum",
      "Liam Fowl",
      "Soheil Feizi",
      "Tom Goldstein"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5816",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5816/5672",
    "published": "2020-02",
    "summary": "Knowledge distillation is effective for producing small, high-performance neural networks for classification, but these small networks are vulnerable to adversarial attacks. This paper studies how adversarial robustness transfers from teacher to student during knowledge distillation. We find that a large amount of robustness may be inherited by the student even when distilled on only clean images. Second, we introduce Adversarially Robust Distillation (ARD) for distilling robustness onto student networks. In addition to producing small models with high test accuracy like conventional distillation, ARD also passes the superior robustness of large networks onto the student. In our experiments, we find that ARD student models decisively outperform adversarially trained networks of identical architecture in terms of robust accuracy, surpassing state-of-the-art methods on standard robustness benchmarks. Finally, we adapt recent fast adversarial training methods to ARD for accelerated robust distillation."
  },
  "aaai2020_main_robustgradient-basedmarkovsubsampling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Robust Gradient-Based Markov Subsampling ",
    "authors": [
      "Tieliang Gong",
      "Quanhan Xi",
      "Chen Xu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5817",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5817/5673",
    "published": "2020-02",
    "summary": "Subsampling is a widely used and effective method to deal with the challenges brought by big data. Most subsampling procedures are designed based on the importance sampling framework, where samples with high importance measures are given corresponding sampling probabilities. However, in the highly noisy case, these samples may cause an unstable estimator which could lead to a misleading result. To tackle this issue, we propose a gradient-based Markov subsampling (GMS) algorithm to achieve robust estimation. The core idea is to construct a subset which allows us to conservatively correct a crude initial estimate towards the true signal. Specifically, GMS selects samples with small gradients via a probabilistic procedure, constructing a subset that is likely to exclude noisy samples and provide a safe improvement over the initial estimate. We show that the GMS estimator is statistically consistent at a rate which matches the optimal in the minimax sense. The promising performance of GMS is supported by simulation studies and real data examples."
  },
  "aaai2020_main_onlinemetriclearningformulti-labelclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Online Metric Learning for Multi-Label Classification ",
    "authors": [
      "Xiuwen Gong",
      "Dong Yuan",
      "Wei Bao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5818",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5818/5674",
    "published": "2020-02",
    "summary": "Existing research into online multi-label classification, such as online sequential multi-label extreme learning machine (OSML-ELM) and stochastic gradient descent (SGD), has achieved promising performance. However, these works lack an analysis of loss function and do not consider label dependency. Accordingly, to fill the current research gap, we propose a novel online metric learning paradigm for multi-label classification. More specifically, we first project instances and labels into a lower dimension for comparison, then leverage the large margin principle to learn a metric with an efficient optimization algorithm. Moreover, we provide theoretical analysis on the upper bound of the cumulative loss for our method. Comprehensive experiments on a number of benchmark multi-label datasets validate our theoretical approach and illustrate that our proposed online metric learning (OML) algorithm outperforms state-of-the-art methods."
  },
  "aaai2020_main_potentialpassengerflowpredictionanovelstudyforurbantransportationdevelopment": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Potential Passenger Flow Prediction: A Novel Study for Urban Transportation Development ",
    "authors": [
      "Yongshun Gong",
      "Zhibin Li",
      "Jian Zhang",
      "Wei Liu",
      "Jinfeng Yi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5819",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5819/5675",
    "published": "2020-02",
    "summary": "Recently, practical applications for passenger flow prediction have brought many benefits to urban transportation development. With the development of urbanization, a real-world demand from transportation managers is to construct a new metro station in one city area that never planned before. Authorities are interested in the picture of the future volume of commuters before constructing a new station, and estimate how would it affect other areas. In this paper, this specific problem is termed as potential passenger flow (PPF) prediction, which is a novel and important study connected with urban computing and intelligent transportation systems. For example, an accurate PPF predictor can provide invaluable knowledge to designers, such as the advice of station scales and influences on other areas, etc. To address this problem, we propose a multi-view localized correlation learning method. The core idea of our strategy is to learn the passenger flow correlations between the target areas and their localized areas with adaptive-weight. To improve the prediction accuracy, other domain knowledge is involved via a multi-view learning process. We conduct intensive experiments to evaluate the effectiveness of our method with real-world official transportation datasets. The results demonstrate that our method can achieve excellent performance compared with other available baselines. Besides, our method can provide an effective solution to the cold-start problem in the recommender system as well, which proved by its outperformed experimental results."
  },
  "aaai2020_main_alignflowcycleconsistentlearningfrommultipledomainsvianormalizingflows": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AlignFlow: Cycle Consistent Learning from Multiple Domains via Normalizing Flows ",
    "authors": [
      "Aditya Grover",
      "Christopher Chute",
      "Rui Shu",
      "Zhangjie Cao",
      "Stefano Ermon"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5820",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5820/5676",
    "published": "2020-02",
    "summary": "Given datasets from multiple domains, a key challenge is to efficiently exploit these data sources for modeling a target domain. Variants of this problem have been studied in many contexts, such as cross-domain translation and domain adaptation. We propose AlignFlow, a generative modeling framework that models each domain via a normalizing flow. The use of normalizing flows allows for a) flexibility in specifying learning objectives via adversarial training, maximum likelihood estimation, or a hybrid of the two methods; and b) learning and exact inference of a shared representation in the latent space of the generative model. We derive a uniform set of conditions under which AlignFlow is marginally-consistent for the different learning objectives. Furthermore, we show that AlignFlow guarantees exact cycle consistency in mapping datapoints from a source domain to target and back to the source domain. Empirically, AlignFlow outperforms relevant baselines on image-to-image translation and unsupervised domain adaptation and can be used to simultaneously interpolate across the various domains using the learned representation."
  },
  "aaai2020_main_robuststochasticbanditalgorithmsunderprobabilisticunboundedadversarialattack": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Robust Stochastic Bandit Algorithms under Probabilistic Unbounded Adversarial Attack ",
    "authors": [
      "Ziwei Guan",
      "Kaiyi Ji",
      "Donald J. Bucci Jr.",
      "Timothy Y. Hu",
      "Joseph Palombo",
      "Michael Liston",
      "Yingbin Liang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5821",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5821/5677",
    "published": "2020-02",
    "summary": "The multi-armed bandit formalism has been extensively studied under various attack models, in which an adversary can modify the reward revealed to the player. Previous studies focused on scenarios where the attack value either is bounded at each round or has a vanishing probability of occurrence. These models do not capture powerful adversaries that can catastrophically perturb the revealed reward. This paper investigates the attack model where an adversary attacks with a certain probability at each round, and its attack value can be arbitrary and unbounded if it attacks. Furthermore, the attack value does not necessarily follow a statistical distribution. We propose a novel sample median-based and exploration-aided UCB algorithm (called med-E-UCB) and a median-based \u03f5-greedy algorithm (called med-\u03f5-greedy). Both of these algorithms are provably robust to the aforementioned attack model. More specifically we show that both algorithms achieve O(log T) pseudo-regret (i.e., the optimal regret without attacks). We also provide a high probability guarantee of O(log T) regret with respect to random rewards and random occurrence of attacks. These bounds are achieved under arbitrary and unbounded reward perturbation as long as the attack probability does not exceed a certain constant threshold. We provide multiple synthetic simulations of the proposed algorithms to verify these claims and showcase the inability of existing techniques to achieve sublinear regret. We also provide experimental results of the algorithm operating in a cognitive radio setting using multiple software-defined radios."
  },
  "aaai2020_main_nonlinearmixupout-of-manifolddataaugmentationfortextclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Nonlinear Mixup: Out-Of-Manifold Data Augmentation for Text Classification ",
    "authors": [
      "Hongyu Guo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5822",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5822/5678",
    "published": "2020-02",
    "summary": "Data augmentation with Mixup (Zhang et al. 2018) has shown to be an effective model regularizer for current art deep classification networks. It generates out-of-manifold samples through linearly interpolating inputs and their corresponding labels of random sample pairs. Despite its great successes, Mixup requires convex combination of the inputs as well as the modeling targets of a sample pair, thus significantly limits the space of its synthetic samples and consequently its regularization effect. To cope with this limitation, we propose \u201cnonlinear Mixup\u201d. Unlike Mixup where the input and label pairs share the same, linear, scalar mixing policy, our approach embraces nonlinear interpolation policy for both the input and label pairs, where the mixing policy for the labels is adaptively learned based on the mixed input. Experiments on benchmark sentence classification datasets indicate that our approach significantly improves upon Mixup. Our empirical studies also show that the out-of-manifold samples generated by our strategy encourage training samples in each class to form a tight representation cluster that is far from others."
  },
  "aaai2020_main_iwe-netinstanceweightnetworkforlocatingnegativecommentsanditsapplicationtoimprovetrafficuserexperience": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " IWE-Net: Instance Weight Network for Locating Negative Comments and its application to improve Traffic User Experience ",
    "authors": [
      "Lan-Zhe Guo",
      "Feng Kuang",
      "Zhang-Xun Liu",
      "Yu-Feng Li",
      "Nan Ma",
      "Xiao-Hu Qie"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5823",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5823/5679",
    "published": "2020-02",
    "summary": "Weakly supervised learning aims at coping with scarce labeled data. Previous weakly supervised studies typically assume that there is only one kind of weak supervision in data. In many applications, however, raw data usually contains more than one kind of weak supervision at the same time. For example, in user experience enhancement from Didi, one of the largest online ride-sharing platforms, the ride comment data contains severe label noise (due to the subjective factors of passengers) and severe label distribution bias (due to the sampling bias). We call such a problem as \u2018compound weakly supervised learning\u2019. In this paper, we propose the CWSL method to address this problem based on Didi ride-sharing comment data. Specifically, an instance reweighting strategy is employed to cope with severe label noise in comment data, where the weights for harmful noisy instances are small. Robust criteria like AUC rather than accuracy and the validation performance are optimized for the correction of biased data label. Alternating optimization and stochastic gradient methods accelerate the optimization on large-scale data. Experiments on Didi ride-sharing comment data clearly validate the effectiveness. We hope this work may shed some light on applying weakly supervised learning to complex real situations."
  },
  "aaai2020_main_adafilteradaptivefilterfine-tuningfordeeptransferlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AdaFilter: Adaptive Filter Fine-Tuning for Deep Transfer Learning ",
    "authors": [
      "Yunhui Guo",
      "Yandong Li",
      "Liqiang Wang",
      "Tajana Rosing"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5824",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5824/5680",
    "published": "2020-02",
    "summary": "There is an increasing number of pre-trained deep neural network models. However, it is still unclear how to effectively use these models for a new task. Transfer learning, which aims to transfer knowledge from source tasks to a target task, is an effective solution to this problem. Fine-tuning is a popular transfer learning technique for deep neural networks where a few rounds of training are applied to the parameters of a pre-trained model to adapt them to a new task. Despite its popularity, in this paper we show that fine-tuning suffers from several drawbacks. We propose an adaptive fine-tuning approach, called AdaFilter, which selects only a part of the convolutional filters in the pre-trained model to optimize on a per-example basis. We use a recurrent gated network to selectively fine-tune convolutional filters based on the activations of the previous layer. We experiment with 7 public image classification datasets and the results show that AdaFilter can reduce the average classification error of the standard fine-tuning by 2.54%."
  },
  "aaai2020_main_asymptoticallyunambitiousartificialgeneralintelligence": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Asymptotically Unambitious Artificial General Intelligence ",
    "authors": [
      "Michael Cohen",
      "Badri Vellambi",
      "Marcus Hutter"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5628",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5628/5484",
    "published": "2020-02",
    "summary": "General intelligence, the ability to solve arbitrary solvable problems, is supposed by many to be artificially constructible. Narrow intelligence, the ability to solve a given particularly difficult problem, has seen impressive recent development. Notable examples include self-driving cars, Go engines, image classifiers, and translators. Artificial General Intelligence (AGI) presents dangers that narrow intelligence does not: if something smarter than us across every domain were indifferent to our concerns, it would be an existential threat to humanity, just as we threaten many species despite no ill will. Even the theory of how to maintain the alignment of an AGI's goals with our own has proven highly elusive. We present the first algorithm we are aware of for asymptotically unambitious AGI, where \u201cunambitiousness\u201d includes not seeking arbitrary power. Thus, we identify an exception to the Instrumental Convergence Thesis, which is roughly that by default, an AGI would seek power, including over us."
  },
  "aaai2020_main_hightissuecontrastmrisynthesisusingmulti-stageattention-ganforsegmentation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " High Tissue Contrast MRI Synthesis Using Multi-Stage Attention-GAN for Segmentation ",
    "authors": [
      "Mohammad Hamghalam",
      "Baiying Lei",
      "Tianfu Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5825",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5825/5681",
    "published": "2020-02",
    "summary": "Magnetic resonance imaging (MRI) provides varying tissue contrast images of internal organs based on a strong magnetic field. Despite the non-invasive advantage of MRI in frequent imaging, the low contrast MR images in the target area make tissue segmentation a challenging problem. This paper demonstrates the potential benefits of image-to-image translation techniques to generate synthetic high tissue contrast (HTC) images. Notably, we adopt a new cycle generative adversarial network (CycleGAN) with an attention mechanism to increase the contrast within underlying tissues. The attention block, as well as training on HTC images, guides our model to converge on certain tissues. To increase the resolution of HTC images, we employ multi-stage architecture to focus on one particular tissue as a foreground and filter out the irrelevant background in each stage. This multi-stage structure also alleviates the common artifacts of the synthetic images by decreasing the gap between source and target domains. We show the application of our method for synthesizing HTC images on brain MR scans, including glioma tumor. We also employ HTC MR images in both the end-to-end and two-stage segmentation structure to confirm the effectiveness of these images. The experiments over three competitive segmentation baselines on BraTS 2018 dataset indicate that incorporating the synthetic HTC images in the multi-modal segmentation framework improves the average Dice scores 0.8%, 0.6%, and 0.5% on the whole tumor, tumor core, and enhancing tumor, respectively, while eliminating one real MRI sequence from the segmentation procedure."
  },
  "aaai2020_main_robustfederatedlearningviacollaborativemachineteaching": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Robust Federated Learning via Collaborative Machine Teaching ",
    "authors": [
      "Yufei Han",
      "Xiangliang Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5826",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5826/5682",
    "published": "2020-02",
    "summary": "For federated learning systems deployed in the wild, data flaws hosted on local agents are widely witnessed. On one hand, given a large amount (e.g. over 60%) of training data are corrupted by systematic sensor noise and environmental perturbations, the performances of federated model training can be degraded significantly. On the other hand, it is prohibitively expensive for either clients or service providers to set up manual sanitary checks to verify the quality of data instances. In our study, we echo this challenge by proposing a collaborative and privacy-preserving machine teaching method. Specifically, we use a few trusted instances provided by teachers as benign examples in the teaching process. Our collaborative teaching approach seeks jointly the optimal tuning on the distributed training set, such that the model learned from the tuned training set predicts labels of the trusted items correctly. The proposed method couples the process of teaching and learning and thus produces directly a robust prediction model despite the extremely pervasive systematic data corruption. The experimental study on real benchmark data sets demonstrates the validity of our method."
  },
  "aaai2020_main_interpretableanddifferentiallyprivatepredictions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Interpretable and Differentially Private Predictions ",
    "authors": [
      "Frederik Harder",
      "Matthias Bauer",
      "Mijung Park"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5827",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5827/5683",
    "published": "2020-02",
    "summary": "Interpretable predictions, which clarify why a machine learning model makes a particular decision, can compromise privacy by revealing the characteristics of individual data points. This raises the central question addressed in this paper: Can models be interpretable without compromising privacy? For complex \u201cbig\u201d data fit by correspondingly rich models, balancing privacy and explainability is particularly challenging, such that this question has remained largely unexplored. In this paper, we propose a family of simple models with the aim of approximating complex models using several locally linear maps per class to provide high classification accuracy, as well as differentially private explanations on the classification. We illustrate the usefulness of our approach on several image benchmark datasets as well as a medical dataset."
  },
  "aaai2020_main_sneqsemi-supervisedattributednetworkembeddingwithattention-basedquantisation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " SNEQ: Semi-Supervised Attributed Network Embedding with Attention-Based Quantisation ",
    "authors": [
      "Tao He",
      "Lianli Gao",
      "Jingkuan Song",
      "Xin Wang",
      "Kejie Huang",
      "Yuanfang Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5832",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5832/5688",
    "published": "2020-02",
    "summary": "Learning accurate low-dimensional embeddings for a network is a crucial task as it facilitates many network analytics tasks. Moreover, the trained embeddings often require a significant amount of space to store, making storage and processing a challenge, especially as large-scale networks become more prevalent. In this paper, we present a novel semi-supervised network embedding and compression method, SNEQ, that is competitive with state-of-art embedding methods while being far more space- and time-efficient. SNEQ incorporates a novel quantisation method based on a self-attention layer that is trained in an end-to-end fashion, which is able to dramatically compress the size of the trained embeddings, thus reduces storage footprint and accelerates retrieval speed. Our evaluation on four real-world networks of diverse characteristics shows that SNEQ outperforms a number of state-of-the-art embedding methods in link prediction, node classification and node recommendation. Moreover, the quantised embedding shows a great advantage in terms of storage and time compared with continuous embeddings as well as hashing methods."
  },
  "aaai2020_main_heterogeneoustransferlearningwithweightedinstance-correspondencedata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Heterogeneous Transfer Learning with Weighted Instance-Correspondence Data ",
    "authors": [
      "Yuwei He",
      "Xiaoming Jin",
      "Guiguang Ding",
      "Yuchen Guo",
      "Jungong Han",
      "Jiyong Zhang",
      "Sicheng Zhao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5829",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5829/5685",
    "published": "2020-02",
    "summary": "Instance-correspondence (IC) data are potent resources for heterogeneous transfer learning (HeTL) due to the capability of bridging the source and the target domains at the instance-level. To this end, people tend to use machine-generated IC data, because manually establishing IC data is expensive and primitive. However, existing IC data machine generators are not perfect and always produce the data that are not of high quality, thus hampering the performance of domain adaption. In this paper, instead of improving the IC data generator, which might not be an optimal way, we accept the fact that data quality variation does exist but find a better way to use the data. Specifically, we propose a novel heterogeneous transfer learning method named Transfer Learning with Weighted Correspondence (TLWC), which utilizes IC data to adapt the source domain to the target domain. Rather than treating IC data equally, TLWC can assign solid weights to each IC data pair depending on the quality of the data. We conduct extensive experiments on HeTL datasets and the state-of-the-art results verify the effectiveness of TLWC."
  },
  "aaai2020_main_epocefficientperceptionviaoptimalcommunication": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " EPOC: Efficient Perception via Optimal Communication ",
    "authors": [
      "Masoumeh Heidari Kapourchali",
      "Bonny Banerjee"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5830",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5830/5686",
    "published": "2020-02",
    "summary": "We propose an agent model capable of actively and selectively communicating with other agents to predict its environmental state efficiently. Selecting whom to communicate with is a challenge when the internal model of other agents is unobservable. Our agent learns a communication policy as a mapping from its belief state to with whom to communicate in an online and unsupervised manner, without any reinforcement. Human activity recognition from multimodal, multisource and heterogeneous sensor data is used as a testbed to evaluate the proposed model where each sensor is assumed to be monitored by an agent. The recognition accuracy on benchmark datasets is comparable to the state-of-the-art even though our model uses significantly fewer parameters and infers the state in a localized manner. The learned policy reduces number of communications. The agent is tolerant to communication failures and can recognize unreliable agents through their communication messages. To the best of our knowledge, this is the first work on learning communication policies by an agent for predicting its environmental state."
  },
  "aaai2020_main_eigenvaluenormalizedrecurrentneuralnetworksforshorttermmemory": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Eigenvalue Normalized Recurrent Neural Networks for Short Term Memory ",
    "authors": [
      "Kyle Helfrich",
      "Qiang Ye"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5831",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5831/5687",
    "published": "2020-02",
    "summary": "Several variants of recurrent neural networks (RNNs) with orthogonal or unitary recurrent matrices have recently been developed to mitigate the vanishing/exploding gradient problem and to model long-term dependencies of sequences. However, with the eigenvalues of the recurrent matrix on the unit circle, the recurrent state retains all input information which may unnecessarily consume model capacity. In this paper, we address this issue by proposing an architecture that expands upon an orthogonal/unitary RNN with a state that is generated by a recurrent matrix with eigenvalues in the unit disc. Any input to this state dissipates in time and is replaced with new inputs, simulating short-term memory. A gradient descent algorithm is derived for learning such a recurrent matrix. The resulting method, called the Eigenvalue Normalized RNN (ENRNN), is shown to be highly competitive in several experiments."
  },
  "aaai2020_main_reasoningonknowledgegraphswithdebatedynamics": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reasoning on Knowledge Graphs with Debate Dynamics ",
    "authors": [
      "Marcel Hildebrandt",
      "Jorge Andres Quintero Serna",
      "Yunpu Ma",
      "Martin Ringsquandl",
      "Mitchell Joblin",
      "Volker Tresp"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6600",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6600/6454",
    "published": "2020-02",
    "summary": "We propose a novel method for automatic reasoning on knowledge graphs based on debate dynamics. The main idea is to frame the task of triple classification as a debate game between two reinforcement learning agents which extract arguments \u2013 paths in the knowledge graph \u2013 with the goal to promote the fact being true (thesis) or the fact being false (antithesis), respectively. Based on these arguments, a binary classifier, called the judge, decides whether the fact is true or false. The two agents can be considered as sparse, adversarial feature generators that present interpretable evidence for either the thesis or the antithesis. In contrast to other black-box methods, the arguments allow users to get an understanding of the decision of the judge. Since the focus of this work is to create an explainable method that maintains a competitive predictive accuracy, we benchmark our method on the triple classification and link prediction task. Thereby, we find that our method outperforms several baselines on the benchmark datasets FB15k-237, WN18RR, and Hetionet. We also conduct a survey and find that the extracted arguments are informative for users."
  },
  "aaai2020_main_anattention-basedgraphneuralnetworkforheterogeneousstructurallearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Attention-Based Graph Neural Network for Heterogeneous Structural Learning ",
    "authors": [
      "Huiting Hong",
      "Hantao Guo",
      "Yucheng Lin",
      "Xiaoqing Yang",
      "Zang Li",
      "Jieping Ye"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5833",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5833/5689",
    "published": "2020-02",
    "summary": "In this paper, we focus on graph representation learning of heterogeneous information network (HIN), in which various types of vertices are connected by various types of relations. Most of the existing methods conducted on HIN revise homogeneous graph embedding models via meta-paths to learn low-dimensional vector space of HIN. In this paper, we propose a novel Heterogeneous Graph Structural Attention Neural Network (HetSANN) to directly encode structural information of HIN without meta-path and achieve more informative representations. With this method, domain experts will not be needed to design meta-path schemes and the heterogeneous information can be processed automatically by our proposed model. Specifically, we implicitly represent heterogeneous information using the following two methods: 1) we model the transformation between heterogeneous vertices through a projection in low-dimensional entity spaces; 2) afterwards, we apply the graph neural network to aggregate multi-relational information of projected neighborhood by means of attention mechanism. We also present three extensions of HetSANN, i.e., voices-sharing product attention for the pairwise relationships in HIN, cycle-consistency loss to retain the transformation between heterogeneous entity spaces, and multi-task learning with full use of information. The experiments conducted on three public datasets demonstrate that our proposed models achieve significant and consistent improvements compared to state-of-the-art solutions."
  },
  "aaai2020_main_end-to-endunpairedimagedenoisingwithconditionaladversarialnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " End-to-End Unpaired Image Denoising with Conditional Adversarial Networks ",
    "authors": [
      "Zhiwei Hong",
      "Xiaocheng Fan",
      "Tao Jiang",
      "Jianxing Feng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5834",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5834/5690",
    "published": "2020-02",
    "summary": "Image denoising is a classic low level vision problem that attempts to recover a noise-free image from a noisy observation. Recent advances in deep neural networks have outperformed traditional prior based methods for image denoising. However, the existing methods either require paired noisy and clean images for training or impose certain assumptions on the noise distribution and data types. In this paper, we present an end-to-end unpaired image denoising framework (UIDNet) that denoises images with only unpaired clean and noisy training images. The critical component of our model is a noise learning module based on a conditional Generative Adversarial Network (cGAN). The model learns the noise distribution from the input noisy images and uses it to transform the input clean images to noisy ones without any assumption on the noise distribution and data types. This process results in pairs of clean and pseudo-noisy images. Such pairs are then used to train another denoising network similar to the existing denoising methods based on paired images. The noise learning and denoising components are integrated together so that they can be trained end-to-end. Extensive experimental evaluation has been performed on both synthetic and real data including real photographs and computer tomography (CT) images. The results demonstrate that our model outperforms the previous models trained on unpaired images as well as the state-of-the-art methods based on paired training data when proper training pairs are unavailable."
  },
  "aaai2020_main_telltailfastscoringanddetectionofdensesubgraphs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " TellTail: Fast Scoring and Detection of Dense Subgraphs ",
    "authors": [
      "Bryan Hooi",
      "Kijung Shin",
      "Hemank Lamba",
      "Christos Faloutsos"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5835",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5835/5691",
    "published": "2020-02",
    "summary": "Suppose you visit an e-commerce site, and see that 50 users each reviewed almost all of the same 500 products several times each: would you get suspicious? Similarly, given a Twitter follow graph, how can we design principled measures for identifying surprisingly dense subgraphs? Dense subgraphs often indicate interesting structure, such as network attacks in network traffic graphs. However, most existing dense subgraph measures either do not model normal variation, or model it using an Erd\u0151s-Renyi assumption - but this assumption has been discredited decades ago. What is the right assumption then? We propose a novel application of extreme value theory to the dense subgraph problem, which allows us to propose measures and algorithms which evaluate the surprisingness of a subgraph probabilistically, without requiring restrictive assumptions (e.g. Erd\u0151s-Renyi). We then improve the practicality of our approach by incorporating empirical observations about dense subgraph patterns in real graphs, and by proposing a fast pruning-based search algorithm. Our approach (a) provides theoretical guarantees of consistency, (b) scales quasi-linearly, and (c) outperforms baselines in synthetic and ground truth settings."
  },
  "aaai2020_main_query-drivenmulti-instancelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Query-Driven Multi-Instance Learning ",
    "authors": [
      "Yen-Chi Hsu",
      "Cheng-Yao Hong",
      "Ming-Sui Lee",
      "Tyng-Luh Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5836",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5836/5692",
    "published": "2020-02",
    "summary": "We introduce a query-driven approach (qMIL) to multi-instance learning where the queries aim to uncover the class labels embodied in a given bag of instances. Specifically, it solves a multi-instance multi-label learning (MIML) problem with a more challenging setting than the conventional one. Each MIML bag in our formulation is annotated only with a binary label indicating whether the bag contains the instance of a certain class and the query is specified by the word2vec of a class label/name. To learn a deep-net model for qMIL, we construct a network component that achieves a generalized compatibility measure for query-visual co-embedding and yields proper instance attentions to the given query. The bag representation is then formed as the attention-weighted sum of the instances' weights, and passed to the classification layer at the end of the network. In addition, the qMIL formulation is flexible for extending the network to classify unseen class labels, leading to a new technique to solve the zero-shot MIML task through an iterative querying process. Experimental results on action classification over video clips and three MIML datasets from MNIST, CIFAR10 and Scene are provided to demonstrate the effectiveness of our method."
  },
  "aaai2020_main_towardsinterpretationofpairwiselearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Interpretation of Pairwise Learning ",
    "authors": [
      "Mengdi Huai",
      "Di Wang",
      "Chenglin Miao",
      "Aidong Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5837",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5837/5693",
    "published": "2020-02",
    "summary": "Recently, there are increasingly more attentions paid to an important family of learning problems called pairwise learning, in which the associated loss functions depend on pairs of instances. Despite the tremendous success of pairwise learning in many real-world applications, the lack of transparency behind the learned pairwise models makes it difficult for users to understand how particular decisions are made by these models, which further impedes users from trusting the predicted results. To tackle this problem, in this paper, we study feature importance scoring as a specific approach to the problem of interpreting the predictions of black-box pairwise models. Specifically, we first propose a novel adaptive Shapley-value-based interpretation method, based on which a vector of importance scores associated with the underlying features of a testing instance pair can be adaptively calculated with the consideration of feature correlations, and these scores can be used to indicate which features make key contributions to the final prediction. Considering that Shapley-value-based methods are usually computationally challenging, we further propose a novel robust approximation interpretation method for pairwise models. This method is not only much more efficient but also robust to data noise. To the best of our knowledge, we are the first to investigate how to enable interpretation in pairwise learning. Theoretical analysis and extensive experiments demonstrate the effectiveness of the proposed methods."
  },
  "aaai2020_main_dwmadecomposablewinogradmethodforconvolutionacceleration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DWM: A Decomposable Winograd Method for Convolution Acceleration ",
    "authors": [
      "Di Huang",
      "Xishan Zhang",
      "Rui Zhang",
      "Tian Zhi",
      "Deyuan He",
      "Jiaming Guo",
      "Chang Liu",
      "Qi Guo",
      "Zidong Du",
      "Shaoli Liu",
      "Tianshi Chen",
      "Yunji Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5838",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5838/5694",
    "published": "2020-02",
    "summary": "Winograd's minimal filtering algorithm has been widely used in Convolutional Neural Networks (CNNs) to reduce the number of multiplications for faster processing. However, it is only effective on convolutions with kernel size as 3x3 and stride as 1, because it suffers from significantly increased FLOPs and numerical accuracy problem for kernel size larger than 3x3 and fails on convolution with stride larger than 1. In this paper, we propose a novel Decomposable Winograd Method (DWM), which breaks through the limitation of original Winograd's minimal filtering algorithm to a wide and general convolutions. DWM decomposes kernels with large size or large stride to several small kernels with stride as 1 for further applying Winograd method, so that DWM can reduce the number of multiplications while keeping the numerical accuracy. It enables the fast exploring of larger kernel size and larger stride value in CNNs for high performance and accuracy and even the potential for new CNNs. Comparing against the original Winograd, the proposed DWM is able to support all kinds of convolutions with a speedup of \u223c2, without affecting the numerical accuracy."
  },
  "aaai2020_main_unsupervisednonlinearfeatureselectionfromhigh-dimensionalsignednetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Unsupervised Nonlinear Feature Selection from High-Dimensional Signed Networks ",
    "authors": [
      "Qiang Huang",
      "Tingyu Xia",
      "Huiyan Sun",
      "Makoto Yamada",
      "Yi Chang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5839",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5839/5695",
    "published": "2020-02",
    "summary": "With the rapid development of social media services in recent years, relational data are explosively growing. The signed network, which consists of a mixture of positive and negative links, is an effective way to represent the friendly and hostile relations among nodes, which can represent users or items. Because the features associated with a node of a signed network are usually incomplete, noisy, unlabeled, and high-dimensional, feature selection is an important procedure to eliminate irrelevant features. However, existing network-based feature selection methods are linear methods, which means they can only select features that having the linear dependency on the output values. Moreover, in many social data, most nodes are unlabeled; therefore, selecting features in an unsupervised manner is generally preferred. To this end, in this paper, we propose a nonlinear unsupervised feature selection method for signed networks, called SignedLasso. This method can select a small number of important features with nonlinear associations between inputs and output from a high-dimensional data. More specifically, we formulate unsupervised feature selection as a nonlinear feature selection problem with the Hilbert-Schmidt Independence Criterion Lasso (HSIC Lasso), which can find a small number of features in a nonlinear manner. Then, we propose the use of a deep learning-based node embedding to represent node similarity without label information and incorporate the node embedding into the HSIC Lasso. Through experiments on two real world datasets, we show that the proposed algorithm is superior to existing linear unsupervised feature selection methods."
  },
  "aaai2020_main_featurevarianceregularizationasimplewaytoimprovethegeneralizabilityofneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Feature Variance Regularization: A Simple Way to Improve the Generalizability of Neural Networks ",
    "authors": [
      "Ranran Huang",
      "Hanbo Sun",
      "Ji Liu",
      "Lu Tian",
      "Li Wang",
      "Yi Shan",
      "Yu Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5840",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5840/5696",
    "published": "2020-02",
    "summary": "To improve the generalization ability of neural networks, we propose a novel regularization method that regularizes the empirical risk using a penalty on the empirical variance of the features. Intuitively, our approach introduces confusion into feature extraction and prevents the models from learning features that may relate to specific training samples. According to our theoretical analysis, our method encourages models to generate closer feature distributions for the training set and unobservable true data and minimize the expected risk as well, which allows the model to adapt to new samples better. We provide a thorough empirical justification of our approach, and achieves a greater improvement than other regularization methods. The experimental results show the effectiveness of our method on multiple visual tasks, including classification (CIFAR100, ImageNet, fine-grained datasets) and semantic segmentation (Cityscapes)."
  },
  "aaai2020_main_meta-learningpac-bayespriorsinmodelaveraging": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Meta-Learning PAC-Bayes Priors in Model Averaging ",
    "authors": [
      "Yimin Huang",
      "Weiran Huang",
      "Liang Li",
      "Zhenguo Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5841",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5841/5697",
    "published": "2020-02",
    "summary": "Nowadays model uncertainty has become one of the most important problems in both academia and industry. In this paper, we mainly consider the scenario in which we have a common model set used for model averaging instead of selecting a single final model via a model selection procedure to account for this model's uncertainty in order to improve reliability and accuracy of inferences. Here one main challenge is to learn the prior over the model set. To tackle this problem, we propose two data-based algorithms to get proper priors for model averaging. One is for meta-learner, the analysts should use historical similar tasks to extract the information about the prior. The other one is for base-learner, a subsampling method is used to deal with the data step by step. Theoretically, an upper bound of risk for our algorithm is presented to guarantee the performance of the worst situation. In practice, both methods perform well in simulations and real data studies, especially with poor quality data."
  },
  "aaai2020_main_dianetdense-and-implicitattentionnetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DIANet: Dense-and-Implicit Attention Network ",
    "authors": [
      "Zhongzhan Huang",
      "Senwei Liang",
      "Mingfu Liang",
      "Haizhao Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5842",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5842/5698",
    "published": "2020-02",
    "summary": "Attention networks have successfully boosted the performance in various vision problems. Previous works lay emphasis on designing a new attention module and individually plug them into the networks. Our paper proposes a novel-and-simple framework that shares an attention module throughout different network layers to encourage the integration of layer-wise information and this parameter-sharing module is referred to as Dense-and-Implicit-Attention (DIA) unit. Many choices of modules can be used in the DIA unit. Since Long Short Term Memory (LSTM) has a capacity of capturing long-distance dependency, we focus on the case when the DIA unit is the modified LSTM (called DIA-LSTM). Experiments on benchmark datasets show that the DIA-LSTM unit is capable of emphasizing layer-wise feature interrelation and leads to significant improvement of image classification accuracy. We further empirically show that the DIA-LSTM has a strong regularization ability on stabilizing the training of deep networks by the experiments with the removal of skip connections (He et al. 2016a) or Batch Normalization (Ioffe and Szegedy 2015) in the whole residual network."
  },
  "aaai2020_main_collaborativegraphconvolutionalnetworksunsupervisedlearningmeetssemi-supervisedlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Collaborative Graph Convolutional Networks: Unsupervised Learning Meets Semi-Supervised Learning ",
    "authors": [
      "Binyuan Hui",
      "Pengfei Zhu",
      "Qinghua Hu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5843",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5843/5699",
    "published": "2020-02",
    "summary": "Graph convolutional networks (GCN) have achieved promising performance in attributed graph clustering and semi-supervised node classification because it is capable of modeling complex graphical structure, and jointly learning both features and relations of nodes. Inspired by the success of unsupervised learning in the training of deep models, we wonder whether graph-based unsupervised learning can collaboratively boost the performance of semi-supervised learning. In this paper, we propose a multi-task graph learning model, called collaborative graph convolutional networks (CGCN). CGCN is composed of an attributed graph clustering network and a semi-supervised node classification network. As Gaussian mixture models can effectively discover the inherent complex data distributions, a new end to end attributed graph clustering network is designed by combining variational graph auto-encoder with Gaussian mixture models (GMM-VGAE) rather than the classic k-means. If the pseudo-label of an unlabeled sample assigned by GMM-VGAE is consistent with the prediction of the semi-supervised GCN, it is selected to further boost the performance of semi-supervised learning with the help of the pseudo-labels. Extensive experiments on benchmark graph datasets validate the superiority of our proposed GMM-VGAE compared with the state-of-the-art attributed graph clustering networks. The performance of node classification is greatly improved by our proposed CGCN, which verifies graph-based unsupervised learning can be well exploited to enhance the performance of semi-supervised learning."
  },
  "aaai2020_main_controlflowgraphembeddingbasedonmulti-instancedecompositionforbuglocalization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Control Flow Graph Embedding Based on Multi-Instance Decomposition for Bug Localization ",
    "authors": [
      "Xuan Huo",
      "Ming Li",
      "Zhi-Hua Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5844",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5844/5700",
    "published": "2020-02",
    "summary": "During software maintenance, bug report is an effective way to identify potential bugs hidden in a software system. It is a great challenge to automatically locate the potential buggy source code according to a bug report. Traditional approaches usually represent bug reports and source code from a lexical perspective to measure their similarities. Recently, some deep learning models are proposed to learn the unified features by exploiting the local and sequential nature, which overcomes the difficulty in modeling the difference between natural and programming languages. However, only considering local and sequential information from one dimension is not enough to represent the semantics, some multi-dimension information such as structural and functional nature that carries additional semantics has not been well-captured. Such information beyond the lexical and structural terms is extremely vital in modeling program functionalities and behaviors, leading to a better representation for identifying buggy source code. In this paper, we propose a novel model named CG-CNN, which is a multi-instance learning framework that enhances the unified features for bug localization by exploiting structural and sequential nature from the control flow graph. Experimental results on widely-used software projects demonstrate the effectiveness of our proposed CG-CNN model."
  },
  "aaai2020_main_word-levelcontextualsentimentanalysiswithinterpretability": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Word-Level Contextual Sentiment Analysis with Interpretability ",
    "authors": [
      "Tomoki Ito",
      "Kota Tsubouchi",
      "Hiroki Sakaji",
      "Tatsuo Yamashita",
      "Kiyoshi Izumi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5845",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5845/5701",
    "published": "2020-02",
    "summary": "Word-level contextual sentiment analysis (WCSA) is an important task for mining reviews or opinions. When analyzing this type of sentiment in the industry, both the interpretability and practicality are often required. However, such a WCSA method has not been established. This study aims to develop a WCSA method with interpretability and practicality. To achieve this aim, we propose a novel neural network architecture called Sentiment Interpretable Neural Network (SINN). To realize this SINN practically, we propose a novel learning strategy called Lexical Initialization Learning (LEXIL). SINN is interpretable because it can extract word-level contextual sentiment through extracting word-level original sentiment and its local and global word-level contexts. Moreover, LEXIL can develop the SINN without any specific knowledge for context; therefore, this strategy is practical. Using real textual datasets, we experimentally demonstrate that the proposed LEXIL is effective for improving the interpretability of SINN and that the SINN features both the high WCSA ability and high interpretability."
  },
  "aaai2020_main_semi-supervisedlearningformaximizingthepartialauc": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Semi-Supervised Learning for Maximizing the Partial AUC ",
    "authors": [
      "Tomoharu Iwata",
      "Akinori Fujino",
      "Naonori Ueda"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5846",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5846/5702",
    "published": "2020-02",
    "summary": "The partial area under a receiver operating characteristic curve (pAUC) is a performance measurement for binary classification problems that summarizes the true positive rate with the specific range of the false positive rate. Obtaining classifiers that achieve high pAUC is important in a wide variety of applications, such as cancer screening and spam filtering. Although many methods have been proposed for maximizing the pAUC, existing methods require many labeled data for training. In this paper, we propose a semi-supervised learning method for maximizing the pAUC, which trains a classifier with a small amount of labeled data and a large amount of unlabeled data. To exploit the unlabeled data, we derive two approximations of the pAUC: the first is calculated from positive and unlabeled data, and the second is calculated from negative and unlabeled data. A classifier is trained by maximizing the weighted sum of the two approximations of the pAUC and the pAUC that is calculated from positive and negative data. With experiments using various datasets, we demonstrate that the proposed method achieves higher test pAUCs than existing methods."
  },
  "aaai2020_main_co-occurrenceestimationfromaggregateddatawithauxiliaryinformation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Co-Occurrence Estimation from Aggregated Data with Auxiliary Information ",
    "authors": [
      "Tomoharu Iwata",
      "Naoki Marumo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5847",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5847/5703",
    "published": "2020-02",
    "summary": "Complete co-occurrence data are unavailable in many applications, including purchase records and medical histories, because of their high cost or privacy protection. Even with such applications, aggregated data would be available, such as the number of purchasers for each item and the number of patients with each disease. We propose a method for estimating the co-occurrence of items from aggregated data with auxiliary information. For auxiliary information, we use item features that describe the characteristics of each item. Although many methods have been proposed for estimating the co-occurrence given aggregated data, no existing method can use auxiliary information. We also use records of a small number of users. With our proposed method, we introduce latent co-occurrence variables that represent the amount of co-occurrence for each pair of items. We model a probabilistic generative process of the latent co-occurrence variables by a multinomial distribution with Dirichlet priors. The parameters of the Dirichlet priors are parameterized with neural networks that take the auxiliary information as input, where neural networks are shared across different item pairs. The shared neural networks enable us to learn unknown relationships between auxiliary information and co-occurrence using the data of multiple items. The latent co-occurrence variables and the neural network parameters are estimated by maximizing the sum of the likelihood of the latent co-occurrence variables and the likelihood of the small records. We demonstrate the effectiveness of our proposed method using user-item rating datasets."
  },
  "aaai2020_main_classpriorestimationwithbiasedpositivesandunlabeledexamples": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Class Prior Estimation with Biased Positives and Unlabeled Examples ",
    "authors": [
      "Shantanu Jain",
      "Justin Delano",
      "Himanshu Sharma",
      "Predrag Radivojac"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5848",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5848/5704",
    "published": "2020-02",
    "summary": "Positive-unlabeled learning is often studied under the assumption that the labeled positive sample is drawn randomly from the true distribution of positives. In many application domains, however, certain regions in the support of the positive class-conditional distribution are over-represented while others are under-represented in the positive sample. Although this introduces problems in all aspects of positive-unlabeled learning, we begin to address this challenge by focusing on the estimation of class priors, quantities central to the estimation of posterior probabilities and the recovery of true classification performance. We start by making a set of assumptions to model the sampling bias. We then extend the identifiability theory of class priors from the unbiased to the biased setting. Finally, we derive an algorithm for estimating the class priors that relies on clustering to decompose the original problem into subproblems of unbiased positive-unlabeled learning. Our empirical investigation suggests feasibility of the correction strategy and overall good performance."
  },
  "aaai2020_main_maximizingoveralldiversityforimproveduncertaintyestimatesindeepensembles": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Maximizing Overall Diversity for Improved Uncertainty Estimates in Deep Ensembles ",
    "authors": [
      "Siddhartha Jain",
      "Ge Liu",
      "Jonas Mueller",
      "David Gifford"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5849",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5849/5705",
    "published": "2020-02",
    "summary": "The inaccuracy of neural network models on inputs that do not stem from the distribution underlying the training data is problematic and at times unrecognized. Uncertainty estimates of model predictions are often based on the variation in predictions produced by a diverse ensemble of models applied to the same input. Here we describe Maximize Overall Diversity (MOD), an approach to improve ensemble-based uncertainty estimates by encouraging larger overall diversity in ensemble predictions across all possible inputs. We apply MOD to regression tasks including 38 Protein-DNA binding datasets, 9 UCI datasets, and the IMDB-Wiki image dataset. We also explore variants that utilize adversarial training techniques and data density estimation. For out-of-distribution test examples, MOD significantly improves predictive performance and uncertainty calibration without sacrificing performance on test data drawn from same distribution as the training data. We also find that in Bayesian optimization tasks, the performance of UCB acquisition is improved via MOD uncertainty estimates."
  },
  "aaai2020_main_invariantrepresentationsthroughadversarialforgetting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Invariant Representations through Adversarial Forgetting ",
    "authors": [
      "Ayush Jaiswal",
      "Daniel Moyer",
      "Greg Ver Steeg",
      "Wael AbdAlmageed",
      "Premkumar Natarajan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5850",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5850/5706",
    "published": "2020-02",
    "summary": "We propose a novel approach to achieving invariance for deep neural networks in the form of inducing amnesia to unwanted factors of data through a new adversarial forgetting mechanism. We show that the forgetting mechanism serves as an information-bottleneck, which is manipulated by the adversarial training to learn invariance to unwanted factors. Empirical results show that the proposed framework achieves state-of-the-art performance at learning invariance in both nuisance and bias settings on a diverse collection of datasets and tasks."
  },
  "aaai2020_main_boundingregretinempiricalgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bounding Regret in Empirical Games ",
    "authors": [
      "Steven Jecmen",
      "Arunesh Sinha",
      "Zun Li",
      "Long Tran-Thanh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5851",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5851/5707",
    "published": "2020-02",
    "summary": "Empirical game-theoretic analysis refers to a set of models and techniques for solving large-scale games. However, there is a lack of a quantitative guarantee about the quality of output approximate Nash equilibria (NE). A natural quantitative guarantee for such an approximate NE is the regret in the game (i.e. the best deviation gain). We formulate this deviation gain computation as a multi-armed bandit problem, with a new optimization goal unlike those studied in prior work. We propose an efficient algorithm Super-Arm UCB (SAUCB) for the problem and a number of variants. We present sample complexity results as well as extensive experiments that show the better performance of SAUCB compared to several baselines."
  },
  "aaai2020_main_anefficientexplorativesamplingconsideringthegenerativeboundariesofdeepgenerativeneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Efficient Explorative Sampling Considering the Generative Boundaries of Deep Generative Neural Networks ",
    "authors": [
      "Giyoung Jeon",
      "Haedong Jeong",
      "Jaesik Choi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5852",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5852/5708",
    "published": "2020-02",
    "summary": "Deep generative neural networks (DGNNs) have achieved realistic and high-quality data generation. In particular, the adversarial training scheme has been applied to many DGNNs and has exhibited powerful performance. Despite of recent advances in generative networks, identifying the image generation mechanism still remains challenging. In this paper, we present an explorative sampling algorithm to analyze generation mechanism of DGNNs. Our method efficiently obtains samples with identical attributes from a query image in a perspective of the trained model. We define generative boundaries which determine the activation of nodes in the internal layer and probe inside the model with this information. To handle a large number of boundaries, we obtain the essential set of boundaries using optimization. By gathering samples within the region surrounded by generative boundaries, we can empirically reveal the characteristics of the internal layers of DGNNs. We also demonstrate that our algorithm can find more homogeneous, the model specific samples compared to the variations of \u03f5-based sampling method."
  },
  "aaai2020_main_defogganpredictinghiddeninformationinthestarcraftfogofwarwithgenerativeadversarialnets": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DefogGAN: Predicting Hidden Information in the StarCraft Fog of War with Generative Adversarial Nets ",
    "authors": [
      "Yonghyun Jeong",
      "Hyunjin Choi",
      "Byoungjip Kim",
      "Youngjune Gwon"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5853",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5853/5709",
    "published": "2020-02",
    "summary": "We propose DefogGAN, a generative approach to the problem of inferring state information hidden in the fog of war for real-time strategy (RTS) games. Given a partially observed state, DefogGAN generates defogged images of a game as predictive information. Such information can lead to create a strategic agent for the game. DefogGAN is a conditional GAN variant featuring pyramidal reconstruction loss to optimize on multiple feature resolution scales. We have validated DefogGAN empirically using a large dataset of professional StarCraft replays. Our results indicate that DefogGAN can predict the enemy buildings and combat units as accurately as professional players do and achieves a superior performance among state-of-the-art defoggers."
  },
  "aaai2020_main_sequentialrecommendationwithrelation-awarekernelizedself-attention": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Sequential Recommendation with Relation-Aware Kernelized Self-Attention ",
    "authors": [
      "Mingi Ji",
      "Weonyoung Joo",
      "Kyungwoo Song",
      "Yoon-Yeong Kim",
      "Il-Chul Moon"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5854",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5854/5710",
    "published": "2020-02",
    "summary": "Recent studies identified that sequential Recommendation is improved by the attention mechanism. By following this development, we propose Relation-Aware Kernelized Self-Attention (RKSA) adopting a self-attention mechanism of the Transformer with augmentation of a probabilistic model. The original self-attention of Transformer is a deterministic measure without relation-awareness. Therefore, we introduce a latent space to the self-attention, and the latent space models the recommendation context from relation as a multivariate skew-normal distribution with a kernelized covariance matrix from co-occurrences, item characteristics, and user information. This work merges the self-attention of the Transformer and the sequential recommendation by adding a probabilistic model of the recommendation task specifics. We experimented RKSA over the benchmark datasets, and RKSA shows significant improvements compared to the recent baseline models. Also, RKSA were able to produce a latent space model that answers the reasons for recommendation."
  },
  "aaai2020_main_maximummarginmulti-dimensionalclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Maximum Margin Multi-Dimensional Classification ",
    "authors": [
      "Bin-Bin Jia",
      "Min-Ling Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5855",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5855/5711",
    "published": "2020-02",
    "summary": "Multi-dimensional classification (MDC) assumes heterogenous class spaces for each example, where class variables from different class spaces characterize semantics of the example along different dimensions. Due to the heterogeneity of class spaces, the major difficulty in designing margin-based MDC techniques lies in that the modeling outputs from different class spaces are not comparable to each other. In this paper, a first attempt towards maximum margin multi-dimensional classification is investigated. Following the one-vs-one decomposition within each class space, the resulting models are optimized by leveraging classification margin maximization on individual class variable and model relationship regularization across class variables. We derive convex formulation for the maximum margin MDC problem, which can be tackled with alternating optimization admitting QP or closed-form solution in either alternating step. Experimental studies over real-world MDC data sets clearly validate effectiveness of the proposed maximum margin MDC techniques."
  },
  "aaai2020_main_representationlearningwithmultiplelipschitz-constrainedalignmentsonpartially-labeledcross-domaindata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Representation Learning with Multiple Lipschitz-Constrained Alignments on Partially-Labeled Cross-Domain Data ",
    "authors": [
      "Songlei Jian",
      "Liang Hu",
      "Longbing Cao",
      "Kai Lu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5856",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5856/5712",
    "published": "2020-02",
    "summary": "The cross-domain representation learning plays an important role in tasks including domain adaptation and transfer learning. However, existing cross-domain representation learning focuses on building one shared space and ignores the unlabeled data in the source domain, which cannot effectively capture the distribution and structure heterogeneities in cross-domain data. To address this challenge, we propose a new cross-domain representation learning approach: MUltiple Lipschitz-constrained AligNments (MULAN) on partially-labeled cross-domain data. MULAN produces two representation spaces: a common representation space to incorporate knowledge from the source domain and a complementary representation space to complement the common representation with target local topological information by Lipschitz-constrained representation transformation. MULAN utilizes both unlabeled and labeled data in the source and target domains to address distribution heterogeneity by Lipschitz-constrained adversarial distribution alignment and structure heterogeneity by cluster assumption-based class alignment while keeping the target local topological information in complementary representation by self alignment. Moreover, MULAN is effectively equipped with a customized learning process and an iterative parameter updating process. MULAN shows its superior performance on partially-labeled semi-supervised domain adaptation and few-shot domain adaptation and outperforms the state-of-the-art visual domain adaptation models by up to 12.1%."
  },
  "aaai2020_main_algorithmicimprovementsfordeepreinforcementlearningappliedtointeractivefiction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Algorithmic Improvements for Deep Reinforcement Learning Applied to Interactive Fiction ",
    "authors": [
      "Vishal Jain",
      "William Fedus",
      "Hugo Larochelle",
      "Doina Precup",
      "Marc G. Bellemare"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5857",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5857/5713",
    "published": "2020-02",
    "summary": "Text-based games are a natural challenge domain for deep reinforcement learning algorithms. Their state and action spaces are combinatorially large, their reward function is sparse, and they are partially observable: the agent is informed of the consequences of its actions through textual feedback. In this paper we emphasize this latter point and consider the design of a deep reinforcement learning agent that can play from feedback alone. Our design recognizes and takes advantage of the structural characteristics of text-based games. We first propose a contextualisation mechanism, based on accumulated reward, which simplifies the learning problem and mitigates partial observability. We then study different methods that rely on the notion that most actions are ineffectual in any given situation, following Zahavy et al.'s idea of an admissible action. We evaluate these techniques in a series of text-based games of increasing difficulty based on the TextWorld framework, as well as the iconic game Zork. Empirically, we find that these techniques improve the performance of a baseline deep reinforcement learning agent applied to text-based games."
  },
  "aaai2020_main_generativeexplorationandexploitation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generative Exploration and Exploitation ",
    "authors": [
      "Jiechuan Jiang",
      "Zongqing Lu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5858",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5858/5714",
    "published": "2020-02",
    "summary": "Sparse reward is one of the biggest challenges in reinforcement learning (RL). In this paper, we propose a novel method called Generative Exploration and Exploitation (GENE) to overcome sparse reward. GENE automatically generates start states to encourage the agent to explore the environment and to exploit received reward signals. GENE can adaptively tradeoff between exploration and exploitation according to the varying distributions of states experienced by the agent as the learning progresses. GENE relies on no prior knowledge about the environment and can be combined with any RL algorithm, no matter on-policy or off-policy, single-agent or multi-agent. Empirically, we demonstrate that GENE significantly outperforms existing methods in three tasks with only binary rewards, including Maze, Maze Ant, and Cooperative Navigation. Ablation studies verify the emergence of progressive exploration and automatic reversing."
  },
  "aaai2020_main_longshort-termsampledistillation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Long Short-Term Sample Distillation ",
    "authors": [
      "Liang Jiang",
      "Zujie Wen",
      "Zhongping Liang",
      "Yafang Wang",
      "Gerard de Melo",
      "Zhe Li",
      "Liangzhuang Ma",
      "Jiaxing Zhang",
      "Xiaolong Li",
      "Yuan Qi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5859",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5859/5715",
    "published": "2020-02",
    "summary": "In the past decade, there has been substantial progress at training increasingly deep neural networks. Recent advances within the teacher\u2013student training paradigm have established that information about past training updates show promise as a source of guidance during subsequent training steps. Based on this notion, in this paper, we propose Long Short-Term Sample Distillation, a novel training policy that simultaneously leverages multiple phases of the previous training process to guide the later training updates to a neural network, while efficiently proceeding in just one single generation pass. With Long Short-Term Sample Distillation, the supervision signal for each sample is decomposed into two parts: a long-term signal and a short-term one. The long-term teacher draws on snapshots from several epochs ago in order to provide steadfast guidance and to guarantee teacher\u2013student differences, while the short-term one yields more up-to-date cues with the goal of enabling higher-quality updates. Moreover, the teachers for each sample are unique, such that, overall, the model learns from a very diverse set of teachers. Comprehensive experimental results across a range of vision and NLP tasks demonstrate the effectiveness of this new training method."
  },
  "aaai2020_main_rankaggregationviaheterogeneousthurstonepreferencemodels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Rank Aggregation via Heterogeneous Thurstone Preference Models ",
    "authors": [
      "Tao Jin",
      "Pan Xu",
      "Quanquan Gu",
      "Farzad Farnoud"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5860",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5860/5716",
    "published": "2020-02",
    "summary": "We propose the Heterogeneous Thurstone Model (HTM) for aggregating ranked data, which can take the accuracy levels of different users into account. By allowing different noise distributions, the proposed HTM model maintains the generality of Thurstone's original framework, and as such, also extends the Bradley-Terry-Luce (BTL) model for pairwise comparisons to heterogeneous populations of users. Under this framework, we also propose a rank aggregation algorithm based on alternating gradient descent to estimate the underlying item scores and accuracy levels of different users simultaneously from noisy pairwise comparisons. We theoretically prove that the proposed algorithm converges linearly up to a statistical error which matches that of the state-of-the-art method for the single-user BTL model. We evaluate the proposed HTM model and algorithm on both synthetic and real data, demonstrating that it outperforms existing methods."
  },
  "aaai2020_main_gralspgraphneuralnetworkswithlocalstructuralpatterns": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " GraLSP: Graph Neural Networks with Local Structural Patterns ",
    "authors": [
      "Yilun Jin",
      "Guojie Song",
      "Chuan Shi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5861",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5861/5717",
    "published": "2020-02",
    "summary": "It is not until recently that graph neural networks (GNNs) are adopted to perform graph representation learning, among which, those based on the aggregation of features within the neighborhood of a node achieved great success. However, despite such achievements, GNNs illustrate defects in identifying some common structural patterns which, unfortunately, play significant roles in various network phenomena. In this paper, we propose GraLSP, a GNN framework which explicitly incorporates local structural patterns into the neighborhood aggregation through random anonymous walks. Specifically, we capture local graph structures via random anonymous walks, powerful and flexible tools that represent structural patterns. The walks are then fed into the feature aggregation, where we design various mechanisms to address the impact of structural features, including adaptive receptive radius, attention and amplification. In addition, we design objectives that capture similarities between structures and are optimized jointly with node proximity objectives. With the adequate leverage of structural patterns, our model is able to outperform competitive counterparts in various prediction tasks in multiple datasets."
  },
  "aaai2020_main_dynamicinstancenormalizationforarbitrarystyletransfer": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Dynamic Instance Normalization for Arbitrary Style Transfer ",
    "authors": [
      "Yongcheng Jing",
      "Xiao Liu",
      "Yukang Ding",
      "Xinchao Wang",
      "Errui Ding",
      "Mingli Song",
      "Shilei Wen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5862",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5862/5718",
    "published": "2020-02",
    "summary": "Prior normalization methods rely on affine transformations to produce arbitrary image style transfers, of which the parameters are computed in a pre-defined way. Such manually-defined nature eventually results in the high-cost and shared encoders for both style and content encoding, making style transfer systems cumbersome to be deployed in resource-constrained environments like on the mobile-terminal side. In this paper, we propose a new and generalized normalization module, termed as Dynamic Instance Normalization (DIN), that allows for flexible and more efficient arbitrary style transfers. Comprising an instance normalization and a dynamic convolution, DIN encodes a style image into learnable convolution parameters, upon which the content image is stylized. Unlike conventional methods that use shared complex encoders to encode content and style, the proposed DIN introduces a sophisticated style encoder, yet comes with a compact and lightweight content encoder for fast inference. Experimental results demonstrate that the proposed approach yields very encouraging results on challenging style patterns and, to our best knowledge, for the first time enables an arbitrary style transfer using MobileNet-based lightweight architecture, leading to a reduction factor of more than twenty in computational cost as compared to existing approaches. Furthermore, the proposed DIN provides flexible support for state-of-the-art convolutional operations, and thus triggers novel functionalities, such as uniform-stroke placement for non-natural images and automatic spatial-stroke control."
  },
  "aaai2020_main_invnetencodinggeometricandstatisticalinvariancesindeepgenerativemodels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " InvNet: Encoding Geometric and Statistical Invariances in Deep Generative Models ",
    "authors": [
      "Ameya Joshi",
      "Minsu Cho",
      "Viraj Shah",
      "Balaji Pokuri",
      "Soumik Sarkar",
      "Baskar Ganapathysubramanian",
      "Chinmay Hegde"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5863",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5863/5719",
    "published": "2020-02",
    "summary": "Generative Adversarial Networks (GANs), while widely successful in modeling complex data distributions, have not yet been sufficiently leveraged in scientific computing and design. Reasons for this include the lack of flexibility of GANs to represent discrete-valued image data, as well as the lack of control over physical properties of generated samples. We propose a new conditional generative modeling approach (InvNet) that efficiently enables modeling discrete-valued images, while allowing control over their parameterized geometric and statistical properties. We evaluate our approach on several synthetic and real world problems: navigating manifolds of geometric shapes with desired sizes; generation of binary two-phase materials; and the (challenging) problem of generating multi-orientation polycrystalline microstructures."
  },
  "aaai2020_main_moreaccuratelearningofk-dnfreferenceclasses": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " More Accurate Learning of k-DNF Reference Classes ",
    "authors": [
      "Brendan Juba",
      "Hengxuan Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5864",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5864/5720",
    "published": "2020-02",
    "summary": "In machine learning, predictors trained on a given data distribution are usually guaranteed to perform well for further examples from the same distribution on average. This often may involve disregarding or diminishing the predictive power on atypical examples; or, in more extreme cases, a data distribution may be composed of a mixture of individually \u201catypical\u201d heterogeneous populations, and the kind of simple predictors we can train may find it difficult to fit all of these populations simultaneously. In such cases, we may wish to make predictions for an atypical point by selecting a suitable reference class for that point: a subset of the data that is \u201cmore similar\u201d to the given query point in an appropriate sense. Closely related tasks also arise in applications such as diagnosis or explaining the output of classifiers. We present new algorithms for computing k-DNF reference classes and establish much stronger approximation guarantees for their error rates."
  },
  "aaai2020_main_absumsimpleregularizationmethodforreducingstructuralsensitivityofconvolutionalneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Absum: Simple Regularization Method for Reducing Structural Sensitivity of Convolutional Neural Networks ",
    "authors": [
      "Sekitoshi Kanai",
      "Yasutoshi Ida",
      "Yasuhiro Fujiwara",
      "Masanori Yamada",
      "Shuichi Adachi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5865",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5865/5721",
    "published": "2020-02",
    "summary": "We propose Absum, which is a regularization method for improving adversarial robustness of convolutional neural networks (CNNs). Although CNNs can accurately recognize images, recent studies have shown that the convolution operations in CNNs commonly have structural sensitivity to specific noise composed of Fourier basis functions. By exploiting this sensitivity, they proposed a simple black-box adversarial attack: Single Fourier attack. To reduce structural sensitivity, we can use regularization of convolution filter weights since the sensitivity of linear transform can be assessed by the norm of the weights. However, standard regularization methods can prevent minimization of the loss function because they impose a tight constraint for obtaining high robustness. To solve this problem, Absum imposes a loose constraint; it penalizes the absolute values of the summation of the parameters in the convolution layers. Absum can improve robustness against single Fourier attack while being as simple and efficient as standard regularization methods (e.g., weight decay and L1 regularization). Our experiments demonstrate that Absum improves robustness against single Fourier attack more than standard regularization methods. Furthermore, we reveal that robust CNNs with Absum are more robust against transferred attacks due to decreasing the common sensitivity and against high-frequency noise than standard regularization methods. We also reveal that Absum can improve robustness against gradient-based attacks (projected gradient descent) when used with adversarial training."
  },
  "aaai2020_main_towardsoracleknowledgedistillationwithneuralarchitecturesearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Oracle Knowledge Distillation with Neural Architecture Search ",
    "authors": [
      "Minsoo Kang",
      "Jonghwan Mun",
      "Bohyung Han"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5866",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5866/5722",
    "published": "2020-02",
    "summary": "We present a novel framework of knowledge distillation that is capable of learning powerful and efficient student models from ensemble teacher networks. Our approach addresses the inherent model capacity issue between teacher and student and aims to maximize benefit from teacher models during distillation by reducing their capacity gap. Specifically, we employ a neural architecture search technique to augment useful structures and operations, where the searched network is appropriate for knowledge distillation towards student models and free from sacrificing its performance by fixing the network capacity. We also introduce an oracle knowledge distillation loss to facilitate model search and distillation using an ensemble-based teacher model, where a student network is learned to imitate oracle performance of the teacher. We perform extensive experiments on the image classification datasets\u2014CIFAR-100 and TinyImageNet\u2014using various networks. We also show that searching for a new student model is effective in both accuracy and memory size and that the searched models often outperform their teacher models thanks to neural architecture search with oracle knowledge distillation."
  },
  "aaai2020_main_large-scalemulti-viewsubspaceclusteringinlineartime": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Large-Scale Multi-View Subspace Clustering in Linear Time ",
    "authors": [
      "Zhao Kang",
      "Wangtao Zhou",
      "Zhitong Zhao",
      "Junming Shao",
      "Meng Han",
      "Zenglin Xu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5867",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5867/5723",
    "published": "2020-02",
    "summary": "A plethora of multi-view subspace clustering (MVSC) methods have been proposed over the past few years. Researchers manage to boost clustering accuracy from different points of view. However, many state-of-the-art MVSC algorithms, typically have a quadratic or even cubic complexity, are inefficient and inherently difficult to apply at large scales. In the era of big data, the computational issue becomes critical. To fill this gap, we propose a large-scale MVSC (LMVSC) algorithm with linear order complexity. Inspired by the idea of anchor graph, we first learn a smaller graph for each view. Then, a novel approach is designed to integrate those graphs so that we can implement spectral clustering on a smaller graph. Interestingly, it turns out that our model also applies to single-view scenario. Extensive experiments on various large-scale benchmark data sets validate the effectiveness and efficiency of our approach with respect to state-of-the-art clustering methods."
  },
  "aaai2020_main_nonlinearsystemidentificationviatensorcompletion": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Nonlinear System Identification via Tensor Completion ",
    "authors": [
      "Nikos Kargas",
      "Nicholas D. Sidiropoulos"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5868",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5868/5724",
    "published": "2020-02",
    "summary": "Function approximation from input and output data pairs constitutes a fundamental problem in supervised learning. Deep neural networks are currently the most popular method for learning to mimic the input-output relationship of a general nonlinear system, as they have proven to be very effective in approximating complex highly nonlinear functions. In this work, we show that identifying a general nonlinear function y = \u0192(x1,\u2026,xN) from input-output examples can be formulated as a tensor completion problem and under certain conditions provably correct nonlinear system identification is possible. Specifically, we model the interactions between the N input variables and the scalar output of a system by a single N-way tensor, and setup a weighted low-rank tensor completion problem with smoothness regularization which we tackle using a block coordinate descent algorithm. We extend our method to the multi-output setting and the case of partially observed data, which cannot be readily handled by neural networks. Finally, we demonstrate the effectiveness of the approach using several regression tasks including some standard benchmarks and a challenging student grade prediction task."
  },
  "aaai2020_main_gradientbooststheapproximatevanishingideal": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Gradient Boosts the Approximate Vanishing Ideal ",
    "authors": [
      "Hiroshi Kera",
      "Yoshihiko Hasegawa"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5869",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5869/5725",
    "published": "2020-02",
    "summary": "In the last decade, the approximate vanishing ideal and its basis construction algorithms have been extensively studied in computer algebra and machine learning as a general model to reconstruct the algebraic variety on which noisy data approximately lie. In particular, the basis construction algorithms developed in machine learning are widely used in applications across many fields because of their monomial-order-free property; however, they lose many of the theoretical properties of computer-algebraic algorithms. In this paper, we propose general methods that equip monomial-order-free algorithms with several advantageous theoretical properties. Specifically, we exploit the gradient to (i) sidestep the spurious vanishing problem in polynomial time to remove symbolically trivial redundant bases, (ii) achieve consistent output with respect to the translation and scaling of input, and (iii) remove nontrivially redundant bases. The proposed methods work in a fully numerical manner, whereas existing algorithms require the awkward monomial order or exponentially costly (and mostly symbolic) computation to realize properties (i) and (iii). To our knowledge, property (ii) has not been achieved by any existing basis construction algorithm of the approximate vanishing ideal."
  },
  "aaai2020_main_beingoptimistictobeconservativequicklylearningacvarpolicy": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Being Optimistic to Be Conservative: Quickly Learning a CVaR Policy ",
    "authors": [
      "Ramtin Keramati",
      "Christoph Dann",
      "Alex Tamkin",
      "Emma Brunskill"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5870",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5870/5726",
    "published": "2020-02",
    "summary": "While maximizing expected return is the goal in most reinforcement learning approaches, risk-sensitive objectives such as conditional value at risk (CVaR) are more suitable for many high-stakes applications. However, relatively little is known about how to explore to quickly learn policies with good CVaR. In this paper, we present the first algorithm for sample-efficient learning of CVaR-optimal policies in Markov decision processes based on the optimism in the face of uncertainty principle. This method relies on a novel optimistic version of the distributional Bellman operator that moves probability mass from the lower to the upper tail of the return distribution. We prove asymptotic convergence and optimism of this operator for the tabular policy evaluation case. We further demonstrate that our algorithm finds CVaR-optimal policies substantially faster than existing baselines in several simulated environments with discrete and continuous state spaces."
  },
  "aaai2020_main_optionsofinteresttemporalabstractionwithinterestfunctions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Options of Interest: Temporal Abstraction with Interest Functions ",
    "authors": [
      "Khimya Khetarpal",
      "Martin Klissarov",
      "Maxime Chevalier-Boisvert",
      "Pierre-Luc Bacon",
      "Doina Precup"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5871",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5871/5727",
    "published": "2020-02",
    "summary": "Temporal abstraction refers to the ability of an agent to use behaviours of controllers which act for a limited, variable amount of time. The options framework describes such behaviours as consisting of a subset of states in which they can initiate, an internal policy and a stochastic termination condition. However, much of the subsequent work on option discovery has ignored the initiation set, because of difficulty in learning it from data. We provide a generalization of initiation sets suitable for general function approximation, by defining an interest function associated with an option. We derive a gradient-based learning algorithm for interest functions, leading to a new interest-option-critic architecture. We investigate how interest functions can be leveraged to learn interpretable and reusable temporal abstractions. We demonstrate the efficacy of the proposed approach through quantitative and qualitative results, in both discrete and continuous environments."
  },
  "aaai2020_main_plug-in,trainablegateforstreamliningarbitraryneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Plug-in, Trainable Gate for Streamlining Arbitrary Neural Networks ",
    "authors": [
      "Jaedeok Kim",
      "Chiyoun Park",
      "Hyun-Joo Jung",
      "Yoonsuck Choe"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5872",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5872/5728",
    "published": "2020-02",
    "summary": "Architecture optimization, which is a technique for finding an efficient neural network that meets certain requirements, generally reduces to a set of multiple-choice selection problems among alternative sub-structures or parameters. The discrete nature of the selection problem, however, makes this optimization difficult. To tackle this problem we introduce a novel concept of a trainable gate function. The trainable gate function, which confers a differentiable property to discrete-valued variables, allows us to directly optimize loss functions that include non-differentiable discrete values such as 0-1 selection. The proposed trainable gate can be applied to pruning. Pruning can be carried out simply by appending the proposed trainable gate functions to each intermediate output tensor followed by fine-tuning the overall model, using any gradient-based training methods. So the proposed method can jointly optimize the selection of the pruned channels while fine-tuning the weights of the pruned model at the same time. Our experimental results demonstrate that the proposed method efficiently optimizes arbitrary neural networks in various tasks such as image classification, style transfer, optical flow estimation, and neural machine translation."
  },
  "aaai2020_main_aunifiedframeworkforknowledgeintensivegradientboostingleveraginghumanexpertsfornoisysparsedomains": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Unified Framework for Knowledge Intensive Gradient Boosting: Leveraging Human Experts for Noisy Sparse Domains ",
    "authors": [
      "Harsha Kokel",
      "Phillip Odom",
      "Shuo Yang",
      "Sriraam Natarajan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5873",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5873/5729",
    "published": "2020-02",
    "summary": "Incorporating richer human inputs including qualitative constraints such as monotonic and synergistic influences has long been adapted inside AI. Inspired by this, we consider the problem of using such influence statements in the successful gradient-boosting framework. We develop a unified framework for both classification and regression settings that can both effectively and efficiently incorporate such constraints to accelerate learning to a better model. Our results in a large number of standard domains and two particularly novel real-world domains demonstrate the superiority of using domain knowledge rather than treating the human as a mere labeler."
  },
  "aaai2020_main_learningstudentnetworkswithfewdata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Student Networks with Few Data ",
    "authors": [
      "Shumin Kong",
      "Tianyu Guo",
      "Shan You",
      "Chang Xu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5874",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5874/5730",
    "published": "2020-02",
    "summary": "Recently, the teacher-student learning paradigm has drawn much attention in compressing neural networks on low-end edge devices, such as mobile phones and wearable watches. Current algorithms mainly assume the complete dataset for the teacher network is also available for the training of the student network. However, for real-world scenarios, users may only have access to part of training examples due to commercial profits or data privacy, and severe over-fitting issues would happen as a result. In this paper, we tackle the challenge of learning student networks with few data by investigating the ground-truth data-generating distribution underlying these few data. Taking Wasserstein distance as the measurement, we assume this ideal data distribution lies in a neighborhood of the discrete empirical distribution induced by the training examples. Thus we propose to safely optimize the worst-case cost within this neighborhood to boost the generalization. Furthermore, with theoretical analysis, we derive a novel and easy-to-implement loss for training the student network in an end-to-end fashion. Experimental results on benchmark datasets validate the effectiveness of our proposed method."
  },
  "aaai2020_main_specifyingweightpriorsinbayesiandeepneuralnetworkswithempiricalbayes": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Specifying Weight Priors in Bayesian Deep Neural Networks with Empirical Bayes ",
    "authors": [
      "Ranganath Krishnan",
      "Mahesh Subedar",
      "Omesh Tickoo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5875",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5875/5731",
    "published": "2020-02",
    "summary": "Stochastic variational inference for Bayesian deep neural network (DNN) requires specifying priors and approximate posterior distributions over neural network weights. Specifying meaningful weight priors is a challenging problem, particularly for scaling variational inference to deeper architectures involving high dimensional weight space. We propose MOdel Priors with Empirical Bayes using DNN (MOPED) method to choose informed weight priors in Bayesian neural networks. We formulate a two-stage hierarchical modeling, first find the maximum likelihood estimates of weights with DNN, and then set the weight priors using empirical Bayes approach to infer the posterior with variational inference. We empirically evaluate the proposed approach on real-world tasks including image classification, video activity recognition and audio classification with varying complex neural network architectures. We also evaluate our proposed approach on diabetic retinopathy diagnosis task and benchmark with the state-of-the-art Bayesian deep learning techniques. We demonstrate MOPED method enables scalable variational inference and provides reliable uncertainty quantification."
  },
  "aaai2020_main_stablepredictionwithmodelmisspecificationandagnosticdistributionshift": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Stable Prediction with Model Misspecification and Agnostic Distribution Shift ",
    "authors": [
      "Kun Kuang",
      "Ruoxuan Xiong",
      "Peng Cui",
      "Susan Athey",
      "Bo Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5876",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5876/5732",
    "published": "2020-02",
    "summary": "For many machine learning algorithms, two main assumptions are required to guarantee performance. One is that the test data are drawn from the same distribution as the training data, and the other is that the model is correctly specified. In real applications, however, we often have little prior knowledge on the test data and on the underlying true model. Under model misspecification, agnostic distribution shift between training and test data leads to inaccuracy of parameter estimation and instability of prediction across unknown test data. To address these problems, we propose a novel Decorrelated Weighting Regression (DWR) algorithm which jointly optimizes a variable decorrelation regularizer and a weighted regression model. The variable decorrelation regularizer estimates a weight for each sample such that variables are decorrelated on the weighted training data. Then, these weights are used in the weighted regression to improve the accuracy of estimation on the effect of each variable, thus help to improve the stability of prediction across unknown test data. Extensive experiments clearly demonstrate that our DWR algorithm can significantly improve the accuracy of parameter estimation and stability of prediction with model misspecification and agnostic distribution shift."
  },
  "aaai2020_main_learningmax-satfromcontextualexamplesforcombinatorialoptimisation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning MAX-SAT from Contextual Examples for Combinatorial Optimisation ",
    "authors": [
      "Mohit Kumar",
      "Samuel Kolb",
      "Stefano Teso",
      "Luc De Raedt"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5877",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5877/5733",
    "published": "2020-02",
    "summary": "Combinatorial optimization problems are ubiquitous in artificial intelligence. Designing the underlying models, however, requires substantial expertise, which is a limiting factor in practice. The models typically consist of hard and soft constraints, or combine hard constraints with a preference function. We introduce a novel setting for learning combinatorial optimisation problems from contextual examples. These positive and negative examples show \u2013 in a particular context \u2013 whether the solutions are good enough or not. We develop our framework using the MAX-SAT formalism. We provide learnability results within the realizable and agnostic settings, as well as hassle, an implementation based on syntax-guided synthesis and showcase its promise on recovering synthetic and benchmark instances from examples."
  },
  "aaai2020_main_googleresearchfootballanovelreinforcementlearningenvironment": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Google Research Football: A Novel Reinforcement Learning Environment ",
    "authors": [
      "Karol Kurach",
      "Anton Raichuk",
      "Piotr Sta\u0144czyk",
      "Micha\u0142 Zaj\u0105c",
      "Olivier Bachem",
      "Lasse Espeholt",
      "Carlos Riquelme",
      "Damien Vincent",
      "Marcin Michalski",
      "Olivier Bousquet",
      "Sylvain Gelly"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5878",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5878/5734",
    "published": "2020-02",
    "summary": "Recent progress in the field of reinforcement learning has been accelerated by virtual learning environments such as video games, where novel algorithms and ideas can be quickly tested in a safe and reproducible manner. We introduce the Google Research Football Environment, a new reinforcement learning environment where agents are trained to play football in an advanced, physics-based 3D simulator. The resulting environment is challenging, easy to use and customize, and it is available under a permissive open-source license. In addition, it provides support for multiplayer and multi-agent experiments. We propose three full-game scenarios of varying difficulty with the Football Benchmarks and report baseline results for three commonly used reinforcement algorithms (IMPALA, PPO, and Ape-X DQN). We also provide a diverse set of simpler scenarios with the Football Academy and showcase several promising research directions."
  },
  "aaai2020_main_correctingpredictionsforapproximatebayesianinference": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Correcting Predictions for Approximate Bayesian Inference ",
    "authors": [
      "Tomasz Ku\u015bmierczyk",
      "Joseph Sakaya",
      "Arto Klami"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5879",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5879/5735",
    "published": "2020-02",
    "summary": "Bayesian models quantify uncertainty and facilitate optimal decision-making in downstream applications. For most models, however, practitioners are forced to use approximate inference techniques that lead to sub-optimal decisions due to incorrect posterior predictive distributions. We present a novel approach that corrects for inaccuracies in posterior inference by altering the decision-making process. We train a separate model to make optimal decisions under the approximate posterior, combining interpretable Bayesian modeling with optimization of direct predictive accuracy in a principled fashion. The solution is generally applicable as a plug-in module for predictive decision-making for arbitrary probabilistic programs, irrespective of the posterior inference strategy. We demonstrate the approach empirically in several problems, confirming its potential."
  },
  "aaai2020_main_improvedsubsampledrandomizedhadamardtransformforlinearsvm": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Improved Subsampled Randomized Hadamard Transform for Linear SVM ",
    "authors": [
      "Zijian Lei",
      "Liang Lan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5880",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5880/5736",
    "published": "2020-02",
    "summary": "Subsampled Randomized Hadamard Transform (SRHT), a popular random projection method that can efficiently project a d-dimensional data into r-dimensional space (r \u226a d) in O(dlog(d)) time, has been widely used to address the challenge of high-dimensionality in machine learning. SRHT works by rotating the input data matrix X \u2208 \u211dd \u00d7 n by Randomized Walsh-Hadamard Transform followed with a subsequent uniform column sampling on the rotated matrix. Despite the advantages of SRHT, one limitation of SRHT is that it generates the new low-dimensional embedding without considering any specific properties of a given dataset. Therefore, this data-independent random projection method may result in inferior and unstable performance when used for a particular machine learning task, e.g., classification. To overcome this limitation, we analyze the effect of using SRHT for random projection in the context of linear SVM classification. Based on our analysis, we propose importance sampling and deterministic top-r sampling to produce effective low-dimensional embedding instead of uniform sampling SRHT. In addition, we also proposed a new supervised non-uniform sampling method. Our experimental results have demonstrated that our proposed methods can achieve higher classification accuracies than SRHT and other random projection methods on six real-life datasets."
  },
  "aaai2020_main_asimpleandefficienttensorcalculus": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Simple and Efficient Tensor Calculus ",
    "authors": [
      "S\u00f6ren Laue",
      "Matthias Mitterreiter",
      "Joachim Giesen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5881",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5881/5737",
    "published": "2020-02",
    "summary": "Computing derivatives of tensor expressions, also known as tensor calculus, is a fundamental task in machine learning. A key concern is the efficiency of evaluating the expressions and their derivatives that hinges on the representation of these expressions. Recently, an algorithm for computing higher order derivatives of tensor expressions like Jacobians or Hessians has been introduced that is a few orders of magnitude faster than previous state-of-the-art approaches. Unfortunately, the approach is based on Ricci notation and hence cannot be incorporated into automatic differentiation frameworks like TensorFlow, PyTorch, autograd, or JAX that use the simpler Einstein notation. This leaves two options, to either change the underlying tensor representation in these frameworks or to develop a new, provably correct algorithm based on Einstein notation. Obviously, the first option is impractical. Hence, we pursue the second option. Here, we show that using Ricci notation is not necessary for an efficient tensor calculus and develop an equally efficient method for the simpler Einstein notation. It turns out that turning to Einstein notation enables further improvements that lead to even better efficiency."
  },
  "aaai2020_main_proximitypreservingbinarycodeusingsignedgraph-cut": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Proximity Preserving Binary Code Using Signed Graph-Cut ",
    "authors": [
      "Inbal Lavi",
      "Shai Avidan",
      "Yoram Singer",
      "Yacov Hel-Or"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5882",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5882/5738",
    "published": "2020-02",
    "summary": "We introduce a binary embedding framework, called Proximity Preserving Code (PPC), which learns similarity and dissimilarity between data points to create a compact and affinity-preserving binary code. This code can be used to apply fast and memory-efficient approximation to nearest-neighbor searches. Our framework is flexible, enabling different proximity definitions between data points. In contrast to previous methods that extract binary codes based on unsigned graph partitioning, our system models the attractive and repulsive forces in the data by incorporating positive and negative graph weights. The proposed framework is shown to boil down to finding the minimal cut of a signed graph, a problem known to be NP-hard. We offer an efficient approximation and achieve superior results by constructing the code bit after bit. We show that the proposed approximation is superior to the commonly used spectral methods with respect to both accuracy and complexity. Thus, it is useful for many other problems that can be translated into signed graph cut."
  },
  "aaai2020_main_residualneuralprocesses": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Residual Neural Processes ",
    "authors": [
      "Byung-Jun Lee",
      "Seunghoon Hong",
      "Kee-Eung Kim"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5883",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5883/5739",
    "published": "2020-02",
    "summary": "A Neural Process (NP) is a map from a set of observed input-output pairs to a predictive distribution over functions, which is designed to mimic other stochastic processes' inference mechanisms. NPs are shown to work effectively in tasks that require complex distributions, where traditional stochastic processes struggle, e.g. image completion tasks. This paper concerns the practical capacity of set function approximators despite their universality. By delving deeper into the relationship between an NP and a Bayesian last layer (BLL), it is possible to see that NPs may struggle in simple examples, which other stochastic processes can easily solve. In this paper, we propose a simple yet effective remedy; the Residual Neural Process (RNP) that leverages traditional BLL for faster training and better prediction. We demonstrate that the RNP shows faster convergence and better performance, both qualitatively and quantitatively."
  },
  "aaai2020_main_residualcontinuallearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Residual Continual Learning ",
    "authors": [
      "Janghyeon Lee",
      "Donggyu Joo",
      "Hyeong Gwon Hong",
      "Junmo Kim"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5884",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5884/5740",
    "published": "2020-02",
    "summary": "We propose a novel continual learning method called Residual Continual Learning (ResCL). Our method can prevent the catastrophic forgetting phenomenon in sequential learning of multiple tasks, without any source task information except the original network. ResCL reparameterizes network parameters by linearly combining each layer of the original network and a fine-tuned network; therefore, the size of the network does not increase at all. To apply the proposed method to general convolutional neural networks, the effects of batch normalization layers are also considered. By utilizing residual-learning-like reparameterization and a special weight decay loss, the trade-off between source and target performance is effectively controlled. The proposed method exhibits state-of-the-art performance in various continual learning scenarios."
  },
  "aaai2020_main_monte-carlotreesearchincontinuousactionspaceswithvaluegradients": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Monte-Carlo Tree Search in Continuous Action Spaces with Value Gradients ",
    "authors": [
      "Jongmin Lee",
      "Wonseok Jeon",
      "Geon-Hyeong Kim",
      "Kee-Eung Kim"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5885",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5885/5741",
    "published": "2020-02",
    "summary": "Monte-Carlo Tree Search (MCTS) is the state-of-the-art online planning algorithm for large problems with discrete action spaces. However, many real-world problems involve continuous action spaces, where MCTS is not as effective as in discrete action spaces. This is mainly due to common practices such as coarse discretization of the entire action space and failure to exploit local smoothness. In this paper, we introduce Value-Gradient UCT (VG-UCT), which combines traditional MCTS with gradient-based optimization of action particles. VG-UCT simultaneously performs a global search via UCT with respect to the finitely sampled set of actions and performs a local improvement via action value gradients. In the experiments, we demonstrate that our approach outperforms existing MCTS methods and other strong baseline algorithms for continuous action spaces."
  },
  "aaai2020_main_urnetuser-resizableresidualnetworkswithconditionalgatingmodule": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " URNet: User-Resizable Residual Networks with Conditional Gating Module ",
    "authors": [
      "Sangho Lee",
      "Simyung Chang",
      "Nojun Kwak"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5886",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5886/5742",
    "published": "2020-02",
    "summary": "Convolutional Neural Networks are widely used to process spatial scenes, but their computational cost is fixed and depends on the structure of the network used. There are methods to reduce the cost by compressing networks or varying its computational path dynamically according to the input image. However, since a user can not control the size of the learned model, it is difficult to respond dynamically if the amount of service requests suddenly increases. We propose User-Resizable Residual Networks (URNet), which allows users to adjust the computational cost of the network as needed during evaluation. URNet includes Conditional Gating Module (CGM) that determines the use of each residual block according to the input image and the desired cost. CGM is trained in a supervised manner using the newly proposed scale(cost) loss and its corresponding training methods. URNet can control the amount of computation and its inference path according to user's demand without degrading the accuracy significantly. In the experiments on ImageNet, URNet based on ResNet-101 maintains the accuracy of the baseline even when resizing it to approximately 80% of the original network, and demonstrates only about 1% accuracy degradation when using about 65% of the computation."
  },
  "aaai2020_main_spatiotemporallyconstrainedactionspaceattacksondeepreinforcementlearningagents": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Spatiotemporally Constrained Action Space Attacks on Deep Reinforcement Learning Agents ",
    "authors": [
      "Xian Yeow Lee",
      "Sambit Ghadai",
      "Kai Liang Tan",
      "Chinmay Hegde",
      "Soumik Sarkar"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5887",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5887/5743",
    "published": "2020-02",
    "summary": "Robustness of Deep Reinforcement Learning (DRL) algorithms towards adversarial attacks in real world applications such as those deployed in cyber-physical systems (CPS) are of increasing concern. Numerous studies have investigated the mechanisms of attacks on the RL agent's state space. Nonetheless, attacks on the RL agent's action space (corresponding to actuators in engineering systems) are equally perverse, but such attacks are relatively less studied in the ML literature. In this work, we first frame the problem as an optimization problem of minimizing the cumulative reward of an RL agent with decoupled constraints as the budget of attack. We propose the white-box Myopic Action Space (MAS) attack algorithm that distributes the attacks across the action space dimensions. Next, we reformulate the optimization problem above with the same objective function, but with a temporally coupled constraint on the attack budget to take into account the approximated dynamics of the agent. This leads to the white-box Look-ahead Action Space (LAS) attack algorithm that distributes the attacks across the action and temporal dimensions. Our results showed that using the same amount of resources, the LAS attack deteriorates the agent's performance significantly more than the MAS attack. This reveals the possibility that with limited resource, an adversary can utilize the agent's dynamics to malevolently craft attacks that causes the agent to fail. Additionally, we leverage these attack strategies as a possible tool to gain insights on the potential vulnerabilities of DRL agents."
  },
  "aaai2020_main_robustnesscertificatesforsparseadversarialattacksbyrandomizedablation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Robustness Certificates for Sparse Adversarial Attacks by Randomized Ablation ",
    "authors": [
      "Alexander Levine",
      "Soheil Feizi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5888",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5888/5744",
    "published": "2020-02",
    "summary": "Recently, techniques have been developed to provably guarantee the robustness of a classifier to adversarial perturbations of bounded L1 and L2 magnitudes by using randomized smoothing: the robust classification is a consensus of base classifications on randomly noised samples where the noise is additive. In this paper, we extend this technique to the L0 threat model. We propose an efficient and certifiably robust defense against sparse adversarial attacks by randomly ablating input features, rather than using additive noise. Experimentally, on MNIST, we can certify the classifications of over 50% of images to be robust to any distortion of at most 8 pixels. This is comparable to the observed empirical robustness of unprotected classifiers on MNIST to modern L0 attacks, demonstrating the tightness of the proposed robustness certificate. We also evaluate our certificate on ImageNet and CIFAR-10. Our certificates represent an improvement on those provided in a concurrent work (Lee et al. 2019) which uses random noise rather than ablation (median certificates of 8 pixels versus 4 pixels on MNIST; 16 pixels versus 1 pixel on ImageNet.) Additionally, we empirically demonstrate that our classifier is highly robust to modern sparse adversarial attacks on MNIST. Our classifications are robust, in median, to adversarial perturbations of up to 31 pixels, compared to 22 pixels reported as the state-of-the-art defense, at the cost of a slight decrease (around 2.3%) in the classification accuracy. Code and supplementary material is available at https://github.com/alevine0/randomizedAblation/."
  },
  "aaai2020_main_stochasticallyrobustpersonalizedrankingforlshrecommendationretrieval": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Stochastically Robust Personalized Ranking for LSH Recommendation Retrieval ",
    "authors": [
      "Dung D. Le",
      "Hady W. Lauw"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5889",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5889/5745",
    "published": "2020-02",
    "summary": "Locality Sensitive Hashing (LSH) has become one of the most commonly used approximate nearest neighbor search techniques to avoid the prohibitive cost of scanning through all data points. For recommender systems, LSH achieves efficient recommendation retrieval by encoding user and item vectors into binary hash codes, reducing the cost of exhaustively examining all the item vectors to identify the top-k items. However, conventional matrix factorization models may suffer from performance degeneration caused by randomly-drawn LSH hash functions, directly affecting the ultimate quality of the recommendations. In this paper, we propose a framework named \u00f8urmodel, which factors in the stochasticity of LSH hash functions when learning real-valued user and item latent vectors, eventually improving the recommendation accuracy after LSH indexing. Experiments on publicly available datasets show that the proposed framework not only effectively learns user's preferences for prediction, but also achieves high compatibility with LSH stochasticity, producing superior post-LSH indexing performances as compared to state-of-the-art baselines."
  },
  "aaai2020_main_beyondunfoldingexactrecoveryoflatentconvextensordecompositionunderreshuffling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Beyond Unfolding: Exact Recovery of Latent Convex Tensor Decomposition Under Reshuffling ",
    "authors": [
      "Chao Li",
      "Mohammad Emtiyaz Khan",
      "Zhun Sun",
      "Gang Niu",
      "Bo Han",
      "Shengli Xie",
      "Qibin Zhao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5890",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5890/5746",
    "published": "2020-02",
    "summary": "Exact recovery of tensor decomposition (TD) methods is a desirable property in both unsupervised learning and scientific data analysis. The numerical defects of TD methods, however, limit their practical applications on real-world data. As an alternative, convex tensor decomposition (CTD) was proposed to alleviate these problems, but its exact-recovery property is not properly addressed so far. To this end, we focus on latent convex tensor decomposition (LCTD), a practically widely-used CTD model, and rigorously prove a sufficient condition for its exact-recovery property. Furthermore, we show that such property can be also achieved by a more general model than LCTD. In the new model, we generalize the classic tensor (un-)folding into reshuffling operation, a more flexible mapping to relocate the entries of the matrix into a tensor. Armed with the reshuffling operations and exact-recovery property, we explore a totally novel application for (generalized) LCTD, i.e., image steganography. Experimental results on synthetic data validate our theory, and results on image steganography show that our method outperforms the state-of-the-art methods."
  },
  "aaai2020_main_infrared-visiblecross-modalpersonre-identificationwithanxmodality": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Infrared-Visible Cross-Modal Person Re-Identification with an X Modality ",
    "authors": [
      "Diangang Li",
      "Xing Wei",
      "Xiaopeng Hong",
      "Yihong Gong"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5891",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5891/5747",
    "published": "2020-02",
    "summary": "This paper focuses on the emerging Infrared-Visible cross-modal person re-identification task (IV-ReID), which takes infrared images as input and matches with visible color images. IV-ReID is important yet challenging, as there is a significant gap between the visible and infrared images. To reduce this \u2018gap\u2019, we introduce an auxiliary X modality as an assistant and reformulate infrared-visible dual-mode cross-modal learning as an X-Infrared-Visible three-mode learning problem. The X modality restates from RGB channels to a format with which cross-modal learning can be easily performed. With this idea, we propose an X-Infrared-Visible (XIV) ReID cross-modal learning framework. Firstly, the X modality is generated by a lightweight network, which is learnt in a self-supervised manner with the labels inherited from visible images. Secondly, under the XIV framework, cross-modal learning is guided by a carefully designed modality gap constraint, with information exchanged cross the visible, X, and infrared modalities. Extensive experiments are performed on two challenging datasets SYSU-MM01 and RegDB to evaluate the proposed XIV-ReID approach. Experimental results show that our method considerably achieves an absolute gain of over 7% in terms of rank 1 and mAP even compared with the latest state-of-the-art methods."
  },
  "aaai2020_main_automatedspectralkernellearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Automated Spectral Kernel Learning ",
    "authors": [
      "Jian Li",
      "Yong Liu",
      "Weiping Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5892",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5892/5748",
    "published": "2020-02",
    "summary": "The generalization performance of kernel methods is largely determined by the kernel, but spectral representations of stationary kernels are both input-independent and output-independent, which limits their applications on complicated tasks. In this paper, we propose an efficient learning framework that incorporates the process of finding suitable kernels and model training. Using non-stationary spectral kernels and backpropagation w.r.t. the objective, we obtain favorable spectral representations that depends on both inputs and outputs. Further, based on Rademacher complexity, we derive data-dependent generalization error bounds, where we investigate the effect of those factors and introduce regularization terms to improve the performance. Extensive experimental results validate the effectiveness of the proposed algorithm and coincide with our theoretical findings."
  },
  "aaai2020_main_graphattentionbasedproposal3dconvnetsforactiondetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Graph Attention Based Proposal 3D ConvNets for Action Detection ",
    "authors": [
      "Jin Li",
      "Xianglong Liu",
      "Zhuofan Zong",
      "Wanru Zhao",
      "Mingyuan Zhang",
      "Jingkuan Song"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5893",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5893/5749",
    "published": "2020-02",
    "summary": "The recent advances in 3D Convolutional Neural Networks (3D CNNs) have shown promising performance for untrimmed video action detection, employing the popular detection framework that heavily relies on the temporal action proposal generations as the input of the action detector and localization regressor. In practice the proposals usually contain strong intra and inter relations among them, mainly stemming from the temporal and spatial variations in the video actions. However, most of existing 3D CNNs ignore the relations and thus suffer from the redundant proposals degenerating the detection performance and efficiency. To address this problem, we propose graph attention based proposal 3D ConvNets (AGCN-P-3DCNNs) for video action detection. Specifically, our proposed graph attention is composed of intra attention based GCN and inter attention based GCN. We use intra attention to learn the intra long-range dependencies inside each action proposal and update node matrix of Intra Attention based GCN, and use inter attention to learn the inter dependencies between different action proposals as adjacency matrix of Inter Attention based GCN. Afterwards, we fuse intra and inter attention to model intra long-range dependencies and inter dependencies simultaneously. Another contribution is that we propose a simple and effective framewise classifier, which enhances the feature presentation capabilities of backbone model. Experiments on two proposal 3D ConvNets based models (P-C3D and P-ResNet) and two popular action detection benchmarks (THUMOS 2014, ActivityNet v1.3) demonstrate the state-of-the-art performance achieved by our method. Particularly, P-C3D embedded with our module achieves average mAP 3.7% improvement on THUMOS 2014 dataset compared to original model."
  },
  "aaai2020_main_symmetricmetriclearningwithadaptivemarginforrecommendation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Symmetric Metric Learning with Adaptive Margin for Recommendation ",
    "authors": [
      "Mingming Li",
      "Shuai Zhang",
      "Fuqing Zhu",
      "Wanhui Qian",
      "Liangjun Zang",
      "Jizhong Han",
      "Songlin Hu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5894",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5894/5750",
    "published": "2020-02",
    "summary": "Metric learning based methods have attracted extensive interests in recommender systems. Current methods take the user-centric way in metric space to ensure the distance between user and negative item to be larger than that between the current user and positive item by a fixed margin. While they ignore the relations among positive item and negative item. As a result, these two items might be positioned closely, leading to incorrect results. Meanwhile, different users usually have different preferences, the fixed margin used in those methods can not be adaptive to various user biases, and thus decreases the performance as well. To address these two problems, a novel Symmetic Metric Learning with adaptive margin (SML) is proposed. In addition to the current user-centric metric, it symmetically introduces a positive item-centric metric which maintains closer distance from positive items to user, and push the negative items away from the positive items at the same time. Moreover, the dynamically adaptive margins are well trained to mitigate the impact of bias. Experimental results on three public recommendation datasets demonstrate that SML produces a competitive performance compared with several state-of-the-art methods."
  },
  "aaai2020_main_practicalfederatedgradientboostingdecisiontrees": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Practical Federated Gradient Boosting Decision Trees ",
    "authors": [
      "Qinbin Li",
      "Zeyi Wen",
      "Bingsheng He"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5895",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5895/5751",
    "published": "2020-02",
    "summary": "Gradient Boosting Decision Trees (GBDTs) have become very successful in recent years, with many awards in machine learning and data mining competitions. There have been several recent studies on how to train GBDTs in the federated learning setting. In this paper, we focus on horizontal federated learning, where data samples with the same features are distributed among multiple parties. However, existing studies are not efficient or effective enough for practical use. They suffer either from the inefficiency due to the usage of costly data transformations such as secure sharing and homomorphic encryption, or from the low model accuracy due to differential privacy designs. In this paper, we study a practical federated environment with relaxed privacy constraints. In this environment, a dishonest party might obtain some information about the other parties' data, but it is still impossible for the dishonest party to derive the actual raw data of other parties. Specifically, each party boosts a number of trees by exploiting similarity information based on locality-sensitive hashing. We prove that our framework is secure without exposing the original record to other parties, while the computation overhead in the training process is kept low. Our experimental studies show that, compared with normal training with the local data of each party, our approach can significantly improve the predictive accuracy, and achieve comparable accuracy to the original GBDT with the data from all parties."
  },
  "aaai2020_main_newefficientmulti-spikelearningforfastprocessingandrobustlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " New Efficient Multi-Spike Learning for Fast Processing and Robust Learning ",
    "authors": [
      "Shenglan Li",
      "Qiang Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5896",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5896/5752",
    "published": "2020-02",
    "summary": "Spiking neural networks (SNNs) are considered to be more biologically plausible and lower power consuming than traditional artificial neural networks (ANNs). SNNs use discrete spikes as input and output, but how to process and learn these discrete spikes efficiently and accurately still remains a challenging task. Moreover, most existing learning methods are inefficient with complicated neuron dynamics and learning procedures being involved. In this paper, we propose efficient alternatives by firstly introducing a simplified and efficient neuron model. Based on it, we develop two new multi-spike learning rules together with an event-driven scheme being presented to improve the processing efficiency. We show that, with the as-proposed rules, a single neuron can be trained to successfully perform challenging tasks such as multi-category classification and feature extraction. Our learning methods demonstrate a significant robustness against various strong noises. Moreover, experimental results on some real-world classification tasks show that our approaches yield higher efficiency with less requirement on computation resource, highlighting the advantages and potential of spike-based processing and driving more efforts towards neuromorphic computing."
  },
  "aaai2020_main_solvinggeneralellipticalmixturemodelsthroughanapproximatewassersteinmanifold": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Solving General Elliptical Mixture Models through an Approximate Wasserstein Manifold ",
    "authors": [
      "Shengxi Li",
      "Zeyang Yu",
      "Min Xiang",
      "Danilo Mandic"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5897",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5897/5753",
    "published": "2020-02",
    "summary": "We address the estimation problem for general finite mixture models, with a particular focus on the elliptical mixture models (EMMs). Compared to the widely adopted Kullback\u2013Leibler divergence, we show that the Wasserstein distance provides a more desirable optimisation space. We thus provide a stable solution to the EMMs that is both robust to initialisations and reaches a superior optimum by adaptively optimising along a manifold of an approximate Wasserstein distance. To this end, we first provide a unifying account of computable and identifiable EMMs, which serves as a basis to rigorously address the underpinning optimisation problem. Due to a probability constraint, solving this problem is extremely cumbersome and unstable, especially under the Wasserstein distance. To relieve this issue, we introduce an efficient optimisation method on a statistical manifold defined under an approximate Wasserstein distance, which allows for explicit metrics and computable operations, thus significantly stabilising and improving the EMM estimation. We further propose an adaptive method to accelerate the convergence. Experimental results demonstrate the excellent performance of the proposed EMM solver."
  },
  "aaai2020_main_coupled-viewdeepclassifierlearningfrommultiplenoisyannotators": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Coupled-View Deep Classifier Learning from Multiple Noisy Annotators ",
    "authors": [
      "Shikun Li",
      "Shiming Ge",
      "Yingying Hua",
      "Chunhui Zhang",
      "Hao Wen",
      "Tengfei Liu",
      "Weiqiang Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5898",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5898/5754",
    "published": "2020-02",
    "summary": "Typically, learning a deep classifier from massive cleanly annotated instances is effective but impractical in many real-world scenarios. An alternative is collecting and aggregating multiple noisy annotations for each instance to train the classifier. Inspired by that, this paper proposes to learn deep classifier from multiple noisy annotators via a coupled-view learning approach, where the learning view from data is represented by deep neural networks for data classification and the learning view from labels is described by a Naive Bayes classifier for label aggregation. Such coupled-view learning is converted to a supervised learning problem under the mutual supervision of the aggregated and predicted labels, and can be solved via alternate optimization to update labels and refine the classifiers. To alleviate the propagation of incorrect labels, small-loss metric is proposed to select reliable instances in both views. A co-teaching strategy with class-weighted loss is further leveraged in the deep classifier learning, which uses two networks with different learning abilities to teach each other, and the diverse errors introduced by noisy labels can be filtered out by peer networks. By these strategies, our approach can finally learn a robust data classifier which less overfits to label noise. Experimental results on synthetic and real data demonstrate the effectiveness and robustness of the proposed approach."
  },
  "aaai2020_main_stochasticonlinelearningwithprobabilisticgraphfeedback": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Stochastic Online Learning with Probabilistic Graph Feedback ",
    "authors": [
      "Shuai Li",
      "Wei Chen",
      "Zheng Wen",
      "Kwong-Sak Leung"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5899",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5899/5755",
    "published": "2020-02",
    "summary": "We consider a problem of stochastic online learning with general probabilistic graph feedback, where each directed edge in the feedback graph has probability pij. Two cases are covered. (a) The one-step case, where after playing arm i the learner observes a sample reward feedback of arm j with independent probability pij. (b) The cascade case where after playing arm i the learner observes feedback of all arms j in a probabilistic cascade starting from i \u2013 for each (i,j) with probability pij, if arm i is played or observed, then a reward sample of arm j would be observed with independent probability pij. Previous works mainly focus on deterministic graphs which corresponds to one-step case with pij \u2208 {0,1}, an adversarial sequence of graphs with certain topology guarantees, or a specific type of random graphs. We analyze the asymptotic lower bounds and design algorithms in both cases. The regret upper bounds of the algorithms match the lower bounds with high probability."
  },
  "aaai2020_main_relationinferenceamongsensortimeseriesinsmartbuildingswithmetriclearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Relation Inference among Sensor Time Series in Smart Buildings with Metric Learning ",
    "authors": [
      "Shuheng Li",
      "Dezhi Hong",
      "Hongning Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5900",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5900/5756",
    "published": "2020-02",
    "summary": "Smart Building Technologies hold promise for better livability for residents and lower energy footprints. Yet, the rollout of these technologies, from demand response controls to fault detection and diagnosis, significantly lags behind and is impeded by the current practice of manual identification of sensing point relationships, e.g., how equipment is connected or which sensors are co-located in the same space. This manual process is still error-prone, albeit costly and laborious."
  },
  "aaai2020_main_co-gcnformulti-viewsemi-supervisedlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Co-GCN for Multi-View Semi-Supervised Learning ",
    "authors": [
      "Shu Li",
      "Wen-Tao Li",
      "Wei Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5901",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5901/5757",
    "published": "2020-02",
    "summary": "In many real-world applications, the data have several disjoint sets of features and each set is called as a view. Researchers have developed many multi-view learning methods in the past decade. In this paper, we bring Graph Convolutional Network (GCN) into multi-view learning and propose a novel multi-view semi-supervised learning method Co-GCN by adaptively exploiting the graph information from the multiple views with combined Laplacians. Experimental results on real-world data sets verify that Co-GCN can achieve better performance compared with state-of-the-art multi-view semi-supervised methods."
  },
  "aaai2020_main_tweedie-hawkesprocessesinterpretingthephenomenaofoutbreaks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Tweedie-Hawkes Processes: Interpreting the Phenomena of Outbreaks ",
    "authors": [
      "Tianbo Li",
      "Yiping Ke"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5902",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5902/5758",
    "published": "2020-02",
    "summary": "Self-exciting event sequences, in which the occurrence of an event increases the probability of triggering subsequent ones, are common in many disciplines. In this paper, we propose a Bayesian model called Tweedie-Hawkes Processes (THP), which is able to model the outbreaks of events and find out the dominant factors behind. THP leverages on the Tweedie distribution in capturing various excitation effects. A variational EM algorithm is developed for model inference. Some theoretical properties of THP, including the sub-criticality, convergence of the learning algorithm and kernel selection method are discussed. Applications to Epidemiology and information diffusion analysis demonstrate the versatility of our model in various disciplines. Evaluations on real-world datasets show that THP outperforms the rival state-of-the-art baselines in the task of forecasting future events."
  },
  "aaai2020_main_neuralgraphembeddingforneuralarchitecturesearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Neural Graph Embedding for Neural Architecture Search ",
    "authors": [
      "Wei Li",
      "Shaogang Gong",
      "Xiatian Zhu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5903",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5903/5759",
    "published": "2020-02",
    "summary": "Existing neural architecture search (NAS) methods often operate in discrete or continuous spaces directly, which ignores the graphical topology knowledge of neural networks. This leads to suboptimal search performance and efficiency, given the factor that neural networks are essentially directed acyclic graphs (DAG). In this work, we address this limitation by introducing a novel idea of neural graph embedding (NGE). Specifically, we represent the building block (i.e. the cell) of neural networks with a neural DAG, and learn it by leveraging a Graph Convolutional Network to propagate and model the intrinsic topology information of network architectures. This results in a generic neural network representation integrable with different existing NAS frameworks. Extensive experiments show the superiority of NGE over the state-of-the-art methods on image classification and semantic segmentation."
  },
  "aaai2020_main_understandingthedisharmonybetweenweightnormalizationfamilyandweightdecay": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Understanding the Disharmony between Weight Normalization Family and Weight Decay ",
    "authors": [
      "Xiang Li",
      "Shuo Chen",
      "Jian Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5904",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5904/5760",
    "published": "2020-02",
    "summary": "The merits of fast convergence and potentially better performance of the weight normalization family have drawn increasing attention in recent years. These methods use standardization or normalization that changes the weight W to W\u2032, which makes W\u2032 independent to the magnitude of W. Surprisingly, W must be decayed during gradient descent, otherwise we will observe a severe under-fitting problem, which is very counter-intuitive since weight decay is widely known to prevent deep networks from over-fitting. Moreover, if we substitute (e.g., weight normalization) W\u2032 = W\u2225W\u2225 in the original loss function \u2211i L(\u0192(xi; W\u2032),yi) + \u00bd\u03bb\u2225W\u2032\u22252, it is observed that the regularization term \u00bd\u03bb\u2225W\u2032\u22252 will be canceled as a constant \u00bd \u03bb in the optimization objective. Therefore, to decay W, we need to explicitly append: \u00bd\u03bb\u2225W\u22252. In this paper, we theoretically prove that \u00bd\u03bb\u2225W\u22252 improves optimization only by modulating the effective learning rate and fairly has no influence on generalization when the weight normalization family is compositely employed. Furthermore, we also expose several serious problems when introducing weight decay term to weight normalization family, including the missing of global minimum, training instability and sensitivity of initialization. To address these problems, we propose an Adaptive Weight Shrink (AWS) scheme, which gradually shrinks the weights during optimization by a dynamic coefficient proportional to the magnitude of the parameter. This simple yet effective method appropriately controls the effective learning rate, which significantly improves the training stability and makes optimization more robust to initialization."
  },
  "aaai2020_main_dosubsamplednewtonmethodsworkforhigh-dimensionaldata?": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Do Subsampled Newton Methods Work for High-Dimensional Data? ",
    "authors": [
      "Xiang Li",
      "Shusen Wang",
      "Zhihua Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5905",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5905/5761",
    "published": "2020-02",
    "summary": "Subsampled Newton methods approximate Hessian matrices through subsampling techniques to alleviate the per-iteration cost. Previous results require \u03a9 (d) samples to approximate Hessians, where d is the dimension of data points, making it less practical for high-dimensional data. The situation is deteriorated when d is comparably as large as the number of data points n, which requires to take the whole dataset into account, making subsampling not useful. This paper theoretically justifies the effectiveness of subsampled Newton methods on strongly convex empirical risk minimization with high dimensional data. Specifically, we provably require only \u0398\u02dc(deff\u03b3) samples for approximating the Hessian matrices, where deff\u03b3 is the \u03b3-ridge leverage and can be much smaller than d as long as n\u03b3 \u226b 1. Our theories work for three types of Newton methods: subsampled Netwon, distributed Newton, and proximal Newton."
  },
  "aaai2020_main_flowscopespottingmoneylaunderingbasedongraphs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " FlowScope: Spotting Money Laundering Based on Graphs ",
    "authors": [
      "Xiangfeng Li",
      "Shenghua Liu",
      "Zifeng Li",
      "Xiaotian Han",
      "Chuan Shi",
      "Bryan Hooi",
      "He Huang",
      "Xueqi Cheng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5906",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5906/5762",
    "published": "2020-02",
    "summary": "Given a graph of the money transfers between accounts of a bank, how can we detect money laundering? Money laundering refers to criminals using the bank's services to move massive amounts of illegal money to untraceable destination accounts, in order to inject their illegal money into the legitimate financial system. Existing graph fraud detection approaches focus on dense subgraph detection, without considering the fact that money laundering involves high-volume flows of funds through chains of bank accounts, thereby decreasing their detection accuracy. Instead, we propose to model the transactions using a multipartite graph, and detect the complete flow of money from source to destination using a scalable algorithm, FlowScope. Theoretical analysis shows that FlowScope provides guarantees in terms of the amount of money that fraudsters can transfer without being detected. FlowScope outperforms state-of-the-art baselines in accurately detecting the accounts involved in money laundering, in both injected and real-world data settings."
  },
  "aaai2020_main_onthelearningpropertyoflogisticandsoftmaxlossesfordeepneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On the Learning Property of Logistic and Softmax Losses for Deep Neural Networks ",
    "authors": [
      "Xiangrui Li",
      "Xin Li",
      "Deng Pan",
      "Dongxiao Zhu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5907",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5907/5763",
    "published": "2020-02",
    "summary": "Deep convolutional neural networks (CNNs) trained with logistic and softmax losses have made significant advancement in visual recognition tasks in computer vision. When training data exhibit class imbalances, the class-wise reweighted version of logistic and softmax losses are often used to boost performance of the unweighted version. In this paper, motivated to explain the reweighting mechanism, we explicate the learning property of those two loss functions by analyzing the necessary condition (e.g., gradient equals to zero) after training CNNs to converge to a local minimum. The analysis immediately provides us explanations for understanding (1) quantitative effects of the class-wise reweighting mechanism: deterministic effectiveness for binary classification using logistic loss yet indeterministic for multi-class classification using softmax loss; (2) disadvantage of logistic loss for single-label multi-class classification via one-vs.-all approach, which is due to the averaging effect on predicted probabilities for the negative class (e.g., non-target classes) in the learning process. With the disadvantage and advantage of logistic loss disentangled, we thereafter propose a novel reweighted logistic loss for multi-class classification. Our simple yet effective formulation improves ordinary logistic loss by focusing on learning hard non-target classes (target vs. non-target class in one-vs.-all) and turned out to be competitive with softmax loss. We evaluate our method on several benchmark datasets to demonstrate its effectiveness."
  },
  "aaai2020_main_ivfssimpleandefficientfeatureselectionforhighdimensionaltopologypreservation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " IVFS: Simple and Efficient Feature Selection for High Dimensional Topology Preservation ",
    "authors": [
      "Xiaoyun Li",
      "Chenxi Wu",
      "Ping Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5908",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5908/5764",
    "published": "2020-02",
    "summary": "Feature selection is an important tool to deal with high dimensional data. In unsupervised case, many popular algorithms aim at maintaining the structure of the original data. In this paper, we propose a simple and effective feature selection algorithm to enhance sample similarity preservation through a new perspective, topology preservation, which is represented by persistent diagrams from the context of computational topology. This method is designed upon a unified feature selection framework called IVFS, which is inspired by random subset method. The scheme is flexible and can handle cases where the problem is analytically intractable. The proposed algorithm is able to well preserve the pairwise distances, as well as topological patterns, of the full data. We demonstrate that our algorithm can provide satisfactory performance under a sharp sub-sampling rate, which supports efficient implementation of our proposed method to large scale datasets. Extensive experiments validate the effectiveness of the proposed feature selection scheme."
  },
  "aaai2020_main_aforestfromthetreesgenerationthroughneighborhoods": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Forest from the Trees: Generation through Neighborhoods ",
    "authors": [
      "Yang Li",
      "Tianxiang Gao",
      "Junier Oliva"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5909",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5909/5765",
    "published": "2020-02",
    "summary": "In this work, we propose to learn a generative model using both learned features (through a latent space) and memories (through neighbors). Although human learning makes seamless use of both learned perceptual features and instance recall, current generative learning paradigms only make use of one of these two components. Take, for instance, flow models, which learn a latent space that follows a simple distribution. Conversely, kernel density techniques use instances to shift a simple distribution into an aggregate mixture model. Here we propose multiple methods to enhance the latent space of a flow model with neighborhood information. Not only does our proposed framework represent a more human-like approach by leveraging both learned features and memories, but it may also be viewed as a step forward in non-parametric methods. In addition, our proposed framework allows the user to easily control the properties of generated samples by targeting samples based on neighbors. The efficacy of our model is shown empirically with standard image datasets. We observe compelling results and a significant improvement over baselines. Combined further with a contrastive training mechanism, our proposed methods can effectively perform non-parametric novelty detection."
  },
  "aaai2020_main_efficientautomaticcashviarisingbandits": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Efficient Automatic CASH via Rising Bandits ",
    "authors": [
      "Yang Li",
      "Jiawei Jiang",
      "Jinyang Gao",
      "Yingxia Shao",
      "Ce Zhang",
      "Bin Cui"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5910",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5910/5766",
    "published": "2020-02",
    "summary": "The Combined Algorithm Selection and Hyperparameter optimization (CASH) is one of the most fundamental problems in Automatic Machine Learning (AutoML). The existing Bayesian optimization (BO) based solutions turn the CASH problem into a Hyperparameter Optimization (HPO) problem by combining the hyperparameters of all machine learning (ML) algorithms, and use BO methods to solve it. As a result, these methods suffer from the low-efficiency problem due to the huge hyperparameter space in CASH. To alleviate this issue, we propose the alternating optimization framework, where the HPO problem for each ML algorithm and the algorithm selection problem are optimized alternately. In this framework, the BO methods are used to solve the HPO problem for each ML algorithm separately, incorporating a much smaller hyperparameter space for BO methods. Furthermore, we introduce Rising Bandits, a CASH-oriented Multi-Armed Bandits (MAB) variant, to model the algorithm selection in CASH. This framework can take the advantages of both BO in solving the HPO problem with a relatively small hyperparameter space and the MABs in accelerating the algorithm selection. Moreover, we further develop an efficient online algorithm to solve the Rising Bandits with provably theoretical guarantees. The extensive experiments on 30 OpenML datasets demonstrate the superiority of the proposed approach over the competitive baselines."
  },
  "aaai2020_main_learningsignednetworkembeddingviagraphattention": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Signed Network Embedding via Graph Attention ",
    "authors": [
      "Yu Li",
      "Yuan Tian",
      "Jiawei Zhang",
      "Yi Chang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5911",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5911/5767",
    "published": "2020-02",
    "summary": "Learning the low-dimensional representations of graphs (i.e., network embedding) plays a critical role in network analysis and facilitates many downstream tasks. Recently graph convolutional networks (GCNs) have revolutionized the field of network embedding, and led to state-of-the-art performance in network analysis tasks such as link prediction and node classification. Nevertheless, most of the existing GCN-based network embedding methods are proposed for unsigned networks. However, in the real world, some of the networks are signed, where the links are annotated with different polarities, e.g., positive vs. negative. Since negative links may have different properties from the positive ones and can also significantly affect the quality of network embedding. Thus in this paper, we propose a novel network embedding framework SNEA to learn Signed Network Embedding via graph Attention. In particular, we propose a masked self-attentional layer, which leverages self-attention mechanism to estimate the importance coefficient for pair of nodes connected by different type of links during the embedding aggregation process. Then SNEA utilizes the masked self-attentional layers to aggregate more important information from neighboring nodes to generate the node embeddings based on balance theory. Experimental results demonstrate the effectiveness of the proposed framework through signed link prediction task on several real-world signed network datasets."
  },
  "aaai2020_main_rtnreparameterizedternarynetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " RTN: Reparameterized Ternary Network ",
    "authors": [
      "Yuhang Li",
      "Xin Dong",
      "Sai Qian Zhang",
      "Haoli Bai",
      "Yuanpeng Chen",
      "Wei Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5912",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5912/5768",
    "published": "2020-02",
    "summary": "To deploy deep neural networks on resource-limited devices, quantization has been widely explored. In this work, we study the extremely low-bit networks which have tremendous speed-up, memory saving with quantized activation and weights. We first bring up three omitted issues in extremely low-bit networks: the squashing range of quantized values; the gradient vanishing during backpropagation and the unexploited hardware acceleration of ternary networks. By reparameterizing quantized activation and weights vector with full precision scale and offset for fixed ternary vector, we decouple the range and magnitude from direction to extenuate above problems. Learnable scale and offset can automatically adjust the range of quantized values and sparsity without gradient vanishing. A novel encoding and computation pattern are designed to support efficient computing for our reparameterized ternary network (RTN). Experiments on ResNet-18 for ImageNet demonstrate that the proposed RTN finds a much better efficiency between bitwidth and accuracy and achieves up to 26.76% relative accuracy improvement compared with state-of-the-art methods. Moreover, we validate the proposed computation pattern on Field Programmable Gate Arrays (FPGA), and it brings 46.46 \u00d7 and 89.17 \u00d7 savings on power and area compared with the full precision convolution."
  },
  "aaai2020_main_learningtoautoweightentirelydata-drivenandhighlyefficientweightingframework": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Auto Weight: Entirely Data-Driven and Highly Efficient Weighting Framework ",
    "authors": [
      "Zhenmao Li",
      "Yichao Wu",
      "Ken Chen",
      "Yudong Wu",
      "Shunfeng Zhou",
      "Jiaheng Liu",
      "Jiaheng Liu",
      "Junjie Yan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5913",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5913/5769",
    "published": "2020-02",
    "summary": "Example weighting algorithm is an effective solution to the training bias problem, however, most previous typical methods are usually limited to human knowledge and require laborious tuning of hyperparameters. In this paper, we propose a novel example weighting framework called Learning to Auto Weight (LAW). The proposed framework finds step-dependent weighting policies adaptively, and can be jointly trained with target networks without any assumptions or prior knowledge about the dataset. It consists of three key components: Stage-based Searching Strategy (3SM) is adopted to shrink the huge searching space in a complete training process; Duplicate Network Reward (DNR) gives more accurate supervision by removing randomness during the searching process; Full Data Update (FDU) further improves the updating efficiency. Experimental results demonstrate the superiority of weighting policy explored by LAW over standard training pipeline. Compared with baselines, LAW can find a better weighting schedule which achieves much more superior accuracy on both biased CIFAR and ImageNet."
  },
  "aaai2020_main_adaptivetwo-dimensionalembeddedimageclustering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adaptive Two-Dimensional Embedded Image Clustering ",
    "authors": [
      "Zhihui Li",
      "Lina Yao",
      "Sen Wang",
      "Salil Kanhere",
      "Xue Li",
      "Huaxiang Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5914",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5914/5770",
    "published": "2020-02",
    "summary": "With the rapid development of mobile devices, people are generating huge volumes of images data every day for sharing on social media, which draws much research attention to understanding the contents of images. Image clustering plays an important role in image understanding systems. Often, most of the existing image clustering algorithms flatten digital images that are originally represented by matrices into 1D vectors as the image representation for the subsequent learning. The drawbacks of vector-based algorithms include limited consideration of spatial relationship between pixels and computational complexity, both of which blame to the simple vectorized representation. To overcome the drawbacks, we propose a novel image clustering framework that can work directly on matrices of images instead of flattened vectors. Specifically, the proposed algorithm simultaneously learn the clustering results and preserve the original correlation information within the image matrix. To solve the challenging objective function, we propose a fast iterative solution. Extensive experiments have been conducted on various benchmark datasets. The experimental results confirm the superiority of the proposed algorithm."
  },
  "aaai2020_main_tensorcompletionforweakly-dependentdataongraphformetropassengerflowprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Tensor Completion for Weakly-Dependent Data on Graph for Metro Passenger Flow Prediction ",
    "authors": [
      "Ziyue Li",
      "Nurettin Dorukhan Sergin",
      "Hao Yan",
      "Chen Zhang",
      "Fugee Tsung"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5915",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5915/5771",
    "published": "2020-02",
    "summary": "Low-rank tensor decomposition and completion have attracted significant interest from academia given the ubiquity of tensor data. However, low-rank structure is a global property, which will not be fulfilled when the data presents complex and weak dependencies given specific graph structures. One particular application that motivates this study is the spatiotemporal data analysis. As shown in the preliminary study, weakly dependencies can worsen the low-rank tensor completion performance. In this paper, we propose a novel low-rank CANDECOMP / PARAFAC (CP) tensor decomposition and completion framework by introducing the L1-norm penalty and Graph Laplacian penalty to model the weakly dependency on graph. We further propose an efficient optimization algorithm based on the Block Coordinate Descent for efficient estimation. A case study based on the metro passenger flow data in Hong Kong is conducted to demonstrate an improved performance over the regular tensor completion methods."
  },
  "aaai2020_main_lmlfmlongitudinalmulti-levelfactorizationmachine": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " LMLFM: Longitudinal Multi-Level Factorization Machine ",
    "authors": [
      "Junjie Liang",
      "Dongkuan Xu",
      "Yiwei Sun",
      "Vasant Honavar"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5916",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5916/5772",
    "published": "2020-02",
    "summary": "We consider the problem of learning predictive models from longitudinal data, consisting of irregularly repeated, sparse observations from a set of individuals over time. Such data often exhibit longitudinal correlation (LC) (correlations among observations for each individual over time), cluster correlation (CC) (correlations among individuals that have similar characteristics), or both. These correlations are often accounted for using mixed effects models that include fixed effects and random effects, where the fixed effects capture the regression parameters that are shared by all individuals, whereas random effects capture those parameters that vary across individuals. However, the current state-of-the-art methods are unable to select the most predictive fixed effects and random effects from a large number of variables, while accounting for complex correlation structure in the data and non-linear interactions among the variables. We propose Longitudinal Multi-Level Factorization Machine (LMLFM), to the best of our knowledge, the first model to address these challenges in learning predictive models from longitudinal data. We establish the convergence properties, and analyze the computational complexity, of LMLFM. We present results of experiments with both simulated and real-world longitudinal data which show that LMLFM outperforms the state-of-the-art methods in terms of predictive accuracy, variable selection ability, and scalability to data with large number of variables. The code and supplemental material is available at https://github.com/junjieliang672/LMLFM."
  },
  "aaai2020_main_instanceenhancementbatchnormalizationanadaptiveregulatorofbatchnoise": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Instance Enhancement Batch Normalization: An Adaptive Regulator of Batch Noise ",
    "authors": [
      "Senwei Liang",
      "Zhongzhan Huang",
      "Mingfu Liang",
      "Haizhao Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5917",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5917/5773",
    "published": "2020-02",
    "summary": "Batch Normalization (BN) (Ioffe and Szegedy 2015) normalizes the features of an input image via statistics of a batch of images and hence BN will bring the noise to the gradient of training loss. Previous works indicate that the noise is important for the optimization and generalization of deep neural networks, but too much noise will harm the performance of networks. In our paper, we offer a new point of view that the self-attention mechanism can help to regulate the noise by enhancing instance-specific information to obtain a better regularization effect. Therefore, we propose an attention-based BN called Instance Enhancement Batch Normalization (IEBN) that recalibrates the information of each channel by a simple linear transformation. IEBN has a good capacity of regulating the batch noise and stabilizing network training to improve generalization even in the presence of two kinds of noise attacks during training. Finally, IEBN outperforms BN with only a light parameter increment in image classification tasks under different network structures and benchmark datasets."
  },
  "aaai2020_main_differentiablealgorithmformarginalisingchangepoints": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Differentiable Algorithm for Marginalising Changepoints ",
    "authors": [
      "Hyoungjin Lim",
      "Gwonsoo Che",
      "Wonyeol Lee",
      "Hongseok Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5918",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5918/5774",
    "published": "2020-02",
    "summary": "We present an algorithm for marginalising changepoints in time-series models that assume a fixed number of unknown changepoints. Our algorithm is differentiable with respect to its inputs, which are the values of latent random variables other than changepoints. Also, it runs in time O(mn) where n is the number of time steps and m the number of changepoints, an improvement over a naive marginalisation method with O(nm) time complexity. We derive the algorithm by identifying quantities related to this marginalisation problem, showing that these quantities satisfy recursive relationships, and transforming the relationships to an algorithm via dynamic programming. Since our algorithm is differentiable, it can be applied to convert a model non-differentiable due to changepoints to a differentiable one, so that the resulting models can be analysed using gradient-based inference or learning techniques. We empirically show the effectiveness of our algorithm in this application by tackling the posterior inference problem on synthetic and real-world data."
  },
  "aaai2020_main_oogandisentanglingganwithone-hotsamplingandorthogonalregularization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " OOGAN: Disentangling GAN with One-Hot Sampling and Orthogonal Regularization ",
    "authors": [
      "Bingchen Liu",
      "Yizhe Zhu",
      "Zuohui Fu",
      "Gerard de Melo",
      "Ahmed Elgammal"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5919",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5919/5775",
    "published": "2020-02",
    "summary": "Exploring the potential of GANs for unsupervised disentanglement learning, this paper proposes a novel GAN-based disentanglement framework with One-Hot Sampling and Orthogonal Regularization (OOGAN). While previous works mostly attempt to tackle disentanglement learning through VAE and seek to implicitly minimize the Total Correlation (TC) objective with various sorts of approximation methods, we show that GANs have a natural advantage in disentangling with an alternating latent variable (noise) sampling method that is straightforward and robust. Furthermore, we provide a brand-new perspective on designing the structure of the generator and discriminator, demonstrating that a minor structural change and an orthogonal regularization on model weights entails an improved disentanglement. Instead of experimenting on simple toy datasets, we conduct experiments on higher-resolution images and show that OOGAN greatly pushes the boundary of unsupervised disentanglement."
  },
  "aaai2020_main_randomfourierfeaturesviafastsurrogateleverageweightedsampling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Random Fourier Features via Fast Surrogate Leverage Weighted Sampling ",
    "authors": [
      "Fanghui Liu",
      "Xiaolin Huang",
      "Yudong Chen",
      "Jie Yang",
      "Johan Suykens"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5920",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5920/5776",
    "published": "2020-02",
    "summary": "In this paper, we propose a fast surrogate leverage weighted sampling strategy to generate refined random Fourier features for kernel approximation. Compared to the current state-of-the-art method that uses the leverage weighted scheme (Li et al. 2019), our new strategy is simpler and more effective. It uses kernel alignment to guide the sampling process and it can avoid the matrix inversion operator when we compute the leverage function. Given n observations and s random features, our strategy can reduce the time complexity for sampling from O(ns2+s3) to O(ns2), while achieving comparable (or even slightly better) prediction performance when applied to kernel ridge regression (KRR). In addition, we provide theoretical guarantees on the generalization performance of our approach, and in particular characterize the number of random features required to achieve statistical guarantees in KRR. Experiments on several benchmark datasets demonstrate that our algorithm achieves comparable prediction performance and takes less time cost when compared to (Li et al. 2019)."
  },
  "aaai2020_main_ec-ganinferringbraineffectiveconnectivityviagenerativeadversarialnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " EC-GAN: Inferring Brain Effective Connectivity via Generative Adversarial Networks ",
    "authors": [
      "Jinduo Liu",
      "Junzhong Ji",
      "Guangxu Xun",
      "Liuyi Yao",
      "Mengdi Huai",
      "Aidong Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5921",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5921/5777",
    "published": "2020-02",
    "summary": "Inferring effective connectivity between different brain regions from functional magnetic resonance imaging (fMRI) data is an important advanced study in neuroinformatics in recent years. However, current methods have limited usage in effective connectivity studies due to the high noise and small sample size of fMRI data. In this paper, we propose a novel framework for inferring effective connectivity based on generative adversarial networks (GAN), named as EC-GAN. The proposed framework EC-GAN infers effective connectivity via an adversarial process, in which we simultaneously train two models: a generator and a discriminator. The generator consists of a set of effective connectivity generators based on structural equation models which can generate the fMRI time series of each brain region via effective connectivity. Meanwhile, the discriminator is employed to distinguish between the joint distributions of the real and generated fMRI time series. Experimental results on simulated data show that EC-GAN can better infer effective connectivity compared to other state-of-the-art methods. The real-world experiments indicate that EC-GAN can provide a new and reliable perspective analyzing the effective connectivity of fMRI data."
  },
  "aaai2020_main_acluster-weightedkernelk-meansmethodformulti-viewclustering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Cluster-Weighted Kernel K-Means Method for Multi-View Clustering ",
    "authors": [
      "Jing Liu",
      "Fuyuan Cao",
      "Xiao-Zhi Gao",
      "Liqin Yu",
      "Jiye Liang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5922",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5922/5778",
    "published": "2020-02",
    "summary": "Clustering by jointly exploiting information from multiple views can yield better performance than clustering on one single view. Some existing multi-view clustering methods aim at learning a weight for each view to determine its contribution to the final solution. However, the view-weighted scheme can only indicate the overall importance of a view, which fails to recognize the importance of each inner cluster of a view. A view with higher weight cannot guarantee all clusters in this view have higher importance than them in other views. In this paper, we propose a cluster-weighted kernel k-means method for multi-view clustering. Each inner cluster of each view is assigned a weight, which is learned based on the intra-cluster similarity of the cluster compared with all its corresponding clusters in different views, to make the cluster with higher intra-cluster similarity have a higher weight among the corresponding clusters. The cluster labels are learned simultaneously with the cluster weights in an alternative updating way, by minimizing the weighted sum-of-squared errors of the kernel k-means. Compared with the view-weighted scheme, the cluster-weighted scheme enhances the interpretability for the clustering results. Experimental results on both synthetic and real data sets demonstrate the effectiveness of the proposed method."
  },
  "aaai2020_main_attributepropagationnetworkforgraphzero-shotlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Attribute Propagation Network for Graph Zero-Shot Learning ",
    "authors": [
      "Lu Liu",
      "Tianyi Zhou",
      "Guodong Long",
      "Jing Jiang",
      "Chengqi Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5923",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5923/5779",
    "published": "2020-02",
    "summary": "The goal of zero-shot learning (ZSL) is to train a model to classify samples of classes that were not seen during training. To address this challenging task, most ZSL methods relate unseen test classes to seen(training) classes via a pre-defined set of attributes that can describe all classes in the same semantic space, so the knowledge learned on the training classes can be adapted to unseen classes. In this paper, we aim to optimize the attribute space for ZSL by training a propagation mechanism to refine the semantic attributes of each class based on its neighbors and related classes on a graph of classes. We show that the propagated attributes can produce classifiers for zero-shot classes with significantly improved performance in different ZSL settings. The graph of classes is usually free or very cheap to acquire such as WordNet or ImageNet classes. When the graph is not provided, given pre-defined semantic embeddings of the classes, we can learn a mechanism to generate the graph in an end-to-end manner along with the propagation mechanism. However, this graph-aided technique has not been well-explored in the literature. In this paper, we introduce the \u201cattribute propagation network (APNet)\u201d, which is composed of 1) a graph propagation model generating attribute vector for each class and 2) a parameterized nearest neighbor (NN) classifier categorizing an image to the class with the nearest attribute vector to the image's embedding. For better generalization over unseen classes, different from previous methods, we adopt a meta-learning strategy to train the propagation mechanism and the similarity metric for the NN classifier on multiple sub-graphs, each associated with a classification task over a subset of training classes. In experiments with two zero-shot learning settings and five benchmark datasets, APNet achieves either compelling performance or new state-of-the-art results."
  },
  "aaai2020_main_autocompressanautomaticdnnstructuredpruningframeworkforultra-highcompressionrates": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AutoCompress: An Automatic DNN Structured Pruning Framework for Ultra-High Compression Rates ",
    "authors": [
      "Ning Liu",
      "Xiaolong Ma",
      "Zhiyuan Xu",
      "Yanzhi Wang",
      "Jian Tang",
      "Jieping Ye"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5924",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5924/5780",
    "published": "2020-02",
    "summary": "Structured weight pruning is a representative model compression technique of DNNs to reduce the storage and computation requirements and accelerate inference. An automatic hyperparameter determination process is necessary due to the large number of flexible hyperparameters. This work proposes AutoCompress, an automatic structured pruning framework with the following key performance improvements: (i) effectively incorporate the combination of structured pruning schemes in the automatic process; (ii) adopt the state-of-art ADMM-based structured weight pruning as the core algorithm, and propose an innovative additional purification step for further weight reduction without accuracy loss; and (iii) develop effective heuristic search method enhanced by experience-based guided search, replacing the prior deep reinforcement learning technique which has underlying incompatibility with the target pruning problem. Extensive experiments on CIFAR-10 and ImageNet datasets demonstrate that AutoCompress is the key to achieve ultra-high pruning rates on the number of weights and FLOPs that cannot be achieved before. As an example, AutoCompress outperforms the prior work on automatic model compression by up to 33\u00d7 in pruning rate (120\u00d7 reduction in the actual parameter count) under the same accuracy. Significant inference speedup has been observed from the AutoCompress framework on actual measurements on smartphone. We release models of this work at anonymous link: http://bit.ly/2VZ63dS."
  },
  "aaai2020_main_stochasticlossfunction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Stochastic Loss Function ",
    "authors": [
      "Qingliang Liu",
      "Jinmei Lai"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5925",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5925/5781",
    "published": "2020-02",
    "summary": "Training deep neural networks is inherently subject to the predefined and fixed loss functions during optimizing. To improve learning efficiency, we develop Stochastic Loss Function (SLF) to dynamically and automatically generating appropriate gradients to train deep networks in the same round of back-propagation, while maintaining the completeness and differentiability of the training pipeline. In SLF, a generic loss function is formulated as a joint optimization problem of network weights and loss parameters. In order to guarantee the requisite efficiency, gradients with the respect to the generic differentiable loss are leveraged for selecting loss function and optimizing network weights. Extensive experiments on a variety of popular datasets strongly demonstrate that SLF is capable of obtaining appropriate gradients at different stages during training, and can significantly improve the performance of various deep models on real world tasks including classification, clustering, regression, neural machine translation, and objection detection."
  },
  "aaai2020_main_anadmmbasedframeworkforautomlpipelineconfiguration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An ADMM Based Framework for AutoML Pipeline Configuration ",
    "authors": [
      "Sijia Liu",
      "Parikshit Ram",
      "Deepak Vijaykeerthy",
      "Djallel Bouneffouf",
      "Gregory Bramble",
      "Horst Samulowitz",
      "Dakuo Wang",
      "Andrew Conn",
      "Alexander Gray"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5926",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5926/5782",
    "published": "2020-02",
    "summary": "We study the AutoML problem of automatically configuring machine learning pipelines by jointly selecting algorithms and their appropriate hyper-parameters for all steps in supervised learning pipelines. This black-box (gradient-free) optimization with mixed integer & continuous variables is a challenging problem. We propose a novel AutoML scheme by leveraging the alternating direction method of multipliers (ADMM). The proposed framework is able to (i) decompose the optimization problem into easier sub-problems that have a reduced number of variables and circumvent the challenge of mixed variable categories, and (ii) incorporate black-box constraints alongside the black-box optimization objective. We empirically evaluate the flexibility (in utilizing existing AutoML techniques), effectiveness (against open source AutoML toolkits), and unique capability (of executing AutoML with practically motivated black-box constraints) of our proposed scheme on a collection of binary classification data sets from UCI ML & OpenML repositories. We observe that on an average our framework provides significant gains in comparison to other AutoML frameworks (Auto-sklearn & TPOT), highlighting the practical advantages of this framework."
  },
  "aaai2020_main_layerwisesparsecodingforpruneddeepneuralnetworkswithextremecompressionratio": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Layerwise Sparse Coding for Pruned Deep Neural Networks with Extreme Compression Ratio ",
    "authors": [
      "Xiao Liu",
      "Wenbin Li",
      "Jing Huo",
      "Lili Yao",
      "Yang Gao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5927",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5927/5783",
    "published": "2020-02",
    "summary": "Deep neural network compression is important and increasingly developed especially in resource-constrained environments, such as autonomous drones and wearable devices. Basically, we can easily and largely reduce the number of weights of a trained deep model by adopting a widely used model compression technique, e.g., pruning. In this way, two kinds of data are usually preserved for this compressed model, i.e., non-zero weights and meta-data, where meta-data is employed to help encode and decode these non-zero weights. Although we can obtain an ideally small number of non-zero weights through pruning, existing sparse matrix coding methods still need a much larger amount of meta-data (may several times larger than non-zero weights), which will be a severe bottleneck of the deploying of very deep models. To tackle this issue, we propose a layerwise sparse coding (LSC) method to maximize the compression ratio by extremely reducing the amount of meta-data. We first divide a sparse matrix into multiple small blocks and remove zero blocks, and then propose a novel signed relative index (SRI) algorithm to encode the remaining non-zero blocks (with much less meta-data). In addition, the proposed LSC performs parallel matrix multiplication without full decoding, while traditional methods cannot. Through extensive experiments, we demonstrate that LSC achieves substantial gains in pruned DNN compression (e.g., 51.03x compression ratio on ADMM-Lenet) and inference computation (i.e., time reduction and extremely less memory bandwidth), over state-of-the-art baselines."
  },
  "aaai2020_main_weighted-samplingaudioadversarialexampleattack": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Weighted-Sampling Audio Adversarial Example Attack ",
    "authors": [
      "Xiaolei Liu",
      "Kun Wan",
      "Yufei Ding",
      "Xiaosong Zhang",
      "Qingxin Zhu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5928",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5928/5784",
    "published": "2020-02",
    "summary": "Recent studies have highlighted audio adversarial examples as a ubiquitous threat to state-of-the-art automatic speech recognition systems. Thorough studies on how to effectively generate adversarial examples are essential to prevent potential attacks. Despite many research on this, the efficiency and the robustness of existing works are not yet satisfactory. In this paper, we propose weighted-sampling audio adversarial examples, focusing on the numbers and the weights of distortion to reinforce the attack. Further, we apply a denoising method in the loss function to make the adversarial attack more imperceptible. Experiments show that our method is the first in the field to generate audio adversarial examples with low noise and high audio robustness at the minute time-consuming level 1."
  },
  "aaai2020_main_independencepromotedgraphdisentanglednetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Independence Promoted Graph Disentangled Networks ",
    "authors": [
      "Yanbei Liu",
      "Xiao Wang",
      "Shu Wu",
      "Zhitao Xiao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5929",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5929/5785",
    "published": "2020-02",
    "summary": "We address the problem of disentangled representation learning with independent latent factors in graph convolutional networks (GCNs). The current methods usually learn node representation by describing its neighborhood as a perceptual whole in a holistic manner while ignoring the entanglement of the latent factors. However, a real-world graph is formed by the complex interaction of many latent factors (e.g., the same hobby, education or work in social network). While little effort has been made toward exploring the disentangled representation in GCNs. In this paper, we propose a novel Independence Promoted Graph Disentangled Networks (IPGDN) to learn disentangled node representation while enhancing the independence among node representations. In particular, we firstly present disentangled representation learning by neighborhood routing mechanism, and then employ the Hilbert-Schmidt Independence Criterion (HSIC) to enforce independence between the latent representations, which is effectively integrated into a graph convolutional framework as a regularizer at the output layer. Experimental studies on real-world graphs validate our model and demonstrate that our algorithms outperform the state-of-the-arts by a wide margin in different network applications, including semi-supervised graph classification, graph clustering and graph visualization."
  },
  "aaai2020_main_adaptiveactivationnetworkandfunctionalregularizationforefficientandflexibledeepmulti-tasklearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adaptive Activation Network and Functional Regularization for Efficient and Flexible Deep Multi-Task Learning ",
    "authors": [
      "Yingru Liu",
      "Xuewen Yang",
      "Dongliang Xie",
      "Xin Wang",
      "Li Shen",
      "Haozhi Huang",
      "Niranjan Balasubramanian"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5930",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5930/5786",
    "published": "2020-02",
    "summary": "Multi-task learning (MTL) is a common paradigm that seeks to improve the generalization performance of task learning by training related tasks simultaneously. However, it is still a challenging problem to search the flexible and accurate architecture that can be shared among multiple tasks. In this paper, we propose a novel deep learning model called Task Adaptive Activation Network (TAAN) that can automatically learn the optimal network architecture for MTL. The main principle of TAAN is to derive flexible activation functions for different tasks from the data with other parameters of the network fully shared. We further propose two functional regularization methods that improve the MTL performance of TAAN. The improved performance of both TAAN and the regularization methods is demonstrated by comprehensive experiments."
  },
  "aaai2020_main_diversifiedinteractiverecommendationwithimplicitfeedback": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Diversified Interactive Recommendation with Implicit Feedback ",
    "authors": [
      "Yong Liu",
      "Yingtai Xiao",
      "Qiong Wu",
      "Chunyan Miao",
      "Juyong Zhang",
      "Binqiang Zhao",
      "Haihong Tang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5931",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5931/5787",
    "published": "2020-02",
    "summary": "Interactive recommender systems that enable the interactions between users and the recommender system have attracted increasing research attention. Previous methods mainly focus on optimizing recommendation accuracy. However, they usually ignore the diversity of the recommendation results, thus usually results in unsatisfying user experiences. In this paper, we propose a novel diversified recommendation model, named Diversified Contextual Combinatorial Bandit (DC2B), for interactive recommendation with users' implicit feedback. Specifically, DC2B employs determinantal point process in the recommendation procedure to promote diversity of the recommendation results. To learn the model parameters, a Thompson sampling-type algorithm based on variational Bayesian inference is proposed. In addition, theoretical regret analysis is also provided to guarantee the performance of DC2B. Extensive experiments on real datasets are performed to demonstrate the effectiveness of the proposed method in balancing the recommendation accuracy and diversity."
  },
  "aaai2020_main_ipointerior-pointpolicyoptimizationunderconstraints": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " IPO: Interior-Point Policy Optimization under Constraints ",
    "authors": [
      "Yongshuai Liu",
      "Jiaxin Ding",
      "Xin Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5932",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5932/5788",
    "published": "2020-02",
    "summary": "In this paper, we study reinforcement learning (RL) algorithms to solve real-world decision problems with the objective of maximizing the long-term reward as well as satisfying cumulative constraints. We propose a novel first-order policy optimization method, Interior-point Policy Optimization (IPO), which augments the objective with logarithmic barrier functions, inspired by the interior-point method. Our proposed method is easy to implement with performance guarantees and can handle general types of cumulative multi-constraint settings. We conduct extensive evaluations to compare our approach with state-of-the-art baselines. Our algorithm outperforms the baseline algorithms, in terms of reward maximization and constraint satisfaction."
  },
  "aaai2020_main_collaborativesamplingingenerativeadversarialnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Collaborative Sampling in Generative Adversarial Networks ",
    "authors": [
      "Yuejiang Liu",
      "Parth Kothari",
      "Alexandre Alahi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5933",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5933/5789",
    "published": "2020-02",
    "summary": "The standard practice in Generative Adversarial Networks (GANs) discards the discriminator during sampling. However, this sampling method loses valuable information learned by the discriminator regarding the data distribution. In this work, we propose a collaborative sampling scheme between the generator and the discriminator for improved data generation. Guided by the discriminator, our approach refines the generated samples through gradient-based updates at a particular layer of the generator, shifting the generator distribution closer to the real data distribution. Additionally, we present a practical discriminator shaping method that can smoothen the loss landscape provided by the discriminator for effective sample refinement. Through extensive experiments on synthetic and image datasets, we demonstrate that our proposed method can improve generated samples both quantitatively and qualitatively, offering a new degree of freedom in GAN sampling."
  },
  "aaai2020_main_uncertaintyawaregraphgaussianprocessforsemi-supervisedlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Uncertainty Aware Graph Gaussian Process for Semi-Supervised Learning ",
    "authors": [
      "Zhao-Yang Liu",
      "Shao-Yuan Li",
      "Songcan Chen",
      "Yao Hu",
      "Sheng-Jun Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5934",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5934/5790",
    "published": "2020-02",
    "summary": "Graph-based semi-supervised learning (GSSL) studies the problem where in addition to a set of data points with few available labels, there also exists a graph structure that describes the underlying relationship between data items. In practice, structure uncertainty often occurs in graphs when edges exist between data with different labels, which may further results in prediction uncertainty of labels. Considering that Gaussian process generalizes well with few labels and can naturally model uncertainty, in this paper, we propose an Uncertainty aware Graph Gaussian Process based approach (UaGGP) for GSSL. UaGGP exploits the prediction uncertainty and label smooth regularization to guide each other during learning. To further subdue the effect of irrelevant neighbors, UaGGP also aggregates the clean representation in the original space and the learned representation. Experiments on benchmarks demonstrate the effectiveness of the proposed approach."
  },
  "aaai2020_main_interactiverare-category-of-interestminingfromlargedatasets": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Interactive Rare-Category-of-Interest Mining from Large Datasets ",
    "authors": [
      "Zhenguang Liu",
      "Sihao Hu",
      "Yifang Yin",
      "Jianhai Chen",
      "Kevin Chiew",
      "Luming Zhang",
      "Zetian Wu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5935",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5935/5791",
    "published": "2020-02",
    "summary": "In the era of big data, rare category data examples are often of key importance despite their scarcity, e.g., rare bird audio is usually more valuable than common bird audio. However, existing efforts on rare category mining consider only the statistical characteristics of rare category data examples, while ignoring their \u2018true\u2019 interestingness to the user. Moreover, current approaches are unable to support real-time user interactions due to their prohibitive computational costs for answering a single user query."
  },
  "aaai2020_main_towardsfine-grainedtemporalnetworkrepresentationviatime-reinforcedrandomwalk": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Fine-Grained Temporal Network Representation via Time-Reinforced Random Walk ",
    "authors": [
      "Zhining Liu",
      "Dawei Zhou",
      "Yada Zhu",
      "Jinjie Gu",
      "Jingrui He"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5936",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5936/5792",
    "published": "2020-02",
    "summary": "Encoding a large-scale network into a low-dimensional space is a fundamental step for various network analytic problems, such as node classification, link prediction, community detection, etc. Existing methods focus on learning the network representation from either the static graphs or time-aggregated graphs (e.g., time-evolving graphs). However, many real systems are not static or time-aggregated as the nodes and edges are timestamped and dynamically changing over time. For examples, in anti-money laundering analysis, cycles formed with time-ordered transactions might be red flags in online transaction networks; in novelty detection, a star-shaped structure appearing in a short burst might be an underlying hot topic in social networks. Existing embedding models might not be able to well preserve such fine-grained network dynamics due to the incapability of dealing with continuous-time and the negligence of fine-grained interactions. To bridge this gap, in this paper, we propose a fine-grained temporal network embedding framework named FiGTNE, which aims to learn a comprehensive network representation that preserves the rich and complex network context in the temporal network. In particular, we start from the notion of fine-grained temporal networks, where the temporal network can be represented as a series of timestamped nodes and edges. Then, we propose the time-reinforced random walk (TRRW) with a bi-level context sampling strategy to explore the essential structures and temporal contexts in temporal networks. Extensive experimental results on real graphs demonstrate the efficacy of our FiGTNE framework."
  },
  "aaai2020_main_incentivizedexplorationformulti-armedbanditsunderrewarddrift": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Incentivized Exploration for Multi-Armed Bandits under Reward Drift ",
    "authors": [
      "Zhiyuan Liu",
      "Huazheng Wang",
      "Fan Shen",
      "Kai Liu",
      "Lijun Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5937",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5937/5793",
    "published": "2020-02",
    "summary": "We study incentivized exploration for the multi-armed bandit (MAB) problem where the players receive compensation for exploring arms other than the greedy choice and may provide biased feedback on reward. We seek to understand the impact of this drifted reward feedback by analyzing the performance of three instantiations of the incentivized MAB algorithm: UCB, \u03b5-Greedy, and Thompson Sampling. Our results show that they all achieve O(log T) regret and compensation under the drifted reward, and are therefore effective in incentivizing exploration. Numerical examples are provided to complement the theoretical analysis."
  },
  "aaai2020_main_structuredsparsificationofgatedrecurrentneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Structured Sparsification of Gated Recurrent Neural Networks ",
    "authors": [
      "Ekaterina Lobacheva",
      "Nadezhda Chirkova",
      "Alexander Markovich",
      "Dmitry Vetrov"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5938",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5938/5794",
    "published": "2020-02",
    "summary": "One of the most popular approaches for neural network compression is sparsification \u2014 learning sparse weight matrices. In structured sparsification, weights are set to zero by groups corresponding to structure units, e. g. neurons. We further develop the structured sparsification approach for the gated recurrent neural networks, e. g. Long Short-Term Memory (LSTM). Specifically, in addition to the sparsification of individual weights and neurons, we propose sparsifying the preactivations of gates. This makes some gates constant and simplifies an LSTM structure. We test our approach on the text classification and language modeling tasks. Our method improves the neuron-wise compression of the model in most of the tasks. We also observe that the resulting structure of gate sparsity depends on the task and connect the learned structures to the specifics of the particular tasks."
  },
  "aaai2020_main_cost-effectiveincentiveallocationviastructuredcounterfactualinference": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Cost-Effective Incentive Allocation via Structured Counterfactual Inference ",
    "authors": [
      "Romain Lopez",
      "Chenchen Li",
      "Xiang Yan",
      "Junwu Xiong",
      "Michael Jordan",
      "Yuan Qi",
      "Le Song"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5939",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5939/5795",
    "published": "2020-02",
    "summary": "We address a practical problem ubiquitous in modern marketing campaigns, in which a central agent tries to learn a policy for allocating strategic financial incentives to customers and observes only bandit feedback. In contrast to traditional policy optimization frameworks, we take into account the additional reward structure and budget constraints common in this setting, and develop a new two-step method for solving this constrained counterfactual policy optimization problem. Our method first casts the reward estimation problem as a domain adaptation problem with supplementary structure, and then subsequently uses the estimators for optimizing the policy with constraints. We also establish theoretical error bounds for our estimation procedure and we empirically show that the approach leads to significant improvement on both synthetic and real datasets."
  },
  "aaai2020_main_structuredoutputlearningwithconditionalgenerativeflows": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Structured Output Learning with Conditional Generative Flows ",
    "authors": [
      "You Lu",
      "Bert Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5940",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5940/5796",
    "published": "2020-02",
    "summary": "Traditional structured prediction models try to learn the conditional likelihood, i.e., p(y|x), to capture the relationship between the structured output y and the input features x. For many models, computing the likelihood is intractable. These models are therefore hard to train, requiring the use of surrogate objectives or variational inference to approximate likelihood. In this paper, we propose conditional Glow (c-Glow), a conditional generative flow for structured output learning. C-Glow benefits from the ability of flow-based models to compute p(y|x exactly and efficiently. Learning with c-Glow does not require a surrogate objective or performing inference during training. Once trained, we can directly and efficiently generate conditional samples. We develop a sample-based prediction method, which can use this advantage to do efficient and effective inference. In our experiments, we test c-Glow on five different tasks. C-Glow outperforms the state-of-the-art baselines in some tasks and predicts comparable outputs in the other tasks. The results show that c-Glow is versatile and is applicable to many different structured prediction problems."
  },
  "aaai2020_main_enhancingnearestneighborbasedentropyestimatorforhighdimensionaldistributionsviabootstrappinglocalellipsoid": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Enhancing Nearest Neighbor Based Entropy Estimator for High Dimensional Distributions via Bootstrapping Local Ellipsoid ",
    "authors": [
      "Chien Lu",
      "Jaakko Peltonen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5941",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5941/5797",
    "published": "2020-02",
    "summary": "An ellipsoid-based, improved kNN entropy estimator based on random samples of distribution for high dimensionality is developed. We argue that the inaccuracy of the classical kNN estimator in high dimensional spaces results from the local uniformity assumption and the proposed method mitigates the local uniformity assumption by two crucial extensions, a local ellipsoid-based volume correction and a correction acceptance testing procedure. Relevant theoretical contributions are provided and several experiments from simple to complicated cases have shown that the proposed estimator can effectively reduce the bias especially in high dimensionalities, outperforming current state of the art alternative estimators."
  },
  "aaai2020_main_learningfromthepastcontinualmeta-learningwithbayesiangraphneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning from the Past: Continual Meta-Learning with Bayesian Graph Neural Networks ",
    "authors": [
      "Yadan Luo",
      "Zi Huang",
      "Zheng Zhang",
      "Ziwei Wang",
      "Mahsa Baktashmotlagh",
      "Yang Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5942",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5942/5798",
    "published": "2020-02",
    "summary": "Meta-learning for few-shot learning allows a machine to leverage previously acquired knowledge as a prior, thus improving the performance on novel tasks with only small amounts of data. However, most mainstream models suffer from catastrophic forgetting and insufficient robustness issues, thereby failing to fully retain or exploit long-term knowledge while being prone to cause severe error accumulation. In this paper, we propose a novel Continual Meta-Learning approach with Bayesian Graph Neural Networks (CML-BGNN) that mathematically formulates meta-learning as continual learning of a sequence of tasks. With each task forming as a graph, the intra- and inter-task correlations can be well preserved via message-passing and history transition. To remedy topological uncertainty from graph initialization, we utilize Bayes by Backprop strategy that approximates the posterior distribution of task-specific parameters with amortized inference networks, which are seamlessly integrated into the end-to-end edge learning. Extensive experiments conducted on the miniImageNet and tieredImageNet datasets demonstrate the effectiveness and efficiency of the proposed method, improving the performance by 42.8% compared with state-of-the-art on the miniImageNet 5-way 1-shot classification task."
  },
  "aaai2020_main_unsuperviseddomainadaptationviadiscriminativemanifoldembeddingandalignment": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Unsupervised Domain Adaptation via Discriminative Manifold Embedding and Alignment ",
    "authors": [
      "You-Wei Luo",
      "Chuan-Xian Ren",
      "Pengfei Ge",
      "Ke-Kun Huang",
      "Yu-Feng Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5943",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5943/5799",
    "published": "2020-02",
    "summary": "Unsupervised domain adaptation is effective in leveraging the rich information from the source domain to the unsupervised target domain. Though deep learning and adversarial strategy make an important breakthrough in the adaptability of features, there are two issues to be further explored. First, the hard-assigned pseudo labels on the target domain are risky to the intrinsic data structure. Second, the batch-wise training manner in deep learning limits the description of the global structure. In this paper, a Riemannian manifold learning framework is proposed to achieve transferability and discriminability consistently. As to the first problem, this method establishes a probabilistic discriminant criterion on the target domain via soft labels. Further, this criterion is extended to a global approximation scheme for the second issue; such approximation is also memory-saving. The manifold metric alignment is exploited to be compatible with the embedding space. A theoretical error bound is derived to facilitate the alignment. Extensive experiments have been conducted to investigate the proposal and results of the comparison study manifest the superiority of consistent manifold learning framework."
  },
  "aaai2020_main_fastenedcrowntightenedneuralnetworkrobustnesscertificates": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fastened CROWN: Tightened Neural Network Robustness Certificates ",
    "authors": [
      "Zhaoyang Lyu",
      "Ching-Yun Ko",
      "Zhifeng Kong",
      "Ngai Wong",
      "Dahua Lin",
      "Luca Daniel"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5944",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5944/5800",
    "published": "2020-02",
    "summary": "The rapid growth of deep learning applications in real life is accompanied by severe safety concerns. To mitigate this uneasy phenomenon, much research has been done providing reliable evaluations of the fragility level in different deep neural networks. Apart from devising adversarial attacks, quantifiers that certify safeguarded regions have also been designed in the past five years. The summarizing work in (Salman et al. 2019) unifies a family of existing verifiers under a convex relaxation framework. We draw inspiration from such work and further demonstrate the optimality of deterministic CROWN (Zhang et al. 2018) solutions in a given linear programming problem under mild constraints. Given this theoretical result, the computationally expensive linear programming based method is shown to be unnecessary. We then propose an optimization-based approach FROWN (Fastened CROWN): a general algorithm to tighten robustness certificates for neural networks. Extensive experiments on various networks trained individually verify the effectiveness of FROWN in safeguarding larger robust regions."
  },
  "aaai2020_main_memoryaugmentedgraphneuralnetworksforsequentialrecommendation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Memory Augmented Graph Neural Networks for Sequential Recommendation ",
    "authors": [
      "Chen Ma",
      "Liheng Ma",
      "Yingxue Zhang",
      "Jianing Sun",
      "Xue Liu",
      "Mark Coates"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5945",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5945/5801",
    "published": "2020-02",
    "summary": "The chronological order of user-item interactions can reveal time-evolving and sequential user behaviors in many recommender systems. The items that users will interact with may depend on the items accessed in the past. However, the substantial increase of users and items makes sequential recommender systems still face non-trivial challenges: (1) the hardness of modeling the short-term user interests; (2) the difficulty of capturing the long-term user interests; (3) the effective modeling of item co-occurrence patterns. To tackle these challenges, we propose a memory augmented graph neural network (MA-GNN) to capture both the long- and short-term user interests. Specifically, we apply a graph neural network to model the item contextual information within a short-term period and utilize a shared memory network to capture the long-range dependencies between items. In addition to the modeling of user interests, we employ a bilinear function to capture the co-occurrence patterns of related items. We extensively evaluate our model on five real-world datasets, comparing with several state-of-the-art methods and using a variety of performance metrics. The experimental results demonstrate the effectiveness of our model for the task of Top-K sequential recommendation."
  },
  "aaai2020_main_inefficiencyofk-facforlargebatchsizetraining": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Inefficiency of K-FAC for Large Batch Size Training ",
    "authors": [
      "Linjian Ma",
      "Gabe Montague",
      "Jiayu Ye",
      "Zhewei Yao",
      "Amir Gholami",
      "Kurt Keutzer",
      "Michael Mahoney"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5946",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5946/5802",
    "published": "2020-02",
    "summary": "There have been several recent work claiming record times for ImageNet training. This is achieved by using large batch sizes during training to leverage parallel resources to produce faster wall-clock training times per training epoch. However, often these solutions require massive hyper-parameter tuning, which is an important cost that is often ignored. In this work, we perform an extensive analysis of large batch size training for two popular methods that is Stochastic Gradient Descent (SGD) as well as Kronecker-Factored Approximate Curvature (K-FAC) method. We evaluate the performance of these methods in terms of both wall-clock time and aggregate computational cost, and study the hyper-parameter sensitivity by performing more than 512 experiments per batch size for each of these methods. We perform experiments on multiple different models on two datasets of CIFAR-10 and SVHN. The results show that beyond a critical batch size both K-FAC and SGD significantly deviate from ideal strong scaling behaviour, and that despite common belief K-FAC does not exhibit improved large-batch scalability behavior, as compared to SGD."
  },
  "aaai2020_main_temporalpyramidrecurrentneuralnetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Temporal Pyramid Recurrent Neural Network ",
    "authors": [
      "Qianli Ma",
      "Zhenxi Lin",
      "Enhuan Chen",
      "Garrison Cottrell"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5947",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5947/5803",
    "published": "2020-02",
    "summary": "Learning long-term and multi-scale dependencies in sequential data is a challenging task for recurrent neural networks (RNNs). In this paper, a novel RNN structure called temporal pyramid RNN (TP-RNN) is proposed to achieve these two goals. TP-RNN is a pyramid-like structure and generally has multiple layers. In each layer of the network, there are several sub-pyramids connected by a shortcut path to the output, which can efficiently aggregate historical information from hidden states and provide many gradient feedback short-paths. This avoids back-propagating through many hidden states as in usual RNNs. In particular, in the multi-layer structure of TP-RNN, the input sequence of the higher layer is a large-scale aggregated state sequence produced by the sub-pyramids in the previous layer, instead of the usual sequence of hidden states. In this way, TP-RNN can explicitly learn multi-scale dependencies with multi-scale input sequences of different layers, and shorten the input sequence and gradient feedback paths of each layer. This avoids the vanishing gradient problem in deep RNNs and allows the network to efficiently learn long-term dependencies. We evaluate TP-RNN on several sequence modeling tasks, including the masked addition problem, pixel-by-pixel image classification, signal recognition and speaker identification. Experimental results demonstrate that TP-RNN consistently outperforms existing RNNs for learning long-term and multi-scale dependencies in sequential data."
  },
  "aaai2020_main_adversarialdynamicshapeletnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adversarial Dynamic Shapelet Networks ",
    "authors": [
      "Qianli Ma",
      "Wanqing Zhuang",
      "Sen Li",
      "Desen Huang",
      "Garrison Cottrell"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5948",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5948/5804",
    "published": "2020-02",
    "summary": "Shapelets are discriminative subsequences for time series classification. Recently, learning time-series shapelets (LTS) was proposed to learn shapelets by gradient descent directly. Although learning-based shapelet methods achieve better results than previous methods, they still have two shortcomings. First, the learned shapelets are fixed after training and cannot adapt to time series with deformations at the testing phase. Second, the shapelets learned by back-propagation may not be similar to any real subsequences, which is contrary to the original intention of shapelets and reduces model interpretability. In this paper, we propose a novel shapelet learning model called Adversarial Dynamic Shapelet Networks (ADSNs). An adversarial training strategy is employed to prevent the generated shapelets from diverging from the actual subsequences of a time series. During inference, a shapelet generator produces sample-specific shapelets, and a dynamic shapelet transformation uses the generated shapelets to extract discriminative features. Thus, ADSN can dynamically generate shapelets that are similar to the real subsequences rather than having arbitrary shapes. The proposed model has high modeling flexibility while retaining the interpretability of shapelet-based methods. Experiments conducted on extensive time series data sets show that ADSN is state-of-the-art compared to existing shapelet-based methods. The visualization analysis also shows the effectiveness of dynamic shapelet generation and adversarial training."
  },
  "aaai2020_main_onlineplannerselectionwithgraphneuralnetworksandadaptivescheduling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Online Planner Selection with Graph Neural Networks and Adaptive Scheduling ",
    "authors": [
      "Tengfei Ma",
      "Patrick Ferber",
      "Siyu Huo",
      "Jie Chen",
      "Michael Katz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5949",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5949/5805",
    "published": "2020-02",
    "summary": "Automated planning is one of the foundational areas of AI. Since no single planner can work well for all tasks and domains, portfolio-based techniques have become increasingly popular in recent years. In particular, deep learning emerges as a promising methodology for online planner selection. Owing to the recent development of structural graph representations of planning tasks, we propose a graph neural network (GNN) approach to selecting candidate planners. GNNs are advantageous over a straightforward alternative, the convolutional neural networks, in that they are invariant to node permutations and that they incorporate node labels for better inference."
  },
  "aaai2020_main_thehsicbottleneckdeeplearningwithoutback-propagation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " The HSIC Bottleneck: Deep Learning without Back-Propagation ",
    "authors": [
      "Wan-Duo Kurt Ma",
      "J. P. Lewis",
      "W. Bastiaan Kleijn"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5950",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5950/5806",
    "published": "2020-02",
    "summary": "We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance."
  },
  "aaai2020_main_projectivequadraticregressionforonlinelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Projective Quadratic Regression for Online Learning ",
    "authors": [
      "Wenye Ma"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5951",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5951/5807",
    "published": "2020-02",
    "summary": "This paper considers online convex optimization (OCO) problems - the paramount framework for online learning algorithm design. The loss function of learning task in OCO setting is based on streaming data so that OCO is a powerful tool to model large scale applications such as online recommender systems. Meanwhile, real-world data are usually of extreme high-dimensional due to modern feature engineering techniques so that the quadratic regression is impractical. Factorization Machine as well as its variants are efficient models for capturing feature interactions with low-rank matrix model but they can't fulfill the OCO setting due to their non-convexity. In this paper, We propose a projective quadratic regression (PQR) model. First, it can capture the import second-order feature information. Second, it is a convex model, so the requirements of OCO are fulfilled and the global optimal solution can be achieved. Moreover, existing modern online optimization methods such as Online Gradient Descent (OGD) or Follow-The-Regularized-Leader (FTRL) can be applied directly. In addition, by choosing a proper hyper-parameter, we show that it has the same order of space and time complexity as the linear model and thus can handle high-dimensional data. Experimental results demonstrate the performance of the proposed PQR model in terms of accuracy and efficiency by comparing with the state-of-the-art methods."
  },
  "aaai2020_main_particlefilterrecurrentneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Particle Filter Recurrent Neural Networks ",
    "authors": [
      "Xiao Ma",
      "Peter Karkus",
      "David Hsu",
      "Wee Sun Lee"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5952",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5952/5808",
    "published": "2020-02",
    "summary": "Recurrent neural networks (RNNs) have been extraordinarily successful for prediction with sequential data. To tackle highly variable and multi-modal real-world data, we introduce Particle Filter Recurrent Neural Networks (PF-RNNs), a new RNN family that explicitly models uncertainty in its internal structure: while an RNN relies on a long, deterministic latent state vector, a PF-RNN maintains a latent state distribution, approximated as a set of particles. For effective learning, we provide a fully differentiable particle filter algorithm that updates the PF-RNN latent state distribution according to the Bayes rule. Experiments demonstrate that the proposed PF-RNNs outperform the corresponding standard gated RNNs on a synthetic robot localization dataset and 10 real-world sequence prediction datasets for text classification, stock price prediction, etc."
  },
  "aaai2020_main_reinforcementlearningfromimperfectdemonstrationsundersoftexpertguidance": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reinforcement Learning from Imperfect Demonstrations under Soft Expert Guidance ",
    "authors": [
      "Mingxuan Jing",
      "Xiaojian Ma",
      "Wenbing Huang",
      "Fuchun Sun",
      "Chao Yang",
      "Bin Fang",
      "Huaping Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5953",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5953/5809",
    "published": "2020-02",
    "summary": "In this paper, we study Reinforcement Learning from Demonstrations (RLfD) that improves the exploration efficiency of Reinforcement Learning (RL) by providing expert demonstrations. Most of existing RLfD methods require demonstrations to be perfect and sufficient, which yet is unrealistic to meet in practice. To work on imperfect demonstrations, we first define an imperfect expert setting for RLfD in a formal way, and then point out that previous methods suffer from two issues in terms of optimality and convergence, respectively. Upon the theoretical findings we have derived, we tackle these two issues by regarding the expert guidance as a soft constraint on regulating the policy exploration of the agent, which eventually leads to a constrained optimization problem. We further demonstrate that such problem is able to be addressed efficiently by performing a local linear search on its dual form. Considerable empirical evaluations on a comprehensive collection of benchmarks indicate our method attains consistent improvement over other RLfD counterparts."
  },
  "aaai2020_main_pconvthemissingbutdesirablesparsityindnnweightpruningforreal-timeexecutiononmobiledevices": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " PCONV: The Missing but Desirable Sparsity in DNN Weight Pruning for Real-Time Execution on Mobile Devices ",
    "authors": [
      "Xiaolong Ma",
      "Fu-Ming Guo",
      "Wei Niu",
      "Xue Lin",
      "Jian Tang",
      "Kaisheng Ma",
      "Bin Ren",
      "Yanzhi Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5954",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5954/5810",
    "published": "2020-02",
    "summary": "Model compression techniques on Deep Neural Network (DNN) have been widely acknowledged as an effective way to achieve acceleration on a variety of platforms, and DNN weight pruning is a straightforward and effective method. There are currently two mainstreams of pruning methods representing two extremes of pruning regularity: non-structured, fine-grained pruning can achieve high sparsity and accuracy, but is not hardware friendly; structured, coarse-grained pruning exploits hardware-efficient structures in pruning, but suffers from accuracy drop when the pruning rate is high. In this paper, we introduce PCONV, comprising a new sparsity dimension, \u2013 fine-grained pruning patterns inside the coarse-grained structures. PCONV comprises two types of sparsities, Sparse Convolution Patterns (SCP) which is generated from intra-convolution kernel pruning and connectivity sparsity generated from inter-convolution kernel pruning. Essentially, SCP enhances accuracy due to its special vision properties, and connectivity sparsity increases pruning rate while maintaining balanced workload on filter computation. To deploy PCONV, we develop a novel compiler-assisted DNN inference framework and execute PCONV models in real-time without accuracy compromise, which cannot be achieved in prior work. Our experimental results show that, PCONV outperforms three state-of-art end-to-end DNN frameworks, TensorFlow-Lite, TVM, and Alibaba Mobile Neural Network with speedup up to 39.2 \u00d7, 11.4 \u00d7, and 6.3 \u00d7, respectively, with no accuracy loss. Mobile devices can achieve real-time inference on large-scale DNNs."
  },
  "aaai2020_main_count-basedexplorationwiththesuccessorrepresentation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Count-Based Exploration with the Successor Representation ",
    "authors": [
      "Marlos C. Machado",
      "Marc G. Bellemare",
      "Michael Bowling"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5955",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5955/5811",
    "published": "2020-02",
    "summary": "In this paper we introduce a simple approach for exploration in reinforcement learning (RL) that allows us to develop theoretically justified algorithms in the tabular case but that is also extendable to settings where function approximation is required. Our approach is based on the successor representation (SR), which was originally introduced as a representation defining state generalization by the similarity of successor states. Here we show that the norm of the SR, while it is being learned, can be used as a reward bonus to incentivize exploration. In order to better understand this transient behavior of the norm of the SR we introduce the substochastic successor representation (SSR) and we show that it implicitly counts the number of times each state (or feature) has been observed. We use this result to introduce an algorithm that performs as well as some theoretically sample-efficient approaches. Finally, we extend these ideas to a deep RL algorithm and show that it achieves state-of-the-art performance in Atari 2600 games when in a low sample-complexity regime."
  },
  "aaai2020_main_graph-histgraphclassificationfromlatentfeaturehistogramswithapplicationtobotdetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Graph-Hist: Graph Classification from Latent Feature Histograms with Application to Bot Detection ",
    "authors": [
      "Thomas Magelinski",
      "David Beskow",
      "Kathleen M. Carley"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5956",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5956/5812",
    "published": "2020-02",
    "summary": "Neural networks are increasingly used for graph classification in a variety of contexts. Social media is a critical application area in this space, however the characteristics of social media graphs differ from those seen in most popular benchmark datasets. Social networks tend to be large and sparse, while benchmarks are small and dense. Classically, large and sparse networks are analyzed by studying the distribution of local properties. Inspired by this, we introduce Graph-Hist: an end-to-end architecture that extracts a graph's latent local features, bins nodes together along 1-D cross sections of the feature space, and classifies the graph based on this multi-channel histogram. We show that Graph-Hist improves state of the art performance on true social media benchmark datasets, while still performing well on other benchmarks. Finally, we demonstrate Graph-Hist's performance by conducting bot detection in social media. While sophisticated bot and cyborg accounts increasingly evade traditional detection methods, they leave artificial artifacts in their conversational graph that are detected through graph classification. We apply Graph-Hist to classify these conversational graphs. In the process, we confirm that social media graphs are different than most baselines and that Graph-Hist outperforms existing bot-detection models."
  },
  "aaai2020_main_learningagentcommunicationunderlimitedbandwidthbymessagepruning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Agent Communication under Limited Bandwidth by Message Pruning ",
    "authors": [
      "Hangyu Mao",
      "Zhengchao Zhang",
      "Zhen Xiao",
      "Zhibo Gong",
      "Yan Ni"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5957",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5957/5813",
    "published": "2020-02",
    "summary": "Communication is a crucial factor for the big multi-agent world to stay organized and productive. Recently, Deep Reinforcement Learning (DRL) has been applied to learn the communication strategy and the control policy for multiple agents. However, the practical limited bandwidth in multi-agent communication has been largely ignored by the existing DRL methods. Specifically, many methods keep sending messages incessantly, which consumes too much bandwidth. As a result, they are inapplicable to multi-agent systems with limited bandwidth. To handle this problem, we propose a gating mechanism to adaptively prune less beneficial messages. We evaluate the gating mechanism on several tasks. Experiments demonstrate that it can prune a lot of messages with little impact on performance. In fact, the performance may be greatly improved by pruning redundant messages. Moreover, the proposed gating mechanism is applicable to several previous methods, equipping them the ability to address bandwidth restricted settings."
  },
  "aaai2020_main_multi-zoneunitforrecurrentneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Zone Unit for Recurrent Neural Networks ",
    "authors": [
      "Fandong Meng",
      "Jinchao Zhang",
      "Yang Liu",
      "Jie Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5958",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5958/5814",
    "published": "2020-02",
    "summary": "Recurrent neural networks (RNNs) have been widely used to deal with sequence learning problems. The input-dependent transition function, which folds new observations into hidden states to sequentially construct fixed-length representations of arbitrary-length sequences, plays a critical role in RNNs. Based on single space composition, transition functions in existing RNNs often have difficulty in capturing complicated long-range dependencies. In this paper, we introduce a new Multi-zone Unit (MZU) for RNNs. The key idea is to design a transition function that is capable of modeling multiple space composition. The MZU consists of three components: zone generation, zone composition, and zone aggregation. Experimental results on multiple datasets of the character-level language modeling task and the aspect-based sentiment analysis task demonstrate the superiority of the MZU."
  },
  "aaai2020_main_neuralinheritancerelationguidedone-shotlayerassignmentsearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Neural Inheritance Relation Guided One-Shot Layer Assignment Search ",
    "authors": [
      "Rang Meng",
      "Weijie Chen",
      "Di Xie",
      "Yuan Zhang",
      "Shiliang Pu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5959",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5959/5815",
    "published": "2020-02",
    "summary": "Layer assignment is seldom picked out as an independent research topic in neural architecture search. In this paper, for the first time, we systematically investigate the impact of different layer assignments to the network performance by building an architecture dataset of layer assignment on CIFAR-100. Through analyzing this dataset, we discover a neural inheritance relation among the networks with different layer assignments, that is, the optimal layer assignments for deeper networks always inherit from those for shallow networks. Inspired by this neural inheritance relation, we propose an efficient one-shot layer assignment search approach via inherited sampling. Specifically, the optimal layer assignment searched in the shallow network can be provided as a strong sampling priori to train and search the deeper ones in supernet, which extremely reduces the network search space. Comprehensive experiments carried out on CIFAR-100 illustrate the efficiency of our proposed method. Our search results are strongly consistent with the optimal ones directly selected from the architecture dataset. To further confirm the generalization of our proposed method, we also conduct experiments on Tiny-ImageNet and ImageNet. Our searched results are remarkably superior to the handcrafted ones under the unchanged computational budgets. The neural inheritance relation discovered in this paper can provide insights to the universal neural architecture search."
  },
  "aaai2020_main_regularizedwassersteinmeansforaligningdistributionaldata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Regularized Wasserstein Means for Aligning Distributional Data ",
    "authors": [
      "Liang Mi",
      "Wen Zhang",
      "Yalin Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5960",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5960/5816",
    "published": "2020-02",
    "summary": "We propose to align distributional data from the perspective of Wasserstein means. We raise the problem of regularizing Wasserstein means and propose several terms tailored to tackle different problems. Our formulation is based on the variational transportation to distribute a sparse discrete measure into the target domain. The resulting sparse representation well captures the desired property of the domain while reducing the mapping cost. We demonstrate the scalability and robustness of our method with examples in domain adaptation, point set registration, and skeleton layout."
  },
  "aaai2020_main_deepembeddednon-redundantclustering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Embedded Non-Redundant Clustering ",
    "authors": [
      "Lukas Miklautz",
      "Dominik Mautz",
      "Muzaffer Can Altinigneli",
      "Christian B\u00f6hm",
      "Claudia Plant"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5961",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5961/5817",
    "published": "2020-02",
    "summary": "Complex data types like images can be clustered in multiple valid ways. Non-redundant clustering aims at extracting those meaningful groupings by discouraging redundancy between clusterings. Unfortunately, clustering images in pixel space directly has been shown to work unsatisfactory. This has increased interest in combining the high representational power of deep learning with clustering, termed deep clustering. Algorithms of this type combine the non-linear embedding of an autoencoder with a clustering objective and optimize both simultaneously. None of these algorithms try to find multiple non-redundant clusterings. In this paper, we propose the novel Embedded Non-Redundant Clustering algorithm (ENRC). It is the first algorithm that combines neural-network-based representation learning with non-redundant clustering. ENRC can find multiple highly non-redundant clusterings of different dimensionalities within a data set. This is achieved by (softly) assigning each dimension of the embedded space to the different clusterings. For instance, in image data sets it can group the objects by color, material and shape, without the need for explicit feature engineering. We show the viability of ENRC in extensive experiments and empirically demonstrate the advantage of combining non-linear representation learning with non-redundant clustering."
  },
  "aaai2020_main_differentiablereasoningonlargeknowledgebasesandnaturallanguage": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Differentiable Reasoning on Large Knowledge Bases and Natural Language ",
    "authors": [
      "Pasquale Minervini",
      "Matko Bo\u0161njak",
      "Tim Rockt\u00e4schel",
      "Sebastian Riedel",
      "Edward Grefenstette"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5962",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5962/5818",
    "published": "2020-02",
    "summary": "Reasoning with knowledge expressed in natural language and Knowledge Bases (KBs) is a major challenge for Artificial Intelligence, with applications in machine reading, dialogue, and question answering. General neural architectures that jointly learn representations and transformations of text are very data-inefficient, and it is hard to analyse their reasoning process. These issues are addressed by end-to-end differentiable reasoning systems such as Neural Theorem Provers (NTPs), although they can only be used with small-scale symbolic KBs. In this paper we first propose Greedy NTPs (GNTPs), an extension to NTPs addressing their complexity and scalability limitations, thus making them applicable to real-world datasets. This result is achieved by dynamically constructing the computation graph of NTPs and including only the most promising proof paths during inference, thus obtaining orders of magnitude more efficient models 1. Then, we propose a novel approach for jointly reasoning over KBs and textual mentions, by embedding logic facts and natural language sentences in a shared embedding space. We show that GNTPs perform on par with NTPs at a fraction of their cost while achieving competitive link prediction results on large datasets, providing explanations for predictions, and inducing interpretable models."
  },
  "aaai2020_main_improvedknowledgedistillationviateacherassistant": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Improved Knowledge Distillation via Teacher Assistant ",
    "authors": [
      "Seyed Iman Mirzadeh",
      "Mehrdad Farajtabar",
      "Ang Li",
      "Nir Levine",
      "Akihiro Matsukawa",
      "Hassan Ghasemzadeh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5963",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5963/5819",
    "published": "2020-02",
    "summary": "Despite the fact that deep neural networks are powerful models and achieve appealing results on many tasks, they are too large to be deployed on edge devices like smartphones or embedded sensor nodes. There have been efforts to compress these networks, and a popular method is knowledge distillation, where a large (teacher) pre-trained network is used to train a smaller (student) network. However, in this paper, we show that the student network performance degrades when the gap between student and teacher is large. Given a fixed student network, one cannot employ an arbitrarily large teacher, or in other words, a teacher can effectively transfer its knowledge to students up to a certain size, not smaller. To alleviate this shortcoming, we introduce multi-step knowledge distillation, which employs an intermediate-sized network (teacher assistant) to bridge the gap between the student and the teacher. Moreover, we study the effect of teacher assistant size and extend the framework to multi-step distillation. Theoretical analysis and extensive experiments on CIFAR-10,100 and ImageNet datasets and on CNN and ResNet architectures substantiate the effectiveness of our proposed approach."
  },
  "aaai2020_main_onadaptivityininformation-constrainedonlinelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On Adaptivity in Information-Constrained Online Learning ",
    "authors": [
      "Siddharth Mitra",
      "Aditya Gopalan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5964",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5964/5820",
    "published": "2020-02",
    "summary": "We study how to adapt to smoothly-varying (\u2018easy\u2019) environments in well-known online learning problems where acquiring information is expensive. For the problem of label efficient prediction, which is a budgeted version of prediction with expert advice, we present an online algorithm whose regret depends optimally on the number of labels allowed and Q* (the quadratic variation of the losses of the best action in hindsight), along with a parameter-free counterpart whose regret depends optimally on Q (the quadratic variation of the losses of all the actions). These quantities can be significantly smaller than T (the total time horizon), yielding an improvement over existing, variation-independent results for the problem. We then extend our analysis to handle label efficient prediction with bandit (partial) feedback, i.e., label efficient bandits. Our work builds upon the framework of optimistic online mirror descent, and leverages second order corrections along with a carefully designed hybrid regularizer that encodes the constrained information structure of the problem. We then consider revealing action-partial monitoring games \u2013 a version of label efficient prediction with additive information costs \u2013 which in general are known to lie in the hard class of games having minimax regret of order T2/3. We provide a strategy with an O((QT*)1/3 bound for revealing action games, along with one with a O((QT)1/3) bound for the full class of hard partial monitoring games, both being strict improvements over current bounds."
  },
  "aaai2020_main_metareasoninginmodularsoftwaresystemson-the-flyconfigurationusingreinforcementlearningwithrichcontextualrepresentations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Metareasoning in Modular Software Systems: On-the-Fly Configuration Using Reinforcement Learning with Rich Contextual Representations ",
    "authors": [
      "Aditya Modi",
      "Debadeepta Dey",
      "Alekh Agarwal",
      "Adith Swaminathan",
      "Besmira Nushi",
      "Sean Andrist",
      "Eric Horvitz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5965",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5965/5821",
    "published": "2020-02",
    "summary": "Assemblies of modular subsystems are being pressed into service to perform sensing, reasoning, and decision making in high-stakes, time-critical tasks in areas such as transportation, healthcare, and industrial automation. We address the opportunity to maximize the utility of an overall computing system by employing reinforcement learning to guide the configuration of the set of interacting modules that comprise the system. The challenge of doing system-wide optimization is a combinatorial problem. Local attempts to boost the performance of a specific module by modifying its configuration often leads to losses in overall utility of the system's performance as the distribution of inputs to downstream modules changes drastically. We present metareasoning techniques which consider a rich representation of the input, monitor the state of the entire pipeline, and adjust the configuration of modules on-the-fly so as to maximize the utility of a system's operation. We show significant improvement in both real-world and synthetic pipelines across a variety of reinforcement learning techniques."
  },
  "aaai2020_main_self-supervisedlearningforgeneralizableout-of-distributiondetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Self-Supervised Learning for Generalizable Out-of-Distribution Detection ",
    "authors": [
      "Sina Mohseni",
      "Mandar Pitale",
      "JBS Yadawa",
      "Zhangyang Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5966",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5966/5822",
    "published": "2020-02",
    "summary": "The real-world deployment of Deep Neural Networks (DNNs) in safety-critical applications such as autonomous vehicles needs to address a variety of DNNs' vulnerabilities, one of which being detecting and rejecting out-of-distribution outliers that might result in unpredictable fatal errors. We propose a new technique relying on self-supervision for generalizable out-of-distribution (OOD) feature learning and rejecting those samples at the inference time. Our technique does not need to pre-know the distribution of targeted OOD samples and incur no extra overheads compared to other methods. We perform multiple image classification experiments and observe our technique to perform favorably against state-of-the-art OOD detection methods. Interestingly, we witness that our method also reduces in-distribution classification risk via rejecting samples near the boundaries of the training set distribution."
  },
  "aaai2020_main_learningweightedmodelintegrationdistributions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Weighted Model Integration Distributions ",
    "authors": [
      "Paolo Morettin",
      "Samuel Kolb",
      "Stefano Teso",
      "Andrea Passerini"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5967",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5967/5823",
    "published": "2020-02",
    "summary": "Weighted model integration (WMI) is a framework for probabilistic inference over distributions with discrete and continuous variables and structured supports. Despite the growing popularity of WMI, existing density estimators ignore the problem of learning a structured support, and thus fail to handle unfeasible configurations and piecewise-linear relations between continuous variables. We propose lariat, a novel method to tackle this challenging problem. In a first step, our approach induces an SMT(\u2112\u211bA) formula representing the support of the structured distribution. Next, it combines the latter with a density learned using a state-of-the-art estimation method. The overall model automatically accounts for the discontinuous nature of the underlying structured distribution. Our experimental results with synthetic and real-world data highlight the promise of the approach."
  },
  "aaai2020_main_anintrinsically-motivatedapproachforlearninghighlyexploringandfastmixingpolicies": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Intrinsically-Motivated Approach for Learning Highly Exploring and Fast Mixing Policies ",
    "authors": [
      "Mirco Mutti",
      "Marcello Restelli"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5968",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5968/5824",
    "published": "2020-02",
    "summary": "What is a good exploration strategy for an agent that interacts with an environment in the absence of external rewards? Ideally, we would like to get a policy driving towards a uniform state-action visitation (highly exploring) in a minimum number of steps (fast mixing), in order to ease efficient learning of any goal-conditioned policy later on. Unfortunately, it is remarkably arduous to directly learn an optimal policy of this nature. In this paper, we propose a novel surrogate objective for learning highly exploring and fast mixing policies, which focuses on maximizing a lower bound to the entropy of the steady-state distribution induced by the policy. In particular, we introduce three novel lower bounds, that lead to as many optimization problems, that tradeoff the theoretical guarantees with computational complexity. Then, we present a model-based reinforcement learning algorithm, IDE3AL, to learn an optimal policy according to the introduced objective. Finally, we provide an empirical evaluation of this algorithm on a set of hard-exploration tasks."
  },
  "aaai2020_main_efficientlyenumeratingsubstringswithstatisticallysignificantfrequenciesoflocallyoptimaloccurrencesingiganticstring": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Efficiently Enumerating Substrings with Statistically Significant Frequencies of Locally Optimal Occurrences in Gigantic String ",
    "authors": [
      "Atsuyoshi Nakamura",
      "Ichigaku Takigawa",
      "Hiroshi Mamitsuka"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5969",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5969/5825",
    "published": "2020-02",
    "summary": "We propose new frequent substring pattern mining which can enumerate all substrings with statistically significant frequencies of their locally optimal occurrences from a given single sequence. Our target application is genome sequences, around a half being said to be covered by interspersed and consecutive (tandem) repeats, and detecting these repeats is an important task in molecular life sciences. We evaluate the statistical significance of frequent substrings by using a string generation model with a memoryless stationary information source. We combine this idea with an existing algorithm, ESFLOO-0G.C (Nakamura et al. 2016), to enumerate all statistically significant substrings with locally optimal occurrences. We further develop a parallelized version of our algorithm. Experimental results using synthetic datasets showed the proposed algorithm achieved far higher F-measure in extracting substrings (with various lengths and frequencies) embedded in a randomly generated string with noise, than conventional algorithms. The large-scale experiment using the whole human genome sequence with 3,095,677,412 bases (letters) showed that our parallel algorithm covers 75% of the whole positions analyzed, around 4% and 24% higher than the recent report and the current cutting-edge knowledge, implying a biologically unique finding."
  },
  "aaai2020_main_pairwisefairnessforrankingandregression": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Pairwise Fairness for Ranking and Regression ",
    "authors": [
      "Harikrishna Narasimhan",
      "Andrew Cotter",
      "Maya Gupta",
      "Serena Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5970",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5970/5826",
    "published": "2020-02",
    "summary": "We present pairwise fairness metrics for ranking models and regression models that form analogues of statistical fairness notions such as equal opportunity, equal accuracy, and statistical parity. Our pairwise formulation supports both discrete protected groups, and continuous protected attributes. We show that the resulting training problems can be efficiently and effectively solved using existing constrained optimization and robust optimization techniques developed for fair classification. Experiments illustrate the broad applicability and trade-offs of these methods."
  },
  "aaai2020_main_bayesianoptimizationforcategoricalandcategory-specificcontinuousinputs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bayesian Optimization for Categorical and Category-Specific Continuous Inputs ",
    "authors": [
      "Dang Nguyen",
      "Sunil Gupta",
      "Santu Rana",
      "Alistair Shilton",
      "Svetha Venkatesh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5971",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5971/5827",
    "published": "2020-02",
    "summary": "Many real-world functions are defined over both categorical and category-specific continuous variables and thus cannot be optimized by traditional Bayesian optimization (BO) methods. To optimize such functions, we propose a new method that formulates the problem as a multi-armed bandit problem, wherein each category corresponds to an arm with its reward distribution centered around the optimum of the objective function in continuous variables. Our goal is to identify the best arm and the maximizer of the corresponding continuous function simultaneously. Our algorithm uses a Thompson sampling scheme that helps connecting both multi-arm bandit and BO in a unified framework. We extend our method to batch BO to allow parallel optimization when multiple resources are available. We theoretically analyze our method for convergence and prove sub-linear regret bounds. We perform a variety of experiments: optimization of several benchmark functions, hyper-parameter tuning of a neural network, and automatic selection of the best machine learning model along with its optimal hyper-parameters (a.k.a automated machine learning). Comparisons with other methods demonstrate the effectiveness of our proposed method."
  },
  "aaai2020_main_reliablemultilabelclassificationpredictionwithpartialabstention": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reliable Multilabel Classification: Prediction with Partial Abstention ",
    "authors": [
      "Vu-Linh Nguyen",
      "Eyke Hullermeier"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5972",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5972/5828",
    "published": "2020-02",
    "summary": "In contrast to conventional (single-label) classification, the setting of multilabel classification (MLC) allows an instance to belong to several classes simultaneously. Thus, instead of selecting a single class label, predictions take the form of a subset of all labels. In this paper, we study an extension of the setting of MLC, in which the learner is allowed to partially abstain from a prediction, that is, to deliver predictions on some but not necessarily all class labels. We propose a formalization of MLC with abstention in terms of a generalized loss minimization problem and present first results for the case of the Hamming loss, rank loss, and F-measure, both theoretical and experimental."
  },
  "aaai2020_main_ontheanatomyofmcmc-basedmaximumlikelihoodlearningofenergy-basedmodels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On the Anatomy of MCMC-Based Maximum Likelihood Learning of Energy-Based Models ",
    "authors": [
      "Erik Nijkamp",
      "Mitch Hill",
      "Tian Han",
      "Song-Chun Zhu",
      "Ying Nian Wu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5973",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5973/5829",
    "published": "2020-02",
    "summary": "This study investigates the effects of Markov chain Monte Carlo (MCMC) sampling in unsupervised Maximum Likelihood (ML) learning. Our attention is restricted to the family of unnormalized probability densities for which the negative log density (or energy function) is a ConvNet. We find that many of the techniques used to stabilize training in previous studies are not necessary. ML learning with a ConvNet potential requires only a few hyper-parameters and no regularization. Using this minimal framework, we identify a variety of ML learning outcomes that depend solely on the implementation of MCMC sampling."
  },
  "aaai2020_main_brain-mediatedtransferlearningofconvolutionalneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Brain-Mediated Transfer Learning of Convolutional Neural Networks ",
    "authors": [
      "Satoshi Nishida",
      "Yusuke Nakano",
      "Antoine Blanc",
      "Naoya Maeda",
      "Masataka Kado",
      "Shinji Nishimoto"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5974",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5974/5830",
    "published": "2020-02",
    "summary": "The human brain can effectively learn a new task from a small number of samples, which indicates that the brain can transfer its prior knowledge to solve tasks in different domains. This function is analogous to transfer learning (TL) in the field of machine learning. TL uses a well-trained feature space in a specific task domain to improve performance in new tasks with insufficient training data. TL with rich feature representations, such as features of convolutional neural networks (CNNs), shows high generalization ability across different task domains. However, such TL is still insufficient in making machine learning attain generalization ability comparable to that of the human brain. To examine if the internal representation of the brain could be used to achieve more efficient TL, we introduce a method for TL mediated by human brains. Our method transforms feature representations of audiovisual inputs in CNNs into those in activation patterns of individual brains via their association learned ahead using measured brain responses. Then, to estimate labels reflecting human cognition and behavior induced by the audiovisual inputs, the transformed representations are used for TL. We demonstrate that our brain-mediated TL (BTL) shows higher performance in the label estimation than the standard TL. In addition, we illustrate that the estimations mediated by different brains vary from brain to brain, and the variability reflects the individual variability in perception. Thus, our BTL provides a framework to improve the generalization ability of machine-learning feature representations and enable machine learning to estimate human-like cognition and behavior, including individual variability."
  },
  "aaai2020_main_maximumlikelihoodembeddingoflogisticrandomdotproductgraphs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Maximum Likelihood Embedding of Logistic Random Dot Product Graphs ",
    "authors": [
      "Luke J. O'Connor",
      "Muriel Medard",
      "Soheil Feizi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5975",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5975/5831",
    "published": "2020-02",
    "summary": "A latent space model for a family of random graphs assigns real-valued vectors to nodes of the graph such that edge probabilities are determined by latent positions. Latent space models provide a natural statistical framework for graph visualizing and clustering. A latent space model of particular interest is the Random Dot Product Graph (RDPG), which can be fit using an efficient spectral method; however, this method is based on a heuristic that can fail, even in simple cases. Here, we consider a closely related latent space model, the Logistic RDPG, which uses a logistic link function to map from latent positions to edge likelihoods. Over this model, we show that asymptotically exact maximum likelihood inference of latent position vectors can be achieved using an efficient spectral method. Our method involves computing top eigenvectors of a normalized adjacency matrix and scaling eigenvectors using a regression step. The novel regression scaling step is an essential part of the proposed method. In simulations, we show that our proposed method is more accurate and more robust than common practices. We also show the effectiveness of our approach over standard real networks of the karate club and political blogs."
  },
  "aaai2020_main_radialanddirectionalposteriorsforbayesiandeeplearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Radial and Directional Posteriors for Bayesian Deep Learning ",
    "authors": [
      "Changyong Oh",
      "Kamil Adamczewski",
      "Mijung Park"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5976",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5976/5832",
    "published": "2020-02",
    "summary": "We propose a new variational family for Bayesian neural networks. We decompose the variational posterior into two components, where the radial component captures the strength of each neuron in terms of its magnitude; while the directional component captures the statistical dependencies among the weight parameters. The dependencies learned via the directional density provide better modeling performance compared to the widely-used Gaussian mean-field-type variational family. In addition, the strength of input and output neurons learned via our posterior provides a structured way to compress neural networks. Indeed, experiments show that our variational family improves predictive performance and yields compressed networks simultaneously."
  },
  "aaai2020_main_weightedautomataextractionfromrecurrentneuralnetworksviaregressiononstatespaces": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Weighted Automata Extraction from Recurrent Neural Networks via Regression on State Spaces ",
    "authors": [
      "Takamasa Okudono",
      "Masaki Waga",
      "Taro Sekiyama",
      "Ichiro Hasuo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5977",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5977/5833",
    "published": "2020-02",
    "summary": "We present a method to extract a weighted finite automaton (WFA) from a recurrent neural network (RNN). Our method is based on the WFA learning algorithm by Balle and Mohri, which is in turn an extension of Angluin's classic L* algorithm. Our technical novelty is in the use of regression methods for the so-called equivalence queries, thus exploiting the internal state space of an RNN to prioritize counterexample candidates. This way we achieve a quantitative/weighted extension of the recent work by Weiss, Goldberg and Yahav that extracts DFAs. We experimentally evaluate the accuracy, expressivity and efficiency of the extracted WFAs."
  },
  "aaai2020_main_cut-basedgraphlearningnetworkstodiscovercompositionalstructureofsequentialvideodata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Cut-Based Graph Learning Networks to Discover Compositional Structure of Sequential Video Data ",
    "authors": [
      "Kyoung-Woon On",
      "Eun-Sol Kim",
      "Yu-Jung Heo",
      "Byoung-Tak Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5978",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5978/5834",
    "published": "2020-02",
    "summary": "Conventional sequential learning methods such as Recurrent Neural Networks (RNNs) focus on interactions between consecutive inputs, i.e. first-order Markovian dependency. However, most of sequential data, as seen with videos, have complex dependency structures that imply variable-length semantic flows and their compositions, and those are hard to be captured by conventional methods. Here, we propose Cut-Based Graph Learning Networks (CB-GLNs) for learning video data by discovering these complex structures of the video. The CB-GLNs represent video data as a graph, with nodes and edges corresponding to frames of the video and their dependencies respectively. The CB-GLNs find compositional dependencies of the data in multilevel graph forms via a parameterized kernel with graph-cut and a message passing framework. We evaluate the proposed method on the two different tasks for video understanding: Video theme classification (Youtube-8M dataset (Abu-El-Haija et al. 2016)) and Video Question and Answering (TVQA dataset(Lei et al. 2018)). The experimental results show that our model efficiently learns the semantic compositional structure of video data. Furthermore, our model achieves the highest performance in comparison to other baseline methods."
  },
  "aaai2020_main_uncorrectedleast-squarestemporaldifferencewithlambda-return": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Uncorrected Least-Squares Temporal Difference with Lambda-Return ",
    "authors": [
      "Takayuki Osogami"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5979",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5979/5835",
    "published": "2020-02",
    "summary": "Temporal difference, TD(\u03bb), learning is a foundation of reinforcement learning and also of interest in its own right for the tasks of prediction. Recently, true online TD(\u03bb) has been shown to closely approximate the \u201cforward view\u201d at every step, while conventional TD(\u03bb) does this only at the end of an episode. We re-examine least-squares temporal difference, LSTD(\u03bb), which has been derived from conventional TD(\u03bb). We design Uncorrected LSTD(\u03bb) in such a way that, when \u03bb = 1, Uncorrected LSTD(1) is equivalent to the least-squares method for the linear regression of Monte Carlo (MC) return at every step, while conventional LSTD(1) has this equivalence only at the end of an episode, since the MC return is corrected to be unbiased. We prove that Uncorrected LSTD(\u03bb) can have smaller variance than conventional LSTD(\u03bb), and this allows Uncorrected LSTD(\u03bb) to sometimes outperform conventional LSTD(\u03bb) in practice. When \u03bb = 0, however, Uncorrected LSTD(0) is not equivalent to LSTD. We thus also propose Mixed LSTD(\u03bb), which % mixes the two LSTD(\u03bb)s in a way that it matches conventional LSTD(\u03bb) at \u03bb = 0 and Uncorrected LSTD(\u03bb) at \u03bb = 1. In numerical experiments, we study how the three LSTD(\u03bb)s behave under limited training data."
  },
  "aaai2020_main_linearbanditswithfeaturefeedback": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Linear Bandits with Feature Feedback ",
    "authors": [
      "Urvashi Oswal",
      "Aniruddha Bhargava",
      "Robert Nowak"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5980",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5980/5836",
    "published": "2020-02",
    "summary": "This paper explores a new form of the linear bandit problem in which the algorithm receives the usual stochastic rewards as well as stochastic feedback about which features are relevant to the rewards, the latter feedback being the novel aspect. The focus of this paper is the development of new theory and algorithms for linear bandits with feature feedback which can achieve regret over time horizon T that scales like k\u221aT, without prior knowledge of which features are relevant nor the number k of relevant features. In comparison, the regret of traditional linear bandits is d\u221aT, where d is the total number of (relevant and irrelevant) features, so the improvement can be dramatic if k \u226a d. The computational complexity of the algorithm is proportional to k rather than d, making it much more suitable for real-world applications compared to traditional linear bandits. We demonstrate the performance of the algorithm with synthetic and real human-labeled data."
  },
  "aaai2020_main_overcomingcatastrophicforgettingbyneuron-levelplasticitycontrol": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Overcoming Catastrophic Forgetting by Neuron-Level Plasticity Control ",
    "authors": [
      "Inyoung Paik",
      "Sangjun Oh",
      "Taeyeong Kwak",
      "Injung Kim"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5981",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5981/5837",
    "published": "2020-02",
    "summary": "To address the issue of catastrophic forgetting in neural networks, we propose a novel, simple, and effective solution called neuron-level plasticity control (NPC). While learning a new task, the proposed method preserves the existing knowledge from the previous tasks by controlling the plasticity of the network at the neuron level. NPC estimates the importance value of each neuron and consolidates important neurons by applying lower learning rates, rather than restricting individual connection weights to stay close to the values optimized for the previous tasks. The experimental results on the several datasets show that neuron-level consolidation is substantially more effective compared to connection-level consolidation approaches."
  },
  "aaai2020_main_adversariallocalizedenergynetworkforstructuredprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adversarial Localized Energy Network for Structured Prediction ",
    "authors": [
      "Pingbo Pan",
      "Ping Liu",
      "Yan Yan",
      "Tianbao Yang",
      "Yi Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5982",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5982/5838",
    "published": "2020-02",
    "summary": "This paper focuses on energy model based structured output prediction. Though inheriting the benefits from energy-based models to handle the sophisticated cases, previous deep energy-based methods suffered from the substantial computation cost introduced by the enormous amounts of gradient steps in the inference process. To boost the efficiency and accuracy of the energy-based models on structured output prediction, we propose a novel method analogous to the adversarial learning framework. Specifically, in our proposed framework, the generator consists of an inference network while the discriminator is comprised of an energy network. The two sub-modules, i.e., the inference network and the energy network, can benefit each other mutually during the whole computation process. On the one hand, our modified inference network can boost the efficiency by predicting good initializations and reducing the searching space for the inference process; On the other hand, inheriting the benefits of the energy network, the energy module in our network can evaluate the quality of the generated output from the inference network and correspondingly provides a resourceful guide to the training of the inference network. In the ideal case, the adversarial learning strategy makes sure the two sub-modules can achieve an equilibrium state after steps. We conduct extensive experiments to verify the effectiveness and efficiency of our proposed method."
  },
  "aaai2020_main_scalingall-goalsupdatesinreinforcementlearningusingconvolutionalneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": "Scaling All-Goals Updates in Reinforcement Learning Using Convolutional Neural Networks ",
    "authors": [
      "Fabio Pardo",
      "Vitaly Levdik",
      "Petar Kormushev"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5983",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5983/5839",
    "published": "2020-02",
    "summary": "Being able to reach any desired location in the environment can be a valuable asset for an agent. Learning a policy to navigate between all pairs of states individually is often not feasible. An all-goals updating algorithm uses each transition to learn Q-values towards all goals simultaneously and off-policy. However the expensive numerous updates in parallel limited the approach to small tabular cases so far. To tackle this problem we propose to use convolutional network architectures to generate Q-values and updates for a large number of goals at once. We demonstrate the accuracy and generalization qualities of the proposed method on randomly generated mazes and Sokoban puzzles. In the case of on-screen goal coordinates the resulting mapping from frames to distance-maps directly informs the agent about which places are reachable and in how many steps. As an example of application we show that replacing the random actions in \u03b5-greedy exploration by several actions towards feasible goals generates better exploratory trajectories on Montezuma's Revenge and Super Mario All-Stars games."
  },
  "aaai2020_main_evolvegcnevolvinggraphconvolutionalnetworksfordynamicgraphs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs ",
    "authors": [
      "Aldo Pareja",
      "Giacomo Domeniconi",
      "Jie Chen",
      "Tengfei Ma",
      "Toyotaro Suzumura",
      "Hiroki Kanezashi",
      "Tim Kaler",
      "Tao Schardl",
      "Charles Leiserson"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5984",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5984/5840",
    "published": "2020-02",
    "summary": "Graph representation learning resurges as a trending research subject owing to the widespread use of deep learning for Euclidean data, which inspire various creative designs of neural networks in the non-Euclidean domain, particularly graphs. With the success of these graph neural networks (GNN) in the static setting, we approach further practical scenarios where the graph dynamically evolves. Existing approaches typically resort to node embeddings and use a recurrent neural network (RNN, broadly speaking) to regulate the embeddings and learn the temporal dynamics. These methods require the knowledge of a node in the full time span (including both training and testing) and are less applicable to the frequent change of the node set. In some extreme scenarios, the node sets at different time steps may completely differ. To resolve this challenge, we propose EvolveGCN, which adapts the graph convolutional network (GCN) model along the temporal dimension without resorting to node embeddings. The proposed approach captures the dynamism of the graph sequence through using an RNN to evolve the GCN parameters. Two architectures are considered for the parameter evolution. We evaluate the proposed approach on tasks including link prediction, edge classification, and node classification. The experimental results indicate a generally higher performance of EvolveGCN compared with related approaches. The code is available at https://github.com/IBM/EvolveGCN."
  },
  "aaai2020_main_unsupervisedattributedmultiplexnetworkembedding": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Unsupervised Attributed Multiplex Network Embedding ",
    "authors": [
      "Chanyoung Park",
      "Donghyun Kim",
      "Jiawei Han",
      "Hwanjo Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5985",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5985/5841",
    "published": "2020-02",
    "summary": "Nodes in a multiplex network are connected by multiple types of relations. However, most existing network embedding methods assume that only a single type of relation exists between nodes. Even for those that consider the multiplexity of a network, they overlook node attributes, resort to node labels for training, and fail to model the global properties of a graph. We present a simple yet effective unsupervised network embedding method for attributed multiplex network called DMGI, inspired by Deep Graph Infomax (DGI) that maximizes the mutual information between local patches of a graph, and the global representation of the entire graph. We devise a systematic way to jointly integrate the node embeddings from multiple graphs by introducing 1) the consensus regularization framework that minimizes the disagreements among the relation-type specific node embeddings, and 2) the universal discriminator that discriminates true samples regardless of the relation types. We also show that the attention mechanism infers the importance of each relation type, and thus can be useful for filtering unnecessary relation types as a preprocessing step. Extensive experiments on various downstream tasks demonstrate that DMGI outperforms the state-of-the-art methods, even though DMGI is fully unsupervised."
  },
  "aaai2020_main_achievingfairnessinthestochasticmulti-armedbanditproblem": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Achieving Fairness in the Stochastic Multi-Armed Bandit Problem ",
    "authors": [
      "Vishakha Patil",
      "Ganesh Ghalme",
      "Vineet Nair",
      "Y. Narahari"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5986",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5986/5842",
    "published": "2020-02",
    "summary": "We study an interesting variant of the stochastic multi-armed bandit problem, which we call the Fair-MAB problem, where, in addition to the objective of maximizing the sum of expected rewards, the algorithm also needs to ensure that at any time, each arm is pulled at least a pre-specified fraction of times. We investigate the interplay between learning and fairness in terms of a pre-specified vector denoting the fractions of guaranteed pulls. We define a fairness-aware regret, which we call r-Regret, that takes into account the above fairness constraints and extends the conventional notion of regret in a natural way. Our primary contribution is to obtain a complete characterization of a class of Fair-MAB algorithms via two parameters: the unfairness tolerance and the learning algorithm used as a black-box. For this class of algorithms, we provide a fairness guarantee that holds uniformly over time, irrespective of the choice of the learning algorithm. Further, when the learning algorithm is UCB1, we show that our algorithm achieves constant r-Regret for a large enough time horizon. Finally, we analyze the cost of fairness in terms of the conventional notion of regret. We conclude by experimentally validating our theoretical results."
  },
  "aaai2020_main_motif-matchingbasedsubgraph-levelattentionalconvolutionalnetworkforgraphclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Motif-Matching Based Subgraph-Level Attentional Convolutional Network for Graph Classification ",
    "authors": [
      "Hao Peng",
      "Jianxin Li",
      "Qiran Gong",
      "Yuanxin Ning",
      "Senzhang Wang",
      "Lifang He"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5987",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5987/5843",
    "published": "2020-02",
    "summary": "Graph classification is critically important to many real-world applications that are associated with graph data such as chemical drug analysis and social network mining. Traditional methods usually require feature engineering to extract the graph features that can help discriminate the graphs of different classes. Although recently deep learning based graph embedding approaches are proposed to automatically learn graph features, they mostly use a few vertex arrangements extracted from the graph for feature learning, which may lose some structural information. In this work, we present a novel motif-based attentional graph convolution neural network for graph classification, which can learn more discriminative and richer graph features. Specifically, a motif-matching guided subgraph normalization method is developed to better preserve the spatial information. A novel subgraph-level self-attention network is also proposed to capture the different impacts or weights of different subgraphs. Experimental results on both bioinformatics and social network datasets show that the proposed models significantly improve graph classification performance over both traditional graph kernel methods and recent deep learning approaches."
  },
  "aaai2020_main_abayesianapproachforestimatingcausaleffectsfromobservationaldata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Bayesian Approach for Estimating Causal Effects from Observational Data ",
    "authors": [
      "Johan Pensar",
      "Topi Talvitie",
      "Antti Hyttinen",
      "Mikko Koivisto"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5988",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5988/5844",
    "published": "2020-02",
    "summary": "We present a novel Bayesian method for the challenging task of estimating causal effects from passively observed data when the underlying causal DAG structure is unknown. To rigorously capture the inherent uncertainty associated with the estimate, our method builds a Bayesian posterior distribution of the linear causal effect, by integrating Bayesian linear regression and averaging over DAGs. For computing the exact posterior for all cause-effect variable pairs, we give an algorithm that runs in time O(3d d) for d variables, being feasible up to 20 variables. We also give a variant that computes the posterior probabilities of all pairwise ancestor relations within the same time complexity, significantly improving the fastest previous algorithm. In simulations, our Bayesian method outperforms previous methods in estimation accuracy, especially for small sample sizes. We further show that our method for effect estimation is well-adapted for detecting strong causal effects markedly deviating from zero, while our variant for computing posteriors of ancestor relations is the method of choice for detecting the mere existence of a causal relation. Finally, we apply our method on observational flow cytometry data, detecting several causal relations that concur with previous findings from experimental data."
  },
  "aaai2020_main_generalizedhiddenparametermdpstransferablemodel-basedrlinahandfuloftrials": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generalized Hidden Parameter MDPs:Transferable Model-Based RL in a Handful of Trials ",
    "authors": [
      "Christian Perez",
      "Felipe Petroski Such",
      "Theofanis Karaletsos"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5989",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5989/5845",
    "published": "2020-02",
    "summary": "There is broad interest in creating RL agents that can solve many (related) tasks and adapt to new tasks and environments after initial training. Model-based RL leverages learned surrogate models that describe dynamics and rewards of individual tasks, such that planning in a good surrogate can lead to good control of the true system. Rather than solving each task individually from scratch, hierarchical models can exploit the fact that tasks are often related by (unobserved) causal factors of variation in order to achieve efficient generalization, as in learning how the mass of an item affects the force required to lift it can generalize to previously unobserved masses. We propose Generalized Hidden Parameter MDPs (GHP-MDPs) that describe a family of MDPs where both dynamics and reward can change as a function of hidden parameters that vary across tasks. The GHP-MDP augments model-based RL with latent variables that capture these hidden parameters, facilitating transfer across tasks. We also explore a variant of the model that incorporates explicit latent structure mirroring the causal factors of variation across tasks (for instance: agent properties, environmental factors, and goals). We experimentally demonstrate state-of-the-art performance and sample-efficiency on a new challenging MuJoCo task using reward and dynamics latent spaces, while beating a previous state-of-the-art baseline with > 10\u00d7 less data. Using test-time inference of the latent variables, our approach generalizes in a single episode to novel combinations of dynamics and reward, and to novel rewards."
  },
  "aaai2020_main_cagareal-timelow-costenhanced-robustnesshigh-transferabilitycontent-awareadversarialattackgenerator": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " CAG: A Real-Time Low-Cost Enhanced-Robustness High-Transferability Content-Aware Adversarial Attack Generator ",
    "authors": [
      "Huy Phan",
      "Yi Xie",
      "Siyu Liao",
      "Jie Chen",
      "Bo Yuan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5990",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5990/5846",
    "published": "2020-02",
    "summary": "Deep neural networks (DNNs) are vulnerable to adversarial attack despite their tremendous success in many artificial intelligence fields. Adversarial attack is a method that causes the intended misclassfication by adding imperceptible perturbations to legitimate inputs. To date, researchers have developed numerous types of adversarial attack methods. However, from the perspective of practical deployment, these methods suffer from several drawbacks such as long attack generating time, high memory cost, insufficient robustness and low transferability. To address the drawbacks, we propose a Content-aware Adversarial Attack Generator (CAG) to achieve real-time, low-cost, enhanced-robustness and high-transferability adversarial attack. First, as a type of generative model-based attack, CAG shows significant speedup (at least 500 times) in generating adversarial examples compared to the state-of-the-art attacks such as PGD and C&W. Furthermore, CAG only needs a single generative model to perform targeted attack to any targeted class. Because CAG encodes the label information into a trainable embedding layer, it differs from prior generative model-based adversarial attacks that use n different copies of generative models for n different targeted classes. As a result, CAG significantly reduces the required memory cost for generating adversarial examples. Moreover, CAG can generate adversarial perturbations that focus on the critical areas of input by integrating the class activation maps information in the training process, and hence improve the robustness of CAG attack against the state-of-art adversarial defenses. In addition, CAG exhibits high transferability across different DNN classifier models in black-box attack scenario by introducing random dropout in the process of generating perturbations. Extensive experiments on different datasets and DNN models have verified the real-time, low-cost, enhanced-robustness, and high-transferability benefits of CAG."
  },
  "aaai2020_main_diversifiedbayesiannonnegativematrixfactorization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Diversified Bayesian Nonnegative Matrix Factorization ",
    "authors": [
      "Qiao Maoying",
      "Yu Jun",
      "Liu Tongliang",
      "Wang Xinchao",
      "Tao Dacheng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5991",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5991/5847",
    "published": "2020-02",
    "summary": "Nonnegative matrix factorization (NMF) has been widely employed in a variety of scenarios due to its capability of inducing semantic part-based representation. However, because of the non-convexity of its objective, the factorization is generally not unique and may inaccurately discover intrinsic \u201cparts\u201d from the data. In this paper, we approach this issue using a Bayesian framework. We propose to assign a diversity prior to the parts of the factorization to induce correctness based on the assumption that useful parts should be distinct and thus well-spread. A Bayesian framework including this diversity prior is then established. This framework aims at inducing factorizations embracing both good data fitness from maximizing likelihood and large separability from the diversity prior. Specifically, the diversity prior is formulated with determinantal point processes (DPP) and is seamlessly embedded into a Bayesian NMF framework. To carry out the inference, a Monte Carlo Markov Chain (MCMC) based procedure is derived. Experiments conducted on a synthetic dataset and a real-world MULAN dataset for multi-label learning (MLL) task demonstrate the superiority of the proposed method."
  },
  "aaai2020_main_stochasticapproximategradientdescentviathelangevinalgorithm": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Stochastic Approximate Gradient Descent via the Langevin Algorithm ",
    "authors": [
      "Yixuan Qiu",
      "Xiao Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5992",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5992/5848",
    "published": "2020-02",
    "summary": "We introduce a novel and efficient algorithm called the stochastic approximate gradient descent (SAGD), as an alternative to the stochastic gradient descent for cases where unbiased stochastic gradients cannot be trivially obtained. Traditional methods for such problems rely on general-purpose sampling techniques such as Markov chain Monte Carlo, which typically requires manual intervention for tuning parameters and does not work efficiently in practice. Instead, SAGD makes use of the Langevin algorithm to construct stochastic gradients that are biased in finite steps but accurate asymptotically, enabling us to theoretically establish the convergence guarantee for SAGD. Inspired by our theoretical analysis, we also provide useful guidelines for its practical implementation. Finally, we show that SAGD performs well experimentally in popular statistical and machine learning problems such as the expectation-maximization algorithm and the variational autoencoders."
  },
  "aaai2020_main_temporalnetworkembeddingwithhigh-ordernonlinearinformation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Temporal Network Embedding with High-Order Nonlinear Information ",
    "authors": [
      "Zhenyu Qiu",
      "Wenbin Hu",
      "Jia Wu",
      "Weiwei Liu",
      "Bo Du",
      "Xiaohua Jia"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5993",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5993/5849",
    "published": "2020-02",
    "summary": "Temporal network embedding, which aims to learn the low-dimensional representations of nodes in temporal networks that can capture and preserve the network structure and evolution pattern, has attracted much attention from the scientific community. However, existing methods suffer from two main disadvantages: 1) they cannot preserve the node temporal proximity that capture important properties of the network structure; and 2) they cannot represent the nonlinear structure of temporal networks. In this paper, we propose a high-order nonlinear information preserving (HNIP) embedding method to address these issues. Specifically, we define three orders of temporal proximities by exploring network historical information with a time exponential decay model to quantify the temporal proximity between nodes. Then, we propose a novel deep guided auto-encoder to capture the highly nonlinear structure. Meanwhile, the training set of the guide auto-encoder is generated by the temporal random walk (TRW) algorithm. By training the proposed deep guided auto-encoder with a specific mini-batch stochastic gradient descent algorithm, HNIP can efficiently preserves the temporal proximities and highly nonlinear structure of temporal networks. Experimental results on four real-world networks demonstrate the effectiveness of the proposed method."
  },
  "aaai2020_main_anewburrowswheelertransformmarkovdistance": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A New Burrows Wheeler Transform Markov Distance ",
    "authors": [
      "Edward Raff",
      "Charles Nicholas",
      "Mark McLean"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5994",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5994/5850",
    "published": "2020-02",
    "summary": "Prior work inspired by compression algorithms has described how the Burrows Wheeler Transform can be used to create a distance measure for bioinformatics problems. We describe issues with this approach that were not widely known, and introduce our new Burrows Wheeler Markov Distance (BWMD) as an alternative. The BWMD avoids the shortcomings of earlier efforts, and allows us to tackle problems in variable length DNA sequence clustering. BWMD is also more adaptable to other domains, which we demonstrate on malware classification tasks. Unlike other compression-based distance metrics known to us, BWMD works by embedding sequences into a fixed-length feature vector. This allows us to provide significantly improved clustering performance on larger malware corpora, a weakness of prior methods."
  },
  "aaai2020_main_howshouldanagentpractice?": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " How Should an Agent Practice? ",
    "authors": [
      "Janarthanan Rajendran",
      "Richard Lewis",
      "Vivek Veeriah",
      "Honglak Lee",
      "Satinder Singh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5995",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5995/5851",
    "published": "2020-02",
    "summary": "We present a method for learning intrinsic reward functions to drive the learning of an agent during periods of practice in which extrinsic task rewards are not available. During practice, the environment may differ from the one available for training and evaluation with extrinsic rewards. We refer to this setup of alternating periods of practice and objective evaluation as practice-match, drawing an analogy to regimes of skill acquisition common for humans in sports and games. The agent must effectively use periods in the practice environment so that performance improves during matches. In the proposed method the intrinsic practice reward is learned through a meta-gradient approach that adapts the practice reward parameters to reduce the extrinsic match reward loss computed from matches. We illustrate the method on a simple grid world, and evaluate it in two games in which the practice environment differs from match: Pong with practice against a wall without an opponent, and PacMan with practice in a maze without ghosts. The results show gains from learning in practice in addition to match periods over learning in matches only."
  },
  "aaai2020_main_synthesizingactionsequencesformodifyingmodeldecisions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Synthesizing Action Sequences for Modifying Model Decisions ",
    "authors": [
      "Goutham Ramakrishnan",
      "Yun Chan Lee",
      "Aws Albarghouthi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5996",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5996/5852",
    "published": "2020-02",
    "summary": "When a model makes a consequential decision, e.g., denying someone a loan, it needs to additionally generate actionable, realistic feedback on what the person can do to favorably change the decision. We cast this problem through the lens of program synthesis, in which our goal is to synthesize an optimal (realistically cheapest or simplest) sequence of actions that if a person executes successfully can change their classification. We present a novel and general approach that combines search-based program synthesis and test-time adversarial attacks to construct action sequences over a domain-specific set of actions. We demonstrate the effectiveness of our approach on a number of deep neural networks."
  },
  "aaai2020_main_asapadaptivestructureawarepoolingforlearninghierarchicalgraphrepresentations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph Representations ",
    "authors": [
      "Ekagra Ranjan",
      "Soumya Sanyal",
      "Partha Talukdar"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5997",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5997/5853",
    "published": "2020-02",
    "summary": "Graph Neural Networks (GNN) have been shown to work effectively for modeling graph structured data to solve tasks such as node classification, link prediction and graph classification. There has been some recent progress in defining the notion of pooling in graphs whereby the model tries to generate a graph level representation by downsampling and summarizing the information present in the nodes. Existing pooling methods either fail to effectively capture the graph substructure or do not easily scale to large graphs. In this work, we propose ASAP (Adaptive Structure Aware Pooling), a sparse and differentiable pooling method that addresses the limitations of previous graph pooling architectures. ASAP utilizes a novel self-attention network along with a modified GNN formulation to capture the importance of each node in a given graph. It also learns a sparse soft cluster assignment for nodes at each layer to effectively pool the subgraphs to form the pooled graph. Through extensive experiments on multiple datasets and theoretical analysis, we motivate our choice of the components used in ASAP. Our experimental results show that combining existing GNN architectures with ASAP leads to state-of-the-art results on multiple graph classification benchmarks. ASAP has an average improvement of 4%, compared to current sparse hierarchical state-of-the-art method. We make the source code of ASAP available to encourage reproducible research 1."
  },
  "aaai2020_main_abstractinterpretationofdecisiontreeensembleclassifiers": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Abstract Interpretation of Decision Tree Ensemble Classifiers ",
    "authors": [
      "Francesco Ranzato",
      "Marco Zanella"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5998",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5998/5854",
    "published": "2020-02",
    "summary": "We study the problem of formally and automatically verifying robustness properties of decision tree ensemble classifiers such as random forests and gradient boosted decision tree models. A recent stream of works showed how abstract interpretation, which is ubiquitously used in static program analysis, can be successfully deployed to formally verify (deep) neural networks. In this work we push forward this line of research by designing a general and principled abstract interpretation-based framework for the formal verification of robustness and stability properties of decision tree ensemble models. Our abstract interpretation-based method may induce complete robustness checks of standard adversarial perturbations and output concrete adversarial attacks. We implemented our abstract verification technique in a tool called silva, which leverages an abstract domain of not necessarily closed real hyperrectangles and is instantiated to verify random forests and gradient boosted decision trees. Our experimental evaluation on the MNIST dataset shows that silva provides a precise and efficient tool which advances the current state of the art in tree ensembles verification."
  },
  "aaai2020_main_optimizingnondecomposabledatadependentregularizersvialagrangianreparameterizationofferssignificantperformanceandefficiencygains": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Optimizing Nondecomposable Data Dependent Regularizers via Lagrangian Reparameterization Offers Significant Performance and Efficiency Gains ",
    "authors": [
      "Sathya N. Ravi",
      "Abhay Venkatesh",
      "Glenn M. Fung",
      "Vikas Singh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5999",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5999/5855",
    "published": "2020-02",
    "summary": "Data dependent regularization is known to benefit a wide variety of problems in machine learning. Often, these regularizers cannot be easily decomposed into a sum over a finite number of terms, e.g., a sum over individual example-wise terms. The F\u03b2 measure, Area under the ROC curve (AUCROC) and Precision at a fixed recall (P@R) are some prominent examples that are used in many applications. We find that for most medium to large sized datasets, scalability issues severely limit our ability in leveraging the benefits of such regularizers. Importantly, the key technical impediment despite some recent progress is that, such objectives remain difficult to optimize via backpropapagation procedures. While an efficient general-purpose strategy for this problem still remains elusive, in this paper, we show that for many data-dependent nondecomposable regularizers that are relevant in applications, sizable gains in efficiency are possible with minimal code-level changes; in other words, no specialized tools or numerical schemes are needed. Our procedure involves a reparameterization followed by a partial dualization \u2013 this leads to a formulation that has provably cheap projection operators. We present a detailed analysis of runtime and convergence properties of our algorithm. On the experimental side, we show that a direct use of our scheme significantly improves the state of the art IOU measures reported for MSCOCO Stuff segmentation dataset."
  },
  "aaai2020_main_darbadensity-adaptiveregular-blockpruningfordeepneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DARB: A Density-Adaptive Regular-Block Pruning for Deep Neural Networks ",
    "authors": [
      "Ren Ao",
      "Zhang Tao",
      "Wang Yuhao",
      "Lin Sheng",
      "Dong Peiyan",
      "Chen Yen-kuang",
      "Xie Yuan",
      "Wang Yanzhi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6000",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6000/5856",
    "published": "2020-02",
    "summary": "The rapidly growing parameter volume of deep neural networks (DNNs) hinders the artificial intelligence applications on resource constrained devices, such as mobile and wearable devices. Neural network pruning, as one of the mainstream model compression techniques, is under extensive study to reduce the model size and thus the amount of computation. And thereby, the state-of-the-art DNNs are able to be deployed on those devices with high runtime energy efficiency. In contrast to irregular pruning that incurs high index storage and decoding overhead, structured pruning techniques have been proposed as the promising solutions. However, prior studies on structured pruning tackle the problem mainly from the perspective of facilitating hardware implementation, without diving into the deep to analyze the characteristics of sparse neural networks. The neglect on the study of sparse neural networks causes inefficient trade-off between regularity and pruning ratio. Consequently, the potential of structurally pruning neural networks is not sufficiently mined."
  },
  "aaai2020_main_delay-adaptivedistributedstochasticoptimization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Delay-Adaptive Distributed Stochastic Optimization ",
    "authors": [
      "Zhaolin Ren",
      "Zhengyuan Zhou",
      "Linhai Qiu",
      "Ajay Deshpande",
      "Jayant Kalagnanam"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6001",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6001/5857",
    "published": "2020-02",
    "summary": "In large-scale optimization problems, distributed asynchronous stochastic gradient descent (DASGD) is a commonly used algorithm. In most applications, there are often a large number of computing nodes asynchronously computing gradient information. As such, the gradient information received at a given iteration is often stale. In the presence of such delays, which can be unbounded, the convergence of DASGD is uncertain. The contribution of this paper is twofold. First, we propose a delay-adaptive variant of DASGD where we adjust each iteration's step-size based on the size of the delay, and prove asymptotic convergence of the algorithm on variationally coherent stochastic problems, a class of functions which properly includes convex, quasi-convex and star-convex functions. Second, we extend the convergence results of standard DASGD, used usually for problems with bounded domains, to problems with unbounded domains. In this way, we extend the frontier of theoretical guarantees for distributed asynchronous optimization, and provide new insights for practitioners working on large-scale optimization problems."
  },
  "aaai2020_main_fairnessforrobustloglossclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fairness for Robust Log Loss Classification ",
    "authors": [
      "Ashkan Rezaei",
      "Rizal Fathony",
      "Omid Memarrast",
      "Brian Ziebart"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6002",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6002/5858",
    "published": "2020-02",
    "summary": "Developing classification methods with high accuracy that also avoid unfair treatment of different groups has become increasingly important for data-driven decision making in social applications. Many existing methods enforce fairness constraints on a selected classifier (e.g., logistic regression) by directly forming constrained optimizations. We instead re-derive a new classifier from the first principles of distributional robustness that incorporates fairness criteria into a worst-case logarithmic loss minimization. This construction takes the form of a minimax game and produces a parametric exponential family conditional distribution that resembles truncated logistic regression. We present the theoretical benefits of our approach in terms of its convexity and asymptotic convergence. We then demonstrate the practical advantages of our approach on three benchmark fairness datasets."
  },
  "aaai2020_main_ontheroleofweightsharingduringdeepoptionlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On the Role of Weight Sharing During Deep Option Learning ",
    "authors": [
      "Matthew Riemer",
      "Ignacio Cases",
      "Clemens Rosenbaum",
      "Miao Liu",
      "Gerald Tesauro"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6003",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6003/5859",
    "published": "2020-02",
    "summary": "The options framework is a popular approach for building temporally extended actions in reinforcement learning. In particular, the option-critic architecture provides general purpose policy gradient theorems for learning actions from scratch that are extended in time. However, past work makes the key assumption that each of the components of option-critic has independent parameters. In this work we note that while this key assumption of the policy gradient theorems of option-critic holds in the tabular case, it is always violated in practice for the deep function approximation setting. We thus reconsider this assumption and consider more general extensions of option-critic and hierarchical option-critic training that optimize for the full architecture with each update. It turns out that not assuming parameter independence challenges a belief in prior work that training the policy over options can be disentangled from the dynamics of the underlying options. In fact, learning can be sped up by focusing the policy over options on states where options are actually likely to terminate. We put our new algorithms to the test in application to sample efficient learning of Atari games, and demonstrate significantly improved stability and faster convergence when learning long options. 1"
  },
  "aaai2020_main_ensemblesoflocallyindependentpredictionmodels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Ensembles of Locally Independent Prediction Models ",
    "authors": [
      "Andrew Ross",
      "Weiwei Pan",
      "Leo Celi",
      "Finale Doshi-Velez"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6004",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6004/5860",
    "published": "2020-02",
    "summary": "Ensembles depend on diversity for improved performance. Many ensemble training methods, therefore, attempt to optimize for diversity, which they almost always define in terms of differences in training set predictions. In this paper, however, we demonstrate the diversity of predictions on the training set does not necessarily imply diversity under mild covariate shift, which can harm generalization in practical settings. To address this issue, we introduce a new diversity metric and associated method of training ensembles of models that extrapolate differently on local patches of the data manifold. Across a variety of synthetic and real-world tasks, we find that our method improves generalization and diversity in qualitatively novel ways, especially under data limits and covariate shift."
  },
  "aaai2020_main_actionableethicsthroughneurallearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Actionable Ethics through Neural Learning ",
    "authors": [
      "Daniele Rossini",
      "Danilo Croce",
      "Sara Mancini",
      "Massimo Pellegrino",
      "Roberto Basili"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6005",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6005/5861",
    "published": "2020-02",
    "summary": "While AI is going to produce a great impact on society, its alignment with human values and expectations is an essential step towards a correct harnessing of AI potentials for good. There is a corresponding growing need for mature and established technical standards to enable the assessment of an AI application as the evaluation of its graded adherence to formalized ethics. This is clearly dependent on methods to inject ethical awareness at all stages of an AI application development and use. For this reason we introduce the notion of Embedding Principles of ethics by Design (EPbD) as a comprehensive inductive framework. Although extending generic AI applications, it mainly aims at learning the ethical behaviour through numerical optimization, i.e. deep neural models. The core idea is to support ethics by integrating automated reasoning over formal knowledge and induction from ethically enriched training data. A deep neural network is proposed here to model both the functional as well as the ethical conditions characterizing a target decision. In this way, the discovery of latent ethical knowledge is enabled and made available to the learning process. The application of the above framework to a banking application, i.e. AI-driven Digital Lending, is used to show how accurate classification can be achieved without neglecting the ethical dimension. Results over existing datasets demonstrate that the ethical compliance of the sources can be used to output models able to optimally fine tune the balance between business and ethical accuracy."
  },
  "aaai2020_main_generativecontinualconceptlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generative Continual Concept Learning ",
    "authors": [
      "Mohammad Rostami",
      "Soheil Kolouri",
      "Praveen Pilly",
      "James McClelland"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6006",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6006/5862",
    "published": "2020-02",
    "summary": "After learning a concept, humans are also able to continually generalize their learned concepts to new domains by observing only a few labeled instances without any interference with the past learned knowledge. In contrast, learning concepts efficiently in a continual learning setting remains an open challenge for current Artificial Intelligence algorithms as persistent model retraining is necessary. Inspired by the Parallel Distributed Processing learning and the Complementary Learning Systems theories, we develop a computational model that is able to expand its previously learned concepts efficiently to new domains using a few labeled samples. We couple the new form of a concept to its past learned forms in an embedding space for effective continual learning. Doing so, a generative distribution is learned such that it is shared across the tasks in the embedding space and models the abstract concepts. This procedure enables the model to generate pseudo-data points to replay the past experience to tackle catastrophic forgetting."
  },
  "aaai2020_main_linearcontexttransformblock": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Linear Context Transform Block ",
    "authors": [
      "Dongsheng Ruan",
      "Jun Wen",
      "Nenggan Zheng",
      "Min Zheng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6007",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6007/5863",
    "published": "2020-02",
    "summary": "Squeeze-and-Excitation (SE) block presents a channel attention mechanism for modeling global context via explicitly capturing dependencies across channels. However, we are still far from understanding how the SE block works. In this work, we first revisit the SE block, and then present a detailed empirical study of the relationship between global context and attention distribution, based on which we propose a simple yet effective module, called Linear Context Transform (LCT) block. We divide all channels into different groups and normalize the globally aggregated context features within each channel group, reducing the disturbance from irrelevant channels. Through linear transform of the normalized context features, we model global context for each channel independently. The LCT block is extremely lightweight and easy to be plugged into different backbone models while with negligible parameters and computational burden increase. Extensive experiments show that the LCT block outperforms the SE block in image classification task on the ImageNet and object detection/segmentation on the COCO dataset with different backbone models. Moreover, LCT yields consistent performance gains over existing state-of-the-art detection architectures, e.g., 1.5\u223c1.7% APbbox and 1.0%\u223c1.2% APmask improvements on the COCO benchmark, irrespective of different baseline models of varied capacities. We hope our simple yet effective approach will shed some light on future research of attention-based models."
  },
  "aaai2020_main_chainedrepresentationcyclinglearningtoestimate3dhumanposeandshapebycyclingbetweenrepresentations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Chained Representation Cycling: Learning to Estimate 3D Human Pose and Shape by Cycling Between Representations ",
    "authors": [
      "Nadine Rueegg",
      "Christoph Lassner",
      "Michael Black",
      "Konrad Schindler",
      "Nadine Rueegg",
      "Christoph Lassner",
      "Michael Black",
      "Konrad Schindler"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6008",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6008/5864",
    "published": "2020-02",
    "summary": "The goal of many computer vision systems is to transform image pixels into 3D representations. Recent popular models use neural networks to regress directly from pixels to 3D object parameters. Such an approach works well when supervision is available, but in problems like human pose and shape estimation, it is difficult to obtain natural images with 3D ground truth. To go one step further, we propose a new architecture that facilitates unsupervised, or lightly supervised, learning. The idea is to break the problem into a series of transformations between increasingly abstract representations. Each step involves a cycle designed to be learnable without annotated training data, and the chain of cycles delivers the final solution. Specifically, we use 2D body part segments as an intermediate representation that contains enough information to be lifted to 3D, and at the same time is simple enough to be learned in an unsupervised way. We demonstrate the method by learning 3D human pose and shape from un-paired and un-annotated images. We also explore varying amounts of paired data and show that cycling greatly alleviates the need for paired data. While we present results for modeling humans, our formulation is general and can be applied to other vision problems."
  },
  "aaai2020_main_weaklysupervisedsequencetaggingfromnoisyrules": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Weakly Supervised Sequence Tagging from Noisy Rules ",
    "authors": [
      "Esteban Safranchik",
      "Shiying Luo",
      "Stephen Bach"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6009",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6009/5865",
    "published": "2020-02",
    "summary": "We propose a framework for training sequence tagging models with weak supervision consisting of multiple heuristic rules of unknown accuracy. In addition to supporting rules that vote on tags in the output sequence, we introduce a new type of weak supervision, called linking rules, that vote on how sequence elements should be grouped into spans with the same tag. These rules are an alternative to candidate span generators that require significantly more human effort. To estimate the accuracies of the rules and combine their conflicting outputs into training data, we introduce a new type of generative model, linked hidden Markov models (linked HMMs), and prove they are generically identifiable (up to a tag permutation) without any observed training labels. We find that linked HMMs provide an average 7 F1 point boost on benchmark named entity recognition tasks versus generative models that assume the tags are i.i.d. Further, neural sequence taggers trained with these structure-aware generative models outperform comparable state-of-the-art approaches to weak supervision by an average of 2.6 F1 points."
  },
  "aaai2020_main_randomintersectiongraphsandmissingdata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Random Intersection Graphs and Missing Data ",
    "authors": [
      "Dror Salti",
      "Yakir Berchenko"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6010",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6010/5866",
    "published": "2020-02",
    "summary": "Random-graphs and statistical inference with missing data are two separate topics that have been widely explored each in its field. In this paper we demonstrate the relationship between these two different topics and take a novel view of the data matrix as a random intersection graph. We use graph properties and theoretical results from random-graph theory, such as connectivity and the emergence of the giant component, to identify two threshold phenomena in statistical inference with missing data: loss of identifiability and slower convergence of algorithms that are pertinent to statistical inference such as expectation-maximization (EM). We provide two examples corresponding to these threshold phenomena and illustrate the theoretical predictions with simulations that are consistent with our reduction."
  },
  "aaai2020_main_rank3dgansemanticmeshgenerationusingrelativeattributes": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Rank3DGAN: Semantic Mesh Generation Using Relative Attributes ",
    "authors": [
      "Yassir Saquil",
      "Qun-Ce Xu",
      "Yong-Liang Yang",
      "Peter Hall"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6011",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6011/5867",
    "published": "2020-02",
    "summary": "In this paper, we investigate a novel problem of using generative adversarial networks in the task of 3D shape generation according to semantic attributes. Recent works map 3D shapes into 2D parameter domain, which enables training Generative Adversarial Networks (GANs) for 3D shape generation task. We extend these architectures to the conditional setting, where we generate 3D shapes with respect to subjective attributes defined by the user. Given pairwise comparisons of 3D shapes, our model performs two tasks: it learns a generative model with a controlled latent space, and a ranking function for the 3D shapes based on their multi-chart representation in 2D. The capability of the model is demonstrated with experiments on HumanShape, Basel Face Model and reconstructed 3D CUB datasets. We also present various applications that benefit from our model, such as multi-attribute exploration, mesh editing, and mesh attribute transfer."
  },
  "aaai2020_main_weightedsamplingforcombinedmodelselectionandhyperparametertuning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Weighted Sampling for Combined Model Selection and Hyperparameter Tuning ",
    "authors": [
      "Dimitrios Sarigiannis",
      "Thomas Parnell",
      "Haralampos Pozidis"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6012",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6012/5868",
    "published": "2020-02",
    "summary": "The combined algorithm selection and hyperparameter tuning (CASH) problem is characterized by large hierarchical hyperparameter spaces. Model-free hyperparameter tuning methods can explore such large spaces efficiently since they are highly parallelizable across multiple machines. When no prior knowledge or meta-data exists to boost their performance, these methods commonly sample random configurations following a uniform distribution. In this work, we propose a novel sampling distribution as an alternative to uniform sampling and prove theoretically that it has a better chance of finding the best configuration in a worst-case setting. In order to compare competing methods rigorously in an experimental setting, one must perform statistical hypothesis testing. We show that there is little-to-no agreement in the automated machine learning literature regarding which methods should be used. We contrast this disparity with the methods recommended by the broader statistics literature, and identify a suitable approach. We then select three popular model-free solutions to CASH and evaluate their performance, with uniform sampling as well as the proposed sampling scheme, across 67 datasets from the OpenML platform. We investigate the trade-off between exploration and exploitation across the three algorithms, and verify empirically that the proposed sampling distribution improves performance in all cases."
  },
  "aaai2020_main_graphrepresentationlearningvialaddergammavariationalautoencoders": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Graph Representation Learning via Ladder Gamma Variational Autoencoders ",
    "authors": [
      "Arindam Sarkar",
      "Nikhil Mehta",
      "Piyush Rai"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6013",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6013/5869",
    "published": "2020-02",
    "summary": "We present a probabilistic framework for community discovery and link prediction for graph-structured data, based on a novel, gamma ladder variational autoencoder (VAE) architecture. We model each node in the graph via a deep hierarchy of gamma-distributed embeddings, and define each link probability via a nonlinear function of the bottom-most layer's embeddings of its associated nodes. In addition to leveraging the representational power of multiple layers of stochastic variables via the ladder VAE architecture, our framework offers the following benefits: (1) Unlike existing ladder VAE architectures based on real-valued latent variables, the gamma-distributed latent variables naturally result in non-negativity and sparsity of the learned embeddings, and facilitate their direct interpretation as membership of nodes into (possibly multiple) communities/topics; (2) A novel recognition model for our gamma ladder VAE architecture allows fast inference of node embeddings; and (3) The framework also extends naturally to incorporate node side information (features and/or labels). Our framework is also fairly modular and can leverage a wide variety of graph neural networks as the VAE encoder. We report both quantitative and qualitative results on several benchmark datasets and compare our model with several state-of-the-art methods."
  },
  "aaai2020_main_learningcounterfactualrepresentationsforestimatingindividualdose-responsecurves": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Counterfactual Representations for Estimating Individual Dose-Response Curves ",
    "authors": [
      "Patrick Schwab",
      "Lorenz Linhardt",
      "Stefan Bauer",
      "Joachim M. Buhmann",
      "Walter Karlen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6014",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6014/5870",
    "published": "2020-02",
    "summary": "Estimating what would be an individual's potential response to varying levels of exposure to a treatment is of high practical relevance for several important fields, such as healthcare, economics and public policy. However, existing methods for learning to estimate counterfactual outcomes from observational data are either focused on estimating average dose-response curves, or limited to settings with only two treatments that do not have an associated dosage parameter. Here, we present a novel machine-learning approach towards learning counterfactual representations for estimating individual dose-response curves for any number of treatments with continuous dosage parameters with neural networks. Building on the established potential outcomes framework, we introduce performance metrics, model selection criteria, model architectures, and open benchmarks for estimating individual dose-response curves. Our experiments show that the methods developed in this work set a new state-of-the-art in estimating individual dose-response."
  },
  "aaai2020_main_uncertainty-awaredeepclassifiersusinggenerativemodels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Uncertainty-Aware Deep Classifiers Using Generative Models ",
    "authors": [
      "Murat Sensoy",
      "Lance Kaplan",
      "Federico Cerutti",
      "Maryam Saleki"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6015",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6015/5871",
    "published": "2020-02",
    "summary": "Deep neural networks are often ignorant about what they do not know and overconfident when they make uninformed predictions. Some recent approaches quantify classification uncertainty directly by training the model to output high uncertainty for the data samples close to class boundaries or from the outside of the training distribution. These approaches use an auxiliary data set during training to represent out-of-distribution samples. However, selection or creation of such an auxiliary data set is non-trivial, especially for high dimensional data such as images. In this work we develop a novel neural network model that is able to express both aleatoric and epistemic uncertainty to distinguish decision boundary and out-of-distribution regions of the feature space. To this end, variational autoencoders and generative adversarial networks are incorporated to automatically generate out-of-distribution exemplars for training. Through extensive analysis, we demonstrate that the proposed approach provides better estimates of uncertainty for in- and out-of-distribution samples, and adversarial examples on well-known data sets against state-of-the-art approaches including recent Bayesian approaches for neural networks and anomaly detection methods."
  },
  "aaai2020_main_empiricalboundsonlinearregionsofdeeprectifiernetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Empirical Bounds on Linear Regions of Deep Rectifier Networks ",
    "authors": [
      "Thiago Serra",
      "Srikumar Ramalingam"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6016",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6016/5872",
    "published": "2020-02",
    "summary": "We can compare the expressiveness of neural networks that use rectified linear units (ReLUs) by the number of linear regions, which reflect the number of pieces of the piecewise linear functions modeled by such networks. However, enumerating these regions is prohibitive and the known analytical bounds are identical for networks with same dimensions. In this work, we approximate the number of linear regions through empirical bounds based on features of the trained network and probabilistic inference. Our first contribution is a method to sample the activation patterns defined by ReLUs using universal hash functions. This method is based on a Mixed-Integer Linear Programming (MILP) formulation of the network and an algorithm for probabilistic lower bounds of MILP solution sets that we call MIPBound, which is considerably faster than exact counting and reaches values in similar orders of magnitude. Our second contribution is a tighter activation-based bound for the maximum number of linear regions, which is particularly stronger in networks with narrow layers. Combined, these bounds yield a fast proxy for the number of linear regions of a deep neural network."
  },
  "aaai2020_main_universaladversarialtraining": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Universal Adversarial Training ",
    "authors": [
      "Ali Shafahi",
      "Mahyar Najibi",
      "Zheng Xu",
      "John Dickerson",
      "Larry S. Davis",
      "Tom Goldstein"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6017",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6017/5873",
    "published": "2020-02",
    "summary": "Standard adversarial attacks change the predicted class label of a selected image by adding specially tailored small perturbations to its pixels. In contrast, a universal perturbation is an update that can be added to any image in a broad class of images, while still changing the predicted class label. We study the efficient generation of universal adversarial perturbations, and also efficient methods for hardening networks to these attacks. We propose a simple optimization-based universal attack that reduces the top-1 accuracy of various network architectures on ImageNet to less than 20%, while learning the universal perturbation 13\u00d7 faster than the standard method."
  },
  "aaai2020_main_sequentialmodeestimationwithoraclequeries": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Sequential Mode Estimation with Oracle Queries ",
    "authors": [
      "Dhruti Shah",
      "Tuhinangshu Choudhury",
      "Nikhil Karamchandani",
      "Aditya Gopalan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6018",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6018/5874",
    "published": "2020-02",
    "summary": "We consider the problem of adaptively PAC-learning a probability distribution \ud835\udcab's mode by querying an oracle for information about a sequence of i.i.d. samples X1, X2, \u2026 generated from \ud835\udcab. We consider two different query models: (a) each query is an index i for which the oracle reveals the value of the sample Xi, (b) each query is comprised of two indices i and j for which the oracle reveals if the samples Xi and Xj are the same or not. For these query models, we give sequential mode-estimation algorithms which, at each time t, either make a query to the corresponding oracle based on past observations, or decide to stop and output an estimate for the distribution's mode, required to be correct with a specified confidence. We analyze the query complexity of these algorithms for any underlying distribution \ud835\udcab, and derive corresponding lower bounds on the optimal query complexity under the two querying models."
  },
  "aaai2020_main_onlineactivelearningofrejectoptionclassifiers": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Online Active Learning of Reject Option Classifiers ",
    "authors": [
      "Kulin Shah",
      "Naresh Manwani"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6019",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6019/5875",
    "published": "2020-02",
    "summary": "Active learning is an important technique to reduce the number of labeled examples in supervised learning. Active learning for binary classification has been well addressed in machine learning. However, active learning of the reject option classifier remains unaddressed. In this paper, we propose novel algorithms for active learning of reject option classifiers. We develop an active learning algorithm using double ramp loss function. We provide mistake bounds for this algorithm. We also propose a new loss function called double sigmoid loss function for reject option and corresponding active learning algorithm. We offer a convergence guarantee for this algorithm. We provide extensive experimental results to show the effectiveness of the proposed algorithms. The proposed algorithms efficiently reduce the number of label examples required."
  },
  "aaai2020_main_improvedpac-bayesianboundsforlinearregression": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Improved PAC-Bayesian Bounds for Linear Regression ",
    "authors": [
      "Vera Shalaeva",
      "Alireza Fakhrizadeh Esfahani",
      "Pascal Germain",
      "Mihaly Petreczky"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6020",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6020/5876",
    "published": "2020-02",
    "summary": "In this paper, we improve the PAC-Bayesian error bound for linear regression derived in Germain et al. (2016). The improvements are two-fold. First, the proposed error bound is tighter, and converges to the generalization loss with a well-chosen temperature parameter. Second, the error bound also holds for training data that are not independently sampled. In particular, the error bound applies to certain time series generated by well-known classes of dynamical models, such as ARX models."
  },
  "aaai2020_main_adaptivetrustregionpolicyoptimizationglobalconvergenceandfasterratesforregularizedmdps": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adaptive Trust Region Policy Optimization: Global Convergence and Faster Rates for Regularized MDPs ",
    "authors": [
      "Lior Shani",
      "Yonathan Efroni",
      "Shie Mannor"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6021",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6021/5877",
    "published": "2020-02",
    "summary": "Trust region policy optimization (TRPO) is a popular and empirically successful policy search algorithm in Reinforcement Learning (RL) in which a surrogate problem, that restricts consecutive policies to be \u2018close\u2019 to one another, is iteratively solved. Nevertheless, TRPO has been considered a heuristic algorithm inspired by Conservative Policy Iteration (CPI). We show that the adaptive scaling mechanism used in TRPO is in fact the natural \u201cRL version\u201d of traditional trust-region methods from convex analysis. We first analyze TRPO in the planning setting, in which we have access to the model and the entire state space. Then, we consider sample-based TRPO and establish \u00d5(1/\u221aN) convergence rate to the global optimum. Importantly, the adaptive scaling mechanism allows us to analyze TRPO in regularized MDPs for which we prove fast rates of \u00d5(1/N), much like results in convex optimization. This is the first result in RL of better rates when regularizing the instantaneous cost or reward."
  },
  "aaai2020_main_transfervalueiterationnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Transfer Value Iteration Networks ",
    "authors": [
      "Junyi Shen",
      "Hankz Hankui Zhuo",
      "Jin Xu",
      "Bin Zhong",
      "Sinno Pan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6022",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6022/5878",
    "published": "2020-02",
    "summary": "Value iteration networks (VINs) have been demonstrated to have a good generalization ability for reinforcement learning tasks across similar domains. However, based on our experiments, a policy learned by VINs still fail to generalize well on the domain whose action space and feature space are not identical to those in the domain where it is trained. In this paper, we propose a transfer learning approach on top of VINs, termed Transfer VINs (TVINs), such that a learned policy from a source domain can be generalized to a target domain with only limited training data, even if the source domain and the target domain have domain-specific actions and features. We empirically verify that our proposed TVINs outperform VINs when the source and the target domains have similar but not identical action and feature spaces. Furthermore, we show that the performance improvement is consistent across different environments, maze sizes, dataset sizes as well as different values of hyperparameters such as number of iteration and kernel size."
  },
  "aaai2020_main_aucoptimizationwitharejectoption": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AUC Optimization with a Reject Option ",
    "authors": [
      "Song-Qing Shen",
      "Bin-Bin Yang",
      "Wei Gao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6023",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6023/5879",
    "published": "2020-02",
    "summary": "Making an erroneous decision may cause serious results in diverse mission-critical tasks such as medical diagnosis and bioinformatics. Previous work focuses on classification with a reject option, i.e., abstain rather than classify an instance of low confidence. Most mission-critical tasks are always accompanied with class imbalance and cost sensitivity, where AUC has been shown a preferable measure than accuracy in classification. In this work, we propose the framework of AUC optimization with a reject option, and the basic idea is to withhold the decision of ranking a pair of positive and negative instances with a lower cost, rather than mis-ranking. We obtain the Bayes optimal solution for ranking, and learn the reject function and score function for ranking, simultaneously. An online algorithm has been developed for AUC optimization with a reject option, by considering the convex relaxation and plug-in rule. We verify, both theoretically and empirically, the effectiveness of the proposed algorithm."
  },
  "aaai2020_main_stablelearningviasamplereweighting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Stable Learning via Sample Reweighting ",
    "authors": [
      "Zheyan Shen",
      "Peng Cui",
      "Tong Zhang",
      "Kun Kunag"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6024",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6024/5880",
    "published": "2020-02",
    "summary": "We consider the problem of learning linear prediction models with model misspecification bias. In such case, the collinearity among input variables may inflate the error of parameter estimation, resulting in instability of prediction results when training and test distributions do not match. In this paper we theoretically analyze this fundamental problem and propose a sample reweighting method that reduces collinearity among input variables. Our method can be seen as a pretreatment of data to improve the condition of design matrix, and it can then be combined with any standard learning method for parameter estimation and variable selection. Empirical studies on both simulation and real datasets demonstrate the effectiveness of our method in terms of more stable performance across different distributed data."
  },
  "aaai2020_main_fractionalskippingtowardsfiner-graineddynamiccnninference": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fractional Skipping: Towards Finer-Grained Dynamic CNN Inference ",
    "authors": [
      "Jianghao Shen",
      "Yue Wang",
      "Pengfei Xu",
      "Yonggan Fu",
      "Zhangyang Wang",
      "Yingyan Lin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6025",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6025/5881",
    "published": "2020-02",
    "summary": "While increasingly deep networks are still in general desired for achieving state-of-the-art performance, for many specific inputs a simpler network might already suffice. Existing works exploited this observation by learning to skip convolutional layers in an input-dependent manner. However, we argue their binary decision scheme, i.e., either fully executing or completely bypassing one layer for a specific input, can be enhanced by introducing finer-grained, \u201csofter\u201d decisions. We therefore propose a Dynamic Fractional Skipping (DFS) framework. The core idea of DFS is to hypothesize layer-wise quantization (to different bitwidths) as intermediate \u201csoft\u201d choices to be made between fully utilizing and skipping a layer. For each input, DFS dynamically assigns a bitwidth to both weights and activations of each layer, where fully executing and skipping could be viewed as two \u201cextremes\u201d (i.e., full bitwidth and zero bitwidth). In this way, DFS can \u201cfractionally\u201d exploit a layer's expressive power during input-adaptive inference, enabling finer-grained accuracy-computational cost trade-offs. It presents a unified view to link input-adaptive layer skipping and input-adaptive hybrid quantization. Extensive experimental results demonstrate the superior tradeoff between computational cost and model expressive power (accuracy) achieved by DFS. More visualizations also indicate a smooth and consistent transition in the DFS behaviors, especially the learned choices between layer skipping and different quantizations when the total computational budgets vary, validating our hypothesis that layer quantization could be viewed as intermediate variants of layer skipping. Our source code and supplementary material are available at https://github.com/Torment123/DFS."
  },
  "aaai2020_main_revisitingimageaestheticassessmentviaself-supervisedfeaturelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Revisiting Image Aesthetic Assessment via Self-Supervised Feature Learning ",
    "authors": [
      "Kekai Sheng",
      "Weiming Dong",
      "Menglei Chai",
      "Guohui Wang",
      "Peng Zhou",
      "Feiyue Huang",
      "Bao-Gang Hu",
      "Rongrong Ji",
      "Chongyang Ma"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6026",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6026/5882",
    "published": "2020-02",
    "summary": "Visual aesthetic assessment has been an active research field for decades. Although latest methods have achieved promising performance on benchmark datasets, they typically rely on a large number of manual annotations including both aesthetic labels and related image attributes. In this paper, we revisit the problem of image aesthetic assessment from the self-supervised feature learning perspective. Our motivation is that a suitable feature representation for image aesthetic assessment should be able to distinguish different expert-designed image manipulations, which have close relationships with negative aesthetic effects. To this end, we design two novel pretext tasks to identify the types and parameters of editing operations applied to synthetic instances. The features from our pretext tasks are then adapted for a one-layer linear classifier to evaluate the performance in terms of binary aesthetic classification. We conduct extensive quantitative experiments on three benchmark datasets and demonstrate that our approach can faithfully extract aesthetics-aware features and outperform alternative pretext schemes. Moreover, we achieve comparable results to state-of-the-art supervised methods that use 10 million labels from ImageNet."
  },
  "aaai2020_main_gamma-netsgeneralizingvalueestimationovertimescale": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Gamma-Nets: Generalizing Value Estimation over Timescale ",
    "authors": [
      "Craig Sherstan",
      "Shibhansh Dohare",
      "James MacGlashan",
      "Johannes G\u00fcnther",
      "Patrick M. Pilarski"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6027",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6027/5883",
    "published": "2020-02",
    "summary": "Temporal abstraction is a key requirement for agents making decisions over long time horizons\u2014a fundamental challenge in reinforcement learning. There are many reasons why value estimates at multiple timescales might be useful; recent work has shown that value estimates at different time scales can be the basis for creating more advanced discounting functions and for driving representation learning. Further, predictions at many different timescales serve to broaden an agent's model of its environment. One predictive approach of interest within an online learning setting is general value function (GVFs), which represent models of an agent's world as a collection of predictive questions each defined by a policy, a signal to be predicted, and a prediction timescale. In this paper we present \u0393-nets, a method for generalizing value function estimation over timescale, allowing a given GVF to be trained and queried for arbitrary timescales so as to greatly increase the predictive ability and scalability of a GVF-based model. The key to our approach is to use timescale as one of the value estimator's inputs. As a result, the prediction target for any timescale is available at every timestep and we are free to train on any number of timescales. We first provide two demonstrations by 1) predicting a square wave and 2) predicting sensorimotor signals on a robot arm using a linear function approximator. Next, we empirically evaluate \u0393-nets in the deep reinforcement learning setting using policy evaluation on a set of Atari video games. Our results show that \u0393-nets can be effective for predicting arbitrary timescales, with only a small cost in accuracy as compared to learning estimators for fixed timescales. \u0393-nets provide a method for accurately and compactly making predictions at many timescales without requiring a priori knowledge of the task, making it a valuable contribution to ongoing work on model-based planning, representation learning, and lifelong learning algorithms."
  },
  "aaai2020_main_deeptime-streamframeworkforclick-throughratepredictionbytrackinginterestevolution": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Time-Stream Framework for Click-through Rate Prediction by Tracking Interest Evolution ",
    "authors": [
      "Shu-Ting Shi",
      "Wenhao Zheng",
      "Jun Tang",
      "Qing-Guo Chen",
      "Yao Hu",
      "Jianke Zhu",
      "Ming Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6028",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6028/5884",
    "published": "2020-02",
    "summary": "Click-through rate (CTR) prediction is an essential task in industrial applications such as video recommendation. Recently, deep learning models have been proposed to learn the representation of users' overall interests, while ignoring the fact that interests may dynamically change over time. We argue that it is necessary to consider the continuous-time information in CTR models to track user interest trend from rich historical behaviors. In this paper, we propose a novel Deep Time-Stream framework (DTS) which introduces the time information by an ordinary differential equations (ODE). DTS continuously models the evolution of interests using a neural network, and thus is able to tackle the challenge of dynamically representing users' interests based on their historical behaviors. In addition, our framework can be seamlessly applied to any existing deep CTR models by leveraging the additional Time-Stream Module, while no changes are made to the original CTR models. Experiments on public dataset as well as real industry dataset with billions of samples demonstrate the effectiveness of proposed approaches, which achieve superior performance compared with existing methods."
  },
  "aaai2020_main_quadruplystochasticgradientmethodforlargescalenonlinearsemi-supervisedordinalregressionaucoptimization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Quadruply Stochastic Gradient Method for Large Scale Nonlinear Semi-Supervised Ordinal Regression AUC Optimization ",
    "authors": [
      "Wanli Shi",
      "Bin Gu",
      "Xiang Li",
      "Heng Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6029",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6029/5885",
    "published": "2020-02",
    "summary": "Semi-supervised ordinal regression (S2OR) problems are ubiquitous in real-world applications, where only a few ordered instances are labeled and massive instances remain unlabeled. Recent researches have shown that directly optimizing concordance index or AUC can impose a better ranking on the data than optimizing the traditional error rate in ordinal regression (OR) problems. In this paper, we propose an unbiased objective function for S2OR AUC optimization based on ordinal binary decomposition approach. Besides, to handle the large-scale kernelized learning problems, we propose a scalable algorithm called QS3ORAO using the doubly stochastic gradients (DSG) framework for functional optimization. Theoretically, we prove that our method can converge to the optimal solution at the rate of O(1/t), where t is the number of iterations for stochastic data sampling. Extensive experimental results on various benchmark and real-world datasets also demonstrate that our method is efficient and effective while retaining similar generalization performance."
  },
  "aaai2020_main_loss-basedattentionfordeepmultipleinstancelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Loss-Based Attention for Deep Multiple Instance Learning ",
    "authors": [
      "Xiaoshuang Shi",
      "Fuyong Xing",
      "Yuanpu Xie",
      "Zizhao Zhang",
      "Lei Cui",
      "Lin Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6030",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6030/5886",
    "published": "2020-02",
    "summary": "Although attention mechanisms have been widely used in deep learning for many tasks, they are rarely utilized to solve multiple instance learning (MIL) problems, where only a general category label is given for multiple instances contained in one bag. Additionally, previous deep MIL methods firstly utilize the attention mechanism to learn instance weights and then employ a fully connected layer to predict the bag label, so that the bag prediction is largely determined by the effectiveness of learned instance weights. To alleviate this issue, in this paper, we propose a novel loss based attention mechanism, which simultaneously learns instance weights and predictions, and bag predictions for deep multiple instance learning. Specifically, it calculates instance weights based on the loss function, e.g. softmax+cross-entropy, and shares the parameters with the fully connected layer, which is to predict instance and bag predictions. Additionally, a regularization term consisting of learned weights and cross-entropy functions is utilized to boost the recall of instances, and a consistency cost is used to smooth the training process of neural networks for boosting the model generalization performance. Extensive experiments on multiple types of benchmark databases demonstrate that the proposed attention mechanism is a general, effective and efficient framework, which can achieve superior bag and image classification performance over other state-of-the-art MIL methods, with obtaining higher instance precision and recall than previous attention mechanisms. Source codes are available on https://github.com/xsshi2015/Loss-Attention."
  },
  "aaai2020_main_deepmessagepassingonsets": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Message Passing on Sets ",
    "authors": [
      "Yifeng Shi",
      "Junier Oliva",
      "Marc Niethammer"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6031",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6031/5887",
    "published": "2020-02",
    "summary": "Modern methods for learning over graph input data have shown the fruitfulness of accounting for relationships among elements in a collection. However, most methods that learn over set input data use only rudimentary approaches to exploit intra-collection relationships. In this work we introduce Deep Message Passing on Sets (DMPS), a novel method that incorporates relational learning for sets. DMPS not only connects learning on graphs with learning on sets via deep kernel learning, but it also bridges message passing on sets and traditional diffusion dynamics commonly used in denoising models. Based on these connections, we develop two new blocks for relational learning on sets: the set-denoising block and the set-residual block. The former is motivated by the connection between message passing on general graphs and diffusion-based denoising models, whereas the latter is inspired by the well-known residual network. In addition to demonstrating the interpretability of our model by learning the true underlying relational structure experimentally, we also show the effectiveness of our approach on both synthetic and real-world datasets by achieving results that are competitive with or outperform the state-of-the-art. For readers who are interested in the detailed derivations of serveral results that we present in this work, please see the supplementary material at: https://arxiv.org/abs/1909.09877."
  },
  "aaai2020_main_blockhankeltensorarimaformultipleshorttimeseriesforecasting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Block Hankel Tensor ARIMA for Multiple Short Time Series Forecasting ",
    "authors": [
      "Qiquan Shi",
      "Jiaming Yin",
      "Jiajun Cai",
      "Andrzej Cichocki",
      "Tatsuya Yokota",
      "Lei Chen",
      "Mingxuan Yuan",
      "Jia Zeng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6032",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6032/5888",
    "published": "2020-02",
    "summary": "This work proposes a novel approach for multiple time series forecasting. At first, multi-way delay embedding transform (MDT) is employed to represent time series as low-rank block Hankel tensors (BHT). Then, the higher-order tensors are projected to compressed core tensors by applying Tucker decomposition. At the same time, the generalized tensor Autoregressive Integrated Moving Average (ARIMA) is explicitly used on consecutive core tensors to predict future samples. In this manner, the proposed approach tactically incorporates the unique advantages of MDT tensorization (to exploit mutual correlations) and tensor ARIMA coupled with low-rank Tucker decomposition into a unified framework. This framework exploits the low-rank structure of block Hankel tensors in the embedded space and captures the intrinsic correlations among multiple TS, which thus can improve the forecasting results, especially for multiple short time series. Experiments conducted on three public datasets and two industrial datasets verify that the proposed BHT-ARIMA effectively improves forecasting accuracy and reduces computational cost compared with the state-of-the-art methods."
  },
  "aaai2020_main_morphism-basedlearningforstructureddata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Morphism-Based Learning for Structured Data ",
    "authors": [
      "Kilho Shin",
      "Dave Shepard"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6033",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6033/5889",
    "published": "2020-02",
    "summary": "In mathematics, morphism is a term that indicates structure-preserving mappings between mathematical structures of the same type. Linear transformations for linear spaces, homomorphisms for algebraic structures and continuous functions for topological spaces are examples. Many data researched in machine learning, on the other hand, can include mathematical structures in them. Strings are totally ordered sets, and trees can be understood not only as graphs but also as partially ordered sets with respect to an ancestor-to-descendent order and semigroups with respect to the binary operation to determine nearest common ancestor. In this paper, we propose a generic and theoretic framework to investigate similarity of structured data through structure-preserving one-to-one partial mappings, which we call morphisms. Through morphisms, useful and important methods studied in the literature can be abstracted into common concepts, although they have been studied separately. When we study new structures of data, we will be able to extend the legacy methods for the purpose of studying the new structure, if we can define morphisms properly. Also, this view reveals hidden relations between methods known in the literature and can let us understand them more clearly. For example, we see that the center star algorithm, which was originally developed to compute sequential multiple alignments, can be abstracted so that it not only applies to data structures other than strings but also can be used to solve problems of pattern extraction. The methods that we study in this paper include edit distance, multiple alignment, pattern extraction and kernel, but it is sure that there exist much more methods that can be abstracted within our framework."
  },
  "aaai2020_main_hierarchicallyclusteredrepresentationlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Hierarchically Clustered Representation Learning ",
    "authors": [
      "Su-Jin Shin",
      "Kyungwoo Song",
      "Il-Chul Moon"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6034",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6034/5890",
    "published": "2020-02",
    "summary": "The joint optimization of representation learning and clustering in the embedding space has experienced a breakthrough in recent years. In spite of the advance, clustering with representation learning has been limited to flat-level categories, which often involves cohesive clustering with a focus on instance relations. To overcome the limitations of flat clustering, we introduce hierarchically-clustered representation learning (HCRL), which simultaneously optimizes representation learning and hierarchical clustering in the embedding space. Compared with a few prior works, HCRL firstly attempts to consider a generation of deep embeddings from every component of the hierarchy, not just leaf components. In addition to obtaining hierarchically clustered embeddings, we can reconstruct data by the various abstraction levels, infer the intrinsic hierarchical structure, and learn the level-proportion features. We conducted evaluations with image and text domains, and our quantitative analyses showed competent likelihoods and the best accuracies compared with the baselines."
  },
  "aaai2020_main_hlhlpquantizedneuralnetworkstrainingforreachingflatminimainlosssurface": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " HLHLp: Quantized Neural Networks Training for Reaching Flat Minima in Loss Surface ",
    "authors": [
      "Sungho Shin",
      "Jinhwan Park",
      "Yoonho Boo",
      "Wonyong Sung"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6035",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6035/5891",
    "published": "2020-02",
    "summary": "Quantization of deep neural networks is extremely essential for efficient implementations. Low-precision networks are typically designed to represent original floating-point counterparts with high fidelity, and several elaborate quantization algorithms have been developed. We propose a novel training scheme for quantized neural networks to reach flat minima in the loss surface with the aid of quantization noise. The proposed training scheme employs high-low-high-low precision in an alternating manner for network training. The learning rate is also abruptly changed at each stage for coarse- or fine-tuning. With the proposed training technique, we show quite good performance improvements for convolutional neural networks when compared to the previous fine-tuning based quantization scheme. We achieve the state-of-the-art results for recurrent neural network based language modeling with 2-bit weight and activation."
  },
  "aaai2020_main_uncertainty-awareactionadvisingfordeepreinforcementlearningagents": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Uncertainty-Aware Action Advising for Deep Reinforcement Learning Agents ",
    "authors": [
      "Felipe Leno Da Silva",
      "Pablo Hernandez-Leal",
      "Bilal Kartal",
      "Matthew E. Taylor"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6036",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6036/5892",
    "published": "2020-02",
    "summary": "Although Reinforcement Learning (RL) has been one of the most successful approaches for learning in sequential decision making problems, the sample-complexity of RL techniques still represents a major challenge for practical applications. To combat this challenge, whenever a competent policy (e.g., either a legacy system or a human demonstrator) is available, the agent could leverage samples from this policy (advice) to improve sample-efficiency. However, advice is normally limited, hence it should ideally be directed to states where the agent is uncertain on the best action to execute. In this work, we propose Requesting Confidence-Moderated Policy advice (RCMP), an action-advising framework where the agent asks for advice when its epistemic uncertainty is high for a certain state. RCMP takes into account that the advice is limited and might be suboptimal. We also describe a technique to estimate the agent uncertainty by performing minor modifications in standard value-function-based RL methods. Our empirical evaluations show that RCMP performs better than Importance Advising, not receiving advice, and receiving it at random states in Gridworld and Atari Pong scenarios."
  },
  "aaai2020_main_efficientfacialfeaturelearningwithwideensemble-basedconvolutionalneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Efficient Facial Feature Learning with Wide Ensemble-Based Convolutional Neural Networks ",
    "authors": [
      "Henrique Siqueira",
      "Sven Magg",
      "Stefan Wermter"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6037",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6037/5893",
    "published": "2020-02",
    "summary": "Ensemble methods, traditionally built with independently trained de-correlated models, have proven to be efficient methods for reducing the remaining residual generalization error, which results in robust and accurate methods for real-world applications. In the context of deep learning, however, training an ensemble of deep networks is costly and generates high redundancy which is inefficient. In this paper, we present experiments on Ensembles with Shared Representations (ESRs) based on convolutional networks to demonstrate, quantitatively and qualitatively, their data processing efficiency and scalability to large-scale datasets of facial expressions. We show that redundancy and computational load can be dramatically reduced by varying the branching level of the ESR without loss of diversity and generalization power, which are both important for ensemble performance. Experiments on large-scale datasets suggest that ESRs reduce the remaining residual generalization error on the AffectNet and FER+ datasets, reach human-level performance, and outperform state-of-the-art methods on facial expression recognition in the wild using emotion and affect concepts."
  },
  "aaai2020_main_aggregatedlearningavector-quantizationapproachtolearningneuralnetworkclassifiers": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Aggregated Learning: A Vector-Quantization Approach to Learning Neural Network Classifiers ",
    "authors": [
      "Masoumeh Soflaei",
      "Hongyu Guo",
      "Ali Al-Bashabsheh",
      "Yongyi Mao",
      "Richong Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6038",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6038/5894",
    "published": "2020-02",
    "summary": "We consider the problem of learning a neural network classifier. Under the information bottleneck (IB) principle, we associate with this classification problem a representation learning problem, which we call \u201cIB learning\u201d. We show that IB learning is, in fact, equivalent to a special class of the quantization problem. The classical results in rate-distortion theory then suggest that IB learning can benefit from a \u201cvector quantization\u201d approach, namely, simultaneously learning the representations of multiple input objects. Such an approach assisted with some variational techniques, result in a novel learning framework, \u201cAggregated Learning\u201d, for classification with neural network models. In this framework, several objects are jointly classified by a single neural network. The effectiveness of this framework is verified through extensive experiments on standard image recognition and text classification tasks."
  },
  "aaai2020_main_bivariatebeta-lstm": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bivariate Beta-LSTM ",
    "authors": [
      "Kyungwoo Song",
      "JoonHo Jang",
      "Seung jae Shin",
      "Il-Chul Moon"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6039",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6039/5895",
    "published": "2020-02",
    "summary": "Long Short-Term Memory (LSTM) infers the long term dependency through a cell state maintained by the input and the forget gate structures, which models a gate output as a value in [0,1] through a sigmoid function. However, due to the graduality of the sigmoid function, the sigmoid gate is not flexible in representing multi-modality or skewness. Besides, the previous models lack modeling on the correlation between the gates, which would be a new method to adopt inductive bias for a relationship between previous and current input. This paper proposes a new gate structure with the bivariate Beta distribution. The proposed gate structure enables probabilistic modeling on the gates within the LSTM cell so that the modelers can customize the cell state flow with priors and distributions. Moreover, we theoretically show the higher upper bound of the gradient compared to the sigmoid function, and we empirically observed that the bivariate Beta distribution gate structure provides higher gradient values in training. We demonstrate the effectiveness of the bivariate Beta gate structure on the sentence classification, image classification, polyphonic music modeling, and image caption generation."
  },
  "aaai2020_main_mega-rewardachievinghuman-levelplaywithoutextrinsicrewards": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Mega-Reward: Achieving Human-Level Play without Extrinsic Rewards ",
    "authors": [
      "Yuhang Song",
      "Jianyi Wang",
      "Thomas Lukasiewicz",
      "Zhenghua Xu",
      "Shangtong Zhang",
      "Andrzej Wojcicki",
      "Mai Xu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6040",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6040/5896",
    "published": "2020-02",
    "summary": "Intrinsic rewards were introduced to simulate how human intelligence works; they are usually evaluated by intrinsically-motivated play, i.e., playing games without extrinsic rewards but evaluated with extrinsic rewards. However, none of the existing intrinsic reward approaches can achieve human-level performance under this very challenging setting of intrinsically-motivated play. In this work, we propose a novel megalomania-driven intrinsic reward (called mega-reward), which, to our knowledge, is the first approach that achieves human-level performance in intrinsically-motivated play. Intuitively, mega-reward comes from the observation that infants' intelligence develops when they try to gain more control on entities in an environment; therefore, mega-reward aims to maximize the control capabilities of agents on given entities in a given environment. To formalize mega-reward, a relational transition model is proposed to bridge the gaps between direct and latent control. Experimental studies show that mega-reward (i) can greatly outperform all state-of-the-art intrinsic reward approaches, (ii) generally achieves the same level of performance as Ex-PPO and professional human-level scores, and (iii) has also a superior performance when it is incorporated with extrinsic rewards."
  },
  "aaai2020_main_infomaxneuraljointsource-channelcodingviaadversarialbitflip": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Infomax Neural Joint Source-Channel Coding via Adversarial Bit Flip ",
    "authors": [
      "Yuxuan Song",
      "Minkai Xu",
      "Lantao Yu",
      "Hao Zhou",
      "Shuo Shao",
      "Yong Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6041",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6041/5897",
    "published": "2020-02",
    "summary": "Although Shannon theory states that it is asymptotically optimal to separate the source and channel coding as two independent processes, in many practical communication scenarios this decomposition is limited by the finite bit-length and computational power for decoding. Recently, neural joint source-channel coding (NECST) (Choi et al. 2018) is proposed to sidestep this problem. While it leverages the advancements of amortized inference and deep learning (Kingma and Welling 2013; Grover and Ermon 2018) to improve the encoding and decoding process, it still cannot always achieve compelling results in terms of compression and error correction performance due to the limited robustness of its learned coding networks. In this paper, motivated by the inherent connections between neural joint source-channel coding and discrete representation learning, we propose a novel regularization method called Infomax Adversarial-Bit-Flip (IABF) to improve the stability and robustness of the neural joint source-channel coding scheme. More specifically, on the encoder side, we propose to explicitly maximize the mutual information between the codeword and data; while on the decoder side, the amortized reconstruction is regularized within an adversarial framework. Extensive experiments conducted on various real-world datasets evidence that our IABF can achieve state-of-the-art performances on both compression and error correction benchmarks and outperform the baselines by a significant margin."
  },
  "aaai2020_main_benignexamplesimperceptiblechangescanenhanceimagetranslationperformance": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Benign Examples: Imperceptible Changes Can Enhance Image Translation Performance ",
    "authors": [
      "Vignesh Srinivasan",
      "Klaus-Robert M\u00fcller",
      "Wojciech Samek",
      "Shinichi Nakajima"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6042",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6042/5898",
    "published": "2020-02",
    "summary": "Unpaired image-to-image domain translation involves the task of transferring an image in one domain to another domain without having pairs of data for supervision. Several methods have been proposed to address this task using Generative Adversarial Networks (GANs) and cycle consistency constraint enforcing the translated image to be mapped back to the original domain. This way, a Deep Neural Network (DNN) learns mapping such that the input training distribution transferred to the target domain matches the target training distribution. However, not all test images are expected to fall inside the data manifold in the input space where the DNN has learned to perform the mapping very well. Such images can have a poor mapping to the target domain. In this paper, we propose to perform Langevin dynamics, which makes a subtle change in the input space bringing them close to the data manifold, producing benign examples. The effect is significant improvement of the mapped image on the target domain. We also show that the score function estimation by denoising autoencoder (DAE), can practically be replaced with any autoencoding structure, which most image-to-image translation methods contain intrinsically due to the cycle consistency constraint. Thus, no additional training is required. We show advantages of our approach for several state-of-the-art image-to-image domain translation models. Quantitative evaluation shows that our proposed method leads to a substantial increase in the accuracy to the target label on multiple state-of-the-art image classifiers, while qualitative user study proves that our method better represents the target domain, achieving better human preference scores."
  },
  "aaai2020_main_scalableprobabilisticmatrixfactorizationwithgraph-basedpriors": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Scalable Probabilistic Matrix Factorization with Graph-Based Priors ",
    "authors": [
      "Jonathan Strahl",
      "Jaakko Peltonen",
      "Hirsohi Mamitsuka",
      "Samuel Kaski"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6043",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6043/5899",
    "published": "2020-02",
    "summary": "In matrix factorization, available graph side-information may not be well suited for the matrix completion problem, having edges that disagree with the latent-feature relations learnt from the incomplete data matrix. We show that removing these contested edges improves prediction accuracy and scalability. We identify the contested edges through a highly-efficient graphical lasso approximation. The identification and removal of contested edges adds no computational complexity to state-of-the-art graph-regularized matrix factorization, remaining linear with respect to the number of non-zeros. Computational load even decreases proportional to the number of edges removed. Formulating a probabilistic generative model and using expectation maximization to extend graph-regularised alternating least squares (GRALS) guarantees convergence. Rich simulated experiments illustrate the desired properties of the resulting algorithm. On real data experiments we demonstrate improved prediction accuracy with fewer graph edges (empirical evidence that graph side-information is often inaccurate). A 300 thousand dimensional graph with three million edges (Yahoo music side-information) can be analyzed in under ten minutes on a standard laptop computer demonstrating the efficiency of our graph update."
  },
  "aaai2020_main_learningefficientrepresentationsforfakespeechdetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Efficient Representations for Fake Speech Detection ",
    "authors": [
      "Nishant Subramani",
      "Delip Rao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6044",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6044/5900",
    "published": "2020-02",
    "summary": "Synthetic speech or \u201cfake speech\u201d which matches personal vocal traits has become better and cheaper due to advances in deep learning-based speech synthesis and voice conversion approaches. This increased accessibility of synthetic speech systems and the growing misuse of them highlights the critical need to build countermeasures. Furthermore, new synthesis models evolve all the time and the efficacy of previously trained detection models on these unseen attack vectors is poor. In this paper, we focus on: 1) How can we build highly accurate, yet parameter and sample-efficient models for fake speech detection? 2) How can we rapidly adapt detection models to new sources of fake speech? We present four parameter-efficient convolutional architectures for fake speech detection with best detection F1 scores of around 97 points on a large dataset of fake and bonafide speech. We show how the fake speech detection task naturally lends itself to a novel multi-task problem further improving F1 scores for a mere 0.5% increase in model parameters. Our multi-task setting also helps in data-sparse situations, commonplace in adversarial settings. We investigate an alternative approach to the data-sparsity problem using transfer learning and show that it is possible to meet purely supervised detection performance for unseen attack vectors with as little as 6.25% of the training data. This is the first known application of transfer learning in adversarial settings for speech. Finally, we show how well our transfer learning approach adapts in an instance-efficient way to new attack vectors using the Real-Time Voice Cloning toolkit. We exceed the purely supervised detection performance (99.18 F1) with as little as 6.25% of the data."
  },
  "aaai2020_main_lifelongspectralclustering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Lifelong Spectral Clustering ",
    "authors": [
      "Gan Sun",
      "Yang Cong",
      "Qianqian Wang",
      "Jun Li",
      "Yun Fu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6045",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6045/5901",
    "published": "2020-02",
    "summary": "In the past decades, spectral clustering (SC) has become one of the most effective clustering algorithms. However, most previous studies focus on spectral clustering tasks with a fixed task set, which cannot incorporate with a new spectral clustering task without accessing to previously learned tasks. In this paper, we aim to explore the problem of spectral clustering in a lifelong machine learning framework, i.e., Lifelong Spectral Clustering (L2SC). Its goal is to efficiently learn a model for a new spectral clustering task by selectively transferring previously accumulated experience from knowledge library. Specifically, the knowledge library of L2SC contains two components: 1) orthogonal basis library: capturing latent cluster centers among the clusters in each pair of tasks; 2) feature embedding library: embedding the feature manifold information shared among multiple related tasks. As a new spectral clustering task arrives, L2SC firstly transfers knowledge from both basis library and feature library to obtain encoding matrix, and further redefines the library base over time to maximize performance across all the clustering tasks. Meanwhile, a general online update formulation is derived to alternatively update the basis library and feature library. Finally, the empirical experiments on several real-world benchmark datasets demonstrate that our L2SC model can effectively improve the clustering performance when comparing with other state-of-the-art spectral clustering algorithms."
  },
  "aaai2020_main_newinterpretationsofnormalizationmethodsindeeplearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " New Interpretations of Normalization Methods in Deep Learning ",
    "authors": [
      "Jiacheng Sun",
      "Xiangyong Cao",
      "Hanwen Liang",
      "Weiran Huang",
      "Zewei Chen",
      "Zhenguo Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6046",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6046/5902",
    "published": "2020-02",
    "summary": "In recent years, a variety of normalization methods have been proposed to help training neural networks, such as batch normalization (BN), layer normalization (LN), weight normalization (WN), group normalization (GN), etc. However, some necessary tools to analyze all these normalization methods are lacking. In this paper, we first propose a lemma to define some necessary tools. Then, we use these tools to make a deep analysis on popular normalization methods and obtain the following conclusions: 1) Most of the normalization methods can be interpreted in a unified framework, namely normalizing pre-activations or weights onto a sphere; 2) Since most of the existing normalization methods are scaling invariant, we can conduct optimization on a sphere with scaling symmetry removed, which can help to stabilize the training of network; 3) We prove that training with these normalization methods can make the norm of weights increase, which could cause adversarial vulnerability as it amplifies the attack. Finally, a series of experiments are conducted to verify these claims."
  },
  "aaai2020_main_stealthyandefficientadversarialattacksagainstdeepreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Stealthy and Efficient Adversarial Attacks against Deep Reinforcement Learning ",
    "authors": [
      "Jianwen Sun",
      "Tianwei Zhang",
      "Xiaofei Xie",
      "Lei Ma",
      "Yan Zheng",
      "Kangjie Chen",
      "Yang Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6047",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6047/5903",
    "published": "2020-02",
    "summary": "Adversarial attacks against conventional Deep Learning (DL) systems and algorithms have been widely studied, and various defenses were proposed. However, the possibility and feasibility of such attacks against Deep Reinforcement Learning (DRL) are less explored. As DRL has achieved great success in various complex tasks, designing effective adversarial attacks is an indispensable prerequisite towards building robust DRL algorithms. In this paper, we introduce two novel adversarial attack techniques to stealthily and efficiently attack the DRL agents. These two techniques enable an adversary to inject adversarial samples in a minimal set of critical moments while causing the most severe damage to the agent. The first technique is the critical point attack: the adversary builds a model to predict the future environmental states and agent's actions, assesses the damage of each possible attack strategy, and selects the optimal one. The second technique is the antagonist attack: the adversary automatically learns a domain-agnostic model to discover the critical moments of attacking the agent in an episode. Experimental results demonstrate the effectiveness of our techniques. Specifically, to successfully attack the DRL agent, our critical point technique only requires 1 (TORCS) or 2 (Atari Pong and Breakout) steps, and the antagonist technique needs fewer than 5 steps (4 Mujoco tasks), which are significant improvements over state-of-the-art methods."
  },
  "aaai2020_main_multi-stageself-supervisedlearningforgraphconvolutionalnetworksongraphswithfewlabelednodes": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Stage Self-Supervised Learning for Graph Convolutional Networks on Graphs with Few Labeled Nodes ",
    "authors": [
      "Ke Sun",
      "Zhouchen Lin",
      "Zhanxing Zhu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6048",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6048/5904",
    "published": "2020-02",
    "summary": "Graph Convolutional Networks (GCNs) play a crucial role in graph learning tasks, however, learning graph embedding with few supervised signals is still a difficult problem. In this paper, we propose a novel training algorithm for Graph Convolutional Network, called Multi-Stage Self-Supervised (M3S) Training Algorithm, combined with self-supervised learning approach, focusing on improving the generalization performance of GCNs on graphs with few labeled nodes. Firstly, a Multi-Stage Training Framework is provided as the basis of M3S training method. Then we leverage DeepCluster technique, a popular form of self-supervised learning, and design corresponding aligning mechanism on the embedding space to refine the Multi-Stage Training Framework, resulting in M3S Training Algorithm. Finally, extensive experimental results verify the superior performance of our algorithm on graphs with few labeled nodes under different label rates compared with other state-of-the-art approaches."
  },
  "aaai2020_main_attentiveexperiencereplay": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Attentive Experience Replay ",
    "authors": [
      "Peiquan Sun",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6049",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6049/5905",
    "published": "2020-02",
    "summary": "Experience replay (ER) has become an important component of deep reinforcement learning (RL) algorithms. ER enables RL algorithms to reuse past experiences for the update of current policy. By reusing a previous state for training, the RL agent would learn more accurate value estimation and better decision on that state. However, as the policy is continually updated, some states in past experiences become rarely visited, and optimization over these states might not improve the overall performance of current policy. To tackle this issue, we propose a new replay strategy to prioritize the transitions that contain states frequently visited by current policy. We introduce Attentive Experience Replay (AER), a novel experience replay algorithm that samples transitions according to the similarities between their states and the agent's state. We couple AER with different off-policy algorithms and demonstrate that AER makes consistent improvements on the suite of OpenAI gym tasks."
  },
  "aaai2020_main_revisitingprobabilitydistributionassumptionsforinformationtheoreticfeatureselection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Revisiting Probability Distribution Assumptions for Information Theoretic Feature Selection ",
    "authors": [
      "Yuan Sun",
      "Wei Wang",
      "Michael Kirley",
      "Xiaodong Li",
      "Jeffrey Chan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6050",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6050/5906",
    "published": "2020-02",
    "summary": "Feature selection has been shown to be beneficial for many data mining and machine learning tasks, especially for big data analytics. Mutual Information (MI) is a well-known information-theoretic approach used to evaluate the relevance of feature subsets and class labels. However, estimating high-dimensional MI poses significant challenges. Consequently, a great deal of research has focused on using low-order MI approximations or computing a lower bound on MI called Variational Information (VI). These methods often require certain assumptions made on the probability distributions of features such that these distributions are realistic yet tractable to compute. In this paper, we reveal two sets of distribution assumptions underlying many MI and VI based methods: Feature Independence Distribution and Geometric Mean Distribution. We systematically analyze their strengths and weaknesses and propose a logical extension called Arithmetic Mean Distribution, which leads to an unbiased and normalised estimation of probability densities. We conduct detailed empirical studies across a suite of 29 real-world classification problems and illustrate improved prediction accuracy of our methods based on the identification of more informative features, thus providing support for our theoretical findings."
  },
  "aaai2020_main_adversarialtransformationsforsemi-supervisedlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adversarial Transformations for Semi-Supervised Learning ",
    "authors": [
      "Teppei Suzuki",
      "Ikuro Sato"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6051",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6051/5907",
    "published": "2020-02",
    "summary": "We propose a Regularization framework based on Adversarial Transformations (RAT) for semi-supervised learning. RAT is designed to enhance robustness of the output distribution of class prediction for a given data against input perturbation. RAT is an extension of Virtual Adversarial Training (VAT) in such a way that RAT adversraialy transforms data along the underlying data distribution by a rich set of data transformation functions that leave class label invariant, whereas VAT simply produces adversarial additive noises. In addition, we verified that a technique of gradually increasing of perturbation region further improves the robustness. In experiments, we show that RAT significantly improves classification performance on CIFAR-10 and SVHN compared to existing regularization methods under standard semi-supervised image classification settings."
  },
  "aaai2020_main_cgdmulti-viewclusteringviacross-viewgraphdiffusion": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " CGD: Multi-View Clustering via Cross-View Graph Diffusion ",
    "authors": [
      "Chang Tang",
      "Xinwang Liu",
      "Xinzhong Zhu",
      "En Zhu",
      "Zhigang Luo",
      "Lizhe Wang",
      "Wen Gao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6052",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6052/5908",
    "published": "2020-02",
    "summary": "Graph based multi-view clustering has been paid great attention by exploring the neighborhood relationship among data points from multiple views. Though achieving great success in various applications, we observe that most of previous methods learn a consensus graph by building certain data representation models, which at least bears the following drawbacks. First, their clustering performance highly depends on the data representation capability of the model. Second, solving these resultant optimization models usually results in high computational complexity. Third, there are often some hyper-parameters in these models need to tune for obtaining the optimal results. In this work, we propose a general, effective and parameter-free method with convergence guarantee to learn a unified graph for multi-view data clustering via cross-view graph diffusion (CGD), which is the first attempt to employ diffusion process for multi-view clustering. The proposed CGD takes the traditional predefined graph matrices of different views as input, and learns an improved graph for each single view via an iterative cross diffusion process by 1) capturing the underlying manifold geometry structure of original data points, and 2) leveraging the complementary information among multiple graphs. The final unified graph used for clustering is obtained by averaging the improved view associated graphs. Extensive experiments on several benchmark datasets are conducted to demonstrate the effectiveness of the proposed method in terms of seven clustering evaluation metrics."
  },
  "aaai2020_main_labelenhancementwithsamplecorrelationsvialow-rankrepresentation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Label Enhancement with Sample Correlations via Low-Rank Representation ",
    "authors": [
      "Haoyu Tang",
      "Jihua Zhu",
      "Qinghai Zheng",
      "Jun Wang",
      "Shanmin Pang",
      "Zhongyu Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6053",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6053/5909",
    "published": "2020-02",
    "summary": "Compared with single-label and multi-label annotations, label distribution describes the instance by multiple labels with different intensities and accommodates to more-general conditions. Nevertheless, label distribution learning is unavailable in many real-world applications because most existing datasets merely provide logical labels. To handle this problem, a novel label enhancement method, Label Enhancement with Sample Correlations via low-rank representation, is proposed in this paper. Unlike most existing methods, a low-rank representation method is employed so as to capture the global relationships of samples and predict implicit label correlation to achieve label enhancement. Extensive experiments on 14 datasets demonstrate that the algorithm accomplishes state-of-the-art results as compared to previous label enhancement baselines."
  },
  "aaai2020_main_discriminativeadversarialdomainadaptation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Discriminative Adversarial Domain Adaptation ",
    "authors": [
      "Hui Tang",
      "Kui Jia"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6054",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6054/5910",
    "published": "2020-02",
    "summary": "Given labeled instances on a source domain and unlabeled ones on a target domain, unsupervised domain adaptation aims to learn a task classifier that can well classify target instances. Recent advances rely on domain-adversarial training of deep networks to learn domain-invariant features. However, due to an issue of mode collapse induced by the separate design of task and domain classifiers, these methods are limited in aligning the joint distributions of feature and category across domains. To overcome it, we propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA). Based on an integrated category and domain classifier, DADA has a novel adversarial objective that encourages a mutually inhibitory relation between category and domain predictions for any input instance. We show that under practical conditions, it defines a minimax game that can promote the joint distribution alignment. Except for the traditional closed set domain adaptation, we also extend DADA for extremely challenging problem settings of partial and open set domain adaptation. Experiments show the efficacy of our proposed methods and we achieve the new state of the art for all the three settings on benchmark datasets."
  },
  "aaai2020_main_parameterizedindexedvaluefunctionforefficientexplorationinreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Parameterized Indexed Value Function for Efficient Exploration in Reinforcement Learning ",
    "authors": [
      "Tian Tan",
      "Zhihan Xiong",
      "Vikranth R. Dwaracherla"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6055",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6055/5911",
    "published": "2020-02",
    "summary": "It is well known that quantifying uncertainty in the action-value estimates is crucial for efficient exploration in reinforcement learning. Ensemble sampling offers a relatively computationally tractable way of doing this using randomized value functions. However, it still requires a huge amount of computational resources for complex problems. In this paper, we present an alternative, computationally efficient way to induce exploration using index sampling. We use an indexed value function to represent uncertainty in our action-value estimates. We first present an algorithm to learn parameterized indexed value function through a distributional version of temporal difference in a tabular setting and prove its regret bound. Then, in a computational point of view, we propose a dual-network architecture, Parameterized Indexed Networks (PINs), comprising one mean network and one uncertainty network to learn the indexed value function. Finally, we show the efficacy of PINs through computational experiments."
  },
  "aaai2020_main_jointmodelingoflocalandglobaltemporaldynamicsformultivariatetimeseriesforecastingwithmissingvalues": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Joint Modeling of Local and Global Temporal Dynamics for Multivariate Time Series Forecasting with Missing Values ",
    "authors": [
      "Xianfeng Tang",
      "Huaxiu Yao",
      "Yiwei Sun",
      "Charu Aggarwal",
      "Prasenjit Mitra",
      "Suhang Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6056",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6056/5912",
    "published": "2020-02",
    "summary": "Multivariate time series (MTS) forecasting is widely used in various domains, such as meteorology and traffic. Due to limitations on data collection, transmission, and storage, real-world MTS data usually contains missing values, making it infeasible to apply existing MTS forecasting models such as linear regression and recurrent neural networks. Though many efforts have been devoted to this problem, most of them solely rely on local dependencies for imputing missing values, which ignores global temporal dynamics. Local dependencies/patterns would become less useful when the missing ratio is high, or the data have consecutive missing values; while exploring global patterns can alleviate such problem. Thus, jointly modeling local and global temporal dynamics is very promising for MTS forecasting with missing values. However, work in this direction is rather limited. Therefore, we study a novel problem of MTS forecasting with missing values by jointly exploring local and global temporal dynamics. We propose a new framework \u00f8urs, which leverages memory network to explore global patterns given estimations from local perspectives. We further introduce adversarial training to enhance the modeling of global temporal distribution. Experimental results on real-world datasets show the effectiveness of \u00f8urs for MTS forecasting with missing values and its robustness under various missing ratios."
  },
  "aaai2020_main_beyonddropoutfeaturemapdistortiontoregularizedeepneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Beyond Dropout: Feature Map Distortion to Regularize Deep Neural Networks ",
    "authors": [
      "Yehui Tang",
      "Yunhe Wang",
      "Yixing Xu",
      "Boxin Shi",
      "Chao Xu",
      "Chunjing Xu",
      "Chang Xu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6057",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6057/5913",
    "published": "2020-02",
    "summary": "Deep neural networks often consist of a great number of trainable parameters for extracting powerful features from given datasets. One one hand, massive trainable parameters significantly enhance the performance of these deep networks. One the other hand, they bring the problem of over-fitting. To this end, dropout based methods disable some elements in the output feature maps during the training phase for reducing the co-adaptation of neurons. Although the generalization ability of the resulting models can be enhanced by these approaches, the conventional binary dropout is not the optimal solution. Therefore, we investigate the empirical Rademacher complexity related to intermediate layers of deep neural networks and propose a feature distortion method for addressing the aforementioned problem. In the training period, randomly selected elements in the feature maps will be replaced with specific values by exploiting the generalization error bound. The superiority of the proposed feature map distortion for producing deep neural network with higher testing performance is analyzed and demonstrated on several benchmark image datasets."
  },
  "aaai2020_main_rebornfilterspruningconvolutionalneuralnetworkswithlimiteddata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reborn Filters: Pruning Convolutional Neural Networks with Limited Data ",
    "authors": [
      "Yehui Tang",
      "Shan You",
      "Chang Xu",
      "Jin Han",
      "Chen Qian",
      "Boxin Shi",
      "Chao Xu",
      "Changshui Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6058",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6058/5914",
    "published": "2020-02",
    "summary": "Channel pruning is effective in compressing the pretrained CNNs for their deployment on low-end edge devices. Most existing methods independently prune some of the original channels and need the complete original dataset to fix the performance drop after pruning. However, due to commercial protection or data privacy, users may only have access to a tiny portion of training examples, which could be insufficient for the performance recovery. In this paper, for pruning with limited data, we propose to use all original filters to directly develop new compact filters, named reborn filters, so that all useful structure priors in the original filters can be well preserved into the pruned networks, alleviating the performance drop accordingly. During training, reborn filters can be easily implemented via 1\u00d71 convolutional layers and then be fused in the inference stage for acceleration. Based on reborn filters, the proposed channel pruning algorithm shows its effectiveness and superiority on extensive experiments."
  },
  "aaai2020_main_discretizingcontinuousactionspaceforon-policyoptimization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Discretizing Continuous Action Space for On-Policy Optimization ",
    "authors": [
      "Yunhao Tang",
      "Shipra Agrawal"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6059",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6059/5915",
    "published": "2020-02",
    "summary": "In this work, we show that discretizing action space for continuous control is a simple yet powerful technique for on-policy optimization. The explosion in the number of discrete actions can be efficiently addressed by a policy with factorized distribution across action dimensions. We show that the discrete policy achieves significant performance gains with state-of-the-art on-policy optimization algorithms (PPO, TRPO, ACKTR) especially on high-dimensional tasks with complex dynamics. Additionally, we show that an ordinal parameterization of the discrete distribution can introduce the inductive bias that encodes the natural ordering between discrete actions. This ordinal architecture further significantly improves the performance of PPO/TRPO."
  },
  "aaai2020_main_bi-objectivecontinuallearninglearning\u2018new\u2019whileconsolidating\u2018known\u2019": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bi-Objective Continual Learning: Learning \u2018New\u2019 While Consolidating \u2018Known\u2019 ",
    "authors": [
      "Xiaoyu Tao",
      "Xiaopeng Hong",
      "Xinyuan Chang",
      "Yihong Gong"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6060",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6060/5916",
    "published": "2020-02",
    "summary": "In this paper, we propose a novel single-task continual learning framework named Bi-Objective Continual Learning (BOCL). BOCL aims at both consolidating historical knowledge and learning from new data. On one hand, we propose to preserve the old knowledge using a small set of pillars, and develop the pillar consolidation (PLC) loss to preserve the old knowledge and to alleviate the catastrophic forgetting problem. On the other hand, we develop the contrastive pillar (CPL) loss term to improve the classification performance, and examine several data sampling strategies for efficient onsite learning from \u2018new\u2019 with a reasonable amount of computational resources. Comprehensive experiments on CIFAR10/100, CORe50 and a subset of ImageNet validate the BOCL framework. We also reveal the performance accuracy of different sampling strategies when used to finetune a given CNN model. The code will be released."
  },
  "aaai2020_main_scalablevariationalbayesiankernelselectionforsparsegaussianprocessregression": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Scalable Variational Bayesian Kernel Selection for Sparse Gaussian Process Regression ",
    "authors": [
      "Tong Teng",
      "Jie Chen",
      "Yehong Zhang",
      "Bryan Kian Hsiang Low"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6061",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6061/5917",
    "published": "2020-02",
    "summary": "This paper presents a variational Bayesian kernel selection (VBKS) algorithm for sparse Gaussian process regression (SGPR) models. In contrast to existing GP kernel selection algorithms that aim to select only one kernel with the highest model evidence, our VBKS algorithm considers the kernel as a random variable and learns its belief from data such that the uncertainty of the kernel can be interpreted and exploited to avoid overconfident GP predictions. To achieve this, we represent the probabilistic kernel as an additional variational variable in a variational inference (VI) framework for SGPR models where its posterior belief is learned together with that of the other variational variables (i.e., inducing variables and kernel hyperparameters). In particular, we transform the discrete kernel belief into a continuous parametric distribution via reparameterization in order to apply VI. Though it is computationally challenging to jointly optimize a large number of hyperparameters due to many kernels being evaluated simultaneously by our VBKS algorithm, we show that the variational lower bound of the log-marginal likelihood can be decomposed into an additive form such that each additive term depends only on a disjoint subset of the variational variables and can thus be optimized independently. Stochastic optimization is then used to maximize the variational lower bound by iteratively improving the variational approximation of the exact posterior belief via stochastic gradient ascent, which incurs constant time per iteration and hence scales to big data. We empirically evaluate the performance of our VBKS algorithm on synthetic and massive real-world datasets."
  },
  "aaai2020_main_buildingcalibrateddeepmodelsviauncertaintymatchingwithauxiliaryintervalpredictors": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Building Calibrated Deep Models via Uncertainty Matching with Auxiliary Interval Predictors ",
    "authors": [
      "Jayaraman J. Thiagarajan",
      "Bindya Venkatesh",
      "Prasanna Sattigeri",
      "Peer-Timo Bremer"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6062",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6062/5918",
    "published": "2020-02",
    "summary": "With rapid adoption of deep learning in critical applications, the question of when and how much to trust these models often arises, which drives the need to quantify the inherent uncertainties. While identifying all sources that account for the stochasticity of models is challenging, it is common to augment predictions with confidence intervals to convey the expected variations in a model's behavior. We require prediction intervals to be well-calibrated, reflect the true uncertainties, and to be sharp. However, existing techniques for obtaining prediction intervals are known to produce unsatisfactory results in at least one of these criteria. To address this challenge, we develop a novel approach for building calibrated estimators. More specifically, we use separate models for prediction and interval estimation, and pose a bi-level optimization problem that allows the former to leverage estimates from the latter through an uncertainty matching strategy. Using experiments in regression, time-series forecasting, and object localization, we show that our approach achieves significant improvements over existing uncertainty quantification methods, both in terms of model fidelity and calibration error."
  },
  "aaai2020_main_networkasregularizationfortrainingdeepneuralnetworksframework,modelandperformance": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Network as Regularization for Training Deep Neural Networks: Framework, Model and Performance ",
    "authors": [
      "Kai Tian",
      "Yi Xu",
      "Jihong Guan",
      "Shuigeng Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6063",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6063/5919",
    "published": "2020-02",
    "summary": "Despite powerful representation ability, deep neural networks (DNNs) are prone to over-fitting, because of over-parametrization. Existing works have explored various regularization techniques to tackle the over-fitting problem. Some of them employed soft targets rather than one-hot labels to guide network training (e.g. label smoothing in classification tasks), which are called target-based regularization approaches in this paper. To alleviate the over-fitting problem, here we propose a new and general regularization framework that introduces an auxiliary network to dynamically incorporate guided semantic disturbance to the labels. We call it Network as Regularization (NaR in short). During training, the disturbance is constructed by a convex combination of the predictions of the target network and the auxiliary network. These two networks are initialized separately. And the auxiliary network is trained independently from the target network, while providing instance-level and class-level semantic information to the latter progressively. We conduct extensive experiments to validate the effectiveness of the proposed method. Experimental results show that NaR outperforms many state-of-the-art target-based regularization methods, and other regularization approaches (e.g. mixup) can also benefit from combining with NaR."
  },
  "aaai2020_main_sanitychecksforsaliencymetrics": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Sanity Checks for Saliency Metrics ",
    "authors": [
      "Richard Tomsett",
      "Dan Harborne",
      "Supriyo Chakraborty",
      "Prudhvi Gurram",
      "Alun Preece"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6064",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6064/5920",
    "published": "2020-02",
    "summary": "Saliency maps are a popular approach to creating post-hoc explanations of image classifier outputs. These methods produce estimates of the relevance of each pixel to the classification output score, which can be displayed as a saliency map that highlights important pixels. Despite a proliferation of such methods, little effort has been made to quantify how good these saliency maps are at capturing the true relevance of the pixels to the classifier output (i.e. their \u201cfidelity\u201d). We therefore investigate existing metrics for evaluating the fidelity of saliency methods (i.e. saliency metrics). We find that there is little consistency in the literature in how such metrics are calculated, and show that such inconsistencies can have a significant effect on the measured fidelity. Further, we apply measures of reliability developed in the psychometric testing literature to assess the consistency of saliency metrics when applied to individual saliency maps. Our results show that saliency metrics can be statistically unreliable and inconsistent, indicating that comparative rankings between saliency methods generated using such metrics can be untrustworthy."
  },
  "aaai2020_main_differentialequationunitslearningfunctionalformsofactivationfunctionsfromdata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Differential Equation Units: Learning Functional Forms of Activation Functions from Data ",
    "authors": [
      "MohamadAli Torkamani",
      "Shiv Shankar",
      "Amirmohammad Rooshenas",
      "Phillip Wallis"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6065",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6065/5921",
    "published": "2020-02",
    "summary": "Most deep neural networks use simple, fixed activation functions, such as sigmoids or rectified linear units, regardless of domain or network structure. We introduce differential equation units (DEUs), an improvement to modern neural networks, which enables each neuron to learn a particular nonlinear activation function from a family of solutions to an ordinary differential equation. Specifically, each neuron may change its functional form during training based on the behavior of the other parts of the network. We show that using neurons with DEU activation functions results in a more compact network capable of achieving comparable, if not superior, performance when compared to much larger networks."
  },
  "aaai2020_main_order-freelearningalleviatingexposurebiasinmulti-labelclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Order-Free Learning Alleviating Exposure Bias in Multi-Label Classification ",
    "authors": [
      "Che-Ping Tsai",
      "Hung-Yi Lee"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6066",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6066/5922",
    "published": "2020-02",
    "summary": "Multi-label classification (MLC) assigns multiple labels to each sample. Prior studies show that MLC can be transformed to a sequence prediction problem with a recurrent neural network (RNN) decoder to model the label dependency. However, training a RNN decoder requires a predefined order of labels, which is not directly available in the MLC specification. Besides, RNN thus trained tends to overfit the label combinations in the training set and have difficulty generating unseen label sequences. In this paper, we propose a new framework for MLC which does not rely on a predefined label order and thus alleviates exposure bias. The experimental results on three multi-label classification benchmark datasets show that our method outperforms competitive baselines by a large margin. We also find the proposed approach has a higher probability of generating label combinations not seen during training than the baseline models. The result shows that the proposed approach has better generalization capability."
  },
  "aaai2020_main_learningtocrawl": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Crawl ",
    "authors": [
      "Utkarsh Upadhyay",
      "Robert Busa-Fekete",
      "Wojciech Kotlowski",
      "David Pal",
      "Balazs Szorenyi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6067",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6067/5923",
    "published": "2020-02",
    "summary": "Web crawling is the problem of keeping a cache of webpages fresh, i.e., having the most recent copy available when a page is requested. This problem is usually coupled with the natural restriction that the bandwidth available to the web crawler is limited. The corresponding optimization problem was solved optimally by Azar et al. (2018) under the assumption that, for each webpage, both the elapsed time between two changes and the elapsed time between two requests follows a Poisson distribution with known parameters. In this paper, we study the same control problem but under the assumption that the change rates are unknown a priori, and thus we need to estimate them in an online fashion using only partial observations (i.e., single-bit signals indicating whether the page has changed since the last refresh). As a point of departure, we characterise the conditions under which one can solve the problem with such partial observability. Next, we propose a practical estimator and compute confidence intervals for it in terms of the elapsed time between the observations. Finally, we show that the explore-and-commit algorithm achieves an O(\u221aT) regret with a carefully chosen exploration horizon. Our simulation study shows that our online policy scales well and achieves close to optimal performance for a wide range of parameters."
  },
  "aaai2020_main_transferlearningforanomalydetectionthroughlocalizedandunsupervisedinstanceselection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Transfer Learning for Anomaly Detection through Localized and Unsupervised Instance Selection ",
    "authors": [
      "Vercruyssen Vincent",
      "Meert Wannes",
      "Davis Jesse"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6068",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6068/5924",
    "published": "2020-02",
    "summary": "Anomaly detection attempts to identify instances that deviate from expected behavior. Constructing performant anomaly detectors on real-world problems often requires some labeled data, which can be difficult and costly to obtain. However, often one considers multiple, related anomaly detection tasks. Therefore, it may be possible to transfer labeled instances from a related anomaly detection task to the problem at hand. This paper proposes a novel transfer learning algorithm for anomaly detection that selects and transfers relevant labeled instances from a source anomaly detection task to a target one. Then, it classifies target instances using a novel semi-supervised nearest-neighbors technique that considers both unlabeled target and transferred, labeled source instances. The algorithm outperforms a multitude of state-of-the-art transfer learning methods and unsupervised anomaly detection methods on a large benchmark. Furthermore, it outperforms its rivals on a real-world task of detecting anomalous water usage in retail stores."
  },
  "aaai2020_main_meta-learningforgeneralizedzero-shotlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Meta-Learning for Generalized Zero-Shot Learning ",
    "authors": [
      "Vinay Kumar Verma",
      "Dhanajit Brahma",
      "Piyush Rai"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6069",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6069/5925",
    "published": "2020-02",
    "summary": "Learning to classify unseen class samples at test time is popularly referred to as zero-shot learning (ZSL). If test samples can be from training (seen) as well as unseen classes, it is a more challenging problem due to the existence of strong bias towards seen classes. This problem is generally known as generalized zero-shot learning (GZSL). Thanks to the recent advances in generative models such as VAEs and GANs, sample synthesis based approaches have gained considerable attention for solving this problem. These approaches are able to handle the problem of class bias by synthesizing unseen class samples. However, these ZSL/GZSL models suffer due to the following key limitations: (i) Their training stage learns a class-conditioned generator using only seen class data and the training stage does not explicitly learn to generate the unseen class samples; (ii) They do not learn a generic optimal parameter which can easily generalize for both seen and unseen class generation; and (iii) If we only have access to a very few samples per seen class, these models tend to perform poorly. In this paper, we propose a meta-learning based generative model that naturally handles these limitations. The proposed model is based on integrating model-agnostic meta learning with a Wasserstein GAN (WGAN) to handle (i) and (iii), and uses a novel task distribution to handle (ii). Our proposed model yields significant improvements on standard ZSL as well as more challenging GZSL setting. In ZSL setting, our model yields 4.5%, 6.0%, 9.8%, and 27.9% relative improvements over the current state-of-the-art on CUB, AWA1, AWA2, and aPY datasets, respectively."
  },
  "aaai2020_main_deepconservativepolicyiteration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Conservative Policy Iteration ",
    "authors": [
      "Nino Vieillard",
      "Olivier Pietquin",
      "Matthieu Geist"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6070",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6070/5926",
    "published": "2020-02",
    "summary": "Conservative Policy Iteration (CPI) is a founding algorithm of Approximate Dynamic Programming (ADP). Its core principle is to stabilize greediness through stochastic mixtures of consecutive policies. It comes with strong theoretical guarantees, and inspired approaches in deep Reinforcement Learning (RL). However, CPI itself has rarely been implemented, never with neural networks, and only experimented on toy problems. In this paper, we show how CPI can be practically combined with deep RL with discrete actions, in an off-policy manner. We also introduce adaptive mixture rates inspired by the theory. We experiment thoroughly the resulting algorithm on the simple Cartpole problem, and validate the proposed method on a representative subset of Atari games. Overall, this work suggests that revisiting classic ADP may lead to improved and more stable deep RL algorithms."
  },
  "aaai2020_main_justification-basedreliabilityinmachinelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Justification-Based Reliability in Machine Learning ",
    "authors": [
      "Nurali Virani",
      "Naresh Iyer",
      "Zhaoyuan Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6071",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6071/5927",
    "published": "2020-02",
    "summary": "With the advent of Deep Learning, the field of machine learning (ML) has surpassed human-level performance on diverse classification tasks. At the same time, there is a stark need to characterize and quantify reliability of a model's prediction on individual samples. This is especially true in applications of such models in safety-critical domains of industrial control and healthcare. To address this need, we link the question of reliability of a model's individual prediction to the epistemic uncertainty of the model's prediction. More specifically, we extend the theory of Justified True Belief (JTB) in epistemology, created to study the validity and limits of human-acquired knowledge, towards characterizing the validity and limits of knowledge in supervised classifiers. We present an analysis of neural network classifiers linking the reliability of its prediction on a test input to characteristics of the support gathered from the input and hidden layers of the network. We hypothesize that the JTB analysis exposes the epistemic uncertainty (or ignorance) of a model with respect to its inference, thereby allowing for the inference to be only as strong as the justification permits. We explore various forms of support (for e.g., k-nearest neighbors (k-NN) and \u2113p-norm based) generated for an input, using the training data to construct a justification for the prediction with that input. Through experiments conducted on simulated and real datasets, we demonstrate that our approach can provide reliability for individual predictions and characterize regions where such reliability cannot be ascertained."
  },
  "aaai2020_main_fastandefficientbooleanmatrixfactorizationbygeometricsegmentation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fast and Efficient Boolean Matrix Factorization by Geometric Segmentation ",
    "authors": [
      "Changlin Wan",
      "Wennan Chang",
      "Tong Zhao",
      "Mengya Li",
      "Sha Cao",
      "Chi Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6072",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6072/5928",
    "published": "2020-02",
    "summary": "Boolean matrix has been used to represent digital information in many fields, including bank transaction, crime records, natural language processing, protein-protein interaction, etc. Boolean matrix factorization (BMF) aims to find an approximation of a binary matrix as the Boolean product of two low rank Boolean matrices, which could generate vast amount of information for the patterns of relationships between the features and samples. Inspired by binary matrix permutation theories and geometric segmentation, we developed a fast and efficient BMF approach, called MEBF (Median Expansion for Boolean Factorization). Overall, MEBF adopted a heuristic approach to locate binary patterns presented as submatrices that are dense in 1's. At each iteration, MEBF permutates the rows and columns such that the permutated matrix is approximately Upper Triangular-Like (UTL) with so-called Simultaneous Consecutive-ones Property (SC1P). The largest submatrix dense in 1 would lie on the upper triangular area of the permutated matrix, and its location was determined based on a geometric segmentation of a triangular. We compared MEBF with other state of the art approaches on data scenarios with different density and noise levels. MEBF demonstrated superior performances in lower reconstruction error, and higher computational efficiency, as well as more accurate density patterns than popular methods such as ASSO, PANDA and Message Passing. We demonstrated the application of MEBF on both binary and non-binary data sets, and revealed its further potential in knowledge retrieving and data denoising."
  },
  "aaai2020_main_reinforcementlearningbasedmeta-pathdiscoveryinlarge-scaleheterogeneousinformationnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reinforcement Learning Based Meta-Path Discovery in Large-Scale Heterogeneous Information Networks ",
    "authors": [
      "Guojia Wan",
      "Bo Du",
      "Shirui Pan",
      "Gholameza Haffari"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6073",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6073/5929",
    "published": "2020-02",
    "summary": "Meta-paths are important tools for a wide variety of data mining and network analysis tasks in Heterogeneous Information Networks (HINs), due to their flexibility and interpretability to capture the complex semantic relation among objects. To date, most HIN analysis still relies on hand-crafting meta-paths, which requires rich domain knowledge that is extremely difficult to obtain in complex, large-scale, and schema-rich HINs. In this work, we present a novel framework, Meta-path Discovery with Reinforcement Learning (MPDRL), to identify informative meta-paths from complex and large-scale HINs. To capture different semantic information between objects, we propose a novel multi-hop reasoning strategy in a reinforcement learning framework which aims to infer the next promising relation that links a source entity to a target entity. To improve the efficiency, moreover, we develop a type context representation embedded approach to scale the RL framework to handle million-scale HINs. As multi-hop reasoning generates rich meta-paths with various length, we further perform a meta-path induction step to summarize the important meta-paths using Lowest Common Ancestor principle. Experimental results on two large-scale HINs, Yago and NELL, validate our approach and demonstrate that our algorithm not only achieves superior performance in the link prediction task, but also identifies useful meta-paths that would have been ignored by human experts."
  },
  "aaai2020_main_robusttensordecompositionviaorientationinvarianttubalnuclearnorms": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Robust Tensor Decomposition via Orientation Invariant Tubal Nuclear Norms ",
    "authors": [
      "Andong Wang",
      "Chao Li",
      "Zhong Jin",
      "Qibin Zhao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6074",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6074/5930",
    "published": "2020-02",
    "summary": "Low-rank tensor recovery has been widely applied to computer vision and machine learning. Recently, tubal nuclear norm (TNN) based optimization is proposed with superior performance as compared to other tensor nuclear norms. However, one major limitation is its orientation sensitivity due to low-rankness strictly defined along tubal orientation and it cannot simultaneously model spectral low-rankness in multiple orientations. To this end, we introduce two new tensor norms called OITNN-O and OITNN-L to exploit multi-orientational spectral low-rankness for an arbitrary K-way (K \u2265 3) tensors. We further formulate two robust tensor decomposition models via the proposed norms and develop two algorithms as the solutions. Theoretically, we establish non-asymptotic error bounds which can predict the scaling behavior of the estimation error. Experiments on real-world datasets demonstrate the superiority and effectiveness of the proposed norms."
  },
  "aaai2020_main_robustself-weightedmulti-viewprojectionclustering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Robust Self-Weighted Multi-View Projection Clustering ",
    "authors": [
      "Beilei Wang",
      "Yun Xiao",
      "Zhihui Li",
      "Xuanhong Wang",
      "Xiaojiang Chen",
      "Dingyi Fang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6075",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6075/5931",
    "published": "2020-02",
    "summary": "Many real-world applications involve data collected from different views and with high data dimensionality. Furthermore, multi-view data always has unavoidable noise. Clustering on this kind of high-dimensional and noisy multi-view data remains a challenge due to the curse of dimensionality and ineffective de-noising and integration of multiple views. Aiming at this problem, in this paper, we propose a Robust Self-weighted Multi-view Projection Clustering (RSwMPC) based on \u21132,1-norm, which can simultaneously reduce dimensionality, suppress noise and learn local structure graph. Then the obtained optimal graph can be directly used for clustering while no further processing is required. In addition, a new method is introduced to automatically learn the optimal weight of each view with no need to generate additional parameters to adjust the weight. Extensive experimental results on different synthetic datasets and real-world datasets demonstrate that the proposed algorithm outperforms other state-of-the-art methods on clustering performance and robustness."
  },
  "aaai2020_main_learninggenerallatent-variablegraphicalmodelswithpredictivebeliefpropagation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning General Latent-Variable Graphical Models with Predictive Belief Propagation ",
    "authors": [
      "Borui Wang",
      "Geoffrey Gordon"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6076",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6076/5932",
    "published": "2020-02",
    "summary": "Learning general latent-variable probabilistic graphical models is a key theoretical challenge in machine learning and artificial intelligence. All previous methods, including the EM algorithm and the spectral algorithms, face severe limitations that largely restrict their applicability and affect their performance. In order to overcome these limitations, in this paper we introduce a novel formulation of message-passing inference over junction trees named predictive belief propagation, and propose a new learning and inference algorithm for general latent-variable graphical models based on this formulation. Our proposed algorithm reduces the hard parameter learning problem into a sequence of supervised learning problems, and unifies the learning of different kinds of latent graphical models into a single learning framework, which is local-optima-free and statistically consistent. We then give a proof of the correctness of our algorithm and show in experiments on both synthetic and real datasets that our algorithm significantly outperforms both the EM algorithm and the spectral algorithm while also being orders of magnitude faster to compute."
  },
  "aaai2020_main_setrankasetwisebayesianapproachforcollaborativerankingfromimplicitfeedback": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " SetRank: A Setwise Bayesian Approach for Collaborative Ranking from Implicit Feedback ",
    "authors": [
      "Chao Wang",
      "Hengshu Zhu",
      "Chen Zhu",
      "Chuan Qin",
      "Hui Xiong"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6077",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6077/5933",
    "published": "2020-02",
    "summary": "The recent development of online recommender systems has a focus on collaborative ranking from implicit feedback, such as user clicks and purchases. Different from explicit ratings, which reflect graded user preferences, the implicit feedback only generates positive and unobserved labels. While considerable efforts have been made in this direction, the well-known pairwise and listwise approaches have still been limited by various challenges. Specifically, for the pairwise approaches, the assumption of independent pairwise preference is not always held in practice. Also, the listwise approaches cannot efficiently accommodate \u201cties\u201d due to the precondition of the entire list permutation. To this end, in this paper, we propose a novel setwise Bayesian approach for collaborative ranking, namely SetRank, to inherently accommodate the characteristics of implicit feedback in recommender system. Specifically, SetRank aims at maximizing the posterior probability of novel setwise preference comparisons and can be implemented with matrix factorization and neural networks. Meanwhile, we also present the theoretical analysis of SetRank to show that the bound of excess risk can be proportional to \u221aM/N, where M and N are the numbers of items and users, respectively. Finally, extensive experiments on four real-world datasets clearly validate the superiority of SetRank compared with various state-of-the-art baselines."
  },
  "aaai2020_main_estimatingstochasticlinearcombinationofnon-linearregressions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Estimating Stochastic Linear Combination of Non-Linear Regressions ",
    "authors": [
      "Di Wang",
      "Xiangyu Guo",
      "Chaowen Guan",
      "Shi Li",
      "Jinhui Xu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6078",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6078/5934",
    "published": "2020-02",
    "summary": "In this paper we study the problem of estimating stochastic linear combination of non-linear regressions, which has a close connection with many machine learning and statistical models such as non-linear regressions, the Single Index, Multi-index, Varying Coefficient Index Models and Two-layer Neural Networks. Specifically, we first show that with some mild assumptions, if the variate vector x is multivariate Gaussian, then there is an algorithm whose output vectors have \u21132-norm estimation errors of O(\u221ap/n) with high probability, where p is the dimension of x and n is the number of samples. Then we extend our result to the case where x is sub-Gaussian using the zero-bias transformation, which could be seen as a generalization of the classic Stein's lemma. We also show that with some additional assumptions there is an algorithm whose output vectors have \u2113\u221e-norm estimation errors of O(1/\u221ap + \u221ap/n) with high probability. Finally, for both Gaussian and sub-Gaussian cases we propose a faster sub-sampling based algorithm and show that when the sub-sample sizes are large enough then the estimation errors will not be sacrificed by too much. Experiments for both cases support our theoretical results. To the best of our knowledge, this is the first work that studies and provides theoretical guarantees for the stochastic linear combination of non-linear regressions model."
  },
  "aaai2020_main_compactautoregressivenetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Compact Autoregressive Network ",
    "authors": [
      "Di Wang",
      "Feiqing Huang",
      "Jingyu Zhao",
      "Guodong Li",
      "Guangjian Tian"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6079",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6079/5935",
    "published": "2020-02",
    "summary": "Autoregressive networks can achieve promising performance in many sequence modeling tasks with short-range dependence. However, when handling high-dimensional inputs and outputs, the massive amount of parameters in the network leads to expensive computational cost and low learning efficiency. The problem can be alleviated slightly by introducing one more narrow hidden layer to the network, but the sample size required to achieve a certain training error is still substantial. To address this challenge, we rearrange the weight matrices of a linear autoregressive network into a tensor form, and then make use of Tucker decomposition to represent low-rank structures. This leads to a novel compact autoregressive network, called Tucker AutoRegressive (TAR) net. Interestingly, the TAR net can be applied to sequences with long-range dependence since the dimension along the sequential order is reduced. Theoretical studies show that the TAR net improves the learning efficiency, and requires much fewer samples for model training. Experiments on synthetic and real-world datasets demonstrate the promising performance of the proposed compact network."
  },
  "aaai2020_main_neuralcognitivediagnosisforintelligenteducationsystems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Neural Cognitive Diagnosis for Intelligent Education Systems ",
    "authors": [
      "Fei Wang",
      "Qi Liu",
      "Enhong Chen",
      "Zhenya Huang",
      "Yuying Chen",
      "Yu Yin",
      "Zai Huang",
      "Shijin Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6080",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6080/5936",
    "published": "2020-02",
    "summary": "Cognitive diagnosis is a fundamental issue in intelligent education, which aims to discover the proficiency level of students on specific knowledge concepts. Existing approaches usually mine linear interactions of student exercising process by manual-designed function (e.g., logistic function), which is not sufficient for capturing complex relations between students and exercises. In this paper, we propose a general Neural Cognitive Diagnosis (NeuralCD) framework, which incorporates neural networks to learn the complex exercising interactions, for getting both accurate and interpretable diagnosis results. Specifically, we project students and exercises to factor vectors and leverage multi neural layers for modeling their interactions, where the monotonicity assumption is applied to ensure the interpretability of both factors. Furthermore, we propose two implementations of NeuralCD by specializing the required concepts of each exercise, i.e., the NeuralCDM with traditional Q-matrix and the improved NeuralCDM+ exploring the rich text content. Extensive experimental results on real-world datasets show the effectiveness of NeuralCD framework with both accuracy and interpretability."
  },
  "aaai2020_main_adaptingtosmoothnessamoreuniversalalgorithmforonlineconvexoptimization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adapting to Smoothness: A More Universal Algorithm for Online Convex Optimization ",
    "authors": [
      "Guanghui Wang",
      "Shiyin Lu",
      "Yao Hu",
      "Lijun Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6081",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6081/5937",
    "published": "2020-02",
    "summary": "We aim to design universal algorithms for online convex optimization, which can handle multiple common types of loss functions simultaneously. The previous state-of-the-art universal method has achieved the minimax optimality for general convex, exponentially concave and strongly convex loss functions. However, it remains an open problem whether smoothness can be exploited to further improve the theoretical guarantees. In this paper, we provide an affirmative answer by developing a novel algorithm, namely UFO, which achieves O(\u221aL*), O(d log L*) and O(log L*) regret bounds for the three types of loss functions respectively under the assumption of smoothness, where L* is the cumulative loss of the best comparator in hindsight, and d is dimensionality. Thus, our regret bounds are much tighter when the comparator has a small loss, and ensure the minimax optimality in the worst case. In addition, it is worth pointing out that UFO is the first to achieve the O(log L*) regret bound for strongly convex and smooth functions, which is tighter than the existing small-loss bound by an O(d) factor."
  },
  "aaai2020_main_repetitiverepredictiondeepdecipherforsemi-supervisedlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Repetitive Reprediction Deep Decipher for Semi-Supervised Learning ",
    "authors": [
      "Guo-Hua Wang",
      "Jianxin Wu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6082",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6082/5938",
    "published": "2020-02",
    "summary": "Most recent semi-supervised deep learning (deep SSL) methods used a similar paradigm: use network predictions to update pseudo-labels and use pseudo-labels to update network parameters iteratively. However, they lack theoretical support and cannot explain why predictions are good candidates for pseudo-labels. In this paper, we propose a principled end-to-end framework named deep decipher (D2) for SSL. Within the D2 framework, we prove that pseudo-labels are related to network predictions by an exponential link function, which gives a theoretical support for using predictions as pseudo-labels. Furthermore, we demonstrate that updating pseudo-labels by network predictions will make them uncertain. To mitigate this problem, we propose a training strategy called repetitive reprediction (R2). Finally, the proposed R2-D2 method is tested on the large-scale ImageNet dataset and outperforms state-of-the-art methods by 5 percentage points."
  },
  "aaai2020_main_incorporatinglabelembeddingandfeatureaugmentationformulti-dimensionalclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Incorporating Label Embedding and Feature Augmentation for Multi-Dimensional Classification ",
    "authors": [
      "Haobo Wang",
      "Chen Chen",
      "Weiwei Liu",
      "Ke Chen",
      "Tianlei Hu",
      "Gang Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6083",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6083/5939",
    "published": "2020-02",
    "summary": "Feature augmentation, which manipulates the feature space by integrating the label information, is one of the most popular strategies for solving Multi-Dimensional Classification (MDC) problems. However, the vanilla feature augmentation approaches fail to consider the intra-class exclusiveness, and may achieve degenerated performance. To fill this gap, a novel neural network based model is proposed which seamlessly integrates the Label Embedding and Feature Augmentation (LEFA) techniques to learn label correlations. Specifically, based on attentional factorization machine, a cross correlation aware network is introduced to learn a low-dimensional label representation that simultaneously depicts the inter-class correlations and the intra-class exclusiveness. Then the learned latent label vector can be used to augment the original feature space. Extensive experiments on seven real-world datasets demonstrate the superiority of LEFA over state-of-the-art MDC approaches."
  },
  "aaai2020_main_m-nasmetaneuralarchitecturesearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " M-NAS: Meta Neural Architecture Search ",
    "authors": [
      "Jiaxing Wang",
      "Jiaxiang Wu",
      "Haoli Bai",
      "Jian Cheng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6084",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6084/5940",
    "published": "2020-02",
    "summary": "Neural Architecture Search (NAS) has recently outperformed hand-crafted networks in various areas. However, most prevalent NAS methods only focus on a pre-defined task. For a previously unseen task, the architecture is either searched from scratch, which is inefficient, or transferred from the one obtained on some other task, which might be sub-optimal. In this paper, we investigate a previously unexplored problem: whether a universal NAS method exists, such that task-aware architectures can be effectively generated? Towards this problem, we propose Meta Neural Architecture Search (M-NAS). To obtain task-specific architectures, M-NAS adopts a task-aware architecture controller for child model generation. Since optimal weights for different tasks and architectures span diversely, we resort to meta-learning, and learn meta-weights that efficiently adapt to a new task on the corresponding architecture with only several gradient descent steps. Experimental results demonstrate the superiority of M-NAS against a number of competitive baselines on both toy regression and few shot classification problems."
  },
  "aaai2020_main_logo-2k+alarge-scalelogodatasetforscalablelogoclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Logo-2K+: A Large-Scale Logo Dataset for Scalable Logo Classification ",
    "authors": [
      "Jing Wang",
      "Weiqing Min",
      "Sujuan Hou",
      "Shengnan Ma",
      "Yuanjie Zheng",
      "Haishuai Wang",
      "Shuqiang Jiang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6085",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6085/5941",
    "published": "2020-02",
    "summary": "Logo classification has gained increasing attention for its various applications, such as copyright infringement detection, product recommendation and contextual advertising. Compared with other types of object images, the real-world logo images have larger variety in logo appearance and more complexity in their background. Therefore, recognizing the logo from images is challenging. To support efforts towards scalable logo classification task, we have curated a dataset, Logo-2K+, a new large-scale publicly available real-world logo dataset with 2,341 categories and 167,140 images. Compared with existing popular logo datasets, such as FlickrLogos-32 and LOGO-Net, Logo-2K+ has more comprehensive coverage of logo categories and larger quantity of logo images. Moreover, we propose a Discriminative Region Navigation and Augmentation Network (DRNA-Net), which is capable of discovering more informative logo regions and augmenting these image regions for logo classification. DRNA-Net consists of four sub-networks: the navigator sub-network first selected informative logo-relevant regions guided by the teacher sub-network, which can evaluate its confidence belonging to the ground-truth logo class. The data augmentation sub-network then augments the selected regions via both region cropping and region dropping. Finally, the scrutinizer sub-network fuses features from augmented regions and the whole image for logo classification. Comprehensive experiments on Logo-2K+ and other three existing benchmark datasets demonstrate the effectiveness of proposed method. Logo-2K+ and the proposed strong baseline DRNA-Net are expected to further the development of scalable logo image recognition, and the Logo-2K+ dataset can be found at https://github.com/msn199959/Logo-2k-plus-Dataset."
  },
  "aaai2020_main_reinforcementlearningwithperturbedrewards": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Reinforcement Learning with Perturbed Rewards ",
    "authors": [
      "Jingkang Wang",
      "Yang Liu",
      "Bo Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6086",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6086/5942",
    "published": "2020-02",
    "summary": "Recent studies have shown that reinforcement learning (RL) models are vulnerable in various noisy scenarios. For instance, the observed reward channel is often subject to noise in practice (e.g., when rewards are collected through sensors), and is therefore not credible. In addition, for applications such as robotics, a deep reinforcement learning (DRL) algorithm can be manipulated to produce arbitrary errors by receiving corrupted rewards. In this paper, we consider noisy RL problems with perturbed rewards, which can be approximated with a confusion matrix. We develop a robust RL framework that enables agents to learn in noisy environments where only perturbed rewards are observed. Our solution framework builds on existing RL/DRL algorithms and firstly addresses the biased noisy reward setting without any assumptions on the true distribution (e.g., zero-mean Gaussian noise as made in previous works). The core ideas of our solution include estimating a reward confusion matrix and defining a set of unbiased surrogate rewards. We prove the convergence and sample complexity of our approach. Extensive experiments on different DRL platforms show that trained policies based on our estimated surrogate reward can achieve higher expected rewards, and converge faster than existing baselines. For instance, the state-of-the-art PPO algorithm is able to obtain 84.6% and 80.8% improvements on average score for five Atari games, with error rates as 10% and 30% respectively."
  },
  "aaai2020_main_crowdfundingdynamicstrackingareinforcementlearningapproach": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Crowdfunding Dynamics Tracking: A Reinforcement Learning Approach ",
    "authors": [
      "Jun Wang",
      "Hefu Zhang",
      "Qi Liu",
      "Zhen Pan",
      "Hanqing Tao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6087",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6087/5943",
    "published": "2020-02",
    "summary": "Recent years have witnessed the increasing interests in research of crowdfunding mechanism. In this area, dynamics tracking is a significant issue but is still under exploration. Existing studies either fit the fluctuations of time-series or employ regularization terms to constrain learned tendencies. However, few of them take into account the inherent decision-making process between investors and crowdfunding dynamics. To address the problem, in this paper, we propose a Trajectory-based Continuous Control for Crowdfunding (TC3) algorithm to predict the funding progress in crowdfunding. Specifically, actor-critic frameworks are employed to model the relationship between investors and campaigns, where all of the investors are viewed as an agent that could interact with the environment derived from the real dynamics of campaigns. Then, to further explore the in-depth implications of patterns (i.e., typical characters) in funding series, we propose to subdivide them into fast-growing and slow-growing ones. Moreover, for the purpose of switching from different kinds of patterns, the actor component of TC3 is extended with a structure of options, which comes to the TC3-Options. Finally, extensive experiments on the Indiegogo dataset not only demonstrate the effectiveness of our methods, but also validate our assumption that the entire pattern learned by TC3-Options is indeed the U-shaped one."
  },
  "aaai2020_main_differentiallyprivatelearningwithsmallpublicdata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Differentially Private Learning with Small Public Data ",
    "authors": [
      "Jun Wang",
      "Zhi-Hua Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6088",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6088/5944",
    "published": "2020-02",
    "summary": "Differentially private learning tackles tasks where the data are private and the learning process is subject to differential privacy requirements. In real applications, however, some public data are generally available in addition to private data, and it is interesting to consider how to exploit them. In this paper, we study a common situation where a small amount of public data can be used when solving the Empirical Risk Minimization problem over a private database. Specifically, we propose Private-Public Stochastic Gradient Descent, which utilizes such public information to adjust parameters in differentially private stochastic gradient descent and fine-tunes the final result with model reuse. Our method keeps differential privacy for the private database, and empirical study validates its superiority compared with existing approaches."
  },
  "aaai2020_main_dualrelationsemi-supervisedmulti-labellearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Dual Relation Semi-Supervised Multi-Label Learning ",
    "authors": [
      "Lichen Wang",
      "Yunyu Liu",
      "Can Qin",
      "Gan Sun",
      "Yun Fu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6089",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6089/5945",
    "published": "2020-02",
    "summary": "Multi-label learning (MLL) solves the problem that one single sample corresponds to multiple labels. It is a challenging task due to the long-tail label distribution and the sophisticated label relations. Semi-supervised MLL methods utilize a small-scale labeled samples and large-scale unlabeled samples to enhance the performance. However, these approaches mainly focus on exploring the data distribution in feature space while ignoring mining the label relation inside of each instance. To this end, we proposed a Dual Relation Semi-supervised Multi-label Learning (DRML) approach which jointly explores the feature distribution and the label relation simultaneously. A dual-classifier domain adaptation strategy is proposed to align features while generating pseudo labels to improve learning performance. A relation network is proposed to explore the relation knowledge. As a result, DRML effectively explores the feature-label and label-label relations in both labeled and unlabeled samples. It is an end-to-end model without any extra knowledge. Extensive experiments illustrate the effectiveness and efficiency of our method1."
  },
  "aaai2020_main_aknowledgetransferframeworkfordifferentiallyprivatesparselearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Knowledge Transfer Framework for Differentially Private Sparse Learning ",
    "authors": [
      "Lingxiao Wang",
      "Quanquan Gu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6090",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6090/5946",
    "published": "2020-02",
    "summary": "We study the problem of estimating high dimensional models with underlying sparse structures while preserving the privacy of each training example. We develop a differentially private high-dimensional sparse learning framework using the idea of knowledge transfer. More specifically, we propose to distill the knowledge from a \u201cteacher\u201d estimator trained on a private dataset, by creating a new dataset from auxiliary features, and then train a differentially private \u201cstudent\u201d estimator using this new dataset. In addition, we establish the linear convergence rate as well as the utility guarantee for our proposed method. For sparse linear regression and sparse logistic regression, our method achieves improved utility guarantees compared with the best known results (Kifer, Smith and Thakurta 2012; Wang and Gu 2019). We further demonstrate the superiority of our framework through both synthetic and real-world data experiments."
  },
  "aaai2020_main_unsuperviseddomainadaptationviastructuredpredictionbasedselectivepseudo-labeling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Unsupervised Domain Adaptation via Structured Prediction Based Selective Pseudo-Labeling ",
    "authors": [
      "Qian Wang",
      "Toby Breckon"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6091",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6091/5947",
    "published": "2020-02",
    "summary": "Unsupervised domain adaptation aims to address the problem of classifying unlabeled samples from the target domain whilst labeled samples are only available from the source domain and the data distributions are different in these two domains. As a result, classifiers trained from labeled samples in the source domain suffer from significant performance drop when directly applied to the samples from the target domain. To address this issue, different approaches have been proposed to learn domain-invariant features or domain-specific classifiers. In either case, the lack of labeled samples in the target domain can be an issue which is usually overcome by pseudo-labeling. Inaccurate pseudo-labeling, however, could result in catastrophic error accumulation during learning. In this paper, we propose a novel selective pseudo-labeling strategy based on structured prediction. The idea of structured prediction is inspired by the fact that samples in the target domain are well clustered within the deep feature space so that unsupervised clustering analysis can be used to facilitate accurate pseudo-labeling. Experimental results on four datasets (i.e. Office-Caltech, Office31, ImageCLEF-DA and Office-Home) validate our approach outperforms contemporary state-of-the-art methods."
  },
  "aaai2020_main_learningfromweak-labeldataadeepforestexpedition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning from Weak-Label Data: A Deep Forest Expedition ",
    "authors": [
      "Qian-Wei Wang",
      "Liang Yang",
      "Yu-Feng Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6092",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6092/5948",
    "published": "2020-02",
    "summary": "Weak-label learning deals with the problem where each training example is associated with multiple ground-truth labels simultaneously but only partially provided. This circumstance is frequently encountered when the number of classes is very large or when there exists a large ambiguity between class labels, and significantly influences the performance of multi-label learning. In this paper, we propose LCForest, which is the first tree ensemble based deep learning method for weak-label learning. Rather than formulating the problem as a regularized framework, we employ the recently proposed cascade forest structure, which processes information layer-by-layer, and endow it with the ability of exploiting from weak-label data by a concise and highly efficient label complement structure. Specifically, in each layer, the label vector of each instance from testing-fold is modified with the predictions of random forests trained with the corresponding training-fold. Since the ground-truth label matrix is inaccessible, we can not estimate the performance via cross-validation directly. In order to control the growth of cascade forest, we adopt label frequency estimation and the complement flag mechanism. Experiments show that the proposed LCForest method compares favorably against the existing state-of-the-art multi-label and weak-label learning methods."
  },
  "aaai2020_main_intentionnetspsychology-inspireduserchoicebehaviormodelingfornext-basketprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Intention Nets: Psychology-Inspired User Choice Behavior Modeling for Next-Basket Prediction ",
    "authors": [
      "Shoujin Wang",
      "Liang Hu",
      "Yan Wang",
      "Quan Z. Sheng",
      "Mehmet Orgun",
      "Longbing Cao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6093",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6093/5949",
    "published": "2020-02",
    "summary": "Human behaviors are complex, which are often observed as a sequence of heterogeneous actions. In this paper, we take user choices for shopping baskets as a typical case to study the complexity of user behaviors. Most of existing approaches often model user behaviors in a mechanical way, namely treating a user action sequence as homogeneous sequential data, such as hourly temperatures, which fails to consider the complexity in user behaviors. In fact, users' choices are driven by certain underlying intentions (e.g., feeding the baby or relieving pain) according to Psychological theories. Moreover, the durations of intentions to drive user actions are quite different; some of them may be persistent while others may be transient. According to Psychological theories, we develop a hierarchical framework to describe the goal, intentions and action sequences, based on which, we design Intention Nets (IntNet). In IntNet, multiple Action Chain Nets are constructed to model the user actions driven by different intentions, and a specially designed Persistent-Transient Intention Unit models the different intention durations. We apply the IntNet to next-basket prediction, a recent challenging task in recommender systems. Extensive experiments on real-world datasets show the superiority of our Psychology-inspired model IntNet over the state-of-the-art approaches."
  },
  "aaai2020_main_multi-componentgraphconvolutionalcollaborativefiltering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Component Graph Convolutional Collaborative Filtering ",
    "authors": [
      "Xiao Wang",
      "Ruijia Wang",
      "Chuan Shi",
      "Guojie Song",
      "Qingyong Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6094",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6094/5950",
    "published": "2020-02",
    "summary": "The interactions of users and items in recommender system could be naturally modeled as a user-item bipartite graph. In recent years, we have witnessed an emerging research effort in exploring user-item graph for collaborative filtering methods. Nevertheless, the formation of user-item interactions typically arises from highly complex latent purchasing motivations, such as high cost performance or eye-catching appearance, which are indistinguishably represented by the edges. The existing approaches still remain the differences between various purchasing motivations unexplored, rendering the inability to capture fine-grained user preference. Therefore, in this paper we propose a novel Multi-Component graph convolutional Collaborative Filtering (MCCF) approach to distinguish the latent purchasing motivations underneath the observed explicit user-item interactions. Specifically, there are two elaborately designed modules, decomposer and combiner, inside MCCF. The former first decomposes the edges in user-item graph to identify the latent components that may cause the purchasing relationship; the latter then recombines these latent components automatically to obtain unified embeddings for prediction. Furthermore, the sparse regularizer and weighted random sample strategy are utilized to alleviate the overfitting problem and accelerate the optimization. Empirical results on three real datasets and a synthetic dataset not only show the significant performance gains of MCCF, but also well demonstrate the necessity of considering multiple components."
  },
  "aaai2020_main_attention-guidewalkmodelinheterogeneousinformationnetworkformulti-stylerecommendationexplanation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Attention-Guide Walk Model in Heterogeneous Information Network for Multi-Style Recommendation Explanation ",
    "authors": [
      "Xin Wang",
      "Ying Wang",
      "Yunzhi Ling"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6095",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6095/5951",
    "published": "2020-02",
    "summary": "Explainable Recommendation aims at not only providing the recommended items to users, but also making users aware why these items are recommended. Too many interactive factors between users and items can be used to interpret the recommendation in a heterogeneous information network. However, these interactive factors are usually massive, implicit and noisy. The existing recommendation explanation approaches only consider the single explanation style, such as aspect-level or review-level. To address these issues, we propose a framework (MSRE) of generating the multi-style recommendation explanation with the attention-guide walk model on affiliation relations and interaction relations in the heterogeneous information network. Inspired by the attention mechanism, we determine the important contexts for recommendation explanation and learn joint representation of multi-style user-item interactions for enhancing recommendation performance. Constructing extensive experiments on three real-world datasets verifies the effectiveness of our framework on both recommendation performance and recommendation explanation."
  },
  "aaai2020_main_federatedlatentdirichletallocationalocaldifferentialprivacybasedframework": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Federated Latent Dirichlet Allocation: A Local Differential Privacy Based Framework ",
    "authors": [
      "Yansheng Wang",
      "Yongxin Tong",
      "Dingyuan Shi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6096",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6096/5952",
    "published": "2020-02",
    "summary": "Latent Dirichlet Allocation (LDA) is a widely adopted topic model for industrial-grade text mining applications. However, its performance heavily relies on the collection of large amount of text data from users' everyday life for model training. Such data collection risks severe privacy leakage if the data collector is untrustworthy. To protect text data privacy while allowing accurate model training, we investigate federated learning of LDA models. That is, the model is collaboratively trained between an untrustworthy data collector and multiple users, where raw text data of each user are stored locally and not uploaded to the data collector. To this end, we propose FedLDA, a local differential privacy (LDP) based framework for federated learning of LDA models. Central in FedLDA is a novel LDP mechanism called Random Response with Priori (RRP), which provides theoretical guarantees on both data privacy and model accuracy. We also design techniques to reduce the communication cost between the data collector and the users during model training. Extensive experiments on three open datasets verified the effectiveness of our solution."
  },
  "aaai2020_main_transductiveensemblelearningforneuralmachinetranslation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Transductive Ensemble Learning for Neural Machine Translation ",
    "authors": [
      "Yiren Wang",
      "Lijun Wu",
      "Yingce Xia",
      "Tao Qin",
      "ChengXiang Zhai",
      "Tie-Yan Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6097",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6097/5953",
    "published": "2020-02",
    "summary": "Ensemble learning, which aggregates multiple diverse models for inference, is a common practice to improve the accuracy of machine learning tasks. However, it has been observed that the conventional ensemble methods only bring marginal improvement for neural machine translation (NMT) when individual models are strong or there are a large number of individual models. In this paper, we study how to effectively aggregate multiple NMT models under the transductive setting where the source sentences of the test set are known. We propose a simple yet effective approach named transductive ensemble learning (TEL), in which we use all individual models to translate the source test set into the target language space and then finetune a strong model on the translated synthetic corpus. We conduct extensive experiments on different settings (with/without monolingual data) and different language pairs (English\u2194{German, Finnish}). The results show that our approach boosts strong individual models with significant improvement and benefits a lot from more individual models. Specifically, we achieve the state-of-the-art performances on the WMT2016-2018 English\u2194German translations."
  },
  "aaai2020_main_dynamicnetworkpruningwithinterpretablelayerwisechannelselection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Dynamic Network Pruning with Interpretable Layerwise Channel Selection ",
    "authors": [
      "Yulong Wang",
      "Xiaolu Zhang",
      "Xiaolin Hu",
      "Bo Zhang",
      "Hang Su"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6098",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6098/5954",
    "published": "2020-02",
    "summary": "Dynamic network pruning achieves runtime acceleration by dynamically determining the inference paths based on different inputs. However, previous methods directly generate continuous decision values for each weight channel, which cannot reflect a clear and interpretable pruning process. In this paper, we propose to explicitly model the discrete weight channel selections, which encourages more diverse weights utilization, and achieves more sparse runtime inference paths. Meanwhile, with the help of interpretable layerwise channel selections in the dynamic network, we can visualize the network decision paths explicitly for model interpretability. We observe that there are clear differences in the layerwise decisions between normal and adversarial examples. Therefore, we propose a novel adversarial example detection algorithm by discriminating the runtime decision features. Experiments show that our dynamic network achieves higher prediction accuracy under the similar computing budgets on CIFAR10 and ImageNet datasets compared to traditional static pruning methods and other dynamic pruning approaches. The proposed adversarial detection algorithm can significantly improve the state-of-the-art detection rate across multiple attacks, which provides an opportunity to build an interpretable and robust model."
  },
  "aaai2020_main_anobjectiveforhierarchicalclusteringineuclideanspaceanditsconnectiontobisectingk-means": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Objective for Hierarchical Clustering in Euclidean Space and Its Connection to Bisecting K-means ",
    "authors": [
      "Yuyan Wang",
      "Benjamin Moseley"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6099",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6099/5955",
    "published": "2020-02",
    "summary": "This paper explores hierarchical clustering in the case where pairs of points have dissimilarity scores (e.g. distances) as a part of the input. The recently introduced objective for points with dissimilarity scores results in every tree being a \u00bd approximation if the distances form a metric. This shows the objective does not make a significant distinction between a good and poor hierarchical clustering in metric spaces."
  },
  "aaai2020_main_non-localu-netsforbiomedicalimagesegmentation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Non-Local U-Nets for Biomedical Image Segmentation ",
    "authors": [
      "Zhengyang Wang",
      "Na Zou",
      "Dinggang Shen",
      "Shuiwang Ji"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6100",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6100/5956",
    "published": "2020-02",
    "summary": "Deep learning has shown its great promise in various biomedical image segmentation tasks. Existing models are typically based on U-Net and rely on an encoder-decoder architecture with stacked local operators to aggregate long-range information gradually. However, only using the local operators limits the efficiency and effectiveness. In this work, we propose the non-local U-Nets, which are equipped with flexible global aggregation blocks, for biomedical image segmentation. These blocks can be inserted into U-Net as size-preserving processes, as well as down-sampling and up-sampling layers. We perform thorough experiments on the 3D multimodality isointense infant brain MR image segmentation task to evaluate the non-local U-Nets. Results show that our proposed models achieve top performances with fewer parameters and faster computation."
  },
  "aaai2020_main_attention-over-attentionfield-awarefactorizationmachine": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Attention-over-Attention Field-Aware Factorization Machine ",
    "authors": [
      "Zhibo Wang",
      "Jinxin Ma",
      "Yongquan Zhang",
      "Qian Wang",
      "Ju Ren",
      "Peng Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6101",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6101/5957",
    "published": "2020-02",
    "summary": "Factorization Machine (FM) has been a popular approach in supervised predictive tasks, such as click-through rate prediction and recommender systems, due to its great performance and efficiency. Recently, several variants of FM have been proposed to improve its performance. However, most of the state-of-the-art prediction algorithms neglected the field information of features, and they also failed to discriminate the importance of feature interactions due to the problem of redundant features. In this paper, we present a novel algorithm called Attention-over-Attention Field-aware Factorization Machine (AoAFFM) for better capturing the characteristics of feature interactions. Specifically, we propose the field-aware embedding layer to exploit the field information of features, and combine it with the attention-over-attention mechanism to learn both feature-level and interaction-level attention to estimate the weight of feature interactions. Experimental results show that the proposed AoAFFM improves FM and FFM with large margin, and outperforms state-of-the-art algorithms on three public benchmark datasets."
  },
  "aaai2020_main_transparentclassificationwithmultilayerlogicalperceptronsandrandombinarization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Transparent Classification with Multilayer Logical Perceptrons and Random Binarization ",
    "authors": [
      "Zhuo Wang",
      "Wei Zhang",
      "Ning LIU",
      "Jianyong Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6102",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6102/5958",
    "published": "2020-02",
    "summary": "Models with transparent inner structure and high classification performance are required to reduce potential risk and provide trust for users in domains like health care, finance, security, etc. However, existing models are hard to simultaneously satisfy the above two properties. In this paper, we propose a new hierarchical rule-based model for classification tasks, named Concept Rule Sets (CRS), which has both a strong expressive ability and a transparent inner structure. To address the challenge of efficiently learning the non-differentiable CRS model, we propose a novel neural network architecture, Multilayer Logical Perceptron (MLLP), which is a continuous version of CRS. Using MLLP and the Random Binarization (RB) method we proposed, we can search the discrete solution of CRS in continuous space using gradient descent and ensure the discrete CRS acts almost the same as the corresponding continuous MLLP. Experiments on 12 public data sets show that CRS outperforms the state-of-the-art approaches and the complexity of the learned CRS is close to the simple decision tree."
  },
  "aaai2020_main_lessisbetterunweighteddatasubsamplingviainfluencefunction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Less Is Better: Unweighted Data Subsampling via Influence Function ",
    "authors": [
      "Zifeng Wang",
      "Hong Zhu",
      "Zhenhua Dong",
      "Xiuqiang He",
      "Shao-Lun Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6103",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6103/5959",
    "published": "2020-02",
    "summary": "In the time of Big Data, training complex models on large-scale data sets is challenging, making it appealing to reduce data volume for saving computation resources by subsampling. Most previous works in subsampling are weighted methods designed to help the performance of subset-model approach the full-set-model, hence the weighted methods have no chance to acquire a subset-model that is better than the full-set-model. However, we question that how can we achieve better model with less data? In this work, we propose a novel Unweighted Influence Data Subsampling (UIDS) method, and prove that the subset-model acquired through our method can outperform the full-set-model. Besides, we show that overly confident on a given test set for sampling is common in Influence-based subsampling methods, which can eventually cause our subset-model's failure in out-of-sample test. To mitigate it, we develop a probabilistic sampling scheme to control the worst-case risk over all distributions close to the empirical distribution. The experiment results demonstrate our methods superiority over existed subsampling methods in diverse tasks, such as text classification, image classification, click-through prediction, etc."
  },
  "aaai2020_main_multi-viewmultipleclusteringsusingdeepmatrixfactorization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-View Multiple Clusterings Using Deep Matrix Factorization ",
    "authors": [
      "Shaowei Wei",
      "Jun Wang",
      "Guoxian Yu",
      "Carlotta Domeniconi",
      "Xiangliang Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6104",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6104/5960",
    "published": "2020-02",
    "summary": "Multi-view clustering aims at integrating complementary information from multiple heterogeneous views to improve clustering results. Existing multi-view clustering solutions can only output a single clustering of the data. Due to their multiplicity, multi-view data, can have different groupings that are reasonable and interesting from different perspectives. However, how to find multiple, meaningful, and diverse clustering results from multi-view data is still a rarely studied and challenging topic in multi-view clustering and multiple clusterings. In this paper, we introduce a deep matrix factorization based solution (DMClusts) to discover multiple clusterings. DMClusts gradually factorizes multi-view data matrices into representational subspaces layer-by-layer and generates one clustering in each layer. To enforce the diversity between generated clusterings, it minimizes a new redundancy quantification term derived from the proximity between samples in these subspaces. We further introduce an iterative optimization procedure to simultaneously seek multiple clusterings with quality and diversity. Experimental results on benchmark datasets confirm that DMClusts outperforms state-of-the-art multiple clustering solutions."
  },
  "aaai2020_main_towardscertificatedmodelrobustnessagainstweightperturbations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Certificated Model Robustness Against Weight Perturbations ",
    "authors": [
      "Tsui-Wei Weng",
      "Pu Zhao",
      "Sijia Liu",
      "Pin-Yu Chen",
      "Xue Lin",
      "Luca Daniel"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6105",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6105/5961",
    "published": "2020-02",
    "summary": "This work studies the sensitivity of neural networks to weight perturbations, firstly corresponding to a newly developed threat model that perturbs the neural network parameters. We propose an efficient approach to compute a certified robustness bound of weight perturbations, within which neural networks will not make erroneous outputs as desired by the adversary. In addition, we identify a useful connection between our developed certification method and the problem of weight quantization, a popular model compression technique in deep neural networks (DNNs) and a \u2018must-try\u2019 step in the design of DNN inference engines on resource constrained computing platforms, such as mobiles, FPGA, and ASIC. Specifically, we study the problem of weight quantization \u2013 weight perturbations in the non-adversarial setting \u2013 through the lens of certificated robustness, and we demonstrate significant improvements on the generalization ability of quantized networks through our robustness-aware quantization scheme."
  },
  "aaai2020_main_odinode-informedregressionforparameterandstateinferenceintime-continuousdynamicalsystems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ODIN: ODE-Informed Regression for Parameter and State Inference in Time-Continuous Dynamical Systems ",
    "authors": [
      "Philippe Wenk",
      "Gabriele Abbati",
      "Michael A. Osborne",
      "Bernhard Sch\u00f6lkopf",
      "Andreas Krause",
      "Stefan Bauer"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6106",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6106/5962",
    "published": "2020-02",
    "summary": "Parameter inference in ordinary differential equations is an important problem in many applied sciences and in engineering, especially in a data-scarce setting. In this work, we introduce a novel generative modeling approach based on constrained Gaussian processes and leverage it to build a computationally and data efficient algorithm for state and parameter inference. In an extensive set of experiments, our approach outperforms the current state of the art for parameter inference both in terms of accuracy and computational cost. It also shows promising results for the much more challenging problem of model selection."
  },
  "aaai2020_main_characterizingmembershipprivacyinstochasticgradientlangevindynamics": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Characterizing Membership Privacy in Stochastic Gradient Langevin Dynamics ",
    "authors": [
      "Bingzhe Wu",
      "Chaochao Chen",
      "Shiwan Zhao",
      "Cen Chen",
      "Yuan Yao",
      "Guangyu Sun",
      "Li Wang",
      "Xiaolu Zhang",
      "Jun Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6107",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6107/5963",
    "published": "2020-02",
    "summary": "Bayesian deep learning is recently regarded as an intrinsic way to characterize the weight uncertainty of deep neural networks (DNNs). Stochastic Gradient Langevin Dynamics (SGLD) is an effective method to enable Bayesian deep learning on large-scale datasets. Previous theoretical studies have shown various appealing properties of SGLD, ranging from the convergence properties to the generalization bounds. In this paper, we study the properties of SGLD from a novel perspective of membership privacy protection (i.e., preventing the membership attack). The membership attack, which aims to determine whether a specific sample is used for training a given DNN model, has emerged as a common threat against deep learning algorithms. To this end, we build a theoretical framework to analyze the information leakage (w.r.t. the training dataset) of a model trained using SGLD. Based on this framework, we demonstrate that SGLD can prevent the information leakage of the training dataset to a certain extent. Moreover, our theoretical analysis can be naturally extended to other types of Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC) methods. Empirical results on different datasets and models verify our theoretical findings and suggest that the SGLD algorithm can not only reduce the information leakage but also improve the generalization ability of the DNN models in real-world applications."
  },
  "aaai2020_main_vectorquantization-basedregularizationforautoencoders": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Vector Quantization-Based Regularization for Autoencoders ",
    "authors": [
      "Hanwei Wu",
      "Markus Flierl"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6108",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6108/5964",
    "published": "2020-02",
    "summary": "Autoencoders and their variations provide unsupervised models for learning low-dimensional representations for downstream tasks. Without proper regularization, autoencoder models are susceptible to the overfitting problem and the so-called posterior collapse phenomenon. In this paper, we introduce a quantization-based regularizer in the bottleneck stage of autoencoder models to learn meaningful latent representations. We combine both perspectives of Vector Quantized-Variational AutoEncoders (VQ-VAE) and classical denoising regularization methods of neural networks. We interpret quantizers as regularizers that constrain latent representations while fostering a similarity-preserving mapping at the encoder. Before quantization, we impose noise on the latent codes and use a Bayesian estimator to optimize the quantizer-based representation. The introduced bottleneck Bayesian estimator outputs the posterior mean of the centroids to the decoder, and thus, is performing soft quantization of the noisy latent codes. We show that our proposed regularization method results in improved latent representations for both supervised learning and clustering downstream tasks when compared to autoencoders using other bottleneck structures."
  },
  "aaai2020_main_unifiedgraphandlow-ranktensorlearningformulti-viewclustering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Unified Graph and Low-Rank Tensor Learning for Multi-View Clustering ",
    "authors": [
      "Jianlong Wu",
      "Xingyu Xie",
      "Liqiang Nie",
      "Zhouchen Lin",
      "Hongbin Zha"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6109",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6109/5965",
    "published": "2020-02",
    "summary": "Multi-view clustering aims to take advantage of multiple views information to improve the performance of clustering. Many existing methods compute the affinity matrix by low-rank representation (LRR) and pairwise investigate the relationship between views. However, LRR suffers from the high computational cost in self-representation optimization. Besides, compared with pairwise views, tensor form of all views' representation is more suitable for capturing the high-order correlations among all views. Towards these two issues, in this paper, we propose the unified graph and low-rank tensor learning (UGLTL) for multi-view clustering. Specifically, on the one hand, we learn the view-specific affinity matrix based on projected graph learning. On the other hand, we reorganize the affinity matrices into tensor form and learn its intrinsic tensor based on low-rank tensor approximation. Finally, we unify these two terms together and jointly learn the optimal projection matrices, affinity matrices and intrinsic low-rank tensor. We also propose an efficient algorithm to iteratively optimize the proposed model. To evaluate the performance of the proposed method, we conduct extensive experiments on multiple benchmarks across different scenarios and sizes. Compared with the state-of-the-art approaches, our method achieves much better performance."
  },
  "aaai2020_main_estimatingearlyfundraisingperformanceofinnovationsviagraph-basedmarketenvironmentmodel": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Estimating Early Fundraising Performance of Innovations via Graph-Based Market Environment Model ",
    "authors": [
      "Likang Wu",
      "Zhi Li",
      "Hongke Zhao",
      "Zhen Pan",
      "Qi Liu",
      "Enhong Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6110",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6110/5966",
    "published": "2020-02",
    "summary": "Well begun is half done. In the crowdfunding market, the early fundraising performance of the project is a concerned issue for both creators and platforms. However, estimating the early fundraising performance before the project published is very challenging and still under-explored. To that end, in this paper, we present a focused study on this important problem in a market modeling view. Specifically, we propose a Graph-based Market Environment model (GME) for estimating the early fundraising performance of the target project by exploiting the market environment. In addition, we discriminatively model the market competition and market evolution by designing two graph-based neural network architectures and incorporating them into the joint optimization stage. Finally, we conduct extensive experiments on the real-world crowdfunding data collected from Indiegogo.com. The experimental results clearly demonstrate the effectiveness of our proposed model for modeling and estimating the early fundraising performance of the target project."
  },
  "aaai2020_main_meta-amortizedvariationalinferenceandlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Meta-Amortized Variational Inference and Learning ",
    "authors": [
      "Mike Wu",
      "Kristy Choi",
      "Noah Goodman",
      "Stefano Ermon"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6111",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6111/5967",
    "published": "2020-02",
    "summary": "Despite the recent success in probabilistic modeling and their applications, generative models trained using traditional inference techniques struggle to adapt to new distributions, even when the target distribution may be closely related to the ones seen during training. In this work, we present a doubly-amortized variational inference procedure as a way to address this challenge. By sharing computation across not only a set of query inputs, but also a set of different, related probabilistic models, we learn transferable latent representations that generalize across several related distributions. In particular, given a set of distributions over images, we find the learned representations to transfer to different data transformations. We empirically demonstrate the effectiveness of our method by introducing the MetaVAE, and show that it significantly outperforms baselines on downstream image classification tasks on MNIST (10-50%) and NORB (10-35%)."
  },
  "aaai2020_main_regionaltreeregularizationforinterpretabilityindeepneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Regional Tree Regularization for Interpretability in Deep Neural Networks ",
    "authors": [
      "Mike Wu",
      "Sonali Parbhoo",
      "Michael Hughes",
      "Ryan Kindle",
      "Leo Celi",
      "Maurizio Zazzi",
      "Volker Roth",
      "Finale Doshi-Velez"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6112",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6112/5968",
    "published": "2020-02",
    "summary": "The lack of interpretability remains a barrier to adopting deep neural networks across many safety-critical domains. Tree regularization was recently proposed to encourage a deep neural network's decisions to resemble those of a globally compact, axis-aligned decision tree. However, it is often unreasonable to expect a single tree to predict well across all possible inputs. In practice, doing so could lead to neither interpretable nor performant optima. To address this issue, we propose regional tree regularization \u2013 a method that encourages a deep model to be well-approximated by several separate decision trees specific to predefined regions of the input space. Across many datasets, including two healthcare applications, we show our approach delivers simpler explanations than other regularization schemes without compromising accuracy. Specifically, our regional regularizer finds many more \u201cdesirable\u201d optima compared to global analogues."
  },
  "aaai2020_main_sk-netdeeplearningonpointcloudviaend-to-enddiscoveryofspatialkeypoints": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " SK-Net: Deep Learning on Point Cloud via End-to-End Discovery of Spatial Keypoints ",
    "authors": [
      "Weikun Wu",
      "Yan Zhang",
      "David Wang",
      "Yunqi Lei"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6113",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6113/5969",
    "published": "2020-02",
    "summary": "Since the PointNet was proposed, deep learning on point cloud has been the concentration of intense 3D research. However, existing point-based methods usually are not adequate to extract the local features and the spatial pattern of a point cloud for further shape understanding. This paper presents an end-to-end framework, SK-Net, to jointly optimize the inference of spatial keypoint with the learning of feature representation of a point cloud for a specific point cloud task. One key process of SK-Net is the generation of spatial keypoints (Skeypoints). It is jointly conducted by two proposed regulating losses and a task objective function without knowledge of Skeypoint location annotations and proposals. Specifically, our Skeypoints are not sensitive to the location consistency but are acutely aware of shape. Another key process of SK-Net is the extraction of the local structure of Skeypoints (detail feature) and the local spatial pattern of normalized Skeypoints (pattern feature). This process generates a comprehensive representation, pattern-detail (PD) feature, which comprises the local detail information of a point cloud and reveals its spatial pattern through the part district reconstruction on normalized Skeypoints. Consequently, our network is prompted to effectively understand the correlation between different regions of a point cloud and integrate contextual information of the point cloud. In point cloud tasks, such as classification and segmentation, our proposed method performs better than or comparable with the state-of-the-art approaches. We also present an ablation study to demonstrate the advantages of SK-Net."
  },
  "aaai2020_main_multi-labelcausalfeatureselection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Label Causal Feature Selection ",
    "authors": [
      "Xingyu Wu",
      "Bingbing Jiang",
      "Kui Yu",
      "Huanhuan Chen",
      "Chunyan Miao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6114",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6114/5970",
    "published": "2020-02",
    "summary": "Multi-label feature selection has received considerable attentions during the past decade. However, existing algorithms do not attempt to uncover the underlying causal mechanism, and individually solve different types of variable relationships, ignoring the mutual effects between them. Furthermore, these algorithms lack of interpretability, which can only select features for all labels, but cannot explain the correlation between a selected feature and a certain label. To address these problems, in this paper, we theoretically study the causal relationships in multi-label data, and propose a novel Markov blanket based multi-label causal feature selection (MB-MCF) algorithm. MB-MCF mines the causal mechanism of labels and features first, to obtain a complete representation of information about labels. Based on the causal relationships, MB-MCF then selects predictive features and simultaneously distinguishes common features shared by multiple labels and label-specific features owned by single labels. Experiments on real-world data sets validate that MB-MCF could automatically determine the number of selected features and simultaneously achieve the best performance compared with state-of-the-art methods. An experiment in Emotions data set further demonstrates the interpretability of MB-MCF."
  },
  "aaai2020_main_dualadversarialco-learningformulti-domaintextclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Dual Adversarial Co-Learning for Multi-Domain Text Classification ",
    "authors": [
      "Yuan Wu",
      "Yuhong Guo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6115",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6115/5971",
    "published": "2020-02",
    "summary": "With the advent of deep learning, the performance of text classification models have been improved significantly. Nevertheless, the successful training of a good classification model requires a sufficient amount of labeled data, while it is always expensive and time consuming to annotate data. With the rapid growth of digital data, similar classification tasks can typically occur in multiple domains, while the availability of labeled data can largely vary across domains. Some domains may have abundant labeled data, while in some other domains there may only exist a limited amount (or none) of labeled data. Meanwhile text classification tasks are highly domain-dependent \u2014 a text classifier trained in one domain may not perform well in another domain. In order to address these issues, in this paper we propose a novel dual adversarial co-learning approach for multi-domain text classification (MDTC). The approach learns shared-private networks for feature extraction and deploys dual adversarial regularizations to align features across different domains and between labeled and unlabeled data simultaneously under a discrepancy based co-learning framework, aiming to improve the classifiers' generalization capacity with the learned features. We conduct experiments on multi-domain sentiment classification datasets. The results show the proposed approach achieves the state-of-the-art MDTC performance."
  },
  "aaai2020_main_efficientprojection-freeonlinemethodswithstochasticrecursivegradient": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Efficient Projection-Free Online Methods with Stochastic Recursive Gradient ",
    "authors": [
      "Jiahao Xie",
      "Zebang Shen",
      "Chao Zhang",
      "Boyu Wang",
      "Hui Qian"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6116",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6116/5972",
    "published": "2020-02",
    "summary": "This paper focuses on projection-free methods for solving smooth Online Convex Optimization (OCO) problems. Existing projection-free methods either achieve suboptimal regret bounds or have high per-round computational costs. To fill this gap, two efficient projection-free online methods called ORGFW and MORGFW are proposed for solving stochastic and adversarial OCO problems, respectively. By employing a recursive gradient estimator, our methods achieve optimal regret bounds (up to a logarithmic factor) while possessing low per-round computational costs. Experimental results demonstrate the efficiency of the proposed methods compared to state-of-the-arts."
  },
  "aaai2020_main_partialmulti-labellearningwithnoisylabelidentification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Partial Multi-Label Learning with Noisy Label Identification ",
    "authors": [
      "Ming-Kun Xie",
      "Sheng-Jun Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6117",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6117/5973",
    "published": "2020-02",
    "summary": "Partial multi-label learning (PML) deals with problems where each instance is assigned with a candidate label set, which contains multiple relevant labels and some noisy labels. Recent studies usually solve PML problems with the disambiguation strategy, which recovers ground-truth labels from the candidate label set by simply assuming that the noisy labels are generated randomly. In real applications, however, noisy labels are usually caused by some ambiguous contents of the example. Based on this observation, we propose a partial multi-label learning approach to simultaneously recover the ground-truth information and identify the noisy labels. The two objectives are formalized in a unified framework with trace norm and \u21131 norm regularizers. Under the supervision of the observed noise-corrupted label matrix, the multi-label classifier and noisy label identifier are jointly optimized by incorporating the label correlation exploitation and feature-induced noise model. Extensive experiments on synthetic as well as real-world data sets validate the effectiveness of the proposed approach."
  },
  "aaai2020_main_infiniteshapeoddsnonparametricbayesianmodelsforshaperepresentations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Infinite ShapeOdds: Nonparametric Bayesian Models for Shape Representations ",
    "authors": [
      "Wei Xing",
      "Shireen Elhabian",
      "Robert Kirby",
      "Ross T. Whitaker",
      "Shandian Zhe"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6118",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6118/5974",
    "published": "2020-02",
    "summary": "Learning compact representations for shapes (binary images) is important for many applications. Although neural network models are very powerful, they usually involve many parameters, require substantial tuning efforts and easily overfit small datasets, which are common in shape-related applications. The state-of-the-art approach, ShapeOdds, as a latent Gaussian model, can effectively prevent overfitting and is more robust. Nonetheless, it relies on a linear projection assumption and is incapable of capturing intrinsic nonlinear shape variations, hence may leading to inferior representations and structure discovery. To address these issues, we propose Infinite ShapeOdds (InfShapeOdds), a Bayesian nonparametric shape model, which is flexible enough to capture complex shape variations and discover hidden cluster structures, while still avoiding overfitting. Specifically, we use matrix Gaussian priors, nonlinear feature mappings and the kernel trick to generalize ShapeOdds to a shape-variate Gaussian process model, which can grasp various nonlinear correlations among the pixels within and across (different) shapes. To further discover the hidden structures in data, we place a Dirichlet process mixture (DPM) prior over the representations to jointly infer the cluster number and memberships. Finally, we exploit the Kronecker-product structure in our model to develop an efficient, truncated variational expectation-maximization algorithm for model estimation. On synthetic and real-world data, we show the advantage of our method in both representation learning and latent structure discovery."
  },
  "aaai2020_main_learningfeatureinteractionswithlorentzianfactorizationmachine": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning Feature Interactions with Lorentzian Factorization Machine ",
    "authors": [
      "Canran Xu",
      "Ming Wu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6119",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6119/5975",
    "published": "2020-02",
    "summary": "Learning representations for feature interactions to model user behaviors is critical for recommendation system and click-trough rate (CTR) predictions. Recent advances in this area are empowered by deep learning methods which could learn sophisticated feature interactions and achieve the state-of-the-art result in an end-to-end manner. These approaches require large number of training parameters integrated with the low-level representations, and thus are memory and computational inefficient. In this paper, we propose a new model named \u201cLorentzFM\u201d that can learn feature interactions embedded in a hyperbolic space in which the violation of triangle inequality for Lorentz distances is available. To this end, the learned representation is benefited by the peculiar geometric properties of hyperbolic triangles, and result in a significant reduction in the number of parameters (20% to 80%) because all the top deep learning layers are not required. With such a lightweight architecture, LorentzFM achieves comparable and even materially better results than the deep learning methods such as DeepFM, xDeepFM and Deep & Cross in both recommendation and CTR prediction tasks."
  },
  "aaai2020_main_gromov-wassersteinfactorizationmodelsforgraphclustering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Gromov-Wasserstein Factorization Models for Graph Clustering ",
    "authors": [
      "Hongtengl Xu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6120",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6120/5976",
    "published": "2020-02",
    "summary": "We propose a new nonlinear factorization model for graphs that are with topological structures, and optionally, node attributes. This model is based on a pseudometric called Gromov-Wasserstein (GW) discrepancy, which compares graphs in a relational way. It estimates observed graphs as GW barycenters constructed by a set of atoms with different weights. By minimizing the GW discrepancy between each observed graph and its GW barycenter-based estimation, we learn the atoms and their weights associated with the observed graphs. The model achieves a novel and flexible factorization mechanism under GW discrepancy, in which both the observed graphs and the learnable atoms can be unaligned and with different sizes. We design an effective approximate algorithm for learning this Gromov-Wasserstein factorization (GWF) model, unrolling loopy computations as stacked modules and computing gradients with backpropagation. The stacked modules can be with two different architectures, which correspond to the proximal point algorithm (PPA) and Bregman alternating direction method of multipliers (BADMM), respectively. Experiments show that our model obtains encouraging results on clustering graphs."
  },
  "aaai2020_main_federatedpatienthashing": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Federated Patient Hashing ",
    "authors": [
      "Jie Xu",
      "Zhenxing Xu",
      "Peter Walker",
      "Fei Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6121",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6121/5977",
    "published": "2020-02",
    "summary": "Privacy concerns on sharing sensitive data across institutions are particularly paramount for the medical domain, which hinders the research and development of many applications, such as cohort construction for cross-institution observational studies and disease surveillance. Not only that, the large volume and heterogeneity of the patient data pose great challenges for retrieval and analysis. To address these challenges, in this paper, we propose a Federated Patient Hashing (FPH) framework, which collaboratively trains a retrieval model stored in a shared memory while keeping all the patient-level information in local institutions. Specifically, the objective function is constructed by minimization of a similarity preserving loss and a heterogeneity digging loss, which preserves both inter-data and intra-data relationships. Then, by leveraging the concept of Bregman divergence, we implement optimization in a federated manner in both centralized and decentralized learning settings, without accessing the raw training data across institutions. In addition to this, we also analyze the convergence rate of the FPH framework. Extensive experiments on real-world clinical data set from critical care are provided to demonstrate the effectiveness of the proposed method on similar patient matching across institutions."
  },
  "aaai2020_main_deepembeddedcomplementaryandinteractiveinformationformulti-viewclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Embedded Complementary and Interactive Information for Multi-View Classification ",
    "authors": [
      "Jinglin Xu",
      "Wenbin Li",
      "Xinwang Liu",
      "Dingwen Zhang",
      "Ji Liu",
      "Junwei Han"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6122",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6122/5978",
    "published": "2020-02",
    "summary": "Multi-view classification optimally integrates various features from different views to improve classification tasks. Though most of the existing works demonstrate promising performance in various computer vision applications, we observe that they can be further improved by sufficiently utilizing complementary view-specific information, deep interactive information between different views, and the strategy of fusing various views. In this work, we propose a novel multi-view learning framework that seamlessly embeds various view-specific information and deep interactive information and introduces a novel multi-view fusion strategy to make a joint decision during the optimization for classification. Specifically, we utilize different deep neural networks to learn multiple view-specific representations, and model deep interactive information through a shared interactive network using the cross-correlations between attributes of these representations. After that, we adaptively integrate multiple neural networks by flexibly tuning the power exponent of weight, which not only avoids the trivial solution of weight but also provides a new approach to fuse outputs from different deterministic neural networks. Extensive experiments on several public datasets demonstrate the rationality and effectiveness of our method."
  },
  "aaai2020_main_adversarialdomainadaptationwithdomainmixup": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adversarial Domain Adaptation with Domain Mixup ",
    "authors": [
      "Minghao Xu",
      "Jian Zhang",
      "Bingbing Ni",
      "Teng Li",
      "Chengjie Wang",
      "Qi Tian",
      "Wenjun Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6123",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6123/5979",
    "published": "2020-02",
    "summary": "Recent works on domain adaptation reveal the effectiveness of adversarial learning on filling the discrepancy between source and target domains. However, two common limitations exist in current adversarial-learning-based methods. First, samples from two domains alone are not sufficient to ensure domain-invariance at most part of latent space. Second, the domain discriminator involved in these methods can only judge real or fake with the guidance of hard label, while it is more reasonable to use soft scores to evaluate the generated images or features, i.e., to fully utilize the inter-domain information. In this paper, we present adversarial domain adaptation with domain mixup (DM-ADA), which guarantees domain-invariance in a more continuous latent space and guides the domain discriminator in judging samples' difference relative to source and target domains. Domain mixup is jointly conducted on pixel and feature level to improve the robustness of models. Extensive experiments prove that the proposed approach can achieve superior performance on tasks with various degrees of domain shift and data complexity."
  },
  "aaai2020_main_partialmulti-labellearningwithlabeldistribution": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Partial Multi-Label Learning with Label Distribution ",
    "authors": [
      "Ning Xu",
      "Yun-Peng Liu",
      "Xin Geng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6124",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6124/5980",
    "published": "2020-02",
    "summary": "Partial multi-label learning (PML) aims to learn from training examples each associated with a set of candidate labels, among which only a subset are valid for the training example. The common strategy to induce predictive model is trying to disambiguate the candidate label set, such as identifying the ground-truth label via utilizing the confidence of each candidate label or estimating the noisy labels in the candidate label sets. Nonetheless, these strategies ignore considering the essential label distribution corresponding to each instance since the label distribution is not explicitly available in the training set. In this paper, a new partial multi-label learning strategy named Pml-ld is proposed to learn from partial multi-label examples via label enhancement. Specifically, label distributions are recovered by leveraging the topological information of the feature space and the correlations among the labels. After that, a multi-class predictive model is learned by fitting a regularized multi-output regressor with the recovered label distributions. Experimental results on synthetic as well as real-world datasets clearly validate the effectiveness of Pml-ld for solving PML problems."
  },
  "aaai2020_main_contextual-banditbasedpersonalizedrecommendationwithtime-varyinguserinterests": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Contextual-Bandit Based Personalized Recommendation with Time-Varying User Interests ",
    "authors": [
      "Xiao Xu",
      "Fang Dong",
      "Yanghua Li",
      "Shaojian He",
      "Xin Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6125",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6125/5981",
    "published": "2020-02",
    "summary": "A contextual bandit problem is studied in a highly non-stationary environment, which is ubiquitous in various recommender systems due to the time-varying interests of users. Two models with disjoint and hybrid payoffs are considered to characterize the phenomenon that users' preferences towards different items vary differently over time. In the disjoint payoff model, the reward of playing an arm is determined by an arm-specific preference vector, which is piecewise-stationary with asynchronous and distinct changes across different arms. An efficient learning algorithm that is adaptive to abrupt reward changes is proposed and theoretical regret analysis is provided to show that a sublinear scaling of regret in the time length T is achieved. The algorithm is further extended to a more general setting with hybrid payoffs where the reward of playing an arm is determined by both an arm-specific preference vector and a joint coefficient vector shared by all arms. Empirical experiments are conducted on real-world datasets to verify the advantages of the proposed learning algorithms against baseline ones in both settings."
  },
  "aaai2020_main_generative-discriminativecomplementarylearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generative-Discriminative Complementary Learning ",
    "authors": [
      "Yanwu Xu",
      "Mingming Gong",
      "Junxiang Chen",
      "Tongliang Liu",
      "Kun Zhang",
      "Kayhan Batmanghelich"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6126",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6126/5982",
    "published": "2020-02",
    "summary": "The majority of state-of-the-art deep learning methods are discriminative approaches, which model the conditional distribution of labels given inputs features. The success of such approaches heavily depends on high-quality labeled instances, which are not easy to obtain, especially as the number of candidate classes increases. In this paper, we study the complementary learning problem. Unlike ordinary labels, complementary labels are easy to obtain because an annotator only needs to provide a yes/no answer to a randomly chosen candidate class for each instance. We propose a generative-discriminative complementary learning method that estimates the ordinary labels by modeling both the conditional (discriminative) and instance (generative) distributions. Our method, we call Complementary Conditional GAN (CCGAN), improves the accuracy of predicting ordinary labels and is able to generate high-quality instances in spite of weak supervision. In addition to the extensive empirical studies, we also theoretically show that our model can retrieve the true conditional distribution from the complementarily-labeled data."
  },
  "aaai2020_main_toavoidthepitfallofmissinglabelsinfeatureselectionagenerativemodelgivestheanswer": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " To Avoid the Pitfall of Missing Labels in Feature Selection: A Generative Model Gives the Answer ",
    "authors": [
      "Yuanyuan Xu",
      "Jun Wang",
      "Jinmao Wei"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6127",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6127/5983",
    "published": "2020-02",
    "summary": "In multi-label learning, instances have a large number of noisy and irrelevant features, and each instance is associated with a set of class labels wherein label information is generally incomplete. These missing labels possess two sides like a coin; people cannot predict whether their provided information for feature selection is favorable (relevant) or not (irrelevant) during tossing. Existing approaches either superficially consider the missing labels as negative or indiscreetly impute them with some predicted values, which may either overestimate unobserved labels or introduce new noises in selecting discriminative features. To avoid the pitfall of missing labels, a novel unified framework of selecting discriminative features and modeling incomplete label matrix is proposed from a generative point of view in this paper. Concretely, we relax Smoothness Assumption to infer the label observability, which can reveal the positions of unobserved labels, and employ the spike-and-slab prior to perform feature selection by excluding unobserved labels. Using a data-augmentation strategy leads to full local conjugacy in our model, facilitating simple and efficient Expectation Maximization (EM) algorithm for inference. Quantitative and qualitative experimental results demonstrate the superiority of the proposed approach under various evaluation metrics."
  },
  "aaai2020_main_lightmulti-segmentactivationformodelcompression": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Light Multi-Segment Activation for Model Compression ",
    "authors": [
      "Zhenhui Xu",
      "Guolin Ke",
      "Jia Zhang",
      "Jiang Bian",
      "Tie-Yan Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6128",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6128/5984",
    "published": "2020-02",
    "summary": "Model compression has become necessary when applying neural networks (NN) into many real application tasks that can accept slightly-reduced model accuracy but with strict tolerance to model complexity. Recently, Knowledge Distillation, which distills the knowledge from well-trained and highly complex teacher model into a compact student model, has been widely used for model compression. However, under the strict requirement on the resource cost, it is quite challenging to make student model achieve comparable performance with the teacher one, essentially due to the drastically-reduced expressiveness ability of the compact student model. Inspired by the nature of the expressiveness ability in NN, we propose to use multi-segment activation, which can significantly improve the expressiveness ability with very little cost, in the compact student model. Specifically, we propose a highly efficient multi-segment activation, called Light Multi-segment Activation (LMA), which can rapidly produce multiple linear regions with very few parameters by leveraging the statistical information. With using LMA, the compact student model is capable of achieving much better performance effectively and efficiently, than the ReLU-equipped one with same model complexity. Furthermore, the proposed method is compatible with other model compression techniques, such as quantization, which means they can be used jointly for better compression performance. Experiments on state-of-the-art NN architectures over the real-world tasks demonstrate the effectiveness and extensibility of the LMA."
  },
  "aaai2020_main_notallattentionisneededgatedattentionnetworkforsequencedata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Not All Attention Is Needed: Gated Attention Network for Sequence Data ",
    "authors": [
      "Lanqing Xue",
      "Xiaopeng Li",
      "Nevin L. Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6129",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6129/5985",
    "published": "2020-02",
    "summary": "Although deep neural networks generally have fixed network structures, the concept of dynamic mechanism has drawn more and more attention in recent years. Attention mechanisms compute input-dependent dynamic attention weights for aggregating a sequence of hidden states. Dynamic network configuration in convolutional neural networks (CNNs) selectively activates only part of the network at a time for different inputs. In this paper, we combine the two dynamic mechanisms for text classification tasks. Traditional attention mechanisms attend to the whole sequence of hidden states for an input sentence, while in most cases not all attention is needed especially for long sequences. We propose a novel method called Gated Attention Network (GA-Net) to dynamically select a subset of elements to attend to using an auxiliary network, and compute attention weights to aggregate the selected elements. It avoids a significant amount of unnecessary computation on unattended elements, and allows the model to pay attention to important parts of the sequence. Experiments in various datasets show that the proposed method achieves better performance compared with all baseline models with global or local attention while requiring less computation and achieving better interpretability. It is also promising to extend the idea to more complex attention-based models, such as transformers and seq-to-seq models."
  },
  "aaai2020_main_one-shotimageclassificationbylearningtorestoreprototypes": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " One-Shot Image Classification by Learning to Restore Prototypes ",
    "authors": [
      "Wanqi Xue",
      "Wei Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6130",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6130/5986",
    "published": "2020-02",
    "summary": "One-shot image classification aims to train image classifiers over the dataset with only one image per category. It is challenging for modern deep neural networks that typically require hundreds or thousands of images per class. In this paper, we adopt metric learning for this problem, which has been applied for few- and many-shot image classification by comparing the distance between the test image and the center of each class in the feature space. However, for one-shot learning, the existing metric learning approaches would suffer poor performance because the single training image may not be representative of the class. For example, if the image is far away from the class center in the feature space, the metric-learning based algorithms are unlikely to make correct predictions for the test images because the decision boundary is shifted by this noisy image. To address this issue, we propose a simple yet effective regression model, denoted by RestoreNet, which learns a class agnostic transformation on the image feature to move the image closer to the class center in the feature space. Experiments demonstrate that RestoreNet obtains superior performance over the state-of-the-art methods on a broad range of datasets. Moreover, RestoreNet can be easily combined with other methods to achieve further improvement."
  },
  "aaai2020_main_effectivedataaugmentationwithmulti-domainlearninggans": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Effective Data Augmentation with Multi-Domain Learning GANs ",
    "authors": [
      "Shin'ya Yamaguchi",
      "Sekitoshi Kanai",
      "Takeharu Eda"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6131",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6131/5987",
    "published": "2020-02",
    "summary": "For deep learning applications, the massive data development (e.g., collecting, labeling), which is an essential process in building practical applications, still incurs seriously high costs. In this work, we propose an effective data augmentation method based on generative adversarial networks (GANs), called Domain Fusion. Our key idea is to import the knowledge contained in an outer dataset to a target model by using a multi-domain learning GAN. The multi-domain learning GAN simultaneously learns the outer and target dataset and generates new samples for the target tasks. The simultaneous learning process makes GANs generate the target samples with high fidelity and variety. As a result, we can obtain accurate models for the target tasks by using these generated samples even if we only have an extremely low volume target dataset. We experimentally evaluate the advantages of Domain Fusion in image classification tasks on 3 target datasets: CIFAR-100, FGVC-Aircraft, and Indoor Scene Recognition. When trained on each target dataset reduced the samples to 5,000 images, Domain Fusion achieves better classification accuracy than the data augmentation using fine-tuned GANs. Furthermore, we show that Domain Fusion improves the quality of generated samples, and the improvements can contribute to higher accuracy."
  },
  "aaai2020_main_partiallabellearningwithbatchlabelcorrection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Partial Label Learning with Batch Label Correction ",
    "authors": [
      "Yan Yan",
      "Yuhong Guo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6132",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6132/5988",
    "published": "2020-02",
    "summary": "Partial label (PL) learning tackles the problem where each training instance is associated with a set of candidate labels, among which only one is the true label. In this paper, we propose a simple but effective batch-based partial label learning algorithm named PL-BLC, which tackles the partial label learning problem with batch-wise label correction (BLC). PL-BLC dynamically corrects the label confidence matrix of each training batch based on the current prediction network, and adopts a MixUp data augmentation scheme to enhance the underlying true labels against the redundant noisy labels. In addition, it introduces a teacher model through a consistency cost to ensure the stability of the batch-based prediction network update. Extensive experiments are conducted on synthesized and real-world partial label learning datasets, while the proposed approach demonstrates the state-of-the-art performance for partial label learning."
  },
  "aaai2020_main_activelearningwithquerygenerationforcost-effectivetextclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Active Learning with Query Generation for Cost-Effective Text Classification ",
    "authors": [
      "Yi-Fan Yan",
      "Sheng-Jun Huang",
      "Shaoyi Chen",
      "Meng Liao",
      "Jin Xu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6133",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6133/5989",
    "published": "2020-02",
    "summary": "Labeling a text document is usually time consuming because it requires the annotator to read the whole document and check its relevance with each possible class label. It thus becomes rather expensive to train an effective model for text classification when it involves a large dataset of long documents. In this paper, we propose an active learning approach for text classification with lower annotation cost. Instead of scanning all the examples in the unlabeled data pool to select the best one for query, the proposed method automatically generates the most informative examples based on the classification model, and thus can be applied to tasks with large scale or even infinite unlabeled data. Furthermore, we propose to approximate the generated example with a few summary words by sparse reconstruction, which allows the annotators to easily assign the class label by reading a few words rather than the long document. Experiments on different datasets demonstrate that the proposed approach can effectively improve the classification performance while significantly reduce the annotation cost."
  },
  "aaai2020_main_towardsaccuratelowbit-widthquantizationwithmultiplephaseadaptations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Accurate Low Bit-Width Quantization with Multiple Phase Adaptations ",
    "authors": [
      "Zhaoyi Yan",
      "Yemin Shi",
      "Yaowei Wang",
      "Mingkui Tan",
      "Zheyang Li",
      "Wenming Tan",
      "Yonghong Tian"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6134",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6134/5990",
    "published": "2020-02",
    "summary": "Low bit-width model quantization is highly desirable when deploying a deep neural network on mobile and edge devices. Quantization is an effective way to reduce the model size with low bit-width weight representation. However, the unacceptable accuracy drop hinders the development of this approach. One possible reason for this is that the weights in quantization intervals are directly assigned to the center. At the same time, some quantization applications are limited by the various of different network models. Accordingly, in this paper, we propose Multiple Phase Adaptations (MPA), a framework designed to address these two problems. Firstly, weights in the target interval are assigned to center by gradually spreading the quantization range. During the MPA process, the accuracy drop can be compensated for the unquantized parts. Moreover, as MPA does not introduce hyperparameters that depend on different models or bit-width, the framework can be conveniently applied to various models. Extensive experiments demonstrate that MPA achieves higher accuracy than most existing methods on classification tasks for AlexNet, VGG-16 and ResNet."
  },
  "aaai2020_main_variationaladversarialkernellearnedimitationlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Variational Adversarial Kernel Learned Imitation Learning ",
    "authors": [
      "Fan Yang",
      "Alina Vereshchaka",
      "Yufan Zhou",
      "Changyou Chen",
      "Wen Dong"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6135",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6135/5991",
    "published": "2020-02",
    "summary": "Imitation learning refers to the problem where an agent learns to perform a task through observing and mimicking expert demonstrations, without knowledge of the cost function. State-of-the-art imitation learning algorithms reduce imitation learning to distribution-matching problems by minimizing some distance measures. However, the distance measure may not always provide informative signals for a policy update. To this end, we propose the variational adversarial kernel learned imitation learning (VAKLIL), which measures the distance using the maximum mean discrepancy with variational kernel learning. Our method optimizes over a large cost-function space and is sample efficient and robust to overfitting. We demonstrate the performance of our algorithm through benchmarking with four state-of-the-art imitation learning algorithms over five high-dimensional control tasks, and a complex transportation control task. Experimental results indicate that our algorithm significantly outperforms related algorithms in all scenarios."
  },
  "aaai2020_main_revisitingonlinequantumstatelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Revisiting Online Quantum State Learning ",
    "authors": [
      "Feidiao Yang",
      "Jiaqing Jiang",
      "Jialin Zhang",
      "Xiaoming Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6136",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6136/5992",
    "published": "2020-02",
    "summary": "In this paper, we study the online quantum state learning problem which is recently proposed by Aaronson et al. (2018). In this problem, the learning algorithm sequentially predicts quantum states based on observed measurements and losses and the goal is to minimize the regret. In the previous work, the existing algorithms may output mixed quantum states. However, in many scenarios, the prediction of a pure quantum state is required. In this paper, we first propose a Follow-the-Perturbed-Leader (FTPL) algorithm that can guarantee to predict pure quantum states. Theoretical analysis shows that our algorithm can achieve an O(\u221aT) expected regret under some reasonable settings. In the case that the pure state prediction is not mandatory, we propose another deterministic learning algorithm which is simpler and more efficient. The algorithm is based on the online gradient descent (OGD) method and can also achieve an O(\u221aT) regret bound. The main technical contribution of this result is an algorithm of projecting an arbitrary Hermitian matrix onto the set of density matrices with respect to the Frobenius norm. We think this subroutine is of independent interest and can be widely used in many other problems in the quantum computing area. In addition to the theoretical analysis, we evaluate the algorithms with a series of simulation experiments. The experimental results show that our FTPL method and OGD method outperform the existing RFTL approach proposed by Aaronson et al. (2018) in almost all settings. In the implementation of the RFTL approach, we give a closed-form solution to the algorithm. This provides an efficient, accurate, and completely executable solution to the RFTL method."
  },
  "aaai2020_main_bi-directionalgenerationforunsuperviseddomainadaptation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bi-Directional Generation for Unsupervised Domain Adaptation ",
    "authors": [
      "Guanglei Yang",
      "Haifeng Xia",
      "Mingli Ding",
      "Zhengming Ding"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6137",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6137/5993",
    "published": "2020-02",
    "summary": "Unsupervised domain adaptation facilitates the unlabeled target domain relying on well-established source domain information. The conventional methods forcefully reducing the domain discrepancy in the latent space will result in the destruction of intrinsic data structure. To balance the mitigation of domain gap and the preservation of the inherent structure, we propose a Bi-Directional Generation domain adaptation model with consistent classifiers interpolating two intermediate domains to bridge source and target domains. Specifically, two cross-domain generators are employed to synthesize one domain conditioned on the other. The performance of our proposed method can be further enhanced by the consistent classifiers and the cross-domain alignment constraints. We also design two classifiers which are jointly optimized to maximize the consistency on target sample prediction. Extensive experiments verify that our proposed model outperforms the state-of-the-art on standard cross domain visual benchmarks."
  },
  "aaai2020_main_harmoniouscoexistenceofstructuredweightpruningandternarizationfordeepneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Harmonious Coexistence of Structured Weight Pruning and Ternarization for Deep Neural Networks ",
    "authors": [
      "Li Yang",
      "Zhezhi He",
      "Deliang Fan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6138",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6138/5994",
    "published": "2020-02",
    "summary": "Deep convolutional neural network (DNN) has demonstrated phenomenal success and been widely used in many computer vision tasks. However, its enormous model size and high computing complexity prohibits its wide deployment into resource limited embedded system, such as FPGA and mGPU. As the two most widely adopted model compression techniques, weight pruning and quantization compress DNN model through introducing weight sparsity (i.e., forcing partial weights as zeros) and quantizing weights into limited bit-width values, respectively. Although there are works attempting to combine the weight pruning and quantization, we still observe disharmony between weight pruning and quantization, especially when more aggressive compression schemes (e.g., Structured pruning and low bit-width quantization) are used. In this work, taking FPGA as the test computing platform and Processing Elements (PE) as the basic parallel computing unit, we first propose a PE-wise structured pruning scheme, which introduces weight sparsification with considering of the architecture of PE. In addition, we integrate it with an optimized weight ternarization approach which quantizes weights into ternary values ({-1,0,+1}), thus converting the dominant convolution operations in DNN from multiplication-and-accumulation (MAC) to addition-only, as well as compressing the original model (from 32-bit floating point to 2-bit ternary representation) by at least 16 times. Then, we investigate and solve the coexistence issue between PE-wise Structured pruning and ternarization, through proposing a  Weight Penalty Clipping (WPC) technique with self-adapting threshold. Our experiment shows that the fusion of our proposed techniques can achieve the best state-of-the-art \u223c21\u00d7 PE-wise structured compression rate with merely 1.74%/0.94% (top-1/top-5) accuracy degradation of ResNet-18 on ImageNet dataset."
  },
  "aaai2020_main_distributedprimal-dualoptimizationforonlinemulti-tasklearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Distributed Primal-Dual Optimization for Online Multi-Task Learning ",
    "authors": [
      "Peng Yang",
      "Ping Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6139",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6139/5995",
    "published": "2020-02",
    "summary": "Conventional online multi-task learning algorithms suffer from two critical limitations: 1) Heavy communication caused by delivering high velocity of sequential data to a central machine; 2) Expensive runtime complexity for building task relatedness. To address these issues, in this paper we consider a setting where multiple tasks are geographically located in different places, where one task can synchronize data with others to leverage knowledge of related tasks. Specifically, we propose an adaptive primal-dual algorithm, which not only captures task-specific noise in adversarial learning but also carries out a projection-free update with runtime efficiency. Moreover, our model is well-suited to decentralized periodic-connected tasks as it allows the energy-starved or bandwidth-constraint tasks to postpone the update. Theoretical results demonstrate the convergence guarantee of our distributed algorithm with an optimal regret. Empirical results confirm that the proposed model is highly effective on various real-world datasets."
  },
  "aaai2020_main_ml-loodetectingadversarialexampleswithfeatureattribution": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ML-LOO: Detecting Adversarial Examples with Feature Attribution ",
    "authors": [
      "Puyudi Yang",
      "Jianbo Chen",
      "Cho-Jui Hsieh",
      "Jane-Ling Wang",
      "Michael Jordan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6140",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6140/5996",
    "published": "2020-02",
    "summary": "Deep neural networks obtain state-of-the-art performance on a series of tasks. However, they are easily fooled by adding a small adversarial perturbation to the input. The perturbation is often imperceptible to humans on image data. We observe a significant difference in feature attributions between adversarially crafted examples and original examples. Based on this observation, we introduce a new framework to detect adversarial examples through thresholding a scale estimate of feature attribution scores. Furthermore, we extend our method to include multi-layer feature attributions in order to tackle attacks that have mixed confidence levels. As demonstrated in extensive experiments, our method achieves superior performances in distinguishing adversarial examples from popular attack methods on a variety of real data sets compared to state-of-the-art detection methods. In particular, our method is able to detect adversarial examples of mixed confidence levels, and transfer between different attacking methods. We also show that our method achieves competitive performance even when the attacker has complete access to the detector."
  },
  "aaai2020_main_dynamicalsysteminspiredadaptivetimesteppingcontrollerforresidualnetworkfamilies": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Dynamical System Inspired Adaptive Time Stepping Controller for Residual Network Families ",
    "authors": [
      "Yibo Yang",
      "Jianlong Wu",
      "Hongyang Li",
      "Xia Li",
      "Tiancheng Shen",
      "Zhouchen Lin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6141",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6141/5997",
    "published": "2020-02",
    "summary": "The correspondence between residual networks and dynamical systems motivates researchers to unravel the physics of ResNets with well-developed tools in numeral methods of ODE systems. The Runge-Kutta-Fehlberg method is an adaptive time stepping that renders a good trade-off between the stability and efficiency. Can we also have an adaptive time stepping for ResNets to ensure both stability and performance? In this study, we analyze the effects of time stepping on the Euler method and ResNets. We establish a stability condition for ResNets with step sizes and weight parameters, and point out the effects of step sizes on the stability and performance. Inspired by our analyses, we develop an adaptive time stepping controller that is dependent on the parameters of the current step, and aware of previous steps. The controller is jointly optimized with the network training so that variable step sizes and evolution time can be adaptively adjusted. We conduct experiments on ImageNet and CIFAR to demonstrate the effectiveness. It is shown that our proposed method is able to improve both stability and accuracy without introducing additional overhead in inference phase."
  },
  "aaai2020_main_graphfew-shotlearningviaknowledgetransfer": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Graph Few-Shot Learning via Knowledge Transfer ",
    "authors": [
      "Huaxiu Yao",
      "Chuxu Zhang",
      "Ying Wei",
      "Meng Jiang",
      "Suhang Wang",
      "Junzhou Huang",
      "Nitesh Chawla",
      "Zhenhui Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6142",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6142/5998",
    "published": "2020-02",
    "summary": "Towards the challenging problem of semi-supervised node classification, there have been extensive studies. As a frontier, Graph Neural Networks (GNNs) have aroused great interest recently, which update the representation of each node by aggregating information of its neighbors. However, most GNNs have shallow layers with a limited receptive field and may not achieve satisfactory performance especially when the number of labeled nodes is quite small. To address this challenge, we innovatively propose a graph few-shot learning (GFL) algorithm that incorporates prior knowledge learned from auxiliary graphs to improve classification accuracy on the target graph. Specifically, a transferable metric space characterized by a node embedding and a graph-specific prototype embedding function is shared between auxiliary graphs and the target, facilitating the transfer of structural knowledge. Extensive experiments and ablation studies on four real-world graph datasets demonstrate the effectiveness of our proposed model and the contribution of each component."
  },
  "aaai2020_main_efficientneuralarchitecturesearchviaproximaliterations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Efficient Neural Architecture Search via Proximal Iterations ",
    "authors": [
      "Quanming Yao",
      "Ju Xu",
      "Wei-Wei Tu",
      "Zhanxing Zhu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6143",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6143/5999",
    "published": "2020-02",
    "summary": "Neural architecture search (NAS) attracts much research attention because of its ability to identify better architectures than handcrafted ones. Recently, differentiable search methods become the state-of-the-arts on NAS, which can obtain high-performance architectures in several days. However, they still suffer from huge computation costs and inferior performance due to the construction of the supernet. In this paper, we propose an efficient NAS method based on proximal iterations (denoted as NASP). Different from previous works, NASP reformulates the search process as an optimization problem with a discrete constraint on architectures and a regularizer on model complexity. As the new objective is hard to solve, we further propose an efficient algorithm inspired by proximal iterations for optimization. In this way, NASP is not only much faster than existing differentiable search methods, but also can find better architectures and balance the model complexity. Finally, extensive experiments on various tasks demonstrate that NASP can obtain high-performance architectures with more than 10 times speedup over the state-of-the-arts."
  },
  "aaai2020_main_masteringcomplexcontrolinmobagameswithdeepreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Mastering Complex Control in MOBA Games with Deep Reinforcement Learning ",
    "authors": [
      "Deheng Ye",
      "Zhao Liu",
      "Mingfei Sun",
      "Bei Shi",
      "Peilin Zhao",
      "Hao Wu",
      "Hongsheng Yu",
      "Shaojie Yang",
      "Xipeng Wu",
      "Qingwei Guo",
      "Qiaobo Chen",
      "Yinyuting Yin",
      "Hao Zhang",
      "Tengfei Shi",
      "Liang Wang",
      "Qiang Fu",
      "Wei Yang",
      "Lanxiao Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6144",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6144/6000",
    "published": "2020-02",
    "summary": "We study the reinforcement learning problem of complex action control in the Multi-player Online Battle Arena (MOBA) 1v1 games. This problem involves far more complicated state and action spaces than those of traditional 1v1 games, such as Go and Atari series, which makes it very difficult to search any policies with human-level performance. In this paper, we present a deep reinforcement learning framework to tackle this problem from the perspectives of both system and algorithm. Our system is of low coupling and high scalability, which enables efficient explorations at large scale. Our algorithm includes several novel strategies, including control dependency decoupling, action mask, target attention, and dual-clip PPO, with which our proposed actor-critic network can be effectively trained in our system. Tested on the MOBA game Honor of Kings, the trained AI agents can defeat top professional human players in full 1v1 games."
  },
  "aaai2020_main_anovelmodelforimbalanceddataclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Novel Model for Imbalanced Data Classification ",
    "authors": [
      "Jian Yin",
      "Chunjing Gan",
      "Kaiqi Zhao",
      "Xuan Lin",
      "Zhe Quan",
      "Zhi-Jie Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6145",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6145/6001",
    "published": "2020-02",
    "summary": "Recently, imbalanced data classification has received much attention due to its wide applications. In the literature, existing researches have attempted to improve the classification performance by considering various factors such as the imbalanced distribution, cost-sensitive learning, data space improvement, and ensemble learning. Nevertheless, most of the existing methods focus on only part of these main aspects/factors. In this work, we propose a novel imbalanced data classification model that considers all these main aspects. To evaluate the performance of our proposed model, we have conducted experiments based on 14 public datasets. The results show that our model outperforms the state-of-the-art methods in terms of recall, G-mean, F-measure and AUC."
  },
  "aaai2020_main_sharedgenerativelatentrepresentationlearningformulti-viewclustering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Shared Generative Latent Representation Learning for Multi-View Clustering ",
    "authors": [
      "Ming Yin",
      "Weitian Huang",
      "Junbin Gao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6146",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6146/6002",
    "published": "2020-02",
    "summary": "Clustering multi-view data has been a fundamental research topic in the computer vision community. It has been shown that a better accuracy can be achieved by integrating information of all the views than just using one view individually. However, the existing methods often struggle with the issues of dealing with the large-scale datasets and the poor performance in reconstructing samples. This paper proposes a novel multi-view clustering method by learning a shared generative latent representation that obeys a mixture of Gaussian distributions. The motivation is based on the fact that the multi-view data share a common latent embedding despite the diversity among the various views. Specifically, benefitting from the success of the deep generative learning, the proposed model can not only extract the nonlinear features from the views, but render a powerful ability in capturing the correlations among all the views. The extensive experimental results on several datasets with different scales demonstrate that the proposed method outperforms the state-of-the-art methods under a range of performance criteria."
  },
  "aaai2020_main_divide-and-conquerlearningwithnystr\u00f6moptimalrateandalgorithm": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Divide-and-Conquer Learning with Nystr\u00f6m: Optimal Rate and Algorithm ",
    "authors": [
      "Rong Yin",
      "Yong Liu",
      "Lijing Lu",
      "Weiping Wang",
      "Dan Meng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6147",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6147/6003",
    "published": "2020-02",
    "summary": "Kernel Regularized Least Squares (KRLS) is a fundamental learner in machine learning. However, due to the high time and space requirements, it has no capability to large scale scenarios. Therefore, we propose DC-NY, a novel algorithm that combines divide-and-conquer method, Nystr\u00f6m, conjugate gradient, and preconditioning to scale up KRLS, has the same accuracy of exact KRLS and the minimum time and space complexity compared to the state-of-the-art approximate KRLS estimates. We present a theoretical analysis of DC-NY, including a novel error decomposition with the optimal statistical accuracy guarantees. Extensive experimental results on several real-world large-scale datasets containing up to 1M data points show that DC-NY significantly outperforms the state-of-the-art approximate KRLS estimates."
  },
  "aaai2020_main_fragmentationcoagulationbasedmixedmembershipstochasticblockmodel": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fragmentation Coagulation Based Mixed Membership Stochastic Blockmodel ",
    "authors": [
      "Zheng Yu",
      "Xuhui Fan",
      "Marcin Pietrasik",
      "Marek Z. Reformat"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6148",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6148/6004",
    "published": "2020-02",
    "summary": "The Mixed-Membership Stochastic Blockmodel (MMSB) is proposed as one of the state-of-the-art Bayesian relational methods suitable for learning the complex hidden structure underlying the network data. However, the current formulation of MMSB suffers from the following two issues: (1), the prior information (e.g. entities' community structural information) can not be well embedded in the modelling; (2), community evolution can not be well described in the literature. Therefore, we propose a non-parametric fragmentation coagulation based Mixed Membership Stochastic Blockmodel (fcMMSB). Our model performs entity-based clustering to capture the community information for entities and linkage-based clustering to derive the group information for links simultaneously. Besides, the proposed model infers the network structure and models community evolution, manifested by appearances and disappearances of communities, using the discrete fragmentation coagulation process (DFCP). By integrating the community structure with the group compatibility matrix we derive a generalized version of MMSB. An efficient Gibbs sampling scheme with Polya Gamma (PG) approach is implemented for posterior inference. We validate our model on synthetic and real world data."
  },
  "aaai2020_main_trading-offstaticanddynamicregretinonlineleast-squaresandbeyond": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Trading-Off Static and Dynamic Regret in Online Least-Squares and Beyond ",
    "authors": [
      "Jianjun Yuan",
      "Andrew Lamperski"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6149",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6149/6005",
    "published": "2020-02",
    "summary": "Recursive least-squares algorithms often use forgetting factors as a heuristic to adapt to non-stationary data streams. The first contribution of this paper rigorously characterizes the effect of forgetting factors for a class of online Newton algorithms. For exp-concave and strongly convex objectives, the algorithms achieve the dynamic regret of max{O(log T),O(\u221aTV)}, where V is a bound on the path length of the comparison sequence. In particular, we show how classic recursive least-squares with a forgetting factor achieves this dynamic regret bound. By varying V, we obtain a trade-off between static and dynamic regret. In order to obtain more computationally efficient algorithms, our second contribution is a novel gradient descent step size rule for strongly convex functions. Our gradient descent rule recovers the order optimal dynamic regret bounds described above. For smooth problems, we can also obtain static regret of O(T\u03b21-) and dynamic regret of O(T\u03b2 V*), where \u03b2 \u2208 (0,1) and V* is the path length of the sequence of minimizers. By varying \u03b2, we obtain a trade-off between static and dynamic regret."
  },
  "aaai2020_main_apprenticeshiplearningviafrank-wolfe": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Apprenticeship Learning via Frank-Wolfe ",
    "authors": [
      "Tom Zahavy",
      "Alon Cohen",
      "Haim Kaplan",
      "Yishay Mansour"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6150",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6150/6006",
    "published": "2020-02",
    "summary": "We consider the applications of the Frank-Wolfe (FW) algorithm for Apprenticeship Learning (AL). In this setting, we are given a Markov Decision Process (MDP) without an explicit reward function. Instead, we observe an expert that acts according to some policy, and the goal is to find a policy whose feature expectations are closest to those of the expert policy. We formulate this problem as finding the projection of the feature expectations of the expert on the feature expectations polytope \u2013 the convex hull of the feature expectations of all the deterministic policies in the MDP. We show that this formulation is equivalent to the AL objective and that solving this problem using the FW algorithm is equivalent well-known Projection method of Abbeel and Ng (2004). This insight allows us to analyze AL with tools from convex optimization literature and derive tighter convergence bounds on AL. Specifically, we show that a variation of the FW method that is based on taking \u201caway steps\u201d achieves a linear rate of convergence when applied to AL and that a stochastic version of the FW algorithm can be used to avoid precise estimation of feature expectations. We also experimentally show that this version outperforms the FW baseline. To the best of our knowledge, this is the first work that shows linear convergence rates for AL."
  },
  "aaai2020_main_fastnonparametricestimationofclassproportionsinthepositive-unlabeledclassificationsetting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fast Nonparametric Estimation of Class Proportions in the Positive-Unlabeled Classification Setting ",
    "authors": [
      "Daniel Zeiberg",
      "Shantanu Jain",
      "Predrag Radivojac"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6151",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6151/6007",
    "published": "2020-02",
    "summary": "Estimating class proportions has emerged as an important direction in positive-unlabeled learning. Well-estimated class priors are key to accurate approximation of posterior distributions and are necessary for the recovery of true classification performance. While significant progress has been made in the past decade, there remains a need for accurate strategies that scale to big data. Motivated by this need, we propose an intuitive and fast nonparametric algorithm to estimate class proportions. Unlike any of the previous methods, our algorithm uses a sampling strategy to repeatedly (1) draw an example from the set of positives, (2) record the minimum distance to any of the unlabeled examples, and (3) remove the nearest unlabeled example. We show that the point of sharp increase in the recorded distances corresponds to the desired proportion of positives in the unlabeled set and train a deep neural network to identify that point. Our distance-based algorithm is evaluated on forty datasets and compared to all currently available methods. We provide evidence that this new approach results in the most accurate performance and can be readily used on large datasets."
  },
  "aaai2020_main_topicmodelingondocumentnetworkswithadjacent-encoder": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Topic Modeling on Document Networks with Adjacent-Encoder ",
    "authors": [
      "Ce Zhang",
      "Hady W. Lauw"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6152",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6152/6008",
    "published": "2020-02",
    "summary": "Oftentimes documents are linked to one another in a network structure,e.g., academic papers cite other papers, Web pages link to other pages. In this paper we propose a holistic topic model to learn meaningful and unified low-dimensional representations for networked documents that seek to preserve both textual content and network structure. On the basis of reconstructing not only the input document but also its adjacent neighbors, we develop two neural encoder architectures. Adjacent-Encoder, or AdjEnc, induces competition among documents for topic propagation, and reconstruction among neighbors for semantic capture. Adjacent-Encoder-X, or AdjEnc-X, extends this to also encode the network structure in addition to document content. We evaluate our models on real-world document networks quantitatively and qualitatively, outperforming comparable baselines comprehensively."
  },
  "aaai2020_main_aggregatedgradientlangevindynamics": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Aggregated Gradient Langevin Dynamics ",
    "authors": [
      "Chao Zhang",
      "Jiahao Xie",
      "Zebang Shen",
      "Peilin Zhao",
      "Tengfei Zhou",
      "Hui Qian"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6153",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6153/6009",
    "published": "2020-02",
    "summary": "In this paper, we explore a general Aggregated Gradient Langevin Dynamics framework (AGLD) for the Markov Chain Monte Carlo (MCMC) sampling. We investigate the nonasymptotic convergence of AGLD with a unified analysis for different data accessing (e.g. random access, cyclic access and random reshuffle) and snapshot updating strategies, under convex and nonconvex settings respectively. It is the first time that bounds for I/O friendly strategies such as cyclic access and random reshuffle have been established in the MCMC literature. The theoretic results also indicate that methods in AGLD possess the merits of both the low per-iteration computational complexity and the short mixture time. Empirical studies demonstrate that our framework allows to derive novel schemes to generate high-quality samples for large-scale Bayesian posterior learning tasks."
  },
  "aaai2020_main_cd-uapclassdiscriminativeuniversaladversarialperturbation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " CD-UAP: Class Discriminative Universal Adversarial Perturbation ",
    "authors": [
      "Chaoning Zhang",
      "Philipp Benz",
      "Tooba Imtiaz",
      "In-So Kweon"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6154",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6154/6010",
    "published": "2020-02",
    "summary": "A single universal adversarial perturbation (UAP) can be added to all natural images to change most of their predicted class labels. It is of high practical relevance for an attacker to have flexible control over the targeted classes to be attacked, however, the existing UAP method attacks samples from all classes. In this work, we propose a new universal attack method to generate a single perturbation that fools a target network to misclassify only a chosen group of classes, while having limited influence on the remaining classes. Since the proposed attack generates a universal adversarial perturbation that is discriminative to targeted and non-targeted classes, we term it class discriminative universal adversarial perturbation (CD-UAP). We propose one simple yet effective algorithm framework, under which we design and compare various loss function configurations tailored for the class discriminative universal attack. The proposed approach has been evaluated with extensive experiments on various benchmark datasets. Additionally, our proposed approach achieves state-of-the-art performance for the original task of UAP attacking all classes, which demonstrates the effectiveness of our approach."
  },
  "aaai2020_main_learningfrompositiveandunlabeleddatawithoutexplicitestimationofclassprior": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning from Positive and Unlabeled Data without Explicit Estimation of Class Prior ",
    "authors": [
      "Chenguang Zhang",
      "Yuexian Hou",
      "Yan Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6155",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6155/6011",
    "published": "2020-02",
    "summary": "Learning a classifier from positive and unlabeled data may occur in various applications. It differs from the standard classification problems by the absence of labeled negative examples in the training set. So far, two main strategies have typically been used for this issue: the likely negative examplesbased strategy and the class prior-based strategy, in which the likely negative examples or the class prior is required to be obtained in a preprocessing step. In this paper, a new strategy based on the Bhattacharyya coefficient is put forward, which formalizes this learning problem as an optimization problem and does not need a preprocessing step. We first show that with the given positive class conditional probability density function (PDF) and the mixture PDF of both the positive class and the negative class, the class prior can be estimated by minimizing the Bhattacharyya coefficient of the positive class with respect to the negative class. We then show how to use this result in an implicit mixture model of restricted Boltzmann machines to estimate the positive class conditional PDF and the negative class conditional PDF directly to obtain a classifier without the explicit estimation of the class prior. Many experiments on real and synthetic datasets illustrated the superiority of the proposed approach."
  },
  "aaai2020_main_policysearchbytargetdistributionlearningforcontinuouscontrol": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Policy Search by Target Distribution Learning for Continuous Control ",
    "authors": [
      "Chuheng Zhang",
      "Yuanqi Li",
      "Jian Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6156",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6156/6012",
    "published": "2020-02",
    "summary": "It is known that existing policy gradient methods (such as vanilla policy gradient, PPO, A2C) may suffer from overly large gradients when the current policy is close to deterministic, leading to an unstable training process. We show that such instability can happen even in a very simple environment. To address this issue, we propose a new method, called target distribution learning (TDL), for policy improvement in reinforcement learning. TDL alternates between proposing a target distribution and training the policy network to approach the target distribution. TDL is more effective in constraining the KL divergence between updated policies, and hence leads to more stable policy improvements over iterations. Our experiments show that TDL algorithms perform comparably to (or better than) state-of-the-art algorithms for most continuous control tasks in the MuJoCo environment while being more stable in training."
  },
  "aaai2020_main_universalvalueiterationnetworkswhenspatially-invariantisnotuniversal": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Universal Value Iteration Networks: When Spatially-Invariant Is Not Universal ",
    "authors": [
      "Li Zhang",
      "Xin Li",
      "Sen Chen",
      "Hongyu Zang",
      "Jie Huang",
      "Mingzhong Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6157",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6157/6013",
    "published": "2020-02",
    "summary": "In this paper, we first formally define the problem set of spatially invariant Markov Decision Processes (MDPs), and show that Value Iteration Networks (VIN) and its extensions are computationally bounded to it due to the use of the convolution kernel. To generalize VIN to spatially variant MDPs, we propose Universal Value Iteration Networks (UVIN). In comparison with VIN, UVIN automatically learns a flexible but compact network structure to encode the transition dynamics of the problems and support the differentiable planning module. We evaluate UVIN with both spatially invariant and spatially variant tasks, including navigation in regular maze, chessboard maze, and Mars, and Minecraft item syntheses. Results show that UVIN can achieve similar performance as VIN and its extensions on spatially invariant tasks, and significantly outperforms other models on more general problems."
  },
  "aaai2020_main_systematicallyexploringassociationsamongmultivariatedata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Systematically Exploring Associations among Multivariate Data ",
    "authors": [
      "Lifeng Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6158",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6158/6014",
    "published": "2020-02",
    "summary": "Detecting relationships among multivariate data is often of great importance in the analysis of high-dimensional data sets, and has received growing attention for decades from both academic and industrial fields. In this study, we propose a statistical tool named the neighbor correlation coefficient (nCor), which is based on a new idea that measures the local continuity of the reordered data points to quantify the strength of the global association between variables. With sufficient sample size, the new method is able to capture a wide range of functional relationship, whether it is linear or nonlinear, bivariate or multivariate, main effect or interaction. The score of nCor roughly approximates the coefficient of determination (R2) of the data which implies the proportion of variance in one variable that is predictable from one or more other variables. On this basis, three nCor based statistics are also proposed here to further characterize the intra and inter structures of the associations from the aspects of nonlinearity, interaction effect, and variable redundancy. The mechanisms of these measures are proved in theory and demonstrated with numerical analyses."
  },
  "aaai2020_main_highperformancedepthwiseandpointwiseconvolutionsonmobiledevices": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " High Performance Depthwise and Pointwise Convolutions on Mobile Devices ",
    "authors": [
      "Pengfei Zhang",
      "Eric Lo",
      "Baotong Lu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6159",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6159/6015",
    "published": "2020-02",
    "summary": "Lightweight convolutional neural networks (e.g., MobileNets) are specifically designed to carry out inference directly on mobile devices. Among the various lightweight models, depthwise convolution (DWConv) and pointwise convolution (PWConv) are their key operations. In this paper, we observe that the existing implementations of DWConv and PWConv are not well utilizing the ARM processors in the mobile devices, and exhibit lots of cache misses under multi-core and poor data reuse at register level. We propose techniques to re-optimize the implementations of DWConv and PWConv based on ARM architecture. Experimental results show that our implementation can respectively achieve a speedup of up to 5.5\u00d7 and 2.1\u00d7 against TVM (Chen et al. 2018) on DWConv and PWConv."
  },
  "aaai2020_main_variationalinferenceforsparsegaussianprocessmodulatedhawkesprocess": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Variational Inference for Sparse Gaussian Process Modulated Hawkes Process ",
    "authors": [
      "Rui Zhang",
      "Christian Walder",
      "Marian-Andrei Rizoiu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6160",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6160/6016",
    "published": "2020-02",
    "summary": "The Hawkes process (HP) has been widely applied to modeling self-exciting events including neuron spikes, earthquakes and tweets. To avoid designing parametric triggering kernel and to be able to quantify the prediction confidence, the non-parametric Bayesian HP has been proposed. However, the inference of such models suffers from unscalability or slow convergence. In this paper, we aim to solve both problems. Specifically, first, we propose a new non-parametric Bayesian HP in which the triggering kernel is modeled as a squared sparse Gaussian process. Then, we propose a novel variational inference schema for model optimization. We employ the branching structure of the HP so that maximization of evidence lower bound (ELBO) is tractable by the expectation-maximization algorithm. We propose a tighter ELBO which improves the fitting performance. Further, we accelerate the novel variational inference schema to linear time complexity by leveraging the stationarity of the triggering kernel. Different from prior acceleration methods, ours enjoys higher efficiency. Finally, we exploit synthetic data and two large social media datasets to evaluate our method. We show that our approach outperforms state-of-the-art non-parametric frequentist and Bayesian methods. We validate the efficiency of our accelerated variational inference schema and practical utility of our tighter ELBO for model selection. We observe that the tighter ELBO exceeds the common one in model selection."
  },
  "aaai2020_main_atari-headatarihumaneye-trackinganddemonstrationdataset": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Atari-HEAD: Atari Human Eye-Tracking and Demonstration Dataset ",
    "authors": [
      "Ruohan Zhang",
      "Calen Walshe",
      "Zhuode Liu",
      "Lin Guan",
      "Karl Muller",
      "Jake Whritner",
      "Luxin Zhang",
      "Mary Hayhoe",
      "Dana Ballard"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6161",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6161/6017",
    "published": "2020-02",
    "summary": "Large-scale public datasets have been shown to benefit research in multiple areas of modern artificial intelligence. For decision-making research that requires human data, high-quality datasets serve as important benchmarks to facilitate the development of new methods by providing a common reproducible standard. Many human decision-making tasks require visual attention to obtain high levels of performance. Therefore, measuring eye movements can provide a rich source of information about the strategies that humans use to solve decision-making tasks. Here, we provide a large-scale, high-quality dataset of human actions with simultaneously recorded eye movements while humans play Atari video games. The dataset consists of 117 hours of gameplay data from a diverse set of 20 games, with 8 million action demonstrations and 328 million gaze samples. We introduce a novel form of gameplay, in which the human plays in a semi-frame-by-frame manner. This leads to near-optimal game decisions and game scores that are comparable or better than known human records. We demonstrate the usefulness of the dataset through two simple applications: predicting human gaze and imitating human demonstrated actions. The quality of the data leads to promising results in both tasks. Moreover, using a learned human gaze model to inform imitation learning leads to an 115% increase in game performance. We interpret these results as highlighting the importance of incorporating human visual attention in models of decision making and demonstrating the value of the current dataset to the research community. We hope that the scale and quality of this dataset can provide more opportunities to researchers in the areas of visual attention, imitation learning, and reinforcement learning."
  },
  "aaai2020_main_optimalmargindistributionlearningindynamicenvironments": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Optimal Margin Distribution Learning in Dynamic Environments ",
    "authors": [
      "Teng Zhang",
      "Peng Zhao",
      "Hai Jin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6162",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6162/6018",
    "published": "2020-02",
    "summary": "Recently a promising research direction of statistical learning has been advocated, i.e., the optimal margin distribution learning with the central idea that instead of the minimal margin, the margin distribution is more crucial to the generalization performance. Although the superiority of this new learning paradigm has been verified under batch learning settings, it remains open for online learning settings, in particular, the dynamic environments in which the underlying decision function varies over time. In this paper, we propose the dynamic optimal margin distribution machine and theoretically analyze its regret. Although the obtained bound has the same order with the best known one, our method can significantly relax the restrictive assumption that the function variation should be given ahead of time, resulting in better applicability in practical scenarios. We also derive an excess risk bound for the special case when the underlying decision function only evolves several discrete changes rather than varying continuously. Extensive experiments on both synthetic and real data sets demonstrate the superiority of our method."
  },
  "aaai2020_main_autoshrinkatopology-awarenasfordiscoveringefficientneuralarchitecture": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AutoShrink: A Topology-Aware NAS for Discovering Efficient Neural Architecture ",
    "authors": [
      "Tunhou Zhang",
      "Hsin-Pai Cheng",
      "Zhenwen Li",
      "Feng Yan",
      "Chengyu Huang",
      "Hai Li",
      "Yiran Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6163",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6163/6019",
    "published": "2020-02",
    "summary": "Resource is an important constraint when deploying Deep Neural Networks (DNNs) on mobile and edge devices. Existing works commonly adopt the cell-based search approach, which limits the flexibility of network patterns in learned cell structures. Moreover, due to the topology-agnostic nature of existing works, including both cell-based and node-based approaches, the search process is time consuming and the performance of found architecture may be sub-optimal. To address these problems, we propose AutoShrink, a topology-aware Neural Architecture Search (NAS) for searching efficient building blocks of neural architectures. Our method is node-based and thus can learn flexible network patterns in cell structures within a topological search space. Directed Acyclic Graphs (DAGs) are used to abstract DNN architectures and progressively optimize the cell structure through edge shrinking. As the search space intrinsically reduces as the edges are progressively shrunk, AutoShrink explores more flexible search space with even less search time. We evaluate AutoShrink on image classification and language tasks by crafting ShrinkCNN and ShrinkRNN models. ShrinkCNN is able to achieve up to 48% parameter reduction and save 34% Multiply-Accumulates (MACs) on ImageNet-1K with comparable accuracy of state-of-the-art (SOTA) models. Specifically, both ShrinkCNN and ShrinkRNN are crafted within 1.5 GPU hours, which is 7.2\u00d7 and 6.7\u00d7 faster than the crafting time of SOTA CNN and RNN models, respectively."
  },
  "aaai2020_main_adaptivedouble-explorationtradeoffforoutlierdetection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adaptive Double-Exploration Tradeoff for Outlier Detection ",
    "authors": [
      "Xiaojin Zhang",
      "Honglei Zhuang",
      "Shengyu Zhang",
      "Yuan Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6164",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6164/6020",
    "published": "2020-02",
    "summary": "We study a variant of the thresholding bandit problem (TBP) in the context of outlier detection, where the objective is to identify the outliers whose rewards are above a threshold. Distinct from the traditional TBP, the threshold is defined as a function of the rewards of all the arms, which is motivated by the criterion for identifying outliers. The learner needs to explore the rewards of the arms as well as the threshold. We refer to this problem as \"double exploration for outlier detection\". We construct an adaptively updated confidence interval for the threshold, based on the estimated value of the threshold in the previous rounds. Furthermore, by automatically trading off exploring the individual arms and exploring the outlier threshold, we provide an efficient algorithm in terms of the sample complexity. Experimental results on both synthetic datasets and real-world datasets demonstrate the efficiency of our algorithm."
  },
  "aaai2020_main_tapnetmultivariatetimeseriesclassificationwithattentionalprototypicalnetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " TapNet: Multivariate Time Series Classification with Attentional Prototypical Network ",
    "authors": [
      "Xuchao Zhang",
      "Yifeng Gao",
      "Jessica Lin",
      "Chang-Tien Lu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6165",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6165/6021",
    "published": "2020-02",
    "summary": "With the advance of sensor technologies, the Multivariate Time Series classification (MTSC) problem, perhaps one of the most essential problems in the time series data mining domain, has continuously received a significant amount of attention in recent decades. Traditional time series classification approaches based on Bag-of-Patterns or Time Series Shapelet have difficulty dealing with the huge amounts of feature candidates generated in high-dimensional multivariate data but have promising performance even when the training set is small. In contrast, deep learning based methods can learn low-dimensional features efficiently but suffer from a shortage of labelled data. In this paper, we propose a novel MTSC model with an attentional prototype network to take the strengths of both traditional and deep learning based approaches. Specifically, we design a random group permutation method combined with multi-layer convolutional networks to learn the low-dimensional features from multivariate time series data. To handle the issue of limited training labels, we propose a novel attentional prototype network to train the feature representation based on their distance to class prototypes with inadequate data labels. In addition, we extend our model into its semi-supervised setting by utilizing the unlabeled data. Extensive experiments on 18 datasets in a public UEA Multivariate time series archive with eight state-of-the-art baseline methods exhibit the effectiveness of the proposed model."
  },
  "aaai2020_main_self-pacedrobustlearningforleveragingcleanlabelsinnoisydata": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Self-Paced Robust Learning for Leveraging Clean Labels in Noisy Data ",
    "authors": [
      "Xuchao Zhang",
      "Xian Wu",
      "Fanglan Chen",
      "Liang Zhao",
      "Chang-Tien Lu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6166",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6166/6022",
    "published": "2020-02",
    "summary": "The success of training accurate models strongly depends on the availability of a sufficient collection of precisely labeled data. However, real-world datasets contain erroneously labeled data samples that substantially hinder the performance of machine learning models. Meanwhile, well-labeled data is usually expensive to obtain and only a limited amount is available for training. In this paper, we consider the problem of training a robust model by using large-scale noisy data in conjunction with a small set of clean data. To leverage the information contained via the clean labels, we propose a novel self-paced robust learning algorithm (SPRL) that trains the model in a process from more reliable (clean) data instances to less reliable (noisy) ones under the supervision of well-labeled data. The self-paced learning process hedges the risk of selecting corrupted data into the training set. Moreover, theoretical analyses on the convergence of the proposed algorithm are provided under mild assumptions. Extensive experiments on synthetic and real-world datasets demonstrate that our proposed approach can achieve a considerable improvement in effectiveness and robustness to existing methods."
  },
  "aaai2020_main_localregularizerimprovesgeneralization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Local Regularizer Improves Generalization ",
    "authors": [
      "Yikai Zhang",
      "Hui Qu",
      "Dimitris Metaxas",
      "Chao Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6167",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6167/6023",
    "published": "2020-02",
    "summary": "Regularization plays an important role in generalization of deep learning. In this paper, we study the generalization power of an unbiased regularizor for training algorithms in deep learning. We focus on training methods called Locally Regularized Stochastic Gradient Descent (LRSGD). An LRSGD leverages a proximal type penalty in gradient descent steps to regularize SGD in training. We show that by carefully choosing relevant parameters, LRSGD generalizes better than SGD. Our thorough theoretical analysis is supported by experimental evidence. It advances our theoretical understanding of deep learning and provides new perspectives on designing training algorithms. The code is available at https://github.com/huiqu18/LRSGD."
  },
  "aaai2020_main_anordinaldataclusteringalgorithmwithautomateddistancelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Ordinal Data Clustering Algorithm with Automated Distance Learning ",
    "authors": [
      "Yiqun Zhang",
      "Yiu-ming Cheung"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6168",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6168/6024",
    "published": "2020-02",
    "summary": "Clustering ordinal data is a common task in data mining and machine learning fields. As a major type of categorical data, ordinal data is composed of attributes with naturally ordered possible values (also called categories interchangeably in this paper). However, due to the lack of dedicated distance metric, ordinal categories are usually treated as nominal ones, or coded as consecutive integers and treated as numerical ones. Both these two common ways will roughly define the distances between ordinal categories because the former way ignores the order relationship and the latter way simply assigns identical distances to different pairs of adjacent categories that may have intrinsically unequal distances. As a result, they may produce unsatisfactory ordinal data clustering results. This paper, therefore, proposes a novel ordinal data clustering algorithm, which iteratively learns: 1) The partition of ordinal dataset, and 2) the inter-category distances. To the best of our knowledge, this is the first attempt to dynamically adjust inter-category distances during the clustering process to search for a better partition of ordinal data. The proposed algorithm features superior clustering accuracy, low time complexity, fast convergence, and is parameter-free. Extensive experiments show its efficacy."
  },
  "aaai2020_main_jointadversariallearningfordomainadaptationinsemanticsegmentation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Joint Adversarial Learning for Domain Adaptation in Semantic Segmentation ",
    "authors": [
      "Yixin Zhang",
      "Zilei Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6169",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6169/6025",
    "published": "2020-02",
    "summary": "Unsupervised domain adaptation in semantic segmentation is to exploit the pixel-level annotated samples in the source domain to aid the segmentation of unlabeled samples in the target domain. For such a task, the key point is to learn domain-invariant representations and adversarial learning is usually used, in which the discriminator is to distinguish which domain the input comes from, and the segmentation model targets to deceive the domain discriminator. In this work, we first propose a novel joint adversarial learning (JAL) to boost the domain discriminator in output space by introducing the information of domain discriminator from low-level features. Consequently, the training of the high-level decoder would be enhanced. Then we propose a weight transfer module (WTM) to alleviate the inherent bias of the trained decoder towards source domain. Specifically, WTM changes the original decoder into a new decoder, which is learned only under the supervision of adversarial loss and thus mainly focuses on reducing domain divergence. The extensive experiments on two widely used benchmarks show that our method can bring considerable performance improvement over different baseline methods, which well demonstrates the effectiveness of our method in the output space adaptation."
  },
  "aaai2020_main_hypergraphlabelpropagationnetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Hypergraph Label Propagation Network ",
    "authors": [
      "Yubo Zhang",
      "Nan Wang",
      "Yufeng Chen",
      "Changqing Zou",
      "Hai Wan",
      "Xinbin Zhao",
      "Yue Gao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6170",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6170/6026",
    "published": "2020-02",
    "summary": "In recent years, with the explosion of information on the Internet, there has been a large amount of data produced, and analyzing these data is useful and has been widely employed in real world applications. Since data labeling is costly, lots of research has focused on how to efficiently label data through semi-supervised learning. Among the methods, graph and hypergraph based label propagation algorithms have been a widely used method. However, traditional hypergraph learning methods may suffer from their high computational cost. In this paper, we propose a Hypergraph Label Propagation Network (HLPN) which combines hypergraph-based label propagation and deep neural networks in order to optimize the feature embedding for optimal hypergraph learning through an end-to-end architecture. The proposed method is more effective and also efficient for data labeling compared with traditional hypergraph learning methods. We verify the effectiveness of our proposed HLPN method on a real-world microblog dataset gathered from Sina Weibo. Experiments demonstrate that the proposed method can significantly outperform the state-of-the-art methods and alternative approaches."
  },
  "aaai2020_main_onlinesecondpriceauctionwithsemi-banditfeedbackunderthenon-stationarysetting": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Online Second Price Auction with Semi-Bandit Feedback under the Non-Stationary Setting ",
    "authors": [
      "Zhao Haoyu",
      "Chen Wei"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6171",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6171/6027",
    "published": "2020-02",
    "summary": "In this paper, we study the non-stationary online second price auction problem. We assume that the seller is selling the same type of items in T rounds by the second price auction, and she can set the reserve price in each round. In each round, the bidders draw their private values from a joint distribution unknown to the seller. Then, the seller announced the reserve price in this round. Next, bidders with private values higher than the announced reserve price in that round will report their values to the seller as their bids. The bidder with the highest bid larger than the reserved price would win the item and she will pay to the seller the price equal to the second-highest bid or the reserve price, whichever is larger. The seller wants to maximize her total revenue during the time horizon T while learning the distribution of private values over time. The problem is more challenging than the standard online learning scenario since the private value distribution is non-stationary, meaning that the distribution of bidders' private values may change over time, and we need to use the non-stationary regret to measure the performance of our algorithm. To our knowledge, this paper is the first to study the repeated auction in the non-stationary setting theoretically. Our algorithm achieves the non-stationary regret upper bound \u00d5(min{\u221aS T, V\u00af\u2153T\u2154), where S is the number of switches in the distribution, and V\u00af is the sum of total variation, and S and V\u00af are not needed to be known by the algorithm. We also prove regret lower bounds \u03a9(\u221aS T) in the switching case and \u03a9(V\u00af\u2153T\u2154) in the dynamic case, showing that our algorithm has nearly optimal non-stationary regret."
  },
  "aaai2020_main_bridgingmaximumlikelihoodandadversariallearningvia\u03b1-divergence": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bridging Maximum Likelihood and Adversarial Learning via \u03b1-Divergence ",
    "authors": [
      "Miaoyun Zhao",
      "Yulai Cong",
      "Shuyang Dai",
      "Lawrence Carin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6172",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6172/6028",
    "published": "2020-02",
    "summary": "Maximum likelihood (ML) and adversarial learning are two popular approaches for training generative models, and from many perspectives these techniques are complementary. ML learning encourages the capture of all data modes, and it is typically characterized by stable training. However, ML learning tends to distribute probability mass diffusely over the data space, e.g., yielding blurry synthetic images. Adversarial learning is well known to synthesize highly realistic natural images, despite practical challenges like mode dropping and delicate training. We propose an \u03b1-Bridge to unify the advantages of ML and adversarial learning, enabling the smooth transfer from one to the other via the \u03b1-divergence. We reveal that generalizations of the \u03b1-Bridge are closely related to approaches developed recently to regularize adversarial learning, providing insights into that prior work, and further understanding of why the \u03b1-Bridge performs well in practice."
  },
  "aaai2020_main_towardsquery-efficientblack-boxadversarywithzeroth-ordernaturalgradientdescent": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Towards Query-Efficient Black-Box Adversary with Zeroth-Order Natural Gradient Descent ",
    "authors": [
      "Pu Zhao",
      "Pin-yu Chen",
      "Siyue Wang",
      "Xue Lin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6173",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6173/6029",
    "published": "2020-02",
    "summary": "Despite the great achievements of the modern deep neural networks (DNNs), the vulnerability/robustness of state-of-the-art DNNs raises security concerns in many application domains requiring high reliability. Various adversarial attacks are proposed to sabotage the learning performance of DNN models. Among those, the black-box adversarial attack methods have received special attentions owing to their practicality and simplicity. Black-box attacks usually prefer less queries in order to maintain stealthy and low costs. However, most of the current black-box attack methods adopt the first-order gradient descent method, which may come with certain deficiencies such as relatively slow convergence and high sensitivity to hyper-parameter settings. In this paper, we propose a zeroth-order natural gradient descent (ZO-NGD) method to design the adversarial attacks, which incorporates the zeroth-order gradient estimation technique catering to the black-box attack scenario and the second-order natural gradient descent to achieve higher query efficiency. The empirical evaluations on image classification datasets demonstrate that ZO-NGD can obtain significantly lower model query complexities compared with state-of-the-art attack methods."
  },
  "aaai2020_main_hearinglipsimprovinglipreadingbydistillingspeechrecognizers": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Hearing Lips: Improving Lip Reading by Distilling Speech Recognizers ",
    "authors": [
      "Ya Zhao",
      "Rui Xu",
      "Xinchao Wang",
      "Peng Hou",
      "Haihong Tang",
      "Mingli Song"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6174",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6174/6030",
    "published": "2020-02",
    "summary": "Lip reading has witnessed unparalleled development in recent years thanks to deep learning and the availability of large-scale datasets. Despite the encouraging results achieved, the performance of lip reading, unfortunately, remains inferior to the one of its counterpart speech recognition, due to the ambiguous nature of its actuations that makes it challenging to extract discriminant features from the lip movement videos. In this paper, we propose a new method, termed as Lip by Speech (LIBS), of which the goal is to strengthen lip reading by learning from speech recognizers. The rationale behind our approach is that the features extracted from speech recognizers may provide complementary and discriminant clues, which are formidable to be obtained from the subtle movements of the lips, and consequently facilitate the training of lip readers. This is achieved, specifically, by distilling multi-granularity knowledge from speech recognizers to lip readers. To conduct this cross-modal knowledge distillation, we utilize an efficacious alignment scheme to handle the inconsistent lengths of the audios and videos, as well as an innovative filtering strategy to refine the speech recognizer's prediction. The proposed method achieves the new state-of-the-art performance on the CMLR and LRS2 datasets, outperforming the baseline by a margin of 7.66% and 2.75% in character error rate, respectively."
  },
  "aaai2020_main_anannotationsparsificationstrategyfor3dmedicalimagesegmentationviarepresentativeselectionandself-training": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Annotation Sparsification Strategy for 3D Medical Image Segmentation via Representative Selection and Self-Training ",
    "authors": [
      "Hao Zheng",
      "Yizhe Zhang",
      "Lin Yang",
      "Chaoli Wang",
      "Danny Z. Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6175",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6175/6031",
    "published": "2020-02",
    "summary": "Image segmentation is critical to lots of medical applications. While deep learning (DL) methods continue to improve performance for many medical image segmentation tasks, data annotation is a big bottleneck to DL-based segmentation because (1) DL models tend to need a large amount of labeled data to train, and (2) it is highly time-consuming and label-intensive to voxel-wise label 3D medical images. Significantly reducing annotation effort while attaining good performance of DL segmentation models remains a major challenge. In our preliminary experiments, we observe that, using partially labeled datasets, there is indeed a large performance gap with respect to using fully annotated training datasets. In this paper, we propose a new DL framework for reducing annotation effort and bridging the gap between full annotation and sparse annotation in 3D medical image segmentation. We achieve this by (i) selecting representative slices in 3D images that minimize data redundancy and save annotation effort, and (ii) self-training with pseudo-labels automatically generated from the base-models trained using the selected annotated slices. Extensive experiments using two public datasets (the HVSMR 2016 Challenge dataset and mouse piriform cortex dataset) show that our framework yields competitive segmentation results comparing with state-of-the-art DL methods using less than \u223c20% of annotated data."
  },
  "aaai2020_main_anear-optimalchange-detectionbasedalgorithmforpiecewise-stationarycombinatorialsemi-bandits": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Near-Optimal Change-Detection Based Algorithm for Piecewise-Stationary Combinatorial Semi-Bandits ",
    "authors": [
      "Huozhi Zhou",
      "Lingda Wang",
      "Lav Varshney",
      "Ee-Peng Lim"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6176",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6176/6032",
    "published": "2020-02",
    "summary": "We investigate the piecewise-stationary combinatorial semi-bandit problem. Compared to the original combinatorial semi-bandit problem, our setting assumes the reward distributions of base arms may change in a piecewise-stationary manner at unknown time steps. We propose an algorithm, GLR-CUCB, which incorporates an efficient combinatorial semi-bandit algorithm, CUCB, with an almost parameter-free change-point detector, the Generalized Likelihood Ratio Test (GLRT). Our analysis shows that the regret of GLR-CUCB is upper bounded by O(\u221aNKT log T), where N is the number of piecewise-stationary segments, K is the number of base arms, and T is the number of time steps. As a complement, we also derive a nearly matching regret lower bound on the order of \u03a9(\u221aNKT), for both piecewise-stationary multi-armed bandits and combinatorial semi-bandits, using information-theoretic techniques and judiciously constructed piecewise-stationary bandit instances. Our lower bound is tighter than the best available regret lower bound, which is \u03a9(\u221aT). Numerical experiments on both synthetic and real-world datasets demonstrate the superiority of GLR-CUCB compared to other state-of-the-art algorithms."
  },
  "aaai2020_main_deepmodel-basedreinforcementlearningviaestimateduncertaintyandconservativepolicyoptimization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Deep Model-Based Reinforcement Learning via Estimated Uncertainty and Conservative Policy Optimization ",
    "authors": [
      "Qi Zhou",
      "HouQiang Li",
      "Jie Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6177",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6177/6033",
    "published": "2020-02",
    "summary": "Model-based reinforcement learning algorithms tend to achieve higher sample efficiency than model-free methods. However, due to the inevitable errors of learned models, model-based methods struggle to achieve the same asymptotic performance as model-free methods. In this paper, We propose a Policy Optimization method with Model-Based Uncertainty (POMBU)\u2014a novel model-based approach\u2014that can effectively improve the asymptotic performance using the uncertainty in Q-values. We derive an upper bound of the uncertainty, based on which we can approximate the uncertainty accurately and efficiently for model-based methods. We further propose an uncertainty-aware policy optimization algorithm that optimizes the policy conservatively to encourage performance improvement with high probability. This can significantly alleviate the overfitting of policy to inaccurate models. Experiments show POMBU can outperform existing state-of-the-art policy optimization algorithms in terms of sample efficiency and asymptotic performance. Moreover, the experiments demonstrate the excellent robustness of POMBU compared to previous model-based approaches."
  },
  "aaai2020_main_dgedeepgenerativenetworkembeddingbasedoncommonalityandindividuality": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DGE: Deep Generative Network Embedding Based on Commonality and Individuality ",
    "authors": [
      "Sheng Zhou",
      "Xin Wang",
      "Jiajun Bu",
      "Martin Ester",
      "Pinggang Yu",
      "Jiawei Chen",
      "Qihao Shi",
      "Can Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6178",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6178/6034",
    "published": "2020-02",
    "summary": "Network embedding plays a crucial role in network analysis to provide effective representations for a variety of learning tasks. Existing attributed network embedding methods mainly focus on preserving the observed node attributes and network topology in the latent embedding space, with the assumption that nodes connected through edges will share similar attributes. However, our empirical analysis of real-world datasets shows that there exist both commonality and individuality between node attributes and network topology. On the one hand, similar nodes are expected to share similar attributes and have edges connecting them (commonality). On the other hand, each information source may maintain individual differences as well (individuality). Simultaneously capturing commonality and individuality is very challenging due to their exclusive nature and existing work fail to do so. In this paper, we propose a deep generative embedding (DGE) framework which simultaneously captures commonality and individuality between network topology and node attributes in a generative process. Stochastic gradient variational Bayesian (SGVB) optimization is employed to infer model parameters as well as the node embeddings. Extensive experiments on four real-world datasets show the superiority of our proposed DGE framework in various tasks including node classification and link prediction."
  },
  "aaai2020_main_sideinformationdependenceasaregularizerforanalyzinghumanbrainconditionsacrosscognitiveexperiments": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Side Information Dependence as a Regularizer for Analyzing Human Brain Conditions across Cognitive Experiments ",
    "authors": [
      "Shuo Zhou",
      "Wenwen Li",
      "Christopher Cox",
      "Haiping Lu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6179",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6179/6035",
    "published": "2020-02",
    "summary": "The increasing of public neuroimaging datasets opens a door to analyzing homogeneous human brain conditions across datasets by transfer learning (TL). However, neuroimaging data are high-dimensional, noisy, and with small sample sizes. It is challenging to learn a robust model for data across different cognitive experiments and subjects. A recent TL approach minimizes domain dependence to learn common cross-domain features, via the Hilbert-Schmidt Independence Criterion (HSIC). Inspired by this approach and the multi-source TL theory, we propose a Side Information Dependence Regularization (SIDeR) learning framework for TL in brain condition decoding. Specifically, SIDeR simultaneously minimizes the empirical risk and the statistical dependence on the domain side information, to reduce the theoretical generalization error bound. We construct 17 brain decoding TL tasks using public neuroimaging data for evaluation. Comprehensive experiments validate the superiority of SIDeR over ten competing methods, particularly an average improvement of 15.6% on the TL tasks with multi-source experiments."
  },
  "aaai2020_main_multi-viewspectralclusteringwithoptimalneighborhoodlaplacianmatrix": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-View Spectral Clustering with Optimal Neighborhood Laplacian Matrix ",
    "authors": [
      "Sihang Zhou",
      "Xinwang Liu",
      "Jiyuan Liu",
      "Xifeng Guo",
      "Yawei Zhao",
      "En Zhu",
      "Yongping Zhai",
      "Jianping Yin",
      "Wen Gao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6180",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6180/6036",
    "published": "2020-02",
    "summary": "Multi-view spectral clustering aims to group data into different categories by optimally exploring complementary information from multiple Laplacian matrices. However, existing methods usually linearly combine a group of pre-specified first-order Laplacian matrices to construct an optimal Laplacian matrix, which may result in limited representation capability and insufficient information exploitation. In this paper, we propose a novel optimal neighborhood multi-view spectral clustering (ONMSC) algorithm to address these issues. Specifically, the proposed algorithm generates an optimal Laplacian matrix by searching the neighborhood of both the linear combination of the first-order and high-order base Laplacian matrices simultaneously. This design enhances the representative capacity of the optimal Laplacian and better utilizes the hidden high-order connection information, leading to improved clustering performance. An efficient algorithm with proved convergence is designed to solve the resultant optimization problem. Extensive experimental results on 9 datasets demonstrate the superiority of our algorithm against state-of-the-art methods, which verifies the effectiveness and advantages of the proposed ONMSC."
  },
  "aaai2020_main_posterior-guidedneuralarchitecturesearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Posterior-Guided Neural Architecture Search ",
    "authors": [
      "Yizhou Zhou",
      "Xiaoyan Sun",
      "Chong Luo",
      "Zheng-Jun Zha",
      "Wenjun Zeng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6181",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6181/6037",
    "published": "2020-02",
    "summary": "The emergence of neural architecture search (NAS) has greatly advanced the research on network design. Recent proposals such as gradient-based methods or one-shot approaches significantly boost the efficiency of NAS. In this paper, we formulate the NAS problem from a Bayesian perspective. We propose explicitly estimating the joint posterior distribution over pairs of network architecture and weights. Accordingly, a hybrid network representation is presented which enables us to leverage the Variational Dropout so that the approximation of the posterior distribution becomes fully gradient-based and highly efficient. A posterior-guided sampling method is then presented to sample architecture candidates and directly make evaluations. As a Bayesian approach, our posterior-guided NAS (PGNAS) avoids tuning a number of hyper-parameters and enables a very effective architecture sampling in posterior probability space. Interestingly, it also leads to a deeper insight into the weight sharing used in the one-shot NAS and naturally alleviates the mismatch between the sampled architecture and weights caused by the weight sharing. We validate our PGNAS method on the fundamental image classification task. Results on Cifar-10, Cifar-100 and ImageNet show that PGNAS achieves a good trade-off between precision and speed of search among NAS methods. For example, it takes 11 GPU days to search a very competitive architecture with 1.98% and 14.28% test errors on Cifar10 and Cifar100, respectively."
  },
  "aaai2020_main_safesamplescreeningforrobustsupportvectormachine": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Safe Sample Screening for Robust Support Vector Machine ",
    "authors": [
      "Zhou Zhai",
      "Bin Gu",
      "Xiang Li",
      "Heng Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6182",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6182/6038",
    "published": "2020-02",
    "summary": "Robust support vector machine (RSVM) has been shown to perform remarkably well to improve the generalization performance of support vector machine under the noisy environment. Unfortunately, in order to handle the non-convexity induced by ramp loss in RSVM, existing RSVM solvers often adopt the DC programming framework which is computationally inefficient for running multiple outer loops. This hinders the application of RSVM to large-scale problems. Safe sample screening that allows for the exclusion of training samples prior to or early in the training process is an effective method to greatly reduce computational time. However, existing safe sample screening algorithms are limited to convex optimization problems while RSVM is a non-convex problem. To address this challenge, in this paper, we propose two safe sample screening rules for RSVM based on the framework of concave-convex procedure (CCCP). Specifically, we provide screening rule for the inner solver of CCCP and another rule for propagating screened samples between two successive solvers of CCCP. To the best of our knowledge, this is the first work of safe sample screening to a non-convex optimization problem. More importantly, we provide the security guarantee to our sample screening rules to RSVM. Experimental results on a variety of benchmark datasets verify that our safe sample screening rules can significantly reduce the computational time."
  },
  "aaai2020_main_object-orienteddynamicslearningthroughmulti-levelabstraction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Object-Oriented Dynamics Learning through Multi-Level Abstraction ",
    "authors": [
      "Guangxiang Zhu",
      "Jianhao Wang",
      "Zhizhou Ren",
      "Zichuan Lin",
      "Chongjie Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6183",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6183/6039",
    "published": "2020-02",
    "summary": "Object-based approaches for learning action-conditioned dynamics has demonstrated promise for generalization and interpretability. However, existing approaches suffer from structural limitations and optimization difficulties for common environments with multiple dynamic objects. In this paper, we present a novel self-supervised learning framework, called Multi-level Abstraction Object-oriented Predictor (MAOP), which employs a three-level learning architecture that enables efficient object-based dynamics learning from raw visual observations. We also design a spatial-temporal relational reasoning mechanism for MAOP to support instance-level dynamics learning and handle partial observability. Our results show that MAOP significantly outperforms previous methods in terms of sample efficiency and generalization over novel environments for learning environment models. We also demonstrate that learned dynamics models enable efficient planning in unseen environments, comparable to true environment models. In addition, MAOP learns semantically and visually interpretable disentangled representations."
  },
  "aaai2020_main_aknowledge-awareattentionalreasoningnetworkforrecommendation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Knowledge-Aware Attentional Reasoning Network for Recommendation ",
    "authors": [
      "Qiannan Zhu",
      "Xiaofei Zhou",
      "Jia Wu",
      "Jianlong Tan",
      "Li Guo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6184",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6184/6040",
    "published": "2020-02",
    "summary": "Knowledge-graph-aware recommendation systems have increasingly attracted attention in both industry and academic recently. Many existing knowledge-aware recommendation methods have achieved better performance, which usually perform recommendation by reasoning on the paths between users and items in knowledge graphs. However, they ignore the users' personal clicked history sequences that can better reflect users' preferences within a period of time for recommendation. In this paper, we propose a knowledge-aware attentional reasoning network KARN that incorporates the users' clicked history sequences and path connectivity between users and items for recommendation. The proposed KARN not only develops an attention-based RNN to capture the user's history interests from the user's clicked history sequences, but also a hierarchical attentional neural network to reason on paths between users and items for inferring the potential user intents on items. Based on both user's history interest and potential intent, KARN can predict the clicking probability of the user with respective to a candidate item. We conduct experiment on Amazon review dataset, and the experimental results demonstrate the superiority and effectiveness of our proposed KARN model."
  },
  "aaai2020_main_gssnngraphsmoothingsplinesneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " GSSNN: Graph Smoothing Splines Neural Networks ",
    "authors": [
      "Shichao Zhu",
      "Lewei Zhou",
      "Shirui Pan",
      "Chuan Zhou",
      "Guiying Yan",
      "Bin Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6185",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6185/6041",
    "published": "2020-02",
    "summary": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in many graph data analysis tasks. However, they still suffer from two limitations for graph representation learning. First, they exploit non-smoothing node features which may result in suboptimal embedding and degenerated performance for graph classification. Second, they only exploit neighbor information but ignore global topological knowledge. Aiming to overcome these limitations simultaneously, in this paper, we propose a novel, flexible, and end-to-end framework, Graph Smoothing Splines Neural Networks (GSSNN), for graph classification. By exploiting the smoothing splines, which are widely used to learn smoothing fitting function in regression, we develop an effective feature smoothing and enhancement module Scaled Smoothing Splines (S3) to learn graph embedding. To integrate global topological information, we design a novel scoring module, which exploits closeness, degree, as well as self-attention values, to select important node features as knots for smoothing splines. These knots can be potentially used for interpreting classification results. In extensive experiments on biological and social datasets, we demonstrate that our model achieves state-of-the-arts and GSSNN is superior in learning more robust graph representations. Furthermore, we show that S3 module is easily plugged into existing GNNs to improve their performance."
  },
  "aaai2020_main_semi-supervisedstreaminglearningwithemergingnewlabels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Semi-Supervised Streaming Learning with Emerging New Labels ",
    "authors": [
      "Yong-Nan Zhu",
      "Yu-Feng Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6186",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6186/6042",
    "published": "2020-02",
    "summary": "In many real-world applications, the modeling environment is usually dynamic and evolutionary, especially in a data stream where emerging new class often happens. Great efforts have been devoted to learning with novel concepts recently, which are typically in a supervised setting with completely supervised initialization. However, the data collected in the stream are often in a semi-supervised manner actually, which means only a few of them are labeled while the great majority miss ground-truth labels. Besides, new classes hidden in unlabeled instances bring more challenges for the learning task. In this paper, we tackle these issues by a new approach called SEEN which consists of three major components: an effective novel class detector based on clustering random trees, a robust classifier for predictions on the known classes, and an efficient updating process that ensures the whole framework adapts to the changing environment automatically. The classifier produces known labels via label propagation that utilizes all labeled and part unlabeled data in the past which naturally describe the entire stream seen so far. Empirical studies on several datasets validate that the algorithm can accurately classify points on a dynamic stream with a small number of labeled examples and emerging new classes."
  },
  "aaai2020_main_observebeforeplaymulti-armedbanditwithpre-observations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Observe Before Play: Multi-Armed Bandit with Pre-Observations ",
    "authors": [
      "Jinhang Zuo",
      "Xiaoxi Zhang",
      "Carlee Joe-Wong"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6187",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6187/6043",
    "published": "2020-02",
    "summary": "We consider the stochastic multi-armed bandit (MAB) problem in a setting where a player can pay to pre-observe arm rewards before playing an arm in each round. Apart from the usual trade-off between exploring new arms to find the best one and exploiting the arm believed to offer the highest reward, we encounter an additional dilemma: pre-observing more arms gives a higher chance to play the best one, but incurs a larger cost. For the single-player setting, we design an Observe-Before-Play Upper Confidence Bound (OBP-UCB) algorithm for K arms with Bernoulli rewards, and prove a T-round regret upper bound O(K2log T). In the multi-player setting, collisions will occur when players select the same arm to play in the same round. We design a centralized algorithm, C-MP-OBP, and prove its T-round regret relative to an offline greedy strategy is upper bounded in O(K4/M2log T) for K arms and M players. We also propose distributed versions of the C-MP-OBP policy, called D-MP-OBP and D-MP-Adapt-OBP, achieving logarithmic regret with respect to collision-free target policies. Experiments on synthetic data and wireless channel traces show that C-MP-OBP and D-MP-OBP outperform random heuristics and offline optimal policies that do not allow pre-observations."
  },
  "aaai2020_main_subsidyallocationsinthepresenceofincomeshocks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Subsidy Allocations in the Presence of Income Shocks ",
    "authors": [
      "Rediet Abebe",
      "Jon Kleinberg",
      "S. Matthew Weinberg"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6188",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6188/6044",
    "published": "2020-02",
    "summary": "Poverty and economic hardship are understood to be highly complex and dynamic phenomena. Due to the multi-faceted nature of welfare, assistance programs targeted at alleviating hardship can face challenges, as they often rely on simpler welfare measurements, such as income or wealth, that fail to capture to full complexity of each family's state. Here, we explore one important dimension \u2013 susceptibility to income shocks. We introduce a model of welfare that incorporates income, wealth, and income shocks and analyze this model to show that it can vary, at times substantially, from measures of welfare that only use income or wealth. We then study the algorithmic problem of optimally allocating subsidies in the presence of income shocks. We consider two well-studied objectives: the first aims to minimize the expected number of agents that fall below a given welfare threshold (a min-sum objective) and the second aims to minimize the likelihood that the most vulnerable agent falls below this threshold (a min-max objective). We present optimal and near-optimal algorithms for various general settings. We close with a discussion on future directions on allocating societal resources and ethical implications of related approaches."
  },
  "aaai2020_main_parameterisedresource-boundedatl": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Parameterised Resource-Bounded ATL ",
    "authors": [
      "Natasha Alechina",
      "St\u00e9phane Demri",
      "Brian Logan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6189",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6189/6045",
    "published": "2020-02",
    "summary": "It is often advantageous to be able to extract resource requirements in resource logics of strategic ability, rather than to verify whether a fixed resource requirement is sufficient for achieving a goal. We study Parameterised Resource-Bounded Alternating Time Temporal Logic where parameter extraction is possible. We give a parameter extraction algorithm and prove that the model-checking problem is 2EXPTIME-complete."
  },
  "aaai2020_main_partnerselectionfortheemergenceofcooperationinmulti-agentsystemsusingreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Partner Selection for the Emergence of Cooperation in Multi-Agent Systems Using Reinforcement Learning ",
    "authors": [
      "Nicolas Anastassacos",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6190",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6190/6046",
    "published": "2020-02",
    "summary": "Social dilemmas have been widely studied to explain how humans are able to cooperate in society. Considerable effort has been invested in designing artificial agents for social dilemmas that incorporate explicit agent motivations that are chosen to favor coordinated or cooperative responses. The prevalence of this general approach points towards the importance of achieving an understanding of both an agent's internal design and external environment dynamics that facilitate cooperative behavior. In this paper, we investigate how partner selection can promote cooperative behavior between agents who are trained to maximize a purely selfish objective function. Our experiments reveal that agents trained with this dynamic learn a strategy that retaliates against defectors while promoting cooperation with other agents resulting in a prosocial society."
  },
  "aaai2020_main_incentive-compatibleclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Incentive-Compatible Classification ",
    "authors": [
      "Yakov Babichenko",
      "Oren Dean",
      "Moshe Tennenholtz"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6191",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6191/6047",
    "published": "2020-02",
    "summary": "We investigate the possibility of an incentive-compatible (IC, a.k.a. strategy-proof) mechanism for the classification of agents in a network according to their reviews of each other. In the \u03b1-classification problem we are interested in selecting the top \u03b1 fraction of users. We give upper bounds (impossibilities) and lower bounds (mechanisms) on the worst-case coincidence between the classification of an IC mechanism and the ideal \u03b1-classification."
  },
  "aaai2020_main_learningthevalueofteamworktoformefficientteams": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning the Value of Teamwork to Form Efficient Teams ",
    "authors": [
      "Ryan Beal",
      "Narayan Changder",
      "Timothy Norman",
      "Sarvapali Ramchurn"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6192",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6192/6048",
    "published": "2020-02",
    "summary": "In this paper we describe a novel approach to team formation based on the value of inter-agent interactions. Specifically, we propose a model of teamwork that considers outcomes from chains of interactions between agents. Based on our model, we devise a number of network metrics to capture the contribution of interactions between agents. This is then used to learn the value of teamwork from historical team performance data. We apply our model to predict team performance and validate our approach using real-world team performance data from the 2018 FIFA World Cup. Our model is shown to better predict the real-world performance of teams by up to 46% compared to models that ignore inter-agent interactions."
  },
  "aaai2020_main_modelcheckingtemporalepistemiclogicunderboundedrecall": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Model Checking Temporal Epistemic Logic under Bounded Recall ",
    "authors": [
      "Francesco Belardinelli",
      "Alessio Lomuscio",
      "Emily Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6193",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6193/6049",
    "published": "2020-02",
    "summary": "We study the problem of verifying multi-agent systems under the assumption of bounded recall. We introduce the logic CTLKBR, a bounded-recall variant of the temporal-epistemic logic CTLK. We define and study the model checking problem against CTLK specifications under incomplete information and bounded recall and present complexity upper bounds. We present an extension of the BDD-based model checker MCMAS implementing model checking under bounded recall semantics and discuss the experimental results obtained."
  },
  "aaai2020_main_odssefficienthybridizationforoptimalcoalitionstructuregeneration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ODSS: Efficient Hybridization for Optimal Coalition Structure Generation ",
    "authors": [
      "Narayan Changder",
      "Samir Aknine",
      "Sarvapali Ramchurn",
      "Animesh Dutta"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6194",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6194/6050",
    "published": "2020-02",
    "summary": "Coalition Structure Generation (CSG) is an NP-complete problem that remains difficult to solve on account of its complexity. In this paper, we propose an efficient hybrid algorithm for optimal coalition structure generation called ODSS. ODSS is a hybrid version of two previously established algorithms IDP (Rahwan and Jennings 2008) and IP (Rahwan et al. 2009). ODSS minimizes the overlapping between IDP and IP by dividing the whole search space of CSG into two disjoint sets of subspaces and proposes a novel subspace shrinking technique to reduce the size of the subspace searched by IP with the help of IDP. When compared to the state-of-the-art against a wide variety of value distributions, ODSS is shown to perform better by up to 54.15% on benchmark inputs."
  },
  "aaai2020_main_hs-caiahybriddcopalgorithmviacombiningsearchwithcontext-basedinference": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " HS-CAI: A Hybrid DCOP Algorithm via Combining Search with Context-Based Inference ",
    "authors": [
      "Dingding Chen",
      "Yanchen Deng",
      "Ziyu Chen",
      "Wenxing Zhang",
      "Zhongshi He"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6195",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6195/6051",
    "published": "2020-02",
    "summary": "Search and inference are two main strategies for optimally solving Distributed Constraint Optimization Problems (DCOPs). Recently, several algorithms were proposed to combine their advantages. Unfortunately, such algorithms only use an approximated inference as a one-shot preprocessing phase to construct the initial lower bounds which lead to inefficient pruning under the limited memory budget. On the other hand, iterative inference algorithms (e.g., MB-DPOP) perform a context-based complete inference for all possible contexts but suffer from tremendous traffic overheads. In this paper, (i) hybridizing search with context-based inference, we propose a complete algorithm for DCOPs, named HS-CAI where the inference utilizes the contexts derived from the search process to establish tight lower bounds while the search uses such bounds for efficient pruning and thereby reduces contexts for the inference. Furthermore, (ii) we introduce a context evaluation mechanism to select the context patterns for the inference to further reduce the overheads incurred by iterative inferences. Finally, (iii) we prove the correctness of our algorithm and the experimental results demonstrate its superiority over the state-of-the-art."
  },
  "aaai2020_main_aateamachievingtheadhocteamworkbyemployingtheattentionmechanism": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " AATEAM: Achieving the Ad Hoc Teamwork by Employing the Attention Mechanism ",
    "authors": [
      "Shuo Chen",
      "Ewa Andrejczuk",
      "Zhiguang Cao",
      "Jie Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6196",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6196/6052",
    "published": "2020-02",
    "summary": "In the ad hoc teamwork setting, a team of agents needs to perform a task without prior coordination. The most advanced approach learns policies based on previous experiences and reuses one of the policies to interact with new teammates. However, the selected policy in many cases is sub-optimal. Switching between policies to adapt to new teammates' behaviour takes time, which threatens the successful performance of a task. In this paper, we propose AATEAM \u2013 a method that uses the attention-based neural networks to cope with new teammates' behaviour in real-time. We train one attention network per teammate type. The attention networks learn both to extract the temporal correlations from the sequence of states (i.e. contexts) and the mapping from contexts to actions. Each attention network also learns to predict a future state given the current context and its output action. The prediction accuracies help to determine which actions the ad hoc agent should take. We perform extensive experiments to show the effectiveness of our method."
  },
  "aaai2020_main_convergenceofopiniondiffusionispspace-complete": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Convergence of Opinion Diffusion is PSPACE-Complete ",
    "authors": [
      "Dmitry Chistikov",
      "Grzegorz Lisowski",
      "Mike Paterson",
      "Paolo Turrini"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6197",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6197/6053",
    "published": "2020-02",
    "summary": "We analyse opinion diffusion in social networks, where a finite set of individuals is connected in a directed graph and each simultaneously changes their opinion to that of the majority of their influencers. We study the algorithmic properties of the fixed-point behaviour of such networks, showing that the problem of establishing whether individuals converge to stable opinions is PSPACE-complete."
  },
  "aaai2020_main_aparticleswarmbasedalgorithmforfunctionaldistributedconstraintoptimizationproblems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Particle Swarm Based Algorithm for Functional Distributed Constraint Optimization Problems ",
    "authors": [
      "Moumita Choudhury",
      "Saaduddin Mahmud",
      "Md. Mosaddek Khan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6198",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6198/6054",
    "published": "2020-02",
    "summary": "Distributed Constraint Optimization Problems (DCOPs) are a widely studied constraint handling framework. The objective of a DCOP algorithm is to optimize a global objective function that can be described as the aggregation of several distributed constraint cost functions. In a DCOP, each of these functions is defined by a set of discrete variables. However, in many applications, such as target tracking or sleep scheduling in sensor networks, continuous valued variables are more suited than the discrete ones. Considering this, Functional DCOPs (F-DCOPs) have been proposed that can explicitly model a problem containing continuous variables. Nevertheless, state-of-the-art F-DCOPs approaches experience onerous memory or computation overhead. To address this issue, we propose a new F-DCOP algorithm, namely Particle Swarm based F-DCOP (PFD), which is inspired by a meta-heuristic, Particle Swarm Optimization (PSO). Although it has been successfully applied to many continuous optimization problems, the potential of PSO has not been utilized in F-DCOPs. To be exact, PFD devises a distributed method of solution construction while significantly reducing the computation and memory requirements. Moreover, we theoretically prove that PFD is an anytime algorithm. Finally, our empirical results indicate that PFD outperforms the state-of-the-art approaches in terms of solution quality and computation overhead."
  },
  "aaai2020_main_anoperationalsemanticsfortrueconcurrencyinbdiagentsystems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Operational Semantics for True Concurrency in BDI Agent Systems ",
    "authors": [
      "Lavindra de Silva"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6199",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6199/6055",
    "published": "2020-02",
    "summary": "Agent programming languages have proved useful for formally modelling implemented systems such as PRS and JACK, and for reasoning about their behaviour. Over the past decades, many agent programming languages and extensions have been developed. A key feature in some of them is their support for the specification of \u2018concurrent\u2019 actions and programs. However, their notion of concurrency is still limited, as it amounts to a nondeterministic choice between (sequential) action interleavings. Thus, the notion does not represent \u2018true concurrency\u2019, which can more naturally exploit multi-core computers and multi-robot manufacturing cells. This paper provides a true concurrency operational semantics for a BDI agent programming language, allowing actions to overlap in execution. We prove key properties of the semantics, relating to true concurrency and to its link with interleaving."
  },
  "aaai2020_main_scalabledecision-theoreticplanninginopenandtypedmultiagentsystems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Scalable Decision-Theoretic Planning in Open and Typed Multiagent Systems ",
    "authors": [
      "Adam Eck",
      "Maulik Shah",
      "Prashant Doshi",
      "Leen-Kiat Soh"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6200",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6200/6056",
    "published": "2020-02",
    "summary": "In open agent systems, the set of agents that are cooperating or competing changes over time and in ways that are nontrivial to predict. For example, if collaborative robots were tasked with fighting wildfires, they may run out of suppressants and be temporarily unavailable to assist their peers. We consider the problem of planning in these contexts with the additional challenges that the agents are unable to communicate with each other and that there are many of them. Because an agent's optimal action depends on the actions of others, each agent must not only predict the actions of its peers, but, before that, reason whether they are even present to perform an action. Addressing openness thus requires agents to model each other's presence, which becomes computationally intractable with high numbers of agents. We present a novel, principled, and scalable method in this context that enables an agent to reason about others' presence in its shared environment and their actions. Our method extrapolates models of a few peers to the overall behavior of the many-agent system, and combines it with a generalization of Monte Carlo tree search to perform individual agent reasoning in many-agent open environments. Theoretical analyses establish the number of agents to model in order to achieve acceptable worst case bounds on extrapolation error, as well as regret bounds on the agent's utility from modeling only some neighbors. Simulations of multiagent wildfire suppression problems demonstrate our approach's efficacy compared with alternative baselines."
  },
  "aaai2020_main_parameterizedcomplexityofenvy-freeresourceallocationinsocialnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Parameterized Complexity of Envy-Free Resource Allocation in Social Networks ",
    "authors": [
      "Eduard Eiben",
      "Robert Ganian",
      "Thekla Hamm",
      "Sebastian Ordyniak"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6201",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6201/6057",
    "published": "2020-02",
    "summary": "We consider the classical problem of allocating resources among agents in an envy-free (and, where applicable, proportional) way. Recently, the basic model was enriched by introducing the concept of a social network which allows to capture situations where agents might not have full information about the allocation of all resources. We initiate the study of the parameterized complexity of these resource allocation problems by considering natural parameters which capture structural properties of the network and similarities between agents and items. In particular, we show that even very general fragments of the considered problems become tractable as long as the social network has bounded treewidth or bounded clique-width. We complement our results with matching lower bounds which show that our algorithms cannot be substantially improved."
  },
  "aaai2020_main_ontheconvergenceofmodelfreelearninginmeanfieldgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On the Convergence of Model Free Learning in Mean Field Games ",
    "authors": [
      "Romuald Elie",
      "Julien P\u00e9rolat",
      "Mathieu Lauri\u00e8re",
      "Matthieu Geist",
      "Olivier Pietquin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6203",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6203/6059",
    "published": "2020-02",
    "summary": "Learning by experience in Multi-Agent Systems (MAS) is a difficult and exciting task, due to the lack of stationarity of the environment, whose dynamics evolves as the population learns. In order to design scalable algorithms for systems with a large population of interacting agents (e.g., swarms), this paper focuses on Mean Field MAS, where the number of agents is asymptotically infinite. Recently, a very active burgeoning field studies the effects of diverse reinforcement learning algorithms for agents with no prior information on a stationary Mean Field Game (MFG) and learn their policy through repeated experience. We adopt a high perspective on this problem and analyze in full generality the convergence of a fictitious iterative scheme using any single agent learning algorithm at each step. We quantify the quality of the computed approximate Nash equilibrium, in terms of the accumulated errors arising at each learning iteration step. Notably, we show for the first time convergence of model free learning algorithms towards non-stationary MFG equilibria, relying only on classical assumptions on the MFG dynamics. We illustrate our theoretical results with a numerical experiment in a continuous action-space environment, where the approximate best response of the iterative fictitious play scheme is computed with a deep RL algorithm."
  },
  "aaai2020_main_implicitcoordinationusingfondplanning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Implicit Coordination Using FOND Planning ",
    "authors": [
      "Thorsten Engesser",
      "Tim Miller"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6204",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6204/6060",
    "published": "2020-02",
    "summary": "Epistemic planning can be used to achieve implicit coordination in cooperative multi-agent settings where knowledge and capabilities are distributed between the agents. In these scenarios, agents plan and act on their own without having to agree on a common plan or protocol beforehand. However, epistemic planning is undecidable in general. In this paper, we show how implicit coordination can be achieved in a simpler, propositional setting by using nondeterminism as a means to allow the agents to take the other agents' perspectives. We identify a decidable fragment of epistemic planning that allows for arbitrary initial state uncertainty and non-determinism, but where actions can never increase the uncertainty of the agents. We show that in this fragment, planning for implicit coordination can be reduced to a version of fully observable nondeterministic (FOND) planning and that it thus has the same computational complexity as FOND planning. We provide a small case study, modeling the problem of multi-agent path finding with destination uncertainty in FOND, to show that our approach can be successfully applied in practice."
  },
  "aaai2020_main_communicationlearningviabackpropagationindiscretechannelswithunknownnoise": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Communication Learning via Backpropagation in Discrete Channels with Unknown Noise ",
    "authors": [
      "Benjamin Freed",
      "Guillaume Sartoretti",
      "Jiaheng Hu",
      "Howie Choset"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6205",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6205/6061",
    "published": "2020-02",
    "summary": "This work focuses on multi-agent reinforcement learning (RL) with inter-agent communication, in which communication is differentiable and optimized through backpropagation. Such differentiable approaches tend to converge more quickly to higher-quality policies compared to techniques that treat communication as actions in a traditional RL framework. However, modern communication networks (e.g., Wi-Fi or Bluetooth) rely on discrete communication channels, for which existing differentiable approaches that consider real-valued messages cannot be directly applied, or require biased gradient estimators. Some works have overcome this problem by treating the message space as an extension of the action space, and use standard RL to optimize message selection, but these methods tend to converge slower and to inferior policies. In this paper, we propose a stochastic message encoding/decoding procedure that makes a discrete communication channel mathematically equivalent to an analog channel with additive noise, through which gradients can be backpropagated. Additionally, we introduce an encryption step for use in noisy channels that forces channel noise to be message-independent, allowing us to compute unbiased derivative estimates even in the presence of unknown channel noise. To the best of our knowledge, this work presents the first differentiable communication learning approach that can compute unbiased derivatives through channels with unknown noise. We demonstrate the effectiveness of our approach in two example multi-robot tasks: a path finding and a collaborative search problem. There, we show that our approach achieves learning speed and performance similar to differentiable communication learning with real-valued messages (i.e., unlimited communication bandwidth), while naturally handling more realistic real-world communication constraints. Content Areas: Multi-Agent Communication, Reinforcement Learning."
  },
  "aaai2020_main_distributedstochasticgradientdescentwithevent-triggeredcommunication": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Distributed Stochastic Gradient Descent with Event-Triggered Communication ",
    "authors": [
      "Jemin George",
      "Prudhvi Gurram"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6206",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6206/6062",
    "published": "2020-02",
    "summary": "We develop a Distributed Event-Triggered Stochastic GRAdient Descent (DETSGRAD) algorithm for solving non-convex optimization problems typically encountered in distributed deep learning. We propose a novel communication triggering mechanism that would allow the networked agents to update their model parameters aperiodically and provide sufficient conditions on the algorithm step-sizes that guarantee the asymptotic mean-square convergence. The algorithm is applied to a distributed supervised-learning problem, in which a set of networked agents collaboratively train their individual neural networks to perform image classification, while aperiodically sharing the model parameters with their one-hop neighbors. Results indicate that all agents report similar performance that is also comparable to the performance of a centrally trained neural network, while the event-triggered communication provides significant reduction in inter-agent communication. Results also show that the proposed algorithm allows the individual agents to classify the images even though the training data corresponding to all the classes are not locally available to each agent."
  },
  "aaai2020_main_distributedmachinelearningthroughheterogeneousedgesystems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Distributed Machine Learning through Heterogeneous Edge Systems ",
    "authors": [
      "Hanpeng Hu",
      "Dan Wang",
      "Chuan Wu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6207",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6207/6063",
    "published": "2020-02",
    "summary": "Many emerging AI applications request distributed machine learning (ML) among edge systems (e.g., IoT devices and PCs at the edge of the Internet), where data cannot be uploaded to a central venue for model training, due to their large volumes and/or security/privacy concerns. Edge devices are intrinsically heterogeneous in computing capacity, posing significant challenges to parameter synchronization for parallel training with the parameter server (PS) architecture. This paper proposes ADSP, a parameter synchronization model for distributed machine learning (ML) with heterogeneous edge systems. Eliminating the significant waiting time occurring with existing parameter synchronization models, the core idea of ADSP is to let faster edge devices continue training, while committing their model updates at strategically decided intervals. We design algorithms that decide time points for each worker to commit its model update, and ensure not only global model convergence but also faster convergence. Our testbed implementation and experiments show that ADSP outperforms existing parameter synchronization models significantly in terms of ML model convergence time, scalability and adaptability to large heterogeneity."
  },
  "aaai2020_main_improvingpoliciesviasearchincooperativepartiallyobservablegames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Improving Policies via Search in Cooperative Partially Observable Games ",
    "authors": [
      "Adam Lerer",
      "Hengyuan Hu",
      "Jakob Foerster",
      "Noam Brown"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6208",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6208/6064",
    "published": "2020-02",
    "summary": "Recent superhuman results in games have largely been achieved in a variety of zero-sum settings, such as Go and Poker, in which agents need to compete against others. However, just like humans, real-world AI systems have to coordinate and communicate with other agents in cooperative partially observable environments as well. These settings commonly require participants to both interpret the actions of others and to act in a way that is informative when being interpreted. Those abilities are typically summarized as theory of mind and are seen as crucial for social interactions. In this paper we propose two different search techniques that can be applied to improve an arbitrary agreed-upon policy in a cooperative partially observable game. The first one, single-agent search, effectively converts the problem into a single agent setting by making all but one of the agents play according to the agreed-upon policy. In contrast, in multi-agent search all agents carry out the same common-knowledge search procedure whenever doing so is computationally feasible, and fall back to playing according to the agreed-upon policy otherwise. We prove that these search procedures are theoretically guaranteed to at least maintain the original performance of the agreed-upon policy (up to a bounded approximation error). In the benchmark challenge problem of Hanabi, our search technique greatly improves the performance of every agent we tested and when applied to a policy trained using RL achieves a new state-of-the-art score of 24.61 / 25 in the game, compared to a previous-best of 24.08 / 25."
  },
  "aaai2020_main_generativeattentionnetworksformulti-agentbehavioralmodeling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generative Attention Networks for Multi-Agent Behavioral Modeling ",
    "authors": [
      "Guangyu Li",
      "Bo Jiang",
      "Hao Zhu",
      "Zhengping Che",
      "Yan Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6209",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6209/6065",
    "published": "2020-02",
    "summary": "Understanding and modeling behavior of multi-agent systems is a central step for artificial intelligence. Here we present a deep generative model which captures behavior generating process of multi-agent systems, supports accurate predictions and inference, infers how agents interact in a complex system, as well as identifies agent groups and interaction types. Built upon advances in deep generative models and a novel attention mechanism, our model can learn interactions in highly heterogeneous systems with linear complexity in the number of agents. We apply this model to three multi-agent systems in different domains and evaluate performance on a diverse set of tasks including behavior prediction, interaction analysis and system identification. Experimental results demonstrate its ability to model multi-agent systems, yielding improved performance over competitive baselines. We also show the model can successfully identify agent groups and interaction types in these systems. Our model offers new opportunities to predict complex multi-agent behaviors and takes a step forward in understanding interactions in multi-agent systems."
  },
  "aaai2020_main_avariationalperturbativeapproachtoplanningingraph-basedmarkovdecisionprocesses": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Variational Perturbative Approach to Planning in Graph-Based Markov Decision Processes ",
    "authors": [
      "Dominik Linzner",
      "Heinz Koeppl"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6210",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6210/6066",
    "published": "2020-02",
    "summary": "Coordinating multiple interacting agents to achieve a common goal is a difficult task with huge applicability. This problem remains hard to solve, even when limiting interactions to be mediated via a static interaction-graph. We present a novel approximate solution method for multi-agent Markov decision problems on graphs, based on variational perturbation theory. We adopt the strategy of planning via inference, which has been explored in various prior works. We employ a non-trivial extension of a novel high-order variational method that allows for approximate inference in large networks and has been shown to surpass the accuracy of existing variational methods. To compare our method to two state-of-the-art methods for multi-agent planning on graphs, we apply the method different standard GMDP problems. We show that in cases, where the goal is encoded as a non-local cost function, our method performs well, while state-of-the-art methods approach the performance of random guess. In a final experiment, we demonstrate that our method brings significant improvement for synchronization tasks."
  },
  "aaai2020_main_multi-agentgameabstractionviagraphattentionneuralnetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Agent Game Abstraction via Graph Attention Neural Network ",
    "authors": [
      "Yong Liu",
      "Weixun Wang",
      "Yujing Hu",
      "Jianye Hao",
      "Xingguo Chen",
      "Yang Gao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6211",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6211/6067",
    "published": "2020-02",
    "summary": "In large-scale multi-agent systems, the large number of agents and complex game relationship cause great difficulty for policy learning. Therefore, simplifying the learning process is an important research issue. In many multi-agent systems, the interactions between agents often happen locally, which means that agents neither need to coordinate with all other agents nor need to coordinate with others all the time. Traditional methods attempt to use pre-defined rules to capture the interaction relationship between agents. However, the methods cannot be directly used in a large-scale environment due to the difficulty of transforming the complex interactions between agents into rules. In this paper, we model the relationship between agents by a complete graph and propose a novel game abstraction mechanism based on two-stage attention network (G2ANet), which can indicate whether there is an interaction between two agents and the importance of the interaction. We integrate this detection mechanism into graph neural network-based multi-agent reinforcement learning for conducting game abstraction and propose two novel learning algorithms GA-Comm and GA-AC. We conduct experiments in Traffic Junction and Predator-Prey. The results indicate that the proposed methods can simplify the learning process and meanwhile get better asymptotic performance compared with state-of-the-art algorithms."
  },
  "aaai2020_main_neighborhoodcognitionconsistentmulti-agentreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Neighborhood Cognition Consistent Multi-Agent Reinforcement Learning ",
    "authors": [
      "Hangyu Mao",
      "Wulong Liu",
      "Jianye Hao",
      "Jun Luo",
      "Dong Li",
      "Zhengchao Zhang",
      "Jun Wang",
      "Zhen Xiao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6212",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6212/6068",
    "published": "2020-02",
    "summary": "Social psychology and real experiences show that cognitive consistency plays an important role to keep human society in order: if people have a more consistent cognition about their environments, they are more likely to achieve better cooperation. Meanwhile, only cognitive consistency within a neighborhood matters because humans only interact directly with their neighbors. Inspired by these observations, we take the first step to introduce neighborhood cognitive consistency (NCC) into multi-agent reinforcement learning (MARL). Our NCC design is quite general and can be easily combined with existing MARL methods. As examples, we propose neighborhood cognition consistent deep Q-learning and Actor-Critic to facilitate large-scale multi-agent cooperations. Extensive experiments on several challenging tasks (i.e., packet routing, wifi configuration and Google football player control) justify the superior performance of our methods compared with state-of-the-art MARL approaches."
  },
  "aaai2020_main_multi-objectivemulti-agentplanningforjointlydiscoveringandtrackingmobileobjects": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Objective Multi-Agent Planning for Jointly Discovering and Tracking Mobile Objects ",
    "authors": [
      "Hoa Van Nguyen",
      "Hamid Rezatofighi",
      "Ba-Ngu Vo",
      "Damith C. Ranasinghe"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6213",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6213/6069",
    "published": "2020-02",
    "summary": "We consider the challenging problem of online planning for a team of agents to autonomously search and track a time-varying number of mobile objects under the practical constraint of detection range limited onboard sensors. A standard POMDP with a value function that either encourages discovery or accurate tracking of mobile objects is inadequate to simultaneously meet the conflicting goals of searching for undiscovered mobile objects whilst keeping track of discovered objects. The planning problem is further complicated by misdetections or false detections of objects caused by range limited sensors and noise inherent to sensor measurements. We formulate a novel multi-objective POMDP based on information theoretic criteria, and an online multi-object tracking filter for the problem. Since controlling multi-agent is a well known combinatorial optimization problem, assigning control actions to agents necessitates a greedy algorithm. We prove that our proposed multi-objective value function is a monotone submodular set function; consequently, the greedy algorithm can achieve a (1-1/e) approximation for maximizing the submodular multi-objective function."
  },
  "aaai2020_main_multi-agentactor-criticwithhierarchicalgraphattentionnetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Agent Actor-Critic with Hierarchical Graph Attention Network ",
    "authors": [
      "Heechang Ryu",
      "Hayong Shin",
      "Jinkyoo Park"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6214",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6214/6070",
    "published": "2020-02",
    "summary": "Most previous studies on multi-agent reinforcement learning focus on deriving decentralized and cooperative policies to maximize a common reward and rarely consider the transferability of trained policies to new tasks. This prevents such policies from being applied to more complex multi-agent tasks. To resolve these limitations, we propose a model that conducts both representation learning for multiple agents using hierarchical graph attention network and policy learning using multi-agent actor-critic. The hierarchical graph attention network is specially designed to model the hierarchical relationships among multiple agents that either cooperate or compete with each other to derive more advanced strategic policies. Two attention networks, the inter-agent and inter-group attention layers, are used to effectively model individual and group level interactions, respectively. The two attention networks have been proven to facilitate the transfer of learned policies to new tasks with different agent compositions and allow one to interpret the learned strategies. Empirically, we demonstrate that the proposed model outperforms existing methods in several mixed cooperative and competitive tasks."
  },
  "aaai2020_main_clouseaugeneratingcommunicationprotocolsfromcommitments": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Clouseau: Generating Communication Protocols from Commitments ",
    "authors": [
      "Munindar Singh",
      "Amit Chopra"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6215",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6215/6071",
    "published": "2020-02",
    "summary": "Engineering a decentralized multiagent system (MAS) requires realizing interactions modeled as a communication protocol between autonomous agents. We contribute Clouseau, an approach that takes a commitment-based specification of an interaction and generates a communication protocol amenable to decentralized enactment. We show that the generated protocol is (1) correct\u2014realizes all and only the computations that satisfy the input specification; (2) safe\u2014ensures the agents' local views remain consistent; and (3) live\u2014ensures the agents can proceed to completion."
  },
  "aaai2020_main_arenaageneralevaluationplatformandbuildingtoolkitformulti-agentintelligence": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Arena: A General Evaluation Platform and Building Toolkit for Multi-Agent Intelligence ",
    "authors": [
      "Yuhang Song",
      "Andrzej Wojcicki",
      "Thomas Lukasiewicz",
      "Jianyi Wang",
      "Abi Aryan",
      "Zhenghua Xu",
      "Mai Xu",
      "Zihan Ding",
      "Lianlong Wu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6216",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6216/6072",
    "published": "2020-02",
    "summary": "Learning agents that are not only capable of taking tests, but also innovating is becoming a hot topic in AI. One of the most promising paths towards this vision is multi-agent learning, where agents act as the environment for each other, and improving each agent means proposing new problems for others. However, existing evaluation platforms are either not compatible with multi-agent settings, or limited to a specific game. That is, there is not yet a general evaluation platform for research on multi-agent intelligence. To this end, we introduce Arena, a general evaluation platform for multi-agent intelligence with 35 games of diverse logics and representations. Furthermore, multi-agent intelligence is still at the stage where many problems remain unexplored. Therefore, we provide a building toolkit for researchers to easily invent and build novel multi-agent problems from the provided game set based on a GUI-configurable social tree and five basic multi-agent reward schemes. Finally, we provide Python implementations of five state-of-the-art deep multi-agent reinforcement learning baselines. Along with the baseline implementations, we release a set of 100 best agents/teams that we can train with different training schemes for each game, as the base for evaluating agents with population performance. As such, the research community can perform comparisons under a stable and uniform standard. All the implementations and accompanied tutorials have been open-sourced for the community at https://sites.google.com/view/arena-unity/."
  },
  "aaai2020_main_learningtocommunicateimplicitlybyactions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Communicate Implicitly by Actions ",
    "authors": [
      "Zheng Tian",
      "Shihao Zou",
      "Ian Davies",
      "Tim Warr",
      "Lisheng Wu",
      "Haitham Bou Ammar",
      "Jun Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6217",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6217/6073",
    "published": "2020-02",
    "summary": "In situations where explicit communication is limited, human collaborators act by learning to: (i) infer meaning behind their partner's actions, and (ii) convey private information about the state to their partner implicitly through actions. The first component of this learning process has been well-studied in multi-agent systems, whereas the second \u2014 which is equally crucial for successful collaboration \u2014 has not. To mimic both components mentioned above, thereby completing the learning process, we introduce a novel algorithm: Policy Belief Learning (PBL). PBL uses a belief module to model the other agent's private information and a policy module to form a distribution over actions informed by the belief module. Furthermore, to encourage communication by actions, we propose a novel auxiliary reward which incentivizes one agent to help its partner to make correct inferences about its private information. The auxiliary reward for communication is integrated into the learning of the policy module. We evaluate our approach on a set of environments including a matrix game, particle environment and the non-competitive bidding problem from contract bridge. We show empirically that this auxiliary reward is effective and easy to generalize. These results demonstrate that our PBL algorithm can produce strong pairs of agents in collaborative games where explicit communication is disabled."
  },
  "aaai2020_main_fairproceduresforfairstablemarriageoutcomes": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fair Procedures for Fair Stable Marriage Outcomes ",
    "authors": [
      "Nikolaos Tziavelis",
      "Ioannis Giannakopoulos",
      "Rune Quist Johansen",
      "Katerina Doka",
      "Nectarios Koziris",
      "Panagiotis Karras"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6218",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6218/6074",
    "published": "2020-02",
    "summary": "Given a two-sided market where each agent ranks those on the other side by preference, the stable marriage problem calls for finding a perfect matching such that no pair of agents prefer each other to their matches. Recent studies show that the number of stable solutions can be large in practice. Yet the classical solution to the problem, the Gale-Shapley (GS) algorithm, assigns an optimal match to each agent on one side, and a pessimal one to each on the other side; such a solution may fare well in terms of equity only in highly asymmetric markets. Finding a stable matching that minimizes the sex equality cost, an equity measure expressing the discrepancy of mean happiness among the two sides, is strongly NP-hard. Extant heuristics either (a) oblige some agents to involuntarily abandon their matches, or (b) bias the outcome in favor of some agents, or (c) need high-polynomial or unbounded time."
  },
  "aaai2020_main_generalizedandsub-optimalbipartiteconstraintsforconflict-basedsearch": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generalized and Sub-Optimal Bipartite Constraints for Conflict-Based Search ",
    "authors": [
      "Thayne T. Walker",
      "Nathan R. Sturtevant",
      "Ariel Felner"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6219",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6219/6075",
    "published": "2020-02",
    "summary": "The main idea of conflict-based search (CBS), a popular, state-of-the-art algorithm for multi-agent pathfinding is to resolve conflicts between agents by systematically adding constraints to agents. Recently, CBS has been adapted for new domains and variants, including non-unit costs and continuous time settings. These adaptations require new types of constraints. This paper introduces a new automatic constraint generation technique called bipartite reduction (BR). BR converts the constraint generation step of CBS to a surrogate bipartite graph problem. The properties of BR guarantee completeness and optimality for CBS. Also, BR's properties may be relaxed to obtain suboptimal solutions. Empirical results show that BR yields significant speedups in 2k connected grids over the previous state-of-the-art for both optimal and suboptimal search."
  },
  "aaai2020_main_shapleyq-valuealocalrewardapproachtosolveglobalrewardgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Shapley Q-Value: A Local Reward Approach to Solve Global Reward Games ",
    "authors": [
      "Jianhong Wang",
      "Yuan Zhang",
      "Tae-Kyun Kim",
      "Yunjie Gu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6220",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6220/6076",
    "published": "2020-02",
    "summary": "Cooperative game is a critical research area in the multi-agent reinforcement learning (MARL). Global reward game is a subclass of cooperative games, where all agents aim to maximize the global reward. Credit assignment is an important problem studied in the global reward game. Most of previous works stood by the view of non-cooperative-game theoretical framework with the shared reward approach, i.e., each agent being assigned a shared global reward directly. This, however, may give each agent an inaccurate reward on its contribution to the group, which could cause inefficient learning. To deal with this problem, we i) introduce a cooperative-game theoretical framework called extended convex game (ECG) that is a superset of global reward game, and ii) propose a local reward approach called Shapley Q-value. Shapley Q-value is able to distribute the global reward, reflecting each agent's own contribution in contrast to the shared reward approach. Moreover, we derive an MARL algorithm called Shapley Q-value deep deterministic policy gradient (SQDDPG), using Shapley Q-value as the critic for each agent. We evaluate SQDDPG on Cooperative Navigation, Prey-and-Predator and Traffic Junction, compared with the state-of-the-art algorithms, e.g., MADDPG, COMA, Independent DDPG and Independent A2C. In the experiments, SQDDPG shows a significant improvement on the convergence rate. Finally, we plot Shapley Q-value and validate the property of fair credit assignment."
  },
  "aaai2020_main_fromfewtomorelarge-scaledynamicmultiagentcurriculumlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " From Few to More: Large-Scale Dynamic Multiagent Curriculum Learning ",
    "authors": [
      "Weixun Wang",
      "Tianpei Yang",
      "Yong Liu",
      "Jianye Hao",
      "Xiaotian Hao",
      "Yujing Hu",
      "Yingfeng Chen",
      "Changjie Fan",
      "Yang Gao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6221",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6221/6083",
    "published": "2020-02",
    "summary": "A lot of efforts have been devoted to investigating how agents can learn effectively and achieve coordination in multiagent systems. However, it is still challenging in large-scale multiagent settings due to the complex dynamics between the environment and agents and the explosion of state-action space. In this paper, we design a novel Dynamic Multiagent Curriculum Learning (DyMA-CL) to solve large-scale problems by starting from learning on a multiagent scenario with a small size and progressively increasing the number of agents. We propose three transfer mechanisms across curricula to accelerate the learning process. Moreover, due to the fact that the state dimension varies across curricula, and existing network structures cannot be applied in such a transfer setting since their network input sizes are fixed. Therefore, we design a novel network structure called Dynamic Agent-number Network (DyAN) to handle the dynamic size of the network input. Experimental results show that DyMA-CL using DyAN greatly improves the performance of large-scale multiagent learning compared with state-of-the-art deep reinforcement learning approaches. We also investigate the influence of three transfer mechanisms across curricula through extensive simulations."
  },
  "aaai2020_main_smix(\u03bb)enhancingcentralizedvaluefunctionsforcooperativemulti-agentreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " SMIX(\u03bb): Enhancing Centralized Value Functions for Cooperative Multi-Agent Reinforcement Learning ",
    "authors": [
      "Chao Wen",
      "Xinghu Yao",
      "Yuhui Wang",
      "Xiaoyang Tan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6223",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6223/6078",
    "published": "2020-02",
    "summary": "This work presents a sample efficient and effective value-based method, named SMIX(\u03bb), for reinforcement learning in multi-agent environments (MARL) within the paradigm of centralized training with decentralized execution (CTDE), in which learning a stable and generalizable centralized value function (CVF) is crucial. To achieve this, our method carefully combines different elements, including 1) removing the unrealistic centralized greedy assumption during the learning phase, 2) using the \u03bb-return to balance the trade-off between bias and variance and to deal with the environment's non-Markovian property, and 3) adopting an experience-replay style off-policy training. Interestingly, it is revealed that there exists inherent connection between SMIX(\u03bb) and previous off-policy Q(\u03bb) approach for single-agent learning. Experiments on the StarCraft Multi-Agent Challenge (SMAC) benchmark show that the proposed SMIX(\u03bb) algorithm outperforms several state-of-the-art MARL methods by a large margin, and that it can be used as a general tool to improve the overall performance of a CTDE-type method by enhancing the evaluation quality of its CVF. We open-source our code at: https://github.com/chaovven/SMIX."
  },
  "aaai2020_main_optimalcommoncontractwithheterogeneousagents": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Optimal Common Contract with Heterogeneous Agents ",
    "authors": [
      "Shenke Xiao",
      "Zihe Wang",
      "Mengjing Chen",
      "Pingzhong Tang",
      "Xiwang Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6224",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6224/6079",
    "published": "2020-02",
    "summary": "We consider the principal-agent problem with heterogeneous agents. Previous works assume that the principal signs independent incentive contracts with every agent to make them invest more efforts on the tasks. However, in many circumstances, these contracts need to be identical for the sake of fairness. We investigate the optimal common contract problem. To our knowledge, this is the first attempt to consider this natural and important generalization. We first show this problem is NP-complete. Then we provide a dynamic programming algorithm to compute the optimal contract in O(n2m) time, where n,m are the number of agents and actions, under the assumption that the agents' cost functions obey increasing difference property. At last, we generalize the setting such that each agent can choose to directly produce a reward in [0,1]. We provide an O(log n)-approximate algorithm for this generalization."
  },
  "aaai2020_main_cobracontext-awarebernoullineuralnetworksforreputationassessment": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " COBRA: Context-Aware Bernoulli Neural Networks for Reputation Assessment",
    "authors": [
      "Leonit Zeynalvand",
      "Tie Luo",
      "Jie Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6225",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6225/6080",
    "published": "2020-02",
    "summary": "Trust and reputation management (TRM) plays an increasingly important role in large-scale online environments such as multi-agent systems (MAS) and the Internet of Things (IoT). One main objective of TRM is to achieve accurate trust assessment of entities such as agents or IoT service providers. However, this encounters an accuracy-privacy dilemma as we identify in this paper, and we propose a framework called Context-aware Bernoulli Neural Network based Reputation Assessment (COBRA) to address this challenge. COBRA encapsulates agent interactions or transactions, which are prone to privacy leak, in machine learning models, and aggregates multiple such models using a Bernoulli neural network to predict a trust score for an agent. COBRA preserves agent privacy and retains interaction contexts via the machine learning models, and achieves more accurate trust prediction than a fully-connected neural network alternative. COBRA is also robust to security attacks by agents who inject fake machine learning models; notably, it is resistant to the 51-percent attack. The performance of COBRA is validated by our experiments using a real dataset, and by our simulations, where we also show that COBRA outperforms other state-of-the-art TRM systems."
  },
  "aaai2020_main_bi-levelactor-criticformulti-agentcoordination": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bi-Level Actor-Critic for Multi-Agent Coordination ",
    "authors": [
      "Haifeng Zhang",
      "Weizhe Chen",
      "Zeren Huang",
      "Minne Li",
      "Yaodong Yang",
      "Weinan Zhang",
      "Jun Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6226",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6226/6081",
    "published": "2020-02",
    "summary": "Coordination is one of the essential problems in multi-agent systems. Typically multi-agent reinforcement learning (MARL) methods treat agents equally and the goal is to solve the Markov game to an arbitrary Nash equilibrium (NE) when multiple equilibra exist, thus lacking a solution for NE selection. In this paper, we treat agents unequally and consider Stackelberg equilibrium as a potentially better convergence point than Nash equilibrium in terms of Pareto superiority, especially in cooperative environments. Under Markov games, we formally define the bi-level reinforcement learning problem in finding Stackelberg equilibrium. We propose a novel bi-level actor-critic learning method that allows agents to have different knowledge base (thus intelligent), while their actions still can be executed simultaneously and distributedly. The convergence proof is given, while the resulting learning algorithm is tested against the state of the arts. We found that the proposed bi-level actor-critic algorithm successfully converged to the Stackelberg equilibria in matrix games and find a asymmetric solution in a highway merge environment."
  },
  "aaai2020_main_beyondtreesanalysisandconvergenceofbeliefpropagationingraphswithmultiplecycles": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Beyond Trees: Analysis and Convergence of Belief Propagation in Graphs with Multiple Cycles ",
    "authors": [
      "Roie Zivan",
      "Omer Lev",
      "Rotem Galiki"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6227",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6227/6082",
    "published": "2020-02",
    "summary": "Belief propagation, an algorithm for solving problems represented by graphical models, has long been known to converge to the optimal solution when the graph is a tree. When the graph representing the problem includes a single cycle, the algorithm either converges to the optimal solution or performs periodic oscillations. While the conditions that trigger these two behaviors have been established, the question regarding the convergence and divergence of the algorithm on graphs that include more than one cycle is still open."
  },
  "aaai2020_main_ledeepchefdeepreinforcementlearningagentforfamiliesoftext-basedgames": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " LeDeepChef Deep Reinforcement Learning Agent for Families of Text-Based Games ",
    "authors": [
      "Leonard Adolphs",
      "Thomas Hofmann"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6228",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6228/6084",
    "published": "2020-02",
    "summary": "While Reinforcement Learning (RL) approaches lead to significant achievements in a variety of areas in recent history, natural language tasks remained mostly unaffected, due to the compositional and combinatorial nature that makes them notoriously hard to optimize. With the emerging field of Text-Based Games (TBGs), researchers try to bridge this gap. Inspired by the success of RL algorithms on Atari games, the idea is to develop new methods in a restricted game world and then gradually move to more complex environments. Previous work in the area of TBGs has mainly focused on solving individual games. We, however, consider the task of designing an agent that not just succeeds in a single game, but performs well across a whole family of games, sharing the same theme. In this work, we present our deep RL agent\u2014LeDeepChef\u2014that shows generalization capabilities to never-before-seen games of the same family with different environments and task descriptions. The agent participated in Microsoft Research's First TextWorld Problems: A Language and Reinforcement Learning Challenge and outperformed all but one competitor on the final test set. The games from the challenge all share the same theme, namely cooking in a modern house environment, but differ significantly in the arrangement of the rooms, the presented objects, and the specific goal (recipe to cook). To build an agent that achieves high scores across a whole family of games, we use an actor-critic framework and prune the action-space by using ideas from hierarchical reinforcement learning and a specialized module trained on a recipe database."
  },
  "aaai2020_main_knowledgedistillationfrominternalrepresentations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Knowledge Distillation from Internal Representations ",
    "authors": [
      "Gustavo Aguilar",
      "Yuan Ling",
      "Yu Zhang",
      "Benjamin Yao",
      "Xing Fan",
      "Chenlei Guo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6229",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6229/6085",
    "published": "2020-02",
    "summary": "Knowledge distillation is typically conducted by training a small model (the student) to mimic a large and cumbersome model (the teacher). The idea is to compress the knowledge from the teacher by using its output probabilities as soft-labels to optimize the student. However, when the teacher is considerably large, there is no guarantee that the internal knowledge of the teacher will be transferred into the student; even if the student closely matches the soft-labels, its internal representations may be considerably different. This internal mismatch can undermine the generalization capabilities originally intended to be transferred from the teacher to the student. In this paper, we propose to distill the internal representations of a large model such as BERT into a simplified version of it. We formulate two ways to distill such representations and various algorithms to conduct the distillation. We experiment with datasets from the GLUE benchmark and consistently show that adding knowledge distillation from internal representations is a more powerful method than only using soft-label distillation."
  },
  "aaai2020_main_modellingsentencepairsviareinforcementlearninganactor-criticapproachtolearntheirrelevantwords": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Modelling Sentence Pairs via Reinforcement Learning: An Actor-Critic Approach to Learn the Irrelevant Words ",
    "authors": [
      "Mahtab Ahmed",
      "Robert E. Mercer"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6230",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6230/6086",
    "published": "2020-02",
    "summary": "Learning sentence representation is a fundamental task in Natural Language Processing. Most of the existing sentence pair modelling architectures focus only on extracting and using the rich sentence pair features. The drawback of utilizing all of these features makes the learning process much harder. In this study, we propose a reinforcement learning (RL) method to learn a sentence pair representation when performing tasks like semantic similarity, paraphrase identification, and question-answer pair modelling. We formulate this learning problem as a sequential decision making task where the decision made in the current state will have a strong impact on the following decisions. We address this decision making with a policy gradient RL method which chooses the irrelevant words to delete by looking at the sub-optimal representation of the sentences being compared. With this policy, extensive experiments show that our model achieves on par performance when learning task-specific representations of sentence pairs without needing any further knowledge like parse trees. We suggest that the simplicity of each task inference provided by our RL model makes it easier to explain."
  },
  "aaai2020_main_end-to-endargumentationknowledgegraphconstruction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " End-to-End Argumentation Knowledge Graph Construction ",
    "authors": [
      "Khalid Al-Khatib",
      "Yufang Hou",
      "Henning Wachsmuth",
      "Charles Jochim",
      "Francesca Bonin",
      "Benno Stein"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6231",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6231/6087",
    "published": "2020-02",
    "summary": "This paper studies the end-to-end construction of an argumentation knowledge graph that is intended to support argument synthesis, argumentative question answering, or fake news detection, among others. The study is motivated by the proven effectiveness of knowledge graphs for interpretable and controllable text generation and exploratory search. Original in our work is that we propose a model of the knowledge encapsulated in arguments. Based on this model, we build a new corpus that comprises about 16k manual annotations of 4740 claims with instances of the model's elements, and we develop an end-to-end framework that automatically identifies all modeled types of instances. The results of experiments show the potential of the framework for building a web-based argumentation graph that is of high quality and large scale."
  },
  "aaai2020_main_storyrealizationexpandingploteventsintosentences": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Story Realization: Expanding Plot Events into Sentences ",
    "authors": [
      "Prithviraj Ammanabrolu",
      "Ethan Tien",
      "Wesley Cheung",
      "Zhaochen Luo",
      "William Ma",
      "Lara J. Martin",
      "Mark O. Riedl"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6232",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6232/6088",
    "published": "2020-02",
    "summary": "Neural network based approaches to automated story plot generation attempt to learn how to generate novel plots from a corpus of natural language plot summaries. Prior work has shown that a semantic abstraction of sentences called events improves neural plot generation and and allows one to decompose the problem into: (1) the generation of a sequence of events (event-to-event) and (2) the transformation of these events into natural language sentences (event-to-sentence). However, typical neural language generation approaches to event-to-sentence can ignore the event details and produce grammatically-correct but semantically-unrelated sentences. We present an ensemble-based model that generates natural language guided by events. We provide results\u2014including a human subjects study\u2014for a full end-to-end automated story generation system showing that our method generates more coherent and plausible stories than baseline approaches 1."
  },
  "aaai2020_main_donothaveenoughdata?deeplearningtotherescue!": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Do Not Have Enough Data? Deep Learning to the Rescue! ",
    "authors": [
      "Ateret Anaby-Tavor",
      "Boaz Carmeli",
      "Esther Goldbraich",
      "Amir Kantor",
      "George Kour",
      "Segev Shlomov",
      "Naama Tepper",
      "Naama Zwerdling"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6233",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6233/6089",
    "published": "2020-02",
    "summary": "Based on recent advances in natural language modeling and those in text generation capabilities, we propose a novel data augmentation method for text classification tasks. We use a powerful pre-trained neural network model to artificially synthesize new labeled data for supervised learning. We mainly focus on cases with scarce labeled data. Our method, referred to as language-model-based data augmentation (LAMBADA), involves fine-tuning a state-of-the-art language generator to a specific task through an initial training phase on the existing (usually small) labeled data. Using the fine-tuned model and given a class label, new sentences for the class are generated. Our process then filters these new sentences by using a classifier trained on the original data. In a series of experiments, we show that LAMBADA improves classifiers' performance on a variety of datasets. Moreover, LAMBADA significantly improves upon the state-of-the-art techniques for data augmentation, specifically those applicable to text classification tasks with little data."
  },
  "aaai2020_main_fine-grainednamedentitytypingoverdistantlysuperviseddatabasedonrefinedrepresentations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fine-Grained Named Entity Typing over Distantly Supervised Data Based on Refined Representations ",
    "authors": [
      "Muhammad Asif Ali",
      "Yifang Sun",
      "Bing Li",
      "Wei Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6234",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6234/6090",
    "published": "2020-02",
    "summary": "Fine-Grained Named Entity Typing (FG-NET) is a key component in Natural Language Processing (NLP). It aims at classifying an entity mention into a wide range of entity types. Due to a large number of entity types, distant supervision is used to collect training data for this task, which noisily assigns type labels to entity mentions irrespective of the context. In order to alleviate the noisy labels, existing approaches on FG-NET analyze the entity mentions entirely independent of each other and assign type labels solely based on mention's sentence-specific context. This is inadequate for highly overlapping and/or noisy type labels as it hinders information passing across sentence boundaries. For this, we propose an edge-weighted attentive graph convolution network that refines the noisy mention representations by attending over corpus-level contextual clues prior to the end classification. Experimental evaluation shows that the proposed model outperforms the existing research by a relative score of upto 10.2% and 8.3% for macro-f1 and micro-f1 respectively."
  },
  "aaai2020_main_understandingthesemanticcontentofsparsewordembeddingsusingacommonsenseknowledgebase": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Understanding the Semantic Content of Sparse Word Embeddings Using a Commonsense Knowledge Base ",
    "authors": [
      "Vanda Balogh",
      "G\u00e1bor Berend",
      "Dimitrios I. Diochnos",
      "Gy\u00f6rgy Tur\u00e1n"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6235",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6235/6091",
    "published": "2020-02",
    "summary": "Word embeddings have developed into a major NLP tool with broad applicability. Understanding the semantic content of word embeddings remains an important challenge for additional applications. One aspect of this issue is to explore the interpretability of word embeddings. Sparse word embeddings have been proposed as models with improved interpretability. Continuing this line of research, we investigate the extent to which human interpretable semantic concepts emerge along the bases of sparse word representations. In order to have a broad framework for evaluation, we consider three general approaches for constructing sparse word representations, which are then evaluated in multiple ways. We propose a novel methodology to evaluate the semantic content of word embeddings using a commonsense knowledge base, applied here to the sparse case. This methodology is illustrated by two techniques using the ConceptNet knowledge base. The first approach assigns a commonsense concept label to the individual dimensions of the embedding space. The second approach uses a metric, derived by spreading activation, to quantify the coherence of coordinates along the individual axes. We also provide results on the relationship between the two approaches. The results show, for example, that in the individual dimensions of sparse word embeddings, words having high coefficients are more semantically related in terms of path lengths in the knowledge base than the ones having zero coefficients."
  },
  "aaai2020_main_simultaneouslylinkingentitiesandextractingrelationsfrombiomedicaltextwithoutmention-levelsupervision": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Simultaneously Linking Entities and Extracting Relations from Biomedical Text without Mention-Level Supervision ",
    "authors": [
      "Trapit Bansal",
      "Pat Verga",
      "Neha Choudhary",
      "Andrew McCallum"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6236",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6236/6092",
    "published": "2020-02",
    "summary": "Understanding the meaning of text often involves reasoning about entities and their relationships. This requires identifying textual mentions of entities, linking them to a canonical concept, and discerning their relationships. These tasks are nearly always viewed as separate components within a pipeline, each requiring a distinct model and training data. While relation extraction can often be trained with readily available weak or distant supervision, entity linkers typically require expensive mention-level supervision \u2013 which is not available in many domains. Instead, we propose a model which is trained to simultaneously produce entity linking and relation decisions while requiring no mention-level annotations. This approach avoids cascading errors that arise from pipelined methods and more accurately predicts entity relationships from text. We show that our model outperforms a state-of-the art entity linking and relation extraction pipeline on two biomedical datasets and can drastically improve the overall recall of the system."
  },
  "aaai2020_main_zero-resourcecross-lingualnamedentityrecognition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Zero-Resource Cross-Lingual Named Entity Recognition ",
    "authors": [
      "M Saiful Bari",
      "Shafiq Joty",
      "Prathyusha Jwalapuram"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6237",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6237/6093",
    "published": "2020-02",
    "summary": "Recently, neural methods have achieved state-of-the-art (SOTA) results in Named Entity Recognition (NER) tasks for many languages without the need for manually crafted features. However, these models still require manually annotated training data, which is not available for many languages. In this paper, we propose an unsupervised cross-lingual NER model that can transfer NER knowledge from one language to another in a completely unsupervised way without relying on any bilingual dictionary or parallel data. Our model achieves this through word-level adversarial learning and augmented fine-tuning with parameter sharing and feature augmentation. Experiments on five different languages demonstrate the effectiveness of our approach, outperforming existing models by a good margin and setting a new SOTA for each language pair."
  },
  "aaai2020_main_generatingwell-formedanswersbymachinereadingwithstochasticselectornetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Generating Well-Formed Answers by Machine Reading with Stochastic Selector Networks ",
    "authors": [
      "Bin Bi",
      "Chen Wu",
      "Ming Yan",
      "Wei Wang",
      "Jiangnan Xia",
      "Chenliang Li"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6238",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6238/6094",
    "published": "2020-02",
    "summary": "Question answering (QA) based on machine reading comprehension has been a recent surge in popularity, yet most work has focused on extractive methods. We instead address a more challenging QA problem of generating a well-formed answer by reading and summarizing the paragraph for a given question."
  },
  "aaai2020_main_piqareasoningaboutphysicalcommonsenseinnaturallanguage": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " PIQA: Reasoning about Physical Commonsense in Natural Language ",
    "authors": [
      "Yonatan Bisk",
      "Rowan Zellers",
      "Ronan Le bras",
      "Jianfeng Gao",
      "Yejin Choi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6239",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6239/6095",
    "published": "2020-02",
    "summary": "To apply eyeshadow without a brush, should I use a cotton swab or a toothpick? Questions requiring this kind of physical commonsense pose a challenge to today's natural language understanding systems. While recent pretrained models (such as BERT) have made progress on question answering over more abstract domains \u2013 such as news articles and encyclopedia entries, where text is plentiful \u2013 in more physical domains, text is inherently limited due to reporting bias. Can AI systems learn to reliably answer physical commonsense questions without experiencing the physical world?"
  },
  "aaai2020_main_backtothefuture\u2013temporaladaptationoftextrepresentations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Back to the Future \u2013 Temporal Adaptation of Text Representations ",
    "authors": [
      "Johannes Bjerva",
      "Wouter Kouw",
      "Isabelle Augenstein"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6240",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6240/6096",
    "published": "2020-02",
    "summary": "Language evolves over time in many ways relevant to natural language processing tasks. For example, recent occurrences of tokens 'BERT' and 'ELMO' in publications refer to neural network architectures rather than persons. This type of temporal signal is typically overlooked, but is important if one aims to deploy a machine learning model over an extended period of time. In particular, language evolution causes data drift between time-steps in sequential decision-making tasks. Examples of such tasks include prediction of paper acceptance for yearly conferences (regular intervals) or author stance prediction for rumours on Twitter (irregular intervals). Inspired by successes in computer vision, we tackle data drift by sequentially aligning learned representations. We evaluate on three challenging tasks varying in terms of time-scales, linguistic units, and domains. These tasks show our method outperforming several strong baselines, including using all available data. We argue that, due to its low computational expense, sequential alignment is a practical solution to dealing with language evolution."
  },
  "aaai2020_main_modellingsemanticcategoriesusingconceptualneighborhood": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Modelling Semantic Categories Using Conceptual Neighborhood ",
    "authors": [
      "Zied Bouraoui",
      "Jose Camacho-Collados",
      "Luis Espinosa-Anke",
      "Steven Schockaert"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6241",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6241/6097",
    "published": "2020-02",
    "summary": "While many methods for learning vector space embeddings have been proposed in the field of Natural Language Processing, these methods typically do not distinguish between categories and individuals. Intuitively, if individuals are represented as vectors, we can think of categories as (soft) regions in the embedding space. Unfortunately, meaningful regions can be difficult to estimate, especially since we often have few examples of individuals that belong to a given category. To address this issue, we rely on the fact that different categories are often highly interdependent. In particular, categories often have conceptual neighbors, which are disjoint from but closely related to the given category (e.g. fruit and vegetable). Our hypothesis is that more accurate category representations can be learned by relying on the assumption that the regions representing such conceptual neighbors should be adjacent in the embedding space. We propose a simple method for identifying conceptual neighbors and then show that incorporating these conceptual neighbors indeed leads to more accurate region based representations."
  },
  "aaai2020_main_inducingrelationalknowledgefrombert": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Inducing Relational Knowledge from BERT ",
    "authors": [
      "Zied Bouraoui",
      "Jose Camacho-Collados",
      "Steven Schockaert"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6242",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6242/6098",
    "published": "2020-02",
    "summary": "One of the most remarkable properties of word embeddings is the fact that they capture certain types of semantic and syntactic relationships. Recently, pre-trained language models such as BERT have achieved groundbreaking results across a wide range of Natural Language Processing tasks. However, it is unclear to what extent such models capture relational knowledge beyond what is already captured by standard word embeddings. To explore this question, we propose a methodology for distilling relational knowledge from a pre-trained language model. Starting from a few seed instances of a given relation, we first use a large text corpus to find sentences that are likely to express this relation. We then use a subset of these extracted sentences as templates. Finally, we fine-tune a language model to predict whether a given word pair is likely to be an instance of some relation, when given an instantiated template for that relation as input."
  },
  "aaai2020_main_graphtransformerforgraph-to-sequencelearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Graph Transformer for Graph-to-Sequence Learning ",
    "authors": [
      "Deng Cai",
      "Wai Lam"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6243",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6243/6099",
    "published": "2020-02",
    "summary": "The dominant graph-to-sequence transduction models employ graph neural networks for graph representation learning, where the structural information is reflected by the receptive field of neurons. Unlike graph neural networks that restrict the information exchange between immediate neighborhood, we propose a new model, known as Graph Transformer, that uses explicit relation encoding and allows direct communication between two distant nodes. It provides a more efficient way for global graph structure modeling. Experiments on the applications of text generation from Abstract Meaning Representation (AMR) and syntax-based neural machine translation show the superiority of our proposed model. Specifically, our model achieves 27.4 BLEU on LDC2015E86 and 29.7 BLEU on LDC2017T10 for AMR-to-text generation, outperforming the state-of-the-art results by up to 2.2 points. On the syntax-based translation tasks, our model establishes new single-model state-of-the-art BLEU scores, 21.3 for English-to-German and 14.1 for English-to-Czech, improving over the existing best results, including ensembles, by over 1 BLEU."
  },
  "aaai2020_main_learningfromeasytocomplexadaptivemulti-curriculalearningforneuraldialoguegeneration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning from Easy to Complex: Adaptive Multi-Curricula Learning for Neural Dialogue Generation ",
    "authors": [
      "Hengyi Cai",
      "Hongshen Chen",
      "Cheng Zhang",
      "Yonghao Song",
      "Xiaofang Zhao",
      "Yangxi Li",
      "Dongsheng Duan",
      "Dawei Yin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6244",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6244/6100",
    "published": "2020-02",
    "summary": "Current state-of-the-art neural dialogue systems are mainly data-driven and are trained on human-generated responses. However, due to the subjectivity and open-ended nature of human conversations, the complexity of training dialogues varies greatly. The noise and uneven complexity of query-response pairs impede the learning efficiency and effects of the neural dialogue generation models. What is more, so far, there are no unified dialogue complexity measurements, and the dialogue complexity embodies multiple aspects of attributes\u2014specificity, repetitiveness, relevance, etc. Inspired by human behaviors of learning to converse, where children learn from easy dialogues to complex ones and dynamically adjust their learning progress, in this paper, we first analyze five dialogue attributes to measure the dialogue complexity in multiple perspectives on three publicly available corpora. Then, we propose an adaptive multi-curricula learning framework to schedule a committee of the organized curricula. The framework is established upon the reinforcement learning paradigm, which automatically chooses different curricula at the evolving learning process according to the learning status of the neural dialogue generation model. Extensive experiments conducted on five state-of-the-art models demonstrate its learning efficiency and effectiveness with respect to 13 automatic evaluation metrics and human judgments."
  },
  "aaai2020_main_unsuperviseddomainadaptationonreadingcomprehension": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Unsupervised Domain Adaptation on Reading Comprehension ",
    "authors": [
      "Yu Cao",
      "Meng Fang",
      "Baosheng Yu",
      "Joey Tianyi Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6245",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6245/6101",
    "published": "2020-02",
    "summary": "Reading comprehension (RC) has been studied in a variety of datasets with the boosted performance brought by deep neural networks. However, the generalization capability of these models across different domains remains unclear. To alleviate the problem, we investigate unsupervised domain adaptation on RC, wherein a model is trained on the labeled source domain and to be applied to the target domain with only unlabeled samples. We first show that even with the powerful BERT contextual representation, a model can not generalize well from one domain to another. To solve this, we provide a novel conditional adversarial self-training method (CASe). Specifically, our approach leverages a BERT model fine-tuned on the source dataset along with the confidence filtering to generate reliable pseudo-labeled samples in the target domain for self-training. On the other hand, it further reduces domain distribution discrepancy through conditional adversarial learning across domains. Extensive experiments show our approach achieves comparable performance to supervised models on multiple large-scale benchmark datasets."
  },
  "aaai2020_main_zero-shottext-to-sqllearningwithauxiliarytask": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Zero-Shot Text-to-SQL Learning with Auxiliary Task ",
    "authors": [
      "Shuaichen Chang",
      "Pengfei Liu",
      "Yun Tang",
      "Jing Huang",
      "Xiaodong He",
      "Bowen Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6246",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6246/6102",
    "published": "2020-02",
    "summary": "Recent years have seen great success in the use of neural seq2seq models on the text-to-SQL task. However, little work has paid attention to how these models generalize to realistic unseen data, which naturally raises a question: does this impressive performance signify a perfect generalization model, or are there still some limitations?"
  },
  "aaai2020_main_hyperbolicinteractionmodelforhierarchicalmulti-labelclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Hyperbolic Interaction Model for Hierarchical Multi-Label Classification ",
    "authors": [
      "Boli Chen",
      "Xin Huang",
      "Lin Xiao",
      "Zixin Cai",
      "Liping Jing"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6247",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6247/6103",
    "published": "2020-02",
    "summary": "Different from the traditional classification tasks which assume mutual exclusion of labels, hierarchical multi-label classification (HMLC) aims to assign multiple labels to every instance with the labels organized under hierarchical relations. Besides the labels, since linguistic ontologies are intrinsic hierarchies, the conceptual relations between words can also form hierarchical structures. Thus it can be a challenge to learn mappings from word hierarchies to label hierarchies. We propose to model the word and label hierarchies by embedding them jointly in the hyperbolic space. The main reason is that the tree-likeness of the hyperbolic space matches the complexity of symbolic data with hierarchical structures. A new Hyperbolic Interaction Model (HyperIM) is designed to learn the label-aware document representations and make predictions for HMLC. Extensive experiments are conducted on three benchmark datasets. The results have demonstrated that the new model can realistically capture the complex data structures and further improve the performance for HMLC comparing with the state-of-the-art methods. To facilitate future research, our code is publicly available."
  },
  "aaai2020_main_dmrmadual-channelmulti-hopreasoningmodelforvisualdialog": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " DMRM: A Dual-Channel Multi-Hop Reasoning Model for Visual Dialog ",
    "authors": [
      "Feilong Chen",
      "Fandong Meng",
      "Jiaming Xu",
      "Peng Li",
      "Bo Xu",
      "Jie Zhou"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6248",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6248/6104",
    "published": "2020-02",
    "summary": "Visual Dialog is a vision-language task that requires an AI agent to engage in a conversation with humans grounded in an image. It remains a challenging task since it requires the agent to fully understand a given question before making an appropriate response not only from the textual dialog history, but also from the visually-grounded information. While previous models typically leverage single-hop reasoning or single-channel reasoning to deal with this complex multimodal reasoning task, which is intuitively insufficient. In this paper, we thus propose a novel and more powerful Dual-channel Multi-hop Reasoning Model for Visual Dialog, named DMRM. DMRM synchronously captures information from the dialog history and the image to enrich the semantic representation of the question by exploiting dual-channel reasoning. Specifically, DMRM maintains a dual channel to obtain the question- and history-aware image features and the question- and image-aware dialog history features by a mulit-hop reasoning process in each channel. Additionally, we also design an effective multimodal attention to further enhance the decoder to generate more accurate responses. Experimental results on the VisDial v0.9 and v1.0 datasets demonstrate that the proposed model is effective and outperforms compared models by a significant margin."
  },
  "aaai2020_main_sequencegenerationwithoptimal-transport-enhancedreinforcementlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Sequence Generation with Optimal-Transport-Enhanced Reinforcement Learning ",
    "authors": [
      "Liqun Chen",
      "Ke Bai",
      "Chenyang Tao",
      "Yizhe Zhang",
      "Guoyin Wang",
      "Wenlin Wang",
      "Ricardo Henao",
      "Lawrence Carin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6249",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6249/6105",
    "published": "2020-02",
    "summary": "Reinforcement learning (RL) has been widely used to aid training in language generation. This is achieved by enhancing standard maximum likelihood objectives with user-specified reward functions that encourage global semantic consistency. We propose a principled approach to address the difficulties associated with RL-based solutions, namely, high-variance gradients, uninformative rewards and brittle training. By leveraging the optimal transport distance, we introduce a regularizer that significantly alleviates the above issues. Our formulation emphasizes the preservation of semantic features, enabling end-to-end training instead of ad-hoc fine-tuning, and when combined with RL, it controls the exploration space for more efficient model updates. To validate the effectiveness of the proposed solution, we perform a comprehensive evaluation covering a wide variety of NLP tasks: machine translation, abstractive text summarization and image caption, with consistent improvements over competing solutions."
  },
  "aaai2020_main_schema-guidedmulti-domaindialoguestatetrackingwithgraphattentionneuralnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Schema-Guided Multi-Domain Dialogue State Tracking with Graph Attention Neural Networks ",
    "authors": [
      "Lu Chen",
      "Boer Lv",
      "Chi Wang",
      "Su Zhu",
      "Bowen Tan",
      "Kai Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6250",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6250/6106",
    "published": "2020-02",
    "summary": "Dialogue state tracking (DST) aims at estimating the current dialogue state given all the preceding conversation. For multi-domain DST, the data sparsity problem is also a major obstacle due to the increased number of state candidates. Existing approaches generally predict the value for each slot independently and do not consider slot relations, which may aggravate the data sparsity problem. In this paper, we propose a Schema-guided multi-domain dialogue State Tracker with graph attention networks (SST) that predicts dialogue states from dialogue utterances and schema graphs which contain slot relations in edges. We also introduce a graph attention matching network to fuse information from utterances and graphs, and a recurrent graph attention network to control state updating. Experiment results show that our approach obtains new state-of-the-art performance on both MultiWOZ 2.0 and MultiWOZ 2.1 benchmarks."
  },
  "aaai2020_main_improvingentitylinkingbymodelinglatententitytypeinformation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Improving Entity Linking by Modeling Latent Entity Type Information ",
    "authors": [
      "Shuang Chen",
      "Jinpeng Wang",
      "Feng Jiang",
      "Chin-Yew Lin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6251",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6251/6107",
    "published": "2020-02",
    "summary": "Existing state of the art neural entity linking models employ attention-based bag-of-words context model and pre-trained entity embeddings bootstrapped from word embeddings to assess topic level context compatibility. However, the latent entity type information in the immediate context of the mention is neglected, which causes the models often link mentions to incorrect entities with incorrect type. To tackle this problem, we propose to inject latent entity type information into the entity embeddings based on pre-trained BERT. In addition, we integrate a BERT-based entity similarity score into the local context model of a state-of-the-art model to better capture latent entity type information. Our model significantly outperforms the state-of-the-art entity linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis demonstrates that our model corrects most of the type errors produced by the direct baseline."
  },
  "aaai2020_main_tempestsofttemplate-basedpersonalizededmsubjectgenerationthroughcollaborativesummarization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " TemPEST: Soft Template-Based Personalized EDM Subject Generation through Collaborative Summarization ",
    "authors": [
      "Yu-Hsiu Chen",
      "Pin-Yu Chen",
      "Hong-Han Shuai",
      "Wen-Chih Peng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6252",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6252/6108",
    "published": "2020-02",
    "summary": "We address personalized Electronic Direct Mail (EDM) subject generation, which generates an attractive subject line for a product description according to user's preference on different contents or writing styles. Generating personalized EDM subjects has a few notable differences from generating text summaries. The subject has to be not only faithful to the description itself but also attractive to increase the click-through rate. Moreover, different users may have different preferences over the styles of topics. We propose a novel personalized EDM subject generation model named Soft Template-based Personalized EDM Subject Generator (TemPEST) to consider the aforementioned users' characteristics when generating subjects, which contains a soft template-based selective encoder network, a user rating encoder network, a summary decoder network and a rating decoder. Experimental results indicate that TemPEST is able to generate personalized topics and also effectively perform recommending rating reconstruction."
  },
  "aaai2020_main_learningtomapfrequentphrasestosub-structuresofmeaningrepresentationforneuralsemanticparsing": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Map Frequent Phrases to Sub-Structures of Meaning Representation for Neural Semantic Parsing ",
    "authors": [
      "Bo Chen",
      "Xianpei Han",
      "Ben He",
      "Le Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6253",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6253/6109",
    "published": "2020-02",
    "summary": "Neural semantic parsers usually generate meaning representation tokens from natural language tokens via an encoder-decoder model. However, there is often a vocabulary-mismatch problem between natural language utterances and logical forms. That is, one word maps to several atomic logical tokens, which need to be handled as a whole, rather than individual logical tokens at multiple steps. In this paper, we propose that the vocabulary-mismatch problem can be effectively resolved by leveraging appropriate logical tokens. Specifically, we exploit macro actions, which are of the same granularity of words/phrases, and allow the model to learn mappings from frequent phrases to corresponding sub-structures of meaning representation. Furthermore, macro actions are compact, and therefore utilizing them can significantly reduce the search space, which brings a great benefit to weakly supervised semantic parsing. Experiments show that our method leads to substantial performance improvement on three benchmarks, in both supervised and weakly supervised settings."
  },
  "aaai2020_main_attendingtoentitiesforbettertextunderstanding": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Attending to Entities for Better Text Understanding ",
    "authors": [
      "Pengxiang Cheng",
      "Katrin Erk"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6254",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6254/6110",
    "published": "2020-02",
    "summary": "Recent progress in NLP witnessed the development of large-scale pre-trained language models (GPT, BERT, XLNet, etc.) based on Transformer (Vaswani et al. 2017), and in a range of end tasks, such models have achieved state-of-the-art results, approaching human performance. This clearly demonstrates the power of the stacked self-attention architecture when paired with a sufficient number of layers and a large amount of pre-training data. However, on tasks that require complex and long-distance reasoning where surface-level cues are not enough, there is still a large gap between the pre-trained models and human performance. Strubell et al. (2018) recently showed that it is possible to inject knowledge of syntactic structure into a model through supervised self-attention. We conjecture that a similar injection of semantic knowledge, in particular, coreference information, into an existing model would improve performance on such complex problems. On the LAMBADA (Paperno et al. 2016) task, we show that a model trained from scratch with coreference as auxiliary supervision for self-attention outperforms the largest GPT-2 model, setting the new state-of-the-art, while only containing a tiny fraction of parameters compared to GPT-2. We also conduct a thorough analysis of different variants of model architectures and supervision configurations, suggesting future directions on applying similar techniques to other problems."
  },
  "aaai2020_main_dynamicembeddingontextualnetworksviaagaussianprocess": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Dynamic Embedding on Textual Networks via a Gaussian Process ",
    "authors": [
      "Pengyu Cheng",
      "Yitong Li",
      "Xinyuan Zhang",
      "Liqun Chen",
      "David Carlson",
      "Lawrence Carin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6255",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6255/6111",
    "published": "2020-02",
    "summary": "Textual network embedding aims to learn low-dimensional representations of text-annotated nodes in a graph. Prior work in this area has typically focused on fixed graph structures; however, real-world networks are often dynamic. We address this challenge with a novel end-to-end node-embedding model, called Dynamic Embedding for Textual Networks with a Gaussian Process (DetGP). After training, DetGP can be applied efficiently to dynamic graphs without re-training or backpropagation. The learned representation of each node is a combination of textual and structural embeddings. Because the structure is allowed to be dynamic, our method uses the Gaussian process to take advantage of its non-parametric properties. To use both local and global graph structures, diffusion is used to model multiple hops between neighbors. The relative importance of global versus local structure for the embeddings is learned automatically. With the non-parametric nature of the Gaussian process, updating the embeddings for a changed graph structure requires only a forward pass through the learned model. Considering link prediction and node classification, experiments demonstrate the empirical effectiveness of our method compared to baseline approaches. We further show that DetGP can be straightforwardly and efficiently applied to dynamic textual networks."
  },
  "aaai2020_main_cross-lingualnaturallanguagegenerationviapre-training": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Cross-Lingual Natural Language Generation via Pre-Training ",
    "authors": [
      "Zewen Chi",
      "Li Dong",
      "Furu Wei",
      "Wenhui Wang",
      "Xian-Ling Mao",
      "Heyan Huang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6256",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6256/6112",
    "published": "2020-02",
    "summary": "In this work we focus on transferring supervision signals of natural language generation (NLG) tasks between multiple languages. We propose to pretrain the encoder and the decoder of a sequence-to-sequence model under both monolingual and cross-lingual settings. The pre-training objective encourages the model to represent different languages in the shared space, so that we can conduct zero-shot cross-lingual transfer. After the pre-training procedure, we use monolingual data to fine-tune the pre-trained model on downstream NLG tasks. Then the sequence-to-sequence model trained in a single language can be directly evaluated beyond that language (i.e., accepting multi-lingual input and producing multi-lingual output). Experimental results on question generation and abstractive summarization show that our model outperforms the machine-translation-based pipeline methods for zero-shot cross-lingual generation. Moreover, cross-lingual transfer improves NLG performance of low-resource languages by leveraging rich-resource language data. Our implementation and data are available at https://github.com/CZWin32768/xnlg."
  },
  "aaai2020_main_anempiricalstudyofcontentunderstandinginconversationalquestionanswering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Empirical Study of Content Understanding in Conversational Question Answering ",
    "authors": [
      "Ting-Rui Chiang",
      "Hao-Tong Ye",
      "Yun-Nung Chen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6257",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6257/6113",
    "published": "2020-02",
    "summary": "With a lot of work about context-free question answering systems, there is an emerging trend of conversational question answering models in the natural language processing field. Thanks to the recently collected datasets, including QuAC and CoQA, there has been more work on conversational question answering, and recent work has achieved competitive performance on both datasets. However, to best of our knowledge, two important questions for conversational comprehension research have not been well studied: 1) How well can the benchmark dataset reflect models' content understanding? 2) Do the models well utilize the conversation content when answering questions? To investigate these questions, we design different training settings, testing settings, as well as an attack to verify the models' capability of content understanding on QuAC and CoQA. The experimental results indicate some potential hazards in the benchmark datasets, QuAC and CoQA, for conversational comprehension research. Our analysis also sheds light on both what models may learn and how datasets may bias the models. With deep investigation of the task, it is believed that this work can benefit the future progress of conversation comprehension. The source code is available at https://github.com/MiuLab/CQA-Study."
  },
  "aaai2020_main_howtoaskbetterquestions?alarge-scalemulti-domaindatasetforrewritingill-formedquestions": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " How to Ask Better Questions? A Large-Scale Multi-Domain Dataset for Rewriting Ill-Formed Questions ",
    "authors": [
      "Zewei Chu",
      "Mingda Chen",
      "Jing Chen",
      "Miaosen Wang",
      "Kevin Gimpel",
      "Manaal Faruqui",
      "Xiance Si"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6258",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6258/6114",
    "published": "2020-02",
    "summary": "We present a large-scale dataset for the task of rewriting an ill-formed natural language question to a well-formed one. Our multi-domain question rewriting (MQR) dataset is constructed from human contributed Stack Exchange question edit histories. The dataset contains 427,719 question pairs which come from 303 domains. We provide human annotations for a subset of the dataset as a quality estimate. When moving from ill-formed to well-formed questions, the question quality improves by an average of 45 points across three aspects. We train sequence-to-sequence neural models on the constructed dataset and obtain an improvement of 13.2% in BLEU-4 over baseline methods built from other data resources. We release the MQR dataset to encourage research on the problem of question rewriting.1"
  },
  "aaai2020_main_guidingattentioninsequence-to-sequencemodelsfordialogueactprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Guiding Attention in Sequence-to-Sequence Models for Dialogue Act Prediction ",
    "authors": [
      "Pierre Colombo",
      "Emile Chapuis",
      "Matteo Manica",
      "Emmanuel Vignon",
      "Giovanna Varni",
      "Chloe Clavel"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6259",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6259/6115",
    "published": "2020-02",
    "summary": "The task of predicting dialog acts (DA) based on conversational dialog is a key component in the development of conversational agents. Accurately predicting DAs requires a precise modeling of both the conversation and the global tag dependencies. We leverage seq2seq approaches widely adopted in Neural Machine Translation (NMT) to improve the modelling of tag sequentiality. Seq2seq models are known to learn complex global dependencies while currently proposed approaches using linear conditional random fields (CRF) only model local tag dependencies. In this work, we introduce a seq2seq model tailored for DA classification using: a hierarchical encoder, a novel guided attention mechanism and beam search applied to both training and inference. Compared to the state of the art our model does not require handcrafted features and is trained end-to-end. Furthermore, the proposed approach achieves an unmatched accuracy score of 85% on SwDA, and state-of-the-art accuracy score of 91.6% on MRDA."
  },
  "aaai2020_main_discriminativesentencemodelingforstoryendingprediction": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Discriminative Sentence Modeling for Story Ending Prediction ",
    "authors": [
      "Yiming Cui",
      "Wanxiang Che",
      "Wei-Nan Zhang",
      "Ting Liu",
      "Shijin Wang",
      "Guoping Hu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6260",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6260/6116",
    "published": "2020-02",
    "summary": "Story Ending Prediction is a task that needs to select an appropriate ending for the given story, which requires the machine to understand the story and sometimes needs commonsense knowledge. To tackle this task, we propose a new neural network called Diff-Net for better modeling the differences of each ending in this task. The proposed model could discriminate two endings in three semantic levels: contextual representation, story-aware representation, and discriminative representation. Experimental results on the Story Cloze Test dataset show that the proposed model siginificantly outperforms various systems by a large margin, and detailed ablation studies are given for better understanding our model. We also carefully examine the traditional and BERT-based models on both SCT v1.0 and v1.5 with interesting findings that may potentially help future studies."
  },
  "aaai2020_main_multiplepositionalself-attentionnetworkfortextclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multiple Positional Self-Attention Network for Text Classification ",
    "authors": [
      "Biyun Dai",
      "Jinlong Li",
      "Ruoyi Xu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6261",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6261/6117",
    "published": "2020-02",
    "summary": "Self-attention mechanisms have recently caused many concerns on Natural Language Processing (NLP) tasks. Relative positional information is important to self-attention mechanisms. We propose Faraway Mask focusing on the (2m + 1)-gram words and Scaled-Distance Mask putting the logarithmic distance punishment to avoid and weaken the self-attention of distant words respectively. To exploit different masks, we present Positional Self-Attention Layer for generating different Masked-Self-Attentions and a following Position-Fusion Layer in which fused positional information multiplies the Masked-Self-Attentions for generating sentence embeddings. To evaluate our sentence embeddings approach Multiple Positional Self-Attention Network (MPSAN), we perform the comparison experiments on sentiment analysis, semantic relatedness and sentence classification tasks. The result shows that our MPSAN outperforms state-of-the-art methods on five datasets and the test accuracy is improved by 0.81%, 0.6% on SST, CR datasets, respectively. In addition, we reduce training parameters and improve the time efficiency of MPSAN by lowering the dimension number of self-attention and simplifying fusion mechanism."
  },
  "aaai2020_main_adversarialtrainingbasedmulti-sourceunsuperviseddomainadaptationforsentimentanalysis": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Adversarial Training Based Multi-Source Unsupervised Domain Adaptation for Sentiment Analysis ",
    "authors": [
      "Yong Dai",
      "Jian Liu",
      "Xiancong Ren",
      "Zenglin Xu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6262",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6262/6118",
    "published": "2020-02",
    "summary": "Multi-source unsupervised domain adaptation (MS-UDA) for sentiment analysis (SA) aims to leverage useful information in multiple source domains to help do SA in an unlabeled target domain that has no supervised information. Existing algorithms of MS-UDA either only exploit the shared features, i.e., the domain-invariant information, or based on some weak assumption in NLP, e.g., smoothness assumption. To avoid these problems, we propose two transfer learning frameworks based on the multi-source domain adaptation methodology for SA by combining the source hypotheses to derive a good target hypothesis. The key feature of the first framework is a novel Weighting Scheme based Unsupervised Domain Adaptation framework ((WS-UDA), which combine the source classifiers to acquire pseudo labels for target instances directly. While the second framework is a Two-Stage Training based Unsupervised Domain Adaptation framework (2ST-UDA), which further exploits these pseudo labels to train a target private extractor. Importantly, the weights assigned to each source classifier are based on the relations between target instances and source domains, which measured by a discriminator through the adversarial training. Furthermore, through the same discriminator, we also fulfill the separation of shared features and private features.Experimental results on two SA datasets demonstrate the promising performance of our frameworks, which outperforms unsupervised state-of-the-art competitors."
  },
  "aaai2020_main_hypernymdetectionusingstrictpartialordernetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Hypernym Detection Using Strict Partial Order Networks ",
    "authors": [
      "Sarthak Dash",
      "Md Faisal Mahbub Chowdhury",
      "Alfio Gliozzo",
      "Nandana Mihindukulasooriya",
      "Nicolas Rodolfo Fauceglia"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6263",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6263/6119",
    "published": "2020-02",
    "summary": "This paper introduces Strict Partial Order Networks (SPON), a novel neural network architecture designed to enforce asymmetry and transitive properties as soft constraints. We apply it to induce hypernymy relations by training with is-a pairs. We also present an augmented variant of SPON that can generalize type information learned for in-vocabulary terms to previously unseen ones. An extensive evaluation over eleven benchmarks across different tasks shows that SPON consistently either outperforms or attains the state of the art on all but one of these benchmarks."
  },
  "aaai2020_main_justaddfunctionsaneural-symboliclanguagemodel": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Just Add Functions: A Neural-Symbolic Language Model ",
    "authors": [
      "David Demeter",
      "Doug Downey"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6264",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6264/6120",
    "published": "2020-02",
    "summary": "Neural network language models (NNLMs) have achieved ever-improving accuracy due to more sophisticated architectures and increasing amounts of training data. However, the inductive bias of these models (formed by the distributional hypothesis of language), while ideally suited to modeling most running text, results in key limitations for today's models. In particular, the models often struggle to learn certain spatial, temporal, or quantitative relationships, which are commonplace in text and are second-nature for human readers. Yet, in many cases, these relationships can be encoded with simple mathematical or logical expressions. How can we augment today's neural models with such encodings?"
  },
  "aaai2020_main_aniterativepolishingframeworkbasedonqualityawaremaskedlanguagemodelforchinesepoetrygeneration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " An Iterative Polishing Framework Based on Quality Aware Masked Language Model for Chinese Poetry Generation ",
    "authors": [
      "Liming Deng",
      "Jie Wang",
      "Hangming Liang",
      "Hui Chen",
      "Zhiqiang Xie",
      "Bojin Zhuang",
      "Shaojun Wang",
      "Jing Xiao"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6265",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6265/6121",
    "published": "2020-02",
    "summary": "Owing to its unique literal and aesthetical characteristics, automatic generation of Chinese poetry is still challenging in Artificial Intelligence, which can hardly be straightforwardly realized by end-to-end methods. In this paper, we propose a novel iterative polishing framework for highly qualified Chinese poetry generation. In the first stage, an encoder-decoder structure is utilized to generate a poem draft. Afterwards, our proposed Quality-Aware Masked Language Model (QA-MLM) is employed to polish the draft towards higher quality in terms of linguistics and literalness. Based on a multi-task learning scheme, QA-MLM is able to determine whether polishing is needed based on the poem draft. Furthermore, QA-MLM is able to localize improper characters of the poem draft and substitute with newly predicted ones accordingly. Benefited from the masked language model structure, QA-MLM incorporates global context information into the polishing process, which can obtain more appropriate polishing results than the unidirectional sequential decoding. Moreover, the iterative polishing process will be terminated automatically when QA-MLM regards the processed poem as a qualified one. Both human and automatic evaluation have been conducted, and the results demonstrate that our approach is effective to improve the performance of encoder-decoder structure."
  },
  "aaai2020_main_jointlearningofanswerselectionandanswersummarygenerationincommunityquestionanswering": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Joint Learning of Answer Selection and Answer Summary Generation in Community Question Answering ",
    "authors": [
      "Yang Deng",
      "Wai Lam",
      "Yuexiang Xie",
      "Daoyuan Chen",
      "Yaliang Li",
      "Min Yang",
      "Ying Shen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6266",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6266/6122",
    "published": "2020-02",
    "summary": "Community question answering (CQA) gains increasing popularity in both academy and industry recently. However, the redundancy and lengthiness issues of crowdsourced answers limit the performance of answer selection and lead to reading difficulties and misunderstandings for community users. To solve these problems, we tackle the tasks of answer selection and answer summary generation in CQA with a novel joint learning model. Specifically, we design a question-driven pointer-generator network, which exploits the correlation information between question-answer pairs to aid in attending the essential information when generating answer summaries. Meanwhile, we leverage the answer summaries to alleviate noise in original lengthy answers when ranking the relevancy degrees of question-answer pairs. In addition, we construct a new large-scale CQA corpus, WikiHowQA, which contains long answers for answer selection as well as reference summaries for answer summarization. The experimental results show that the joint learning method can effectively address the answer redundancy issue in CQA and achieves state-of-the-art results on both answer selection and text summarization tasks. Furthermore, the proposed model is shown to be of great transferring ability and applicability for resource-poor CQA tasks, which lack of reference answer summaries."
  },
  "aaai2020_main_onmeasuringandmitigatingbiasedinferencesofwordembeddings": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " On Measuring and Mitigating Biased Inferences of Word Embeddings ",
    "authors": [
      "Sunipa Dev",
      "Tao Li",
      "Jeff M. Phillips",
      "Vivek Srikumar"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6267",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6267/6123",
    "published": "2020-02",
    "summary": "Word embeddings carry stereotypical connotations from the text they are trained on, which can lead to invalid inferences in downstream models that rely on them. We use this observation to design a mechanism for measuring stereotypes using the task of natural language inference. We demonstrate a reduction in invalid inferences via bias mitigation strategies on static word embeddings (GloVe). Further, we show that for gender bias, these techniques extend to contextualized embeddings when applied selectively only to the static components of contextualized embeddings (ELMo, BERT)."
  },
  "aaai2020_main_asymmetricalhierarchicalnetworkswithattentiveinteractionsforinterpretablereview-basedrecommendation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Asymmetrical Hierarchical Networks with Attentive Interactions for Interpretable Review-Based Recommendation ",
    "authors": [
      "Xin Dong",
      "Jingchao Ni",
      "Wei Cheng",
      "Zhengzhang Chen",
      "Bo Zong",
      "Dongjin Song",
      "Yanchi Liu",
      "Haifeng Chen",
      "Gerard de Melo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6268",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6268/6124",
    "published": "2020-02",
    "summary": "Recently, recommender systems have been able to emit substantially improved recommendations by leveraging user-provided reviews. Existing methods typically merge all reviews of a given user (item) into a long document, and then process user and item documents in the same manner. In practice, however, these two sets of reviews are notably different: users' reviews reflect a variety of items that they have bought and are hence very heterogeneous in their topics, while an item's reviews pertain only to that single item and are thus topically homogeneous. In this work, we develop a novel neural network model that properly accounts for this important difference by means of asymmetric attentive modules. The user module learns to attend to only those signals that are relevant with respect to the target item, whereas the item module learns to extract the most salient contents with regard to properties of the item. Our multi-hierarchical paradigm accounts for the fact that neither are all reviews equally useful, nor are all sentences within each review equally pertinent. Extensive experimental results on a variety of real datasets demonstrate the effectiveness of our method."
  },
  "aaai2020_main_detectingasksinsocialengineeringattacksimpactoflinguisticandstructuralknowledge": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Detecting Asks in Social Engineering Attacks: Impact of Linguistic and Structural Knowledge ",
    "authors": [
      "Bonnie Dorr",
      "Archna Bhatia",
      "Adam Dalton",
      "Brodie Mather",
      "Bryanna Hebenstreit",
      "Sashank Santhanam",
      "Zhuo Cheng",
      "Samira Shaikh",
      "Alan Zemel",
      "Tomek Strzalkowski"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6269",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6269/6125",
    "published": "2020-02",
    "summary": "Social engineers attempt to manipulate users into undertaking actions such as downloading malware by clicking links or providing access to money or sensitive information. Natural language processing, computational sociolinguistics, and media-specific structural clues provide a means for detecting both the ask (e.g., buy gift card) and the risk/reward implied by the ask, which we call framing (e.g., lose your job, get a raise). We apply linguistic resources such as Lexical Conceptual Structure to tackle ask detection and also leverage structural clues such as links and their proximity to identified asks to improve confidence in our results. Our experiments indicate that the performance of ask detection, framing detection, and identification of the top ask is improved by linguistically motivated classes coupled with structural clues such as links. Our approach is implemented in a system that informs users about social engineering risk situations."
  },
  "aaai2020_main_corpuswideargumentmining\u2014aworkingsolution": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Corpus Wide Argument Mining\u2014A Working Solution ",
    "authors": [
      "Liat Ein-Dor",
      "Eyal Shnarch",
      "Lena Dankin",
      "Alon Halfon",
      "Benjamin Sznajder",
      "Ariel Gera",
      "Carlos Alzate",
      "Martin Gleize",
      "Leshem Choshen",
      "Yufang Hou",
      "Yonatan Bilu",
      "Ranit Aharonov",
      "Noam Slonim"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6270",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6270/6126",
    "published": "2020-02",
    "summary": "One of the main tasks in argument mining is the retrieval of argumentative content pertaining to a given topic. Most previous work addressed this task by retrieving a relatively small number of relevant documents as the initial source for such content. This line of research yielded moderate success, which is of limited use in a real-world system. Furthermore, for such a system to yield a comprehensive set of relevant arguments, over a wide range of topics, it requires leveraging a large and diverse corpus in an appropriate manner. Here we present a first end-to-end high-precision, corpus-wide argument mining system. This is made possible by combining sentence-level queries over an appropriate indexing of a very large corpus of newspaper articles, with an iterative annotation scheme. This scheme addresses the inherent label bias in the data and pinpoints the regions of the sample space whose manual labeling is required to obtain high-precision among top-ranked candidates."
  },
  "aaai2020_main_latentemotionmemoryformulti-labelemotionclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Latent Emotion Memory for Multi-Label Emotion Classification ",
    "authors": [
      "Hao Fei",
      "Yue Zhang",
      "Yafeng Ren",
      "Donghong Ji"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6271",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6271/6127",
    "published": "2020-02",
    "summary": "Identifying multiple emotions in a sentence is an important research topic. Existing methods usually model the problem as multi-label classification task. However, previous methods have two issues, limiting the performance of the task. First, these models do not consider prior emotion distribution in a sentence. Second, they fail to effectively capture the context information closely related to the corresponding emotion. In this paper, we propose a Latent Emotion Memory network (LEM) for multi-label emotion classification. The proposed model can learn the latent emotion distribution without external knowledge, and can effectively leverage it into the classification network. Experimental results on two benchmark datasets show that the proposed model outperforms strong baselines, achieving the state-of-the-art performance."
  },
  "aaai2020_main_translucentanswerpredictionsinmulti-hopreadingcomprehension": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Translucent Answer Predictions in Multi-Hop Reading Comprehension ",
    "authors": [
      "G P Shrivatsa Bhargav",
      "Michael Glass",
      "Dinesh Garg",
      "Shirish Shevade",
      "Saswati Dana",
      "Dinesh Khandelwal",
      "L Venkata Subramaniam",
      "Alfio Gliozzo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6272",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6272/6128",
    "published": "2020-02",
    "summary": "Research on the task of Reading Comprehension style Question Answering (RCQA) has gained momentum in recent years due to the emergence of human annotated datasets and associated leaderboards, for example CoQA, HotpotQA, SQuAD, TriviaQA, etc. While state-of-the-art has advanced considerably, there is still ample opportunity to advance it further on some important variants of the RCQA task. In this paper, we propose a novel deep neural architecture, called TAP (Translucent Answer Prediction), to identify answers and evidence (in the form of supporting facts) in an RCQA task requiring multi-hop reasoning. TAP comprises two loosely coupled networks \u2013 Local and Global Interaction eXtractor (LoGIX) and Answer Predictor (AP). LoGIX predicts supporting facts, whereas AP consumes these predicted supporting facts to predict the answer span. The novel design of LoGIX is inspired by two key design desiderata \u2013 local context and global interaction\u2013 that we identified by analyzing examples of multi-hop RCQA task. The loose coupling between LoGIX and the AP reveals the set of sentences used by the AP in predicting an answer. Therefore, answer predictions of TAP can be interpreted in a translucent manner. TAP offers state-of-the-art performance on the HotpotQA (Yang et al. 2018) dataset \u2013 an apt dataset for multi-hop RCQA task \u2013 as it occupies Rank-1 on its leaderboard (https://hotpotqa.github.io/) at the time of submission."
  },
  "aaai2020_main_posterior-gantowardsinformativeandcoherentresponsegenerationwithposteriorgenerativeadversarialnetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Posterior-GAN: Towards Informative and Coherent Response Generation with Posterior Generative Adversarial Network ",
    "authors": [
      "Shaoxiong Feng",
      "Hongshen Chen",
      "Kan Li",
      "Dawei Yin"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6273",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6273/6129",
    "published": "2020-02",
    "summary": "Neural conversational models learn to generate responses by taking into account the dialog history. These models are typically optimized over the query-response pairs with a maximum likelihood estimation objective. However, the query-response tuples are naturally loosely coupled, and there exist multiple responses that can respond to a given query, which leads the conversational model learning burdensome. Besides, the general dull response problem is even worsened when the model is confronted with meaningless response training instances. Intuitively, a high-quality response not only responds to the given query but also links up to the future conversations, in this paper, we leverage the query-response-future turn triples to induce the generated responses that consider both the given context and the future conversations. To facilitate the modeling of these triples, we further propose a novel encoder-decoder based generative adversarial learning framework, Posterior Generative Adversarial Network (Posterior-GAN), which consists of a forward and a backward generative discriminator to cooperatively encourage the generated response to be informative and coherent by two complementary assessment perspectives. Experimental results demonstrate that our method effectively boosts the informativeness and coherence of the generated response on both automatic and human evaluation, which verifies the advantages of considering two assessment perspectives."
  },
  "aaai2020_main_learningtoselectbi-aspectinformationfordocument-scaletextcontentmanipulation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Select Bi-Aspect Information for Document-Scale Text Content Manipulation ",
    "authors": [
      "Xiaocheng Feng",
      "Yawei Sun",
      "Bing Qin",
      "Heng Gong",
      "Yibo Sun",
      "Wei Bi",
      "XiaoJiang Liu",
      "Ting Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6274",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6274/6130",
    "published": "2020-02",
    "summary": "In this paper, we focus on a new practical task, document-scale text content manipulation, which is the opposite of text style transfer and aims to preserve text styles while altering the content. In detail, the input is a set of structured records and a reference text for describing another recordset. The output is a summary that accurately describes the partial content in the source recordset with the same writing style of the reference. The task is unsupervised due to lack of parallel data, and is challenging to select suitable records and style words from bi-aspect inputs respectively and generate a high-fidelity long document. To tackle those problems, we first build a dataset based on a basketball game report corpus as our testbed, and present an unsupervised neural model with interactive attention mechanism, which is used for learning the semantic relationship between records and reference texts to achieve better content transfer and better style preservation. In addition, we also explore the effectiveness of the back-translation in our task for constructing some pseudo-training pairs. Empirical results show superiority of our approaches over competitive methods, and the models also yield a new state-of-the-art result on a sentence-level dataset. 1"
  },
  "aaai2020_main_discontinuousconstituentparsingwithpointernetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Discontinuous Constituent Parsing with Pointer Networks ",
    "authors": [
      "Daniel Fern\u00e1ndez-Gonz\u00e1lez",
      "Carlos G\u00f3mez-Rodr\u00edguez"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6275",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6275/6131",
    "published": "2020-02",
    "summary": "One of the most complex syntactic representations used in computational linguistics and NLP are discontinuous constituent trees, crucial for representing all grammatical phenomena of languages such as German. Recent advances in dependency parsing have shown that Pointer Networks excel in efficiently parsing syntactic relations between words in a sentence. This kind of sequence-to-sequence models achieve outstanding accuracies in building non-projective dependency trees, but its potential has not been proved yet on a more difficult task. We propose a novel neural network architecture that, by means of Pointer Networks, is able to generate the most accurate discontinuous constituent representations to date, even without the need of Part-of-Speech tagging information. To do so, we internally model discontinuous constituent structures as augmented non-projective dependency structures. The proposed approach achieves state-of-the-art results on the two widely-used NEGRA and TIGER benchmarks, outperforming previous work by a wide margin."
  },
  "aaai2020_main_rethinkinggeneralizationofneuralmodelsanamedentityrecognitioncasestudy": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Rethinking Generalization of Neural Models: A Named Entity Recognition Case Study ",
    "authors": [
      "Jinlan Fu",
      "Pengfei Liu",
      "Qi Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6276",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6276/6132",
    "published": "2020-02",
    "summary": "While neural network-based models have achieved impressive performance on a large body of NLP tasks, the generalization behavior of different models remains poorly understood: Does this excellent performance imply a perfect generalization model, or are there still some limitations? In this paper, we take the NER task as a testbed to analyze the generalization behavior of existing models from different perspectives and characterize the differences of their generalization abilities through the lens of our proposed measures, which guides us to better design models and training methods. Experiments with in-depth analyses diagnose the bottleneck of existing neural NER models in terms of breakdown performance analysis, annotation errors, dataset bias, and category relationships, which suggest directions for improvement. ) for the future research at our project page:PLONER, ReCoNLLWe have released the datasets: ( http://pfliu.com/InterpretNER/."
  },
  "aaai2020_main_documentsummarizationwithvhtmvariationalhierarchicaltopic-awaremechanism": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Document Summarization with VHTM: Variational Hierarchical Topic-Aware Mechanism ",
    "authors": [
      "Xiyan Fu",
      "Jun Wang",
      "Jinghan Zhang",
      "Jinmao Wei",
      "Zhenglu Yang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6277",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6277/6133",
    "published": "2020-02",
    "summary": "Automatic text summarization focuses on distilling summary information from texts. This research field has been considerably explored over the past decades because of its significant role in many natural language processing tasks; however, two challenging issues block its further development: (1) how to yield a summarization model embedding topic inference rather than extending with a pre-trained one and (2) how to merge the latent topics into diverse granularity levels. In this study, we propose a variational hierarchical model to holistically address both issues, dubbed VHTM. Different from the previous work assisted by a pre-trained single-grained topic model, VHTM is the first attempt to jointly accomplish summarization with topic inference via variational encoder-decoder and merge topics into multi-grained levels through topic embedding and attention. Comprehensive experiments validate the superior performance of VHTM compared with the baselines, accompanying with semantically consistent topics."
  },
  "aaai2020_main_opendomaineventtextgeneration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Open Domain Event Text Generation ",
    "authors": [
      "Zihao Fu",
      "Lidong Bing",
      "Wai Lam"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6278",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6278/6134",
    "published": "2020-02",
    "summary": "Text generation tasks aim at generating human-readable text from different kinds of data. Normally, the generated text only contains the information included in the data and its application is thus restricted to some limited scenarios. In this paper, we extend the task to an open domain event text generation scenario with an entity chain as its skeleton. Specifically, given an entity chain containing several related event entities, the model should retrieve from a trustworthy repository (e.g. Wikipedia) the detailed information of these entities and generate a description text based on the retrieved sentences. We build a new dataset called WikiEvent1 that provides 34K pairs of entity chain and its corresponding description sentences. To solve the problem, we propose a wiki augmented generator framework that contains an encoder, a retriever, and a decoder. The encoder encodes the entity chain into a hidden space while the decoder decodes from the hidden space and generates description text. The retriever retrieves relevant text from a trustworthy repository which provides more information for generation. To alleviate the overfitting problem, we propose a novel random drop component that randomly deletes words from the retrieved sentences making our model more robust for handling long input sentences. We apply the proposed model on the WikiEvent dataset and compare it with a few baselines. The experimental results show that our carefully-designed architecture does help generate better event text, and extensive analysis further uncovers the characteristics of the proposed task."
  },
  "aaai2020_main_absentcross-lingualsentencerepresentationmappingwithbidirectionalgans": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ABSent: Cross-Lingual Sentence Representation Mapping with Bidirectional GANs ",
    "authors": [
      "Zuohui Fu",
      "Yikun Xian",
      "Shijie Geng",
      "Yingqiang Ge",
      "Yuting Wang",
      "Xin Dong",
      "Guang Wang",
      "Gerard de Melo"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6279",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6279/6135",
    "published": "2020-02",
    "summary": "A number of cross-lingual transfer learning approaches based on neural networks have been proposed for the case when large amounts of parallel text are at our disposal. However, in many real-world settings, the size of parallel annotated training data is restricted. Additionally, prior cross-lingual mapping research has mainly focused on the word level. This raises the question of whether such techniques can also be applied to effortlessly obtain cross-lingually aligned sentence representations. To this end, we propose an Adversarial Bi-directional Sentence Embedding Mapping (ABSent) framework, which learns mappings of cross-lingual sentence representations from limited quantities of parallel data. The experiments show that our method outperforms several technically more powerful approaches, especially under challenging low-resource circumstances. The source code is available from https://github.com/zuohuif/ABSent along with relevant datasets."
  },
  "aaai2020_main_likelihoodratiosandgenerativeclassifiersforunsupervisedout-of-domaindetectionintaskorienteddialog": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Likelihood Ratios and Generative Classifiers for Unsupervised Out-of-Domain Detection in Task Oriented Dialog ",
    "authors": [
      "Varun Gangal",
      "Abhinav Arora",
      "Arash Einolghozati",
      "Sonal Gupta"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6280",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6280/6136",
    "published": "2020-02",
    "summary": "The task of identifying out-of-domain (OOD) input examples directly at test-time has seen renewed interest recently due to increased real world deployment of models. In this work, we focus on OOD detection for natural language sentence inputs to task-based dialog systems. Our findings are three-fold:"
  },
  "aaai2020_main_neuralsnowballforfew-shotrelationlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Neural Snowball for Few-Shot Relation Learning ",
    "authors": [
      "Tianyu Gao",
      "Xu Han",
      "Ruobing Xie",
      "Zhiyuan Liu",
      "Fen Lin",
      "Leyu Lin",
      "Maosong Sun"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6281",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6281/6137",
    "published": "2020-02",
    "summary": "Knowledge graphs typically undergo open-ended growth of new relations. This cannot be well handled by relation extraction that focuses on pre-defined relations with sufficient training data. To address new relations with few-shot instances, we propose a novel bootstrapping approach, Neural Snowball, to learn new relations by transferring semantic knowledge about existing relations. More specifically, we use Relational Siamese Networks (RSN) to learn the metric of relational similarities between instances based on existing relations and their labeled data. Afterwards, given a new relation and its few-shot instances, we use RSN to accumulate reliable instances from unlabeled corpora; these instances are used to train a relation classifier, which can further identify new facts of the new relation. The process is conducted iteratively like a snowball. Experiments show that our model can gather high-quality instances for better few-shot relation learning and achieves significant improvement compared to baselines. Codes and datasets are released on https://github.com/thunlp/Neural-Snowball."
  },
  "aaai2020_main_tandatransferandadaptpre-trainedtransformermodelsforanswersentenceselection": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection ",
    "authors": [
      "Siddhant Garg",
      "Thuy Vu",
      "Alessandro Moschitti"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6282",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6282/6138",
    "published": "2020-02",
    "summary": "We propose TandA, an effective technique for fine-tuning pre-trained Transformer models for natural language tasks. Specifically, we first transfer a pre-trained model into a model for a general task by fine-tuning it with a large and high-quality dataset. We then perform a second fine-tuning step to adapt the transferred model to the target domain. We demonstrate the benefits of our approach for answer sentence selection, which is a well-known inference task in Question Answering. We built a large scale dataset to enable the transfer step, exploiting the Natural Questions dataset. Our approach establishes the state of the art on two well-known benchmarks, WikiQA and TREC-QA, achieving the impressive MAP scores of 92% and 94.3%, respectively, which largely outperform the the highest scores of 83.4% and 87.5% of previous work. We empirically show that TandA generates more stable and robust models reducing the effort required for selecting optimal hyper-parameters. Additionally, we show that the transfer step of TandA makes the adaptation step more robust to noise. This enables a more effective use of noisy datasets for fine-tuning. Finally, we also confirm the positive impact of TandA in an industrial setting, using domain specific datasets subject to different types of noise."
  },
  "aaai2020_main_predictiveengagementanefficientmetricforautomaticevaluationofopen-domaindialoguesystems": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Predictive Engagement: An Efficient Metric for Automatic Evaluation of Open-Domain Dialogue Systems ",
    "authors": [
      "Sarik Ghazarian",
      "Ralph Weischedel",
      "Aram Galstyan",
      "Nanyun Peng"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6283",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6283/6139",
    "published": "2020-02",
    "summary": "User engagement is a critical metric for evaluating the quality of open-domain dialogue systems. Prior work has focused on conversation-level engagement by using heuristically constructed features such as the number of turns and the total time of the conversation. In this paper, we investigate the possibility and efficacy of estimating utterance-level engagement and define a novel metric, predictive engagement, for automatic evaluation of open-domain dialogue systems. Our experiments demonstrate that (1) human annotators have high agreement on assessing utterance-level engagement scores; (2) conversation-level engagement scores can be predicted from properly aggregated utterance-level engagement scores. Furthermore, we show that the utterance-level engagement scores can be learned from data. These scores can be incorporated into automatic evaluation metrics for open-domain dialogue systems to improve the correlation with human judgements. This suggests that predictive engagement can be used as a real-time feedback for training better dialogue models."
  },
  "aaai2020_main_two-leveltransformerandauxiliarycoherencemodelingforimprovedtextsegmentation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Two-Level Transformer and Auxiliary Coherence Modeling for Improved Text Segmentation ",
    "authors": [
      "Goran Glava\u0161",
      "Swapna Somasundaran"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6284",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6284/6140",
    "published": "2020-02",
    "summary": "Breaking down the structure of long texts into semantically coherent segments makes the texts more readable and supports downstream applications like summarization and retrieval. Starting from an apparent link between text coherence and segmentation, we introduce a novel supervised model for text segmentation with simple but explicit coherence modeling. Our model \u2013 a neural architecture consisting of two hierarchically connected Transformer networks \u2013 is a multi-task learning model that couples the sentence-level segmentation objective with the coherence objective that differentiates correct sequences of sentences from corrupt ones. The proposed model, dubbed Coherence-Aware Text Segmentation (CATS), yields state-of-the-art segmentation performance on a collection of benchmark datasets. Furthermore, by coupling CATS with cross-lingual word embeddings, we demonstrate its effectiveness in zero-shot language transfer: it can successfully segment texts in languages unseen in training."
  },
  "aaai2020_main_alarge-scaledatasetforargumentqualityrankingconstructionandanalysis": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " A Large-Scale Dataset for Argument Quality Ranking: Construction and Analysis ",
    "authors": [
      "Shai Gretz",
      "Roni Friedman",
      "Edo Cohen-Karlik",
      "Assaf Toledo",
      "Dan Lahav",
      "Ranit Aharonov",
      "Noam Slonim"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6285",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6285/6141",
    "published": "2020-02",
    "summary": "Identifying the quality of free-text arguments has become an important task in the rapidly expanding field of computational argumentation. In this work, we explore the challenging task of argument quality ranking. To this end, we created a corpus of 30,497 arguments carefully annotated for point-wise quality, released as part of this work. To the best of our knowledge, this is the largest dataset annotated for point-wise argument quality, larger by a factor of five than previously released datasets. Moreover, we address the core issue of inducing a labeled score from crowd annotations by performing a comprehensive evaluation of different approaches to this problem. In addition, we analyze the quality dimensions that characterize this dataset. Finally, we present a neural method for argument quality ranking, which outperforms several baselines on our own dataset, as well as previous methods published for another dataset."
  },
  "aaai2020_main_twobirdswithonestoneinvestigatinginvertibleneuralnetworksforinverseproblemsinmorphology": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Two Birds with One Stone: Investigating Invertible Neural Networks for Inverse Problems in Morphology ",
    "authors": [
      "G\u00f6zde G\u00fcl \u015eahin",
      "Iryna Gurevych"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6286",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6286/6142",
    "published": "2020-02",
    "summary": "Most problems in natural language processing can be approximated as inverse problems such as analysis and generation at variety of levels from morphological (e.g., cat+Plural\u2194cats) to semantic (e.g., (call + 1 2)\u2194\u201cCalculate one plus two.\u201d). Although the tasks in both directions are closely related, general approach in the field has been to design separate models specific for each task. However, having one shared model for both tasks, would help the researchers exploit the common knowledge among these problems with reduced time and memory requirements. We investigate a specific class of neural networks, called Invertible Neural Networks (INNs) (Ardizzone et al. 2019) that enable simultaneous optimization in both directions, hence allow addressing of inverse problems via a single model. In this study, we investigate INNs on morphological problems casted as inverse problems. We apply INNs to various morphological tasks with varying ambiguity and show that they provide competitive performance in both directions. We show that they are able to recover the morphological input parameters, i.e., predicting the lemma (e.g., cat) or the morphological tags (e.g., Plural) when run in the reverse direction, without any significant performance drop in the forward direction, i.e., predicting the surface form (e.g., cats)."
  },
  "aaai2020_main_workingmemory-drivenneuralnetworkswithanovelknowledgeenhancementparadigmforimplicitdiscourserelationrecognition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Working Memory-Driven Neural Networks with a Novel Knowledge Enhancement Paradigm for Implicit Discourse Relation Recognition ",
    "authors": [
      "Fengyu Guo",
      "Ruifang He",
      "Jianwu Dang",
      "Jian Wang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6287",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6287/6143",
    "published": "2020-02",
    "summary": "Recognizing implicit discourse relation is a challenging task in discourse analysis, which aims to understand and infer the latent relations between two discourse arguments, such as temporal, comparison. Most of the present models largely focus on learning-based methods that utilize only intra-sentence textual information to identify discourse relations, ignoring the wider contexts beyond the discourse. Moreover, people comprehend the meanings and the relations of discourses, heavily relying on their interconnected working memories (e.g., instant memory, long-term memory). Inspired by this, we propose a Knowledge-Enhanced Attentive Neural Network (KANN) framework to address these issues. Specifically, it establishes a mutual attention matrix to capture the reciprocal information between two arguments, as instant memory. While implicitly stated knowledge in the arguments is retrieved from external knowledge source and encoded as inter-words semantic connection embeddings to further construct knowledge matrix, as long-term memory. We devise a novel paradigm with two ways by the collaboration of the memories to enrich the argument representation: 1) integrating the knowledge matrix into the mutual attention matrix, which implicitly maps knowledge into the process of capturing asymmetric interactions between two discourse arguments; 2) directly concatenating the argument representations and the semantic connection embeddings, which explicitly supplements knowledge to help discourse understanding. The experimental results on the PDTB also show that our KANN model is effective."
  },
  "aaai2020_main_multi-sourcedomainadaptationfortextclassificationviadistancenet-bandits": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Source Domain Adaptation for Text Classification via DistanceNet-Bandits ",
    "authors": [
      "Han Guo",
      "Ramakanth Pasunuru",
      "Mohit Bansal"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6288",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6288/6144",
    "published": "2020-02",
    "summary": "Domain adaptation performance of a learning algorithm on a target domain is a function of its source domain error and a divergence measure between the data distribution of these two domains. We present a study of various distance-based measures in the context of NLP tasks, that characterize the dissimilarity between domains based on sample estimates. We first conduct analysis experiments to show which of these distance measures can best differentiate samples from same versus different domains, and are correlated with empirical results. Next, we develop a DistanceNet model which uses these distance measures, or a mixture of these distance measures, as an additional loss function to be minimized jointly with the task's loss function, so as to achieve better unsupervised domain adaptation. Finally, we extend this model to a novel DistanceNet-Bandit model, which employs a multi-armed bandit controller to dynamically switch between multiple source domains and allow the model to learn an optimal trajectory and mixture of domains for transfer to the low-resource target domain. We conduct experiments on popular sentiment analysis datasets with several diverse domains and show that our DistanceNet model, as well as its dynamic bandit variant, can outperform competitive baselines in the context of unsupervised domain adaptation."
  },
  "aaai2020_main_fine-tuningbycurriculumlearningfornon-autoregressiveneuralmachinetranslation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation ",
    "authors": [
      "Junliang Guo",
      "Xu Tan",
      "Linli Xu",
      "Tao Qin",
      "Enhong Chen",
      "Tie-Yan Liu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6289",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6289/6145",
    "published": "2020-02",
    "summary": "Non-autoregressive translation (NAT) models remove the dependence on previous target tokens and generate all target tokens in parallel, resulting in significant inference speedup but at the cost of inferior translation accuracy compared to autoregressive translation (AT) models. Considering that AT models have higher accuracy and are easier to train than NAT models, and both of them share the same model configurations, a natural idea to improve the accuracy of NAT models is to transfer a well-trained AT model to an NAT model through fine-tuning. However, since AT and NAT models differ greatly in training strategy, straightforward fine-tuning does not work well. In this work, we introduce curriculum learning into fine-tuning for NAT. Specifically, we design a curriculum in the fine-tuning process to progressively switch the training from autoregressive generation to non-autoregressive generation. Experiments on four benchmark translation datasets show that the proposed method achieves good improvement (more than 1 BLEU score) over previous NAT baselines in terms of translation accuracy, and greatly speed up (more than 10 times) the inference process over AT baselines."
  },
  "aaai2020_main_multi-scaleself-attentionfortextclassification": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Multi-Scale Self-Attention for Text Classification ",
    "authors": [
      "Qipeng Guo",
      "Xipeng Qiu",
      "Pengfei Liu",
      "Xiangyang Xue",
      "Zheng Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6290",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6290/6146",
    "published": "2020-02",
    "summary": "In this paper, we introduce the prior knowledge, multi-scale structure, into self-attention modules. We propose a Multi-Scale Transformer which uses multi-scale multi-head self-attention to capture features from different scales. Based on the linguistic perspective and the analysis of pre-trained Transformer (BERT) on a huge corpus, we further design a strategy to control the scale distribution for each layer. Results of three different kinds of tasks (21 datasets) show our Multi-Scale Transformer outperforms the standard Transformer consistently and significantly on small and moderate size datasets."
  },
  "aaai2020_main_fact-awaresentencesplitandrephrasewithpermutationinvarianttraining": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Fact-Aware Sentence Split and Rephrase with Permutation Invariant Training ",
    "authors": [
      "Yinuo Guo",
      "Tao Ge",
      "Furu Wei"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6291",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6291/6147",
    "published": "2020-02",
    "summary": "Sentence Split and Rephrase aims to break down a complex sentence into several simple sentences with its meaning preserved. Previous studies tend to address the issue by seq2seq learning from parallel sentence pairs, which takes a complex sentence as input and sequentially generates a series of simple sentences. However, the conventional seq2seq learning has two limitations for this task: (1) it does not take into account the facts stated in the long sentence; As a result, the generated simple sentences may miss or inaccurately state the facts in the original sentence. (2) The order variance of the simple sentences to be generated may confuse the seq2seq model during training because the simple sentences derived from the long source sentence could be in any order."
  },
  "aaai2020_main_p-sifdocumentembeddingsusingpartitionaveraging": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " P-SIF: Document Embeddings Using Partition Averaging ",
    "authors": [
      "Vivek Gupta",
      "Ankit Saw",
      "Pegah Nokhiz",
      "Praneeth Netrapalli",
      "Piyush Rai",
      "Partha Talukdar"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6292",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6292/6148",
    "published": "2020-02",
    "summary": "Simple weighted averaging of word vectors often yields effective representations for sentences which outperform sophisticated seq2seq neural models in many tasks. While it is desirable to use the same method to represent documents as well, unfortunately, the effectiveness is lost when representing long documents involving multiple sentences. One of the key reasons is that a longer document is likely to contain words from many different topics; hence, creating a single vector while ignoring all the topical structure is unlikely to yield an effective document representation. This problem is less acute in single sentences and other short text fragments where the presence of a single topic is most likely. To alleviate this problem, we present P-SIF, a partitioned word averaging model to represent long documents. P-SIF retains the simplicity of simple weighted word averaging while taking a document's topical structure into account. In particular, P-SIF learns topic-specific vectors from a document and finally concatenates them all to represent the overall document. We provide theoretical justifications on the correctness of P-SIF. Through a comprehensive set of experiments, we demonstrate P-SIF's effectiveness compared to simple weighted averaging and many other baselines."
  },
  "aaai2020_main_casecontext-awaresemanticexpansion": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " CASE: Context-Aware Semantic Expansion ",
    "authors": [
      "Jialong Han",
      "Aixin Sun",
      "Haisong Zhang",
      "Chenliang Li",
      "Shuming Shi"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6293",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6293/6149",
    "published": "2020-02",
    "summary": "In this paper, we define and study a new task called Context-Aware Semantic Expansion (CASE). Given a seed term in a sentential context, we aim to suggest other terms that well fit the context as the seed. CASE has many interesting applications such as query suggestion, computer-assisted writing, and word sense disambiguation, to name a few. Previous explorations, if any, only involve some similar tasks, and all require human annotations for evaluation. In this study, we demonstrate that annotations for this task can be harvested at scale from existing corpora, in a fully automatic manner. On a dataset of 1.8 million sentences thus derived, we propose a network architecture that encodes the context and seed term separately before suggesting alternative terms. The context encoder in this architecture can be easily extended by incorporating seed-aware attention. Our experiments demonstrate that competitive results are achieved with appropriate choices of context encoder and attention scoring function."
  },
  "aaai2020_main_manymodalqamodalitydisambiguationandqaoverdiverseinputs": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " ManyModalQA: Modality Disambiguation and QA over Diverse Inputs ",
    "authors": [
      "Darryl Hannan",
      "Akshay Jain",
      "Mohit Bansal"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6294",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6294/6150",
    "published": "2020-02",
    "summary": "We present a new multimodal question answering challenge, ManyModalQA, in which an agent must answer a question by considering three distinct modalities: text, images, and tables. We collect our data by scraping Wikipedia and then utilize crowdsourcing to collect question-answer pairs. Our questions are ambiguous, in that the modality that contains the answer is not easily determined based solely upon the question. To demonstrate this ambiguity, we construct a modality selector (or disambiguator) network, and this model gets substantially lower accuracy on our challenge set, compared to existing datasets, indicating that our questions are more ambiguous. By analyzing this model, we investigate which words in the question are indicative of the modality. Next, we construct a simple baseline ManyModalQA model, which, based on the prediction from the modality selector, fires a corresponding pre-trained state-of-the-art unimodal QA model. We focus on providing the community with a new manymodal evaluation set and only provide a fine-tuning set, with the expectation that existing datasets and approaches will be transferred for most of the training, to encourage low-resource generalization without large, monolithic training sets for each new task. There is a significant gap between our baseline models and human performance; therefore, we hope that this challenge encourages research in end-to-end modality disambiguation and multimodal QA models, as well as transfer learning."
  },
  "aaai2020_main_whatdoyoumean\u2018why?\u2019resolvingsluicesinconversations": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " What Do You Mean \u2018Why?\u2019: Resolving Sluices in Conversations ",
    "authors": [
      "Victor Petr\u00e9n Bach Hansen",
      "Anders S\u00f8gaard"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6295",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6295/6151",
    "published": "2020-02",
    "summary": "In conversation, we often ask one-word questions such as \u2018Why?\u2019 or \u2018Who?\u2019. Such questions are typically easy for humans to answer, but can be hard for computers, because their resolution requires retrieving both the right semantic frames and the right arguments from context. This paper introduces the novel ellipsis resolution task of resolving such one-word questions, referred to as sluices in linguistics. We present a crowd-sourced dataset containing annotations of sluices from over 4,000 dialogues collected from conversational QA datasets, as well as a series of strong baseline architectures."
  },
  "aaai2020_main_onehomonympertranslation": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " One Homonym per Translation ",
    "authors": [
      "Bradley Hauer",
      "Grzegorz Kondrak"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6296",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6296/6152",
    "published": "2020-02",
    "summary": "The study of homonymy is vital to resolving fundamental problems in lexical semantics. In this paper, we propose four hypotheses that characterize the unique behavior of homonyms in the context of translations, discourses, collocations, and sense clusters. We present a new annotated homonym resource that allows us to test our hypotheses on existing WSD resources. The results of the experiments provide strong empirical evidence for the hypotheses. This study represents a step towards a computational method for distinguishing between homonymy and polysemy, and constructing a definitive inventory of coarse-grained senses."
  },
  "aaai2020_main_interactivefictiongamesacolossaladventure": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Interactive Fiction Games: A Colossal Adventure ",
    "authors": [
      "Matthew Hausknecht",
      "Prithviraj Ammanabrolu",
      "Marc-Alexandre C\u00f4t\u00e9",
      "Xingdi Yuan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6297",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6297/6153",
    "published": "2020-02",
    "summary": "A hallmark of human intelligence is the ability to understand and communicate with language. Interactive Fiction games are fully text-based simulation environments where a player issues text commands to effect change in the environment and progress through the story. We argue that IF games are an excellent testbed for studying language-based autonomous agents. In particular, IF games combine challenges of combinatorial action spaces, language understanding, and commonsense reasoning. To facilitate rapid development of language-based agents, we introduce Jericho, a learning environment for man-made IF games and conduct a comprehensive study of text-agents across a rich set of games, highlighting directions in which agents can improve."
  },
  "aaai2020_main_latentrelationlanguagemodels": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Latent Relation Language Models ",
    "authors": [
      "Hiroaki Hayashi",
      "Zecong Hu",
      "Chenyan Xiong",
      "Graham Neubig"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6298",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6298/6154",
    "published": "2020-02",
    "summary": "In this paper, we propose Latent Relation Language Models (LRLMs), a class of language models that parameterizes the joint distribution over the words in a document and the entities that occur therein via knowledge graph relations. This model has a number of attractive properties: it not only improves language modeling performance, but is also able to annotate the posterior probability of entity spans for a given text through relations. Experiments demonstrate empirical improvements over both word-based language models and a previous approach that incorporates knowledge graph information. Qualitative analysis further demonstrates the proposed model's ability to learn to predict appropriate relations in context. 1"
  },
  "aaai2020_main_knowledge-graphaugmentedwordrepresentationsfornamedentityrecognition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Knowledge-Graph Augmented Word Representations for Named Entity Recognition ",
    "authors": [
      "Qizhen He",
      "Liang Wu",
      "Yida Yin",
      "Heming Cai"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6299",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6299/6155",
    "published": "2020-02",
    "summary": "By modeling the context information, ELMo and BERT have successfully improved the state-of-the-art of word representation, and demonstrated their effectiveness on the Named Entity Recognition task. In this paper, in addition to such context modeling, we propose to encode the prior knowledge of entities from an external knowledge base into the representation, and introduce a Knowledge-Graph Augmented Word Representation or KAWR for named entity recognition. Basically, KAWR provides a kind of knowledge-aware representation for words by 1) encoding entity information from a pre-trained KG embedding model with a new recurrent unit (GERU), and 2) strengthening context modeling from knowledge wise by providing a relation attention scheme based on the entity relations defined in KG. We demonstrate that KAWR, as an augmented version of the existing linguistic word representations, promotes F1 scores on 5 datasets in various domains by +0.46\u223c+2.07. Better generalization is also observed for KAWR on new entities that cannot be found in the training sets."
  },
  "aaai2020_main_improvingneuralrelationextractionwithpositiveandunlabeledlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Improving Neural Relation Extraction with Positive and Unlabeled Learning ",
    "authors": [
      "Zhengqiu He",
      "Wenliang Chen",
      "Yuyi Wang",
      "Wei Zhang",
      "Guanchun Wang",
      "Min Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6300",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6300/6156",
    "published": "2020-02",
    "summary": "We present a novel approach to improve the performance of distant supervision relation extraction with Positive and Unlabeled (PU) Learning. This approach first applies reinforcement learning to decide whether a sentence is positive to a given relation, and then positive and unlabeled bags are constructed. In contrast to most previous studies, which mainly use selected positive instances only, we make full use of unlabeled instances and propose two new representations for positive and unlabeled bags. These two representations are then combined in an appropriate way to make bag-level prediction. Experimental results on a widely used real-world dataset demonstrate that this new approach indeed achieves significant and consistent improvements as compared to several competitive baselines."
  },
  "aaai2020_main_emuenhancingmultilingualsentenceembeddingswithsemanticspecialization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Emu: Enhancing Multilingual Sentence Embeddings with Semantic Specialization ",
    "authors": [
      "Wataru Hirota",
      "Yoshihiko Suhara",
      "Behzad Golshan",
      "Wang-Chiew Tan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6301",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6301/6157",
    "published": "2020-02",
    "summary": "We present Emu, a system that semantically enhances multilingual sentence embeddings. Our framework fine-tunes pre-trained multilingual sentence embeddings using two main components: a semantic classifier and a language discriminator. The semantic classifier improves the semantic similarity of related sentences, whereas the language discriminator enhances the multilinguality of the embeddings via multilingual adversarial training. Our experimental results based on several language pairs show that our specialized embeddings outperform the state-of-the-art multilingual sentence embedding model on the task of cross-lingual intent classification using only monolingual labeled data."
  },
  "aaai2020_main_unsupervisedinterlingualsemanticrepresentationsfromsentenceembeddingsforzero-shotcross-lingualtransfer": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Unsupervised Interlingual Semantic Representations from Sentence Embeddings for Zero-Shot Cross-Lingual Transfer ",
    "authors": [
      "Channy Hong",
      "Jaeyeon Lee",
      "Jungkwon Lee"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6302",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6302/6158",
    "published": "2020-02",
    "summary": "As numerous modern NLP models demonstrate high-performance in various tasks when trained with resource-rich language data sets such as those of English, there has been a shift in attention to the idea of applying such learning to low-resource languages via zero-shot or few-shot cross-lingual transfer. While the most prominent efforts made previously on achieving this feat entails the use of parallel corpora for sentence alignment training, we seek to generalize further by assuming plausible scenarios in which such parallel data sets are unavailable. In this work, we present a novel architecture for training interlingual semantic representations on top of sentence embeddings in a completely unsupervised manner, and demonstrate its effectiveness in zero-shot cross-lingual transfer in natural language inference task. Furthermore, we showcase a method of leveraging this framework in a few-shot scenario, and finally analyze the distributional and permutational alignment across languages of these interlingual semantic representations."
  },
  "aaai2020_main_knowledge-enrichedvisualstorytelling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Knowledge-Enriched Visual Storytelling ",
    "authors": [
      "Chao-Chun Hsu",
      "Zi-Yuan Chen",
      "Chi-Yang Hsu",
      "Chih-Chia Li",
      "Tzu-Yuan Lin",
      "Ting-Hao Huang",
      "Lun-Wei Ku"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6303",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6303/6159",
    "published": "2020-02",
    "summary": "Stories are diverse and highly personalized, resulting in a large possible output space for story generation. Existing end-to-end approaches produce monotonous stories because they are limited to the vocabulary and knowledge in a single training dataset. This paper introduces KG-Story, a three-stage framework that allows the story generation model to take advantage of external Knowledge Graphs to produce interesting stories. KG-Story distills a set of representative words from the input prompts, enriches the word set by using external knowledge graphs, and finally generates stories based on the enriched word set. This distill-enrich-generate framework allows the use of external resources not only for the enrichment phase, but also for the distillation and generation phases. In this paper, we show the superiority of KG-Story for visual storytelling, where the input prompt is a sequence of five photos and the output is a short story. Per the human ranking evaluation, stories generated by KG-Story are on average ranked better than that of the state-of-the-art systems. Our code and output stories are available at https://github.com/zychen423/KE-VIST."
  },
  "aaai2020_main_leveragingmulti-tokenentitiesindocument-levelnamedentityrecognition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Leveraging Multi-Token Entities in Document-Level Named Entity Recognition ",
    "authors": [
      "Anwen Hu",
      "Zhicheng Dou",
      "Jian-Yun Nie",
      "Ji-Rong Wen"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6304",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6304/6160",
    "published": "2020-02",
    "summary": "Most state-of-the-art named entity recognition systems are designed to process each sentence within a document independently. These systems are easy to confuse entity types when the context information in a sentence is not sufficient enough. To utilize the context information within the whole document, most document-level work let neural networks on their own to learn the relation across sentences, which is not intuitive enough for us humans. In this paper, we divide entities to multi-token entities that contain multiple tokens and single-token entities that are composed of a single token. We propose that the context information of multi-token entities should be more reliable in document-level NER for news articles. We design a fusion attention mechanism which not only learns the semantic relevance between occurrences of the same token, but also focuses more on occurrences belonging to multi-tokens entities. To identify multi-token entities, we design an auxiliary task namely \u2018Multi-token Entity Classification\u2019 and perform this task simultaneously with document-level NER. This auxiliary task is simplified from NER and doesn't require extra annotation. Experimental results on the CoNLL-2003 dataset and OntoNotesnbm dataset show that our model outperforms state-of-the-art sentence-level and document-level NER methods."
  },
  "aaai2020_main_whatmakesagoodstory?designingcompositerewardsforvisualstorytelling": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " What Makes A Good Story? Designing Composite Rewards for Visual Storytelling ",
    "authors": [
      "Junjie Hu",
      "Yu Cheng",
      "Zhe Gan",
      "Jingjing Liu",
      "Jianfeng Gao",
      "Graham Neubig"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6305",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6305/6161",
    "published": "2020-02",
    "summary": "Previous storytelling approaches mostly focused on optimizing traditional metrics such as BLEU, ROUGE and CIDEr. In this paper, we re-examine this problem from a different angle, by looking deep into what defines a natural and topically-coherent story. To this end, we propose three assessment criteria: relevance, coherence and expressiveness, which we observe through empirical analysis could constitute a \u201chigh-quality\u201d story to the human eye. We further propose a reinforcement learning framework, ReCo-RL, with reward functions designed to capture the essence of these quality criteria. Experiments on the Visual Storytelling Dataset (VIST) with both automatic and human evaluation demonstrate that our ReCo-RL model achieves better performance than state-of-the-art baselines on both traditional metrics and the proposed new criteria."
  },
  "aaai2020_main_malacross-domaindialoguegenerationwithactionlearning": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MALA: Cross-Domain Dialogue Generation with Action Learning ",
    "authors": [
      "Xinting Huang",
      "Jianzhong Qi",
      "Yu Sun",
      "Rui Zhang"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6306",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6306/6162",
    "published": "2020-02",
    "summary": "Response generation for task-oriented dialogues involves two basic components: dialogue planning and surface realization. These two components, however, have a discrepancy in their objectives, i.e., task completion and language quality. To deal with such discrepancy, conditioned response generation has been introduced where the generation process is factorized into action decision and language generation via explicit action representations. To obtain action representations, recent studies learn latent actions in an unsupervised manner based on the utterance lexical similarity. Such an action learning approach is prone to diversities of language surfaces, which may impinge task completion and language quality. To address this issue, we propose multi-stage adaptive latent action learning (MALA) that learns semantic latent actions by distinguishing the effects of utterances on dialogue progress. We model the utterance effect using the transition of dialogue states caused by the utterance and develop a semantic similarity measurement that estimates whether utterances have similar effects. For learning semantic actions on domains without dialogue states, MALA extends the semantic similarity measurement across domains progressively, i.e., from aligning shared actions to learning domain-specific actions. Experiments using multi-domain datasets, SMD and MultiWOZ, show that our proposed model achieves consistent improvements over the baselines models in terms of both task completion and language quality."
  },
  "aaai2020_main_privacyenhancedmultimodalneuralrepresentationsforemotionrecognition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Privacy Enhanced Multimodal Neural Representations for Emotion Recognition ",
    "authors": [
      "Mimansa Jaiswal",
      "Emily Mower Provost"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6307",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6307/6163",
    "published": "2020-02",
    "summary": "Many mobile applications and virtual conversational agents now aim to recognize and adapt to emotions. To enable this, data are transmitted from users' devices and stored on central servers. Yet, these data contain sensitive information that could be used by mobile applications without user's consent or, maliciously, by an eavesdropping adversary. In this work, we show how multimodal representations trained for a primary task, here emotion recognition, can unintentionally leak demographic information, which could override a selected opt-out option by the user. We analyze how this leakage differs in representations obtained from textual, acoustic, and multimodal data. We use an adversarial learning paradigm to unlearn the private information present in a representation and investigate the effect of varying the strength of the adversarial component on the primary task and on the privacy metric, defined here as the inability of an attacker to predict specific demographic information. We evaluate this paradigm on multiple datasets and show that we can improve the privacy metric while not significantly impacting the performance on the primary task. To the best of our knowledge, this is the first work to analyze how the privacy metric differs across modalities and how multiple privacy concerns can be tackled while still maintaining performance on emotion recognition."
  },
  "aaai2020_main_bayes-adaptivemonte-carloplanningandlearningforgoal-orienteddialogues": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Bayes-Adaptive Monte-Carlo Planning and Learning for Goal-Oriented Dialogues ",
    "authors": [
      "Youngsoo Jang",
      "Jongmin Lee",
      "Kee-Eung Kim"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6308",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6308/6164",
    "published": "2020-02",
    "summary": "We consider a strategic dialogue task, where the ability to infer the other agent's goal is critical to the success of the conversational agent. While this problem can be naturally formulated as Bayesian planning, it is known to be a very difficult problem due to its enormous search space consisting of all possible utterances. In this paper, we introduce an efficient Bayes-adaptive planning algorithm for goal-oriented dialogues, which combines RNN-based dialogue generation and MCTS-based Bayesian planning in a novel way, leading to robust decision-making under the uncertainty of the other agent's goal. We then introduce reinforcement learning for the dialogue agent that uses MCTS as a strong policy improvement operator, casting reinforcement learning as iterative alternation of planning and supervised-learning of self-generated dialogues. In the experiments, we demonstrate that our Bayes-adaptive dialogue planning agent significantly outperforms the state-of-the-art in a negotiation dialogue domain. We also show that reinforcement learning via MCTS further improves end-task performance without diverging from human language."
  },
  "aaai2020_main_real-timeemotionrecognitionviaattentiongatedhierarchicalmemorynetwork": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Real-Time Emotion Recognition via Attention Gated Hierarchical Memory Network ",
    "authors": [
      "Wenxiang Jiao",
      "Michael Lyu",
      "Irwin King"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6309",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6309/6165",
    "published": "2020-02",
    "summary": "Real-time emotion recognition (RTER) in conversations is significant for developing emotionally intelligent chatting machines. Without the future context in RTER, it becomes critical to build the memory bank carefully for capturing historical context and summarize the memories appropriately to retrieve relevant information. We propose an Attention Gated Hierarchical Memory Network (AGHMN) to address the problems of prior work: (1) Commonly used convolutional neural networks (CNNs) for utterance feature extraction are less compatible in the memory modules; (2) Unidirectional gated recurrent units (GRUs) only allow each historical utterance to have context before it, preventing information propagation in the opposite direction; (3) The Soft Attention for summarizing loses the positional and ordering information of memories, regardless of how the memory bank is built. Particularly, we propose a Hierarchical Memory Network (HMN) with a bidirectional GRU (BiGRU) as the utterance reader and a BiGRU fusion layer for the interaction between historical utterances. For memory summarizing, we propose an Attention GRU (AGRU) where we utilize the attention weights to update the internal state of GRU. We further promote the AGRU to a bidirectional variant (BiAGRU) to balance the contextual information from recent memories and that from distant memories. We conduct experiments on two emotion conversation datasets with extensive analysis, demonstrating the efficacy of our AGHMN models."
  },
  "aaai2020_main_mmmmulti-stagemulti-tasklearningformulti-choicereadingcomprehension": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " MMM: Multi-Stage Multi-Task Learning for Multi-Choice Reading Comprehension ",
    "authors": [
      "Di Jin",
      "Shuyang Gao",
      "Jiun-Yu Kao",
      "Tagyoung Chung",
      "Dilek Hakkani-tur"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6310",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6310/6166",
    "published": "2020-02",
    "summary": "Machine Reading Comprehension (MRC) for question answering (QA), which aims to answer a question given the relevant context passages, is an important way to test the ability of intelligence systems to understand human language. Multiple-Choice QA (MCQA) is one of the most difficult tasks in MRC because it often requires more advanced reading comprehension skills such as logical reasoning, summarization, and arithmetic operations, compared to the extractive counterpart where answers are usually spans of text within given passages. Moreover, most existing MCQA datasets are small in size, making the task even harder. We introduce MMM, a Multi-stage Multi-task learning framework for Multi-choice reading comprehension. Our method involves two sequential stages: coarse-tuning stage using out-of-domain datasets and multi-task learning stage using a larger in-domain dataset to help model generalize better with limited data. Furthermore, we propose a novel multi-step attention network (MAN) as the top-level classifier for this task. We demonstrate MMM significantly advances the state-of-the-art on four representative MCQA datasets."
  },
  "aaai2020_main_isbertreallyrobust?astrongbaselinefornaturallanguageattackontextclassificationandentailment": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment ",
    "authors": [
      "Di Jin",
      "Zhijing Jin",
      "Joey Tianyi Zhou",
      "Peter Szolovits"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6311",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6311/6167",
    "published": "2020-02",
    "summary": "Machine learning algorithms are often vulnerable to adversarial examples that have imperceptible alterations from the original counterparts but can fool the state-of-the-art models. It is helpful to evaluate or even improve the robustness of these models by exposing the maliciously crafted adversarial examples. In this paper, we present TextFooler, a simple but strong baseline to generate adversarial text. By applying it to two fundamental natural language tasks, text classification and textual entailment, we successfully attacked three target models, including the powerful pre-trained BERT, and the widely used convolutional and recurrent neural networks. We demonstrate three advantages of this framework: (1) effective\u2014it outperforms previous attacks by success rate and perturbation rate, (2) utility-preserving\u2014it preserves semantic content, grammaticality, and correct types classified by humans, and (3) efficient\u2014it generates adversarial text with computational complexity linear to the text length.1"
  },
  "aaai2020_main_semsumsemanticdependencyguidedneuralabstractivesummarization": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " SemSUM: Semantic Dependency Guided Neural Abstractive Summarization ",
    "authors": [
      "Hanqi Jin",
      "Tianming Wang",
      "Xiaojun Wan"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6312",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6312/6168",
    "published": "2020-02",
    "summary": "In neural abstractive summarization, the generated summaries often face semantic irrelevance and content deviation from the input sentences. In this work, we incorporate semantic dependency graphs about predicate-argument structure of input sentences into neural abstractive summarization for the problem. We propose a novel semantics dependency guided summarization model (SemSUM), which can leverage the information of original input texts and the corresponding semantic dependency graphs in a complementary way to guide summarization process. We evaluate our model on the English Gigaword, DUC 2004 and MSR abstractive sentence summarization datasets. Experiments show that the proposed model improves semantic relevance and reduces content deviation, and also brings significant improvements on automatic evaluation ROUGE metrics."
  },
  "aaai2020_main_relationextractionexploitingfulldependencyforests": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Relation Extraction Exploiting Full Dependency Forests ",
    "authors": [
      "Lifeng Jin",
      "Linfeng Song",
      "Yue Zhang",
      "Kun Xu",
      "Wei-Yun Ma",
      "Dong Yu"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6313",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6313/6169",
    "published": "2020-02",
    "summary": "Dependency syntax has long been recognized as a crucial source of features for relation extraction. Previous work considers 1-best trees produced by a parser during preprocessing. However, error propagation from the out-of-domain parser may impact the relation extraction performance. We propose to leverage full dependency forests for this task, where a full dependency forest encodes all possible trees. Such representations of full dependency forests provide a differentiable connection between a parser and a relation extraction model, and thus we are also able to study adjusting the parser parameters based on end-task loss. Experiments on three datasets show that full dependency forests and parser adjustment give significant improvements over carefully designed baselines, showing state-of-the-art or competitive performances on biomedical or newswire benchmarks."
  },
  "aaai2020_main_monolingualtransferlearningviabilingualtranslatorsforstyle-sensitiveparaphrasegeneration": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": "Monolingual Transfer Learning via Bilingual Translators for Style-Sensitive Paraphrase Generation ",
    "authors": [
      "Tomoyuki Kajiwara",
      "Biwa Miura",
      "Yuki Arase"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6314",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6314/6170",
    "published": "2020-02",
    "summary": "We tackle the low-resource problem in style transfer by employing transfer learning that utilizes abundantly available raw corpora. Our method consists of two steps: pre-training learns to generate a semantically equivalent sentence with an input assured grammaticality, and fine-tuning learns to add a desired style. Pre-training has two options, auto-encoding and machine translation based methods. Pre-training based on AutoEncoder is a simple way to learn these from a raw corpus. If machine translators are available, the model can learn more diverse paraphrasing via roundtrip translation. After these, fine-tuning achieves high-quality paraphrase generation even in situations where only 1k sentence pairs of the parallel corpus for style transfer is available. Experimental results of formality style transfer indicated the effectiveness of both pre-training methods and the method based on roundtrip translation achieves state-of-the-art performance."
  },
  "aaai2020_main_syntacticallylook-aheadattentionnetworkforsentencecompression": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Syntactically Look-Ahead Attention Network for Sentence Compression ",
    "authors": [
      "Hidetaka Kamigaito",
      "Manabu Okumura"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6315",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6315/6171",
    "published": "2020-02",
    "summary": "Sentence compression is the task of compressing a long sentence into a short one by deleting redundant words. In sequence-to-sequence (Seq2Seq) based models, the decoder unidirectionally decides to retain or delete words. Thus, it cannot usually explicitly capture the relationships between decoded words and unseen words that will be decoded in the future time steps. Therefore, to avoid generating ungrammatical sentences, the decoder sometimes drops important words in compressing sentences. To solve this problem, we propose a novel Seq2Seq model, syntactically look-ahead attention network (SLAHAN), that can generate informative summaries by explicitly tracking both dependency parent and child words during decoding and capturing important words that will be decoded in the future. The results of the automatic evaluation on the Google sentence compression dataset showed that SLAHAN achieved the best kept-token-based-F1, ROUGE-1, ROUGE-2 and ROUGE-L scores of 85.5, 79.3, 71.3 and 79.1, respectively. SLAHAN also improved the summarization performance on longer sentences. Furthermore, in the human evaluation, SLAHAN improved informativeness without losing readability."
  },
  "aaai2020_main_learningtolearnmorphologicalinflectionforresource-poorlanguages": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Learning to Learn Morphological Inflection for Resource-Poor Languages ",
    "authors": [
      "Katharina Kann",
      "Samuel R. Bowman",
      "Kyunghyun Cho"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6316",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6316/6172",
    "published": "2020-02",
    "summary": "We propose to cast the task of morphological inflection\u2014mapping a lemma to an indicated inflected form\u2014for resource-poor languages as a meta-learning problem. Treating each language as a separate task, we use data from high-resource source languages to learn a set of model parameters that can serve as a strong initialization point for fine-tuning on a resource-poor target language. Experiments with two model architectures on 29 target languages from 3 families show that our suggested approach outperforms all baselines. In particular, it obtains a 31.7% higher absolute accuracy than a previously proposed cross-lingual transfer model and outperforms the previous state of the art by 1.7% absolute accuracy on average over languages."
  },
  "aaai2020_main_weaklysupervisedpostaggersperformpoorlyontrulylow-resourcelanguages": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Weakly Supervised POS Taggers Perform Poorly on Truly Low-Resource Languages ",
    "authors": [
      "Katharina Kann",
      "Oph\u00e9lie Lacroix",
      "Anders S\u00f8gaard"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6317",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6317/6173",
    "published": "2020-02",
    "summary": "Part-of-speech (POS) taggers for low-resource languages which are exclusively based on various forms of weak supervision \u2013 e.g., cross-lingual transfer, type-level supervision, or a combination thereof \u2013 have been reported to perform almost as well as supervised ones. However, weakly supervised POS taggers are commonly only evaluated on languages that are very different from truly low-resource languages, and the taggers use sources of information, like high-coverage and almost error-free dictionaries, which are likely not available for resource-poor languages. We train and evaluate state-of-the-art weakly supervised POS taggers for a typologically diverse set of 15 truly low-resource languages. On these languages, given a realistic amount of resources, even our best model gets only less than half of the words right. Our results highlight the need for new and different approaches to POS tagging for truly low-resource languages."
  },
  "aaai2020_main_infusingknowledgeintothetextualentailmenttaskusinggraphconvolutionalnetworks": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Infusing Knowledge into the Textual Entailment Task Using Graph Convolutional Networks ",
    "authors": [
      "Pavan Kapanipathi",
      "Veronika Thost",
      "Siva Sankalp Patel",
      "Spencer Whitehead",
      "Ibrahim Abdelaziz",
      "Avinash Balakrishnan",
      "Maria Chang",
      "Kshitij Fadnis",
      "Chulaka Gunasekara",
      "Bassem Makni",
      "Nicholas Mattei",
      "Kartik Talamadupula",
      "Achille Fokoue"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6318",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6318/6174",
    "published": "2020-02",
    "summary": "Textual entailment is a fundamental task in natural language processing. Most approaches for solving this problem use only the textual content present in training data. A few approaches have shown that information from external knowledge sources like knowledge graphs (KGs) can add value, in addition to the textual content, by providing background knowledge that may be critical for a task. However, the proposed models do not fully exploit the information in the usually large and noisy KGs, and it is not clear how it can be effectively encoded to be useful for entailment. We present an approach that complements text-based entailment models with information from KGs by (1) using Personalized PageRank to generate contextual subgraphs with reduced noise and (2) encoding these subgraphs using graph convolutional networks to capture the structural and semantic information in KGs. We evaluate our approach on multiple textual entailment datasets and show that the use of external knowledge helps the model to be robust and improves prediction accuracy. This is particularly evident in the challenging BreakingNLI dataset, where we see an absolute improvement of 5-20% over multiple text-based entailment models."
  },
  "aaai2020_main_qascadatasetforquestionansweringviasentencecomposition": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " QASC: A Dataset for Question Answering via Sentence Composition ",
    "authors": [
      "Tushar Khot",
      "Peter Clark",
      "Michal Guerquin",
      "Peter Jansen",
      "Ashish Sabharwal"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6319",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6319/6175",
    "published": "2020-02",
    "summary": "Composing knowledge from multiple pieces of texts is a key challenge in multi-hop question answering. We present a multi-hop reasoning dataset, Question Answering via Sentence Composition (QASC), that requires retrieving facts from a large corpus and composing them to answer a multiple-choice question. QASC is the first dataset to offer two desirable properties: (a) the facts to be composed are annotated in a large corpus, and (b) the decomposition into these facts is not evident from the question itself. The latter makes retrieval challenging as the system must introduce new concepts or relations in order to discover potential decompositions. Further, the reasoning model must then learn to identify valid compositions of these retrieved facts using common-sense reasoning. To help address these challenges, we provide annotation for supporting facts as well as their composition. Guided by these annotations, we present a two-step approach to mitigate the retrieval challenges. We use other multiple-choice datasets as additional training data to strengthen the reasoning model. Our proposed approach improves over current state-of-the-art language models by 11% (absolute). The reasoning and retrieval problems, however, remain unsolved as this model still lags by 20% behind human performance."
  },
  "aaai2020_main_modality-balancedmodelsforvisualdialogue": {
    "conf_id": "AAAI2020",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "AAAI2020",
    "title": " Modality-Balanced Models for Visual Dialogue ",
    "authors": [
      "Hyounghun Kim",
      "Hao Tan",
      "Mohit Bansal"
    ],
    "page_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6320",
    "pdf_url": "https://aaai.org/ojs/index.php/AAAI/article/view/6320/6176",
    "published": "2020-02",
    "summary": "The Visual Dialog task requires a model to exploit both image and conversational context information to generate the next response to the dialogue. However, via manual analysis, we find that a large number of conversational questions can be answered by only looking at the image without any access to the context history, while others still need the conversation context to predict the correct answers. We demonstrate that due to this reason, previous joint-modality (history and image) models over-rely on and are more prone to memorizing the dialogue history (e.g., by extracting certain keywords or patterns in the context information), whereas image-only models are more generalizable (because they cannot memorize or extract keywords from history) and perform substantially better at the primary normalized discounted cumulative gain (NDCG) task metric which allows multiple correct answers. Hence, this observation encourages us to explicitly maintain two models, i.e., an image-only model and an image-history joint model, and combine their complementary abilities for a more balanced multimodal model. We present multiple methods for this integration of the two models, via ensemble and consensus dropout fusion with shared parameters. Empirically, our models achieve strong results on the Visual Dialog challenge 2019 (rank 3 on NDCG and high balance across metrics), and substantially outperform the winner of the Visual Dialog challenge 2018 on most metrics."
  }
}