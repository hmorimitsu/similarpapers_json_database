{
  "iclr2015_main_wordrepresentationsviagaussianembedding": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Word Representations via Gaussian Embedding",
    "authors": [
      "Luke Vilnis",
      "Andrew McCallum"
    ],
    "page_url": "http://arxiv.org/abs/1412.6623",
    "pdf_url": "https://arxiv.org/pdf/1412.6623",
    "published": "2015-05",
    "summary": "Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages, including better capturing uncertainty about a representation and its relationships, expressing asymmetries more naturally than dot product or cosine similarity, and enabling more expressive parameterization of decision boundaries. This paper advocates for density-based distributed embeddings and presents a method for learning representations in the space of Gaussian distributions. We compare performance on various word embedding benchmarks, investigate the ability of these embeddings to model entailment and other asymmetric relationships, and explore novel properties of the representation. ",
    "code_link": ""
  },
  "iclr2015_main_deepcaptioningwithmultimodalrecurrentneuralnetworks(m-rnn)": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)",
    "authors": [
      "Junhua Mao",
      "Wei Xu",
      "Yi Yang",
      "Jiang Wang",
      "Alan Yuille"
    ],
    "page_url": "http://arxiv.org/abs/1412.6632",
    "pdf_url": "https://arxiv.org/pdf/1412.6632",
    "published": "2015-05",
    "summary": "In this paper, we present a multimodal Recurrent Neural Network (m-RNN) model for generating novel image captions. It directly models the probability distribution of generating a word given previous words and an image. Image captions are generated by sampling from this distribution. The model consists of two sub-networks: a deep recurrent neural network for sentences and a deep convolutional network for images. These two sub-networks interact with each other in a multimodal layer to form the whole m-RNN model. The effectiveness of our model is validated on four benchmark datasets (IAPR TC-12, Flickr 8K, Flickr 30K and MS COCO). Our model outperforms the state-of-the-art methods. In addition, we apply the m-RNN model to retrieval tasks for retrieving images or sentences, and achieves significant performance improvement over the state-of-the-art methods which directly optimize the ranking objective function for retrieval. The project page of this work is: this http URL . ",
    "code_link": ""
  },
  "iclr2015_main_deepstructuredoutputlearningforunconstrainedtextrecognition": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Deep Structured Output Learning for Unconstrained Text Recognition",
    "authors": [
      "Max Jaderberg",
      "Karen Simonyan",
      "Andrea Vedaldi",
      "Andrew Zisserman"
    ],
    "page_url": "http://arxiv.org/abs/1412.5903",
    "pdf_url": "https://arxiv.org/pdf/1412.5903",
    "published": "2015-05",
    "summary": "We develop a representation suitable for the unconstrained recognition of words in natural images: the general case of no fixed lexicon and unknown length. To this end we propose a convolutional neural network (CNN) based architecture which incorporates a Conditional Random Field (CRF) graphical model, taking the whole word image as a single input. The unaries of the CRF are provided by a CNN that predicts characters at each position of the output, while higher order terms are provided by another CNN that detects the presence of N-grams. We show that this entire model (CRF, character predictor, N-gram predictor) can be jointly optimised by back-propagating the structured output loss, essentially requiring the system to perform multi-task learning, and training uses purely synthetically generated data. The resulting model is a more accurate system on standard real-world text recognition benchmarks than character prediction alone, setting a benchmark for systems that have not been trained on a particular lexicon. In addition, our model achieves state-of-the-art accuracy in lexicon-constrained scenarios, without being specifically modelled for constrained recognition. To test the generalisation of our model, we also perform experiments with random alpha-numeric strings to evaluate the method when no visual language model is applicable. ",
    "code_link": ""
  },
  "iclr2015_main_verydeepconvolutionalnetworksforlarge-scaleimagerecognition": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "authors": [
      "Karen Simonyan",
      "Andrew Zisserman"
    ],
    "page_url": "http://arxiv.org/abs/1409.1556",
    "pdf_url": "https://arxiv.org/pdf/1409.1556",
    "published": "2015-05",
    "summary": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision. ",
    "code_link": ""
  },
  "iclr2015_main_fastconvolutionalnetswithfbfftagpuperformanceevaluation": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Fast Convolutional Nets With fbfft: A GPU Performance Evaluation",
    "authors": [
      "Nicolas Vasilache",
      "Jeff Johnson",
      "Michael Mathieu",
      "Soumith Chintala",
      "Serkan Piantino",
      "Yann LeCun"
    ],
    "page_url": "http://arxiv.org/abs/1412.7580",
    "pdf_url": "https://arxiv.org/pdf/1412.7580",
    "published": "2015-05",
    "summary": "We examine the performance profile of Convolutional Neural Network training on the current generation of NVIDIA Graphics Processing Units. We introduce two new Fast Fourier Transform convolution implementations: one based on NVIDIA's cuFFT library, and another based on a Facebook authored FFT implementation, fbfft, that provides significant speedups over cuFFT (over 1.5x) for whole CNNs. Both of these convolution implementations are available in open source, and are faster than NVIDIA's cuDNN implementation for many common convolutional layers (up to 23.5x for some synthetic kernel configurations). We discuss different performance regimes of convolutions, comparing areas where straightforward time domain convolutions outperform Fourier frequency domain convolutions. Details on algorithmic applications of NVIDIA GPU hardware specifics in the implementation of fbfft are also provided. ",
    "code_link": ""
  },
  "iclr2015_main_reweightedwake-sleep": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Reweighted Wake-Sleep",
    "authors": [
      "Jorg Bornschein",
      "Yoshua Bengio"
    ],
    "page_url": "http://arxiv.org/abs/1406.2751",
    "pdf_url": "https://arxiv.org/pdf/1406.2751",
    "published": "2015-05",
    "summary": "Training deep directed graphical models with many hidden variables and performing inference remains a major challenge. Helmholtz machines and deep belief networks are such models, and the wake-sleep algorithm has been proposed to train them. The wake-sleep algorithm relies on training not just the directed generative model but also a conditional generative model (the inference network) that runs backward from visible to latent, estimating the posterior distribution of latent given visible. We propose a novel interpretation of the wake-sleep algorithm which suggests that better estimators of the gradient can be obtained by sampling latent variables multiple times from the inference network. This view is based on importance sampling as an estimator of the likelihood, with the approximate inference network as a proposal distribution. This interpretation is confirmed experimentally, showing that better likelihood can be achieved with this reweighted wake-sleep procedure. Based on this interpretation, we propose that a sigmoidal belief network is not sufficiently powerful for the layers of the inference network in order to recover a good estimator of the posterior distribution of latent variables. Our experiments show that using a more powerful layer model, such as NADE, yields substantially better generative models. ",
    "code_link": "https://github.com/jbornschein/reweighted-ws"
  },
  "iclr2015_main_thelocallow-dimensionalityofnaturalimages": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "The local low-dimensionality of natural images",
    "authors": [
      "Olivier Henaff",
      "Johannes Balle",
      "Neil Rabinowitz",
      "Eero Simoncelli"
    ],
    "page_url": "http://arxiv.org/abs/1412.6626",
    "pdf_url": "https://arxiv.org/pdf/1412.6626",
    "published": "2015-05",
    "summary": "We develop a new statistical model for photographic images, in which the local responses of a bank of linear filters are described as jointly Gaussian, with zero mean and a covariance that varies slowly over spatial position. We optimize sets of filters so as to minimize the nuclear norms of matrices of their local activations (i.e., the sum of the singular values), thus encouraging a flexible form of sparsity that is not tied to any particular dictionary or coordinate system. Filters optimized according to this objective are oriented and bandpass, and their responses exhibit substantial local correlation. We show that images can be reconstructed nearly perfectly from estimates of the local filter response covariances alone, and with minimal degradation (either visual or MSE) from low-rank approximations of these covariances. As such, this representation holds much promise for use in applications such as denoising, compression, and texture representation, and may form a useful substrate for hierarchical decompositions. ",
    "code_link": ""
  },
  "iclr2015_main_memorynetworks": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Memory Networks",
    "authors": [
      "Jason Weston",
      "Sumit Chopra",
      "Antoine Bordes"
    ],
    "page_url": "http://arxiv.org/abs/1410.3916",
    "pdf_url": "https://arxiv.org/pdf/1410.3916",
    "published": "2015-05",
    "summary": "We describe a new class of learning models called memory networks. Memory networks reason with inference components combined with a long-term memory component; they learn how to use these jointly. The long-term memory can be read and written to, with the goal of using it for prediction. We investigate these models in the context of question answering (QA) where the long-term memory effectively acts as a (dynamic) knowledge base, and the output is a textual response. We evaluate them on a large-scale QA task, and a smaller, but more complex, toy task generated from a simulated world. In the latter, we show the reasoning power of such models by chaining multiple supporting sentences to answer questions that require understanding the intension of verbs. ",
    "code_link": ""
  },
  "iclr2015_main_objectdetectorsemergeindeepscenecnns": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Object detectors emerge in Deep Scene CNNs",
    "authors": [
      "Bolei Zhou",
      "Aditya Khosla",
      "Agata Lapedriza",
      "Aude Oliva",
      "Antonio Torralba"
    ],
    "page_url": "http://arxiv.org/abs/1412.6856",
    "pdf_url": "https://arxiv.org/pdf/1412.6856",
    "published": "2015-05",
    "summary": "With the success of new computational architectures for visual processing, such as convolutional neural networks (CNN) and access to image databases with millions of labeled examples (e.g., ImageNet, Places), the state of the art in computer vision is advancing rapidly. One important factor for continued progress is to understand the representations that are learned by the inner layers of these deep architectures. Here we show that object detectors emerge from training CNNs to perform scene classification. As scenes are composed of objects, the CNN for scene classification automatically discovers meaningful objects detectors, representative of the learned scene categories. With object detectors emerging as a result of learning to recognize scenes, our work demonstrates that the same network can perform both scene recognition and object localization in a single forward-pass, without ever having been explicitly taught the notion of objects. ",
    "code_link": ""
  },
  "iclr2015_main_qualitativelycharacterizingneuralnetworkoptimizationproblems": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Qualitatively characterizing neural network optimization problems",
    "authors": [
      "Ian Goodfellow",
      "Oriol Vinyals"
    ],
    "page_url": "http://arxiv.org/abs/1412.6544",
    "pdf_url": "https://arxiv.org/pdf/1412.6544",
    "published": "2015-05",
    "summary": "Training neural networks involves solving large-scale non-convex optimization problems. This task has long been believed to be extremely difficult, with fear of local minima and other obstacles motivating a variety of schemes to improve optimization, such as unsupervised pretraining. However, modern neural networks are able to achieve negligible training error on complex tasks, using only direct training with stochastic gradient descent. We introduce a simple analysis technique to look for evidence that such networks are overcoming local optima. We find that, in fact, on a straight path from initialization to solution, a variety of state of the art neural networks never encounter any significant obstacles. ",
    "code_link": ""
  },
  "iclr2015_main_neuralmachinetranslationbyjointlylearningtoalignandtranslate": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
    "authors": [
      "Dzmitry Bahdanau",
      "Kyunghyun Cho",
      "Yoshua Bengio"
    ],
    "page_url": "http://arxiv.org/abs/1409.0473",
    "pdf_url": "https://arxiv.org/pdf/1409.0473",
    "published": "2015-05",
    "summary": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition. ",
    "code_link": "https://github.com/lisa-groundhog/GroundHog"
  },
  "iclr2015_main_fitnetshintsforthindeepnets": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "FitNets: Hints for Thin Deep Nets",
    "authors": [
      "Adriana Romero",
      "Nicolas Ballas",
      "Samira Ebrahimi Kahou",
      "Antoine Chassang",
      "Carlo Gatta",
      "Yoshua Bengio"
    ],
    "page_url": "http://arxiv.org/abs/1412.6550",
    "pdf_url": "https://arxiv.org/pdf/1412.6550",
    "published": "2015-05",
    "summary": "While depth tends to improve network performances, it also makes gradient-based training more difficult since deeper networks tend to be more non-linear. The recently proposed knowledge distillation approach is aimed at obtaining small and fast-to-execute models, and it has shown that a student network could imitate the soft output of a larger teacher network or ensemble of networks. In this paper, we extend this idea to allow the training of a student that is deeper and thinner than the teacher, using not only the outputs but also the intermediate representations learned by the teacher as hints to improve the training process and final performance of the student. Because the student intermediate hidden layer will generally be smaller than the teacher's intermediate hidden layer, additional parameters are introduced to map the student hidden layer to the prediction of the teacher hidden layer. This allows one to train deeper students that can generalize better or run faster, a trade-off that is controlled by the chosen student capacity. For example, on CIFAR-10, a deep student network with almost 10.4 times less parameters outperforms a larger, state-of-the-art teacher network. ",
    "code_link": "https://github.com/adri-romsor/FitNets"
  },
  "iclr2015_main_techniquesforlearningbinarystochasticfeedforwardneuralnetworks": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Techniques for Learning Binary Stochastic Feedforward Neural Networks",
    "authors": [
      "Tapani Raiko",
      "Mathias Berglund",
      "Guillaume Alain",
      "Laurent Dinh"
    ],
    "page_url": "http://arxiv.org/abs/1406.2989",
    "pdf_url": "https://arxiv.org/pdf/1406.2989",
    "published": "2015-05",
    "summary": "Stochastic binary hidden units in a multi-layer perceptron (MLP) network give at least three potential benefits when compared to deterministic MLP networks. (1) They allow to learn one-to-many type of mappings. (2) They can be used in structured prediction problems, where modeling the internal structure of the output is important. (3) Stochasticity has been shown to be an excellent regularizer, which makes generalization performance potentially better in general. However, training stochastic networks is considerably more difficult. We study training using M samples of hidden activations per input. We show that the case M=1 leads to a fundamentally different behavior where the network tries to avoid stochasticity. We propose two new estimators for the training gradient and propose benchmark tests for comparing training algorithms. Our experiments confirm that training stochastic networks is difficult and show that the proposed two estimators perform favorably among all the five known estimators. ",
    "code_link": ""
  },
  "iclr2015_main_semanticimagesegmentationwithdeepconvolutionalnetsandfullyconnectedcrfs": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs",
    "authors": [
      "Liang-Chieh Chen",
      "George Papandreou",
      "Iasonas Kokkinos",
      "Kevin Murphy",
      "Alan Yuille"
    ],
    "page_url": "http://arxiv.org/abs/1412.7062",
    "pdf_url": "https://arxiv.org/pdf/1412.7062",
    "published": "2015-05",
    "summary": "Deep Convolutional Neural Networks (DCNNs) have recently shown state of the art performance in high level vision tasks, such as image classification and object detection. This work brings together methods from DCNNs and probabilistic graphical models for addressing the task of pixel-level classification (also called semantic image segmentation). We show that responses at the final layer of DCNNs are not sufficiently localized for accurate object segmentation. This is due to the very invariance properties that make DCNNs good for high level tasks. We overcome this poor localization property of deep networks by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF). Qualitatively, our DeepLab system is able to localize segment boundaries at a level of accuracy which is beyond previous methods. Quantitatively, our method sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 71.6% IOU accuracy in the test set. We show how these results can be obtained efficiently: Careful network re-purposing and a novel application of the 'hole' algorithm from the wavelet community allow dense computation of neural net responses at 8 frames per second on a modern GPU. ",
    "code_link": ""
  },
  "iclr2015_main_multipleobjectrecognitionwithvisualattention": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Multiple Object Recognition with Visual Attention",
    "authors": [
      "Jimmy Ba",
      "Volodymyr Mnih",
      "Koray Kavukcuoglu"
    ],
    "page_url": "http://arxiv.org/abs/1412.7755",
    "pdf_url": "https://arxiv.org/pdf/1412.7755",
    "published": "2015-05",
    "summary": "We present an attention-based model for recognizing multiple objects in images. The proposed model is a deep recurrent neural network trained with reinforcement learning to attend to the most relevant regions of the input image. We show that the model learns to both localize and recognize multiple objects despite being given only class labels during training. We evaluate the model on the challenging task of transcribing house number sequences from Google Street View images and show that it is both more accurate than the state-of-the-art convolutional networks and uses fewer parameters and less computation. ",
    "code_link": ""
  },
  "iclr2015_main_deepnarrowboltzmannmachinesareuniversalapproximators": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Deep Narrow Boltzmann Machines are Universal Approximators",
    "authors": [
      "Guido Montufar"
    ],
    "page_url": "http://arxiv.org/abs/1411.3784",
    "pdf_url": "https://arxiv.org/pdf/1411.3784",
    "published": "2015-05",
    "summary": "We show that deep narrow Boltzmann machines are universal approximators of probability distributions on the activities of their visible units, provided they have sufficiently many hidden layers, each containing the same number of units as the visible layer. We show that, within certain parameter domains, deep Boltzmann machines can be studied as feedforward networks. We provide upper and lower bounds on the sufficient depth and width of universal approximators. These results settle various intuitions regarding undirected networks and, in particular, they show that deep narrow Boltzmann machines are at least as compact universal approximators as narrow sigmoid belief networks and restricted Boltzmann machines, with respect to the currently available bounds for those models. ",
    "code_link": ""
  },
  "iclr2015_main_transformationpropertiesoflearnedvisualrepresentations": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Transformation Properties of Learned Visual Representations",
    "authors": [
      "Taco Cohen",
      "Max Welling"
    ],
    "page_url": "http://arxiv.org/abs/1412.7659",
    "pdf_url": "https://arxiv.org/pdf/1412.7659",
    "published": "2015-05",
    "summary": "When a three-dimensional object moves relative to an observer, a change occurs on the observer's image plane and in the visual representation computed by a learned model. Starting with the idea that a good visual representation is one that transforms linearly under scene motions, we show, using the theory of group representations, that any such representation is equivalent to a combination of the elementary irreducible representations. We derive a striking relationship between irreducibility and the statistical dependency structure of the representation, by showing that under restricted conditions, irreducible representations are decorrelated. Under partial observability, as induced by the perspective projection of a scene onto the image plane, the motion group does not have a linear action on the space of images, so that it becomes necessary to perform inference over a latent representation that does transform linearly. This idea is demonstrated in a model of rotating NORB objects that employs a latent representation of the non-commutative 3D rotation group SO(3). ",
    "code_link": ""
  },
  "iclr2015_main_jointrnn-basedgreedyparsingandwordcomposition": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Joint RNN-Based Greedy Parsing and Word Composition",
    "authors": [
      "Jo\u00ebl Legrand",
      "Ronan Collobert"
    ],
    "page_url": "http://arxiv.org/abs/1412.7028",
    "pdf_url": "https://arxiv.org/pdf/1412.7028",
    "published": "2015-05",
    "summary": "This paper introduces a greedy parser based on neural networks, which leverages a new compositional sub-tree representation. The greedy parser and the compositional procedure are jointly trained, and tightly depends on each-other. The composition procedure outputs a vector representation which summarizes syntactically (parsing tags) and semantically (words) sub-trees. Composition and tagging is achieved over continuous (word or tag) representations, and recurrent neural networks. We reach F1 performance on par with well-known existing parsers, while having the advantage of speed, thanks to the greedy nature of the parser. We provide a fully functional implementation of the method described in this paper. ",
    "code_link": ""
  },
  "iclr2015_main_adamamethodforstochasticoptimization": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Adam: A Method for Stochastic Optimization",
    "authors": [
      "Jimmy Ba",
      "Diederik Kingma"
    ],
    "page_url": "http://arxiv.org/abs/1412.6980",
    "pdf_url": "https://arxiv.org/pdf/1412.6980",
    "published": "2015-05",
    "summary": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm. ",
    "code_link": ""
  },
  "iclr2015_main_scheduleddenoisingautoencoders": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Scheduled denoising autoencoders",
    "authors": [
      "Krzysztof Geras",
      "Charles Sutton"
    ],
    "page_url": "http://arxiv.org/abs/1406.3269",
    "pdf_url": "https://arxiv.org/pdf/1406.3269",
    "published": "2015-05",
    "summary": "We present a representation learning method that learns features at multiple different levels of scale. Working within the unsupervised framework of denoising autoencoders, we observe that when the input is heavily corrupted during training, the network tends to learn coarse-grained features, whereas when the input is only slightly corrupted, the network tends to learn fine-grained features. This motivates the scheduled denoising autoencoder, which starts with a high level of noise that lowers as training progresses. We find that the resulting representation yields a significant boost on a later supervised task compared to the original input, or to a standard denoising autoencoder trained at a single noise level. After supervised fine-tuning our best model achieves the lowest ever reported error on the CIFAR-10 data set among permutation-invariant methods. ",
    "code_link": ""
  },
  "iclr2015_main_embeddingentitiesandrelationsforlearningandinferenceinknowledgebases": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Embedding Entities and Relations for Learning and Inference in Knowledge Bases",
    "authors": [
      "Bishan Yang",
      "Scott Yih",
      "Xiaodong He",
      "Jianfeng Gao",
      "Li Deng"
    ],
    "page_url": "http://arxiv.org/abs/1412.6575",
    "pdf_url": "https://arxiv.org/pdf/1412.6575",
    "published": "2015-05",
    "summary": "We consider learning representations of entities and relations in KBs using the neural-embedding approach. We show that most existing models, including NTN (Socher et al., 2013) and TransE (Bordes et al., 2013b), can be generalized under a unified learning framework, where entities are low-dimensional vectors learned from a neural network and relations are bilinear and/or linear mapping functions. Under this framework, we compare a variety of embedding models on the link prediction task. We show that a simple bilinear formulation achieves new state-of-the-art results for the task (achieving a top-10 accuracy of 73.2% vs. 54.7% by TransE on Freebase). Furthermore, we introduce a novel approach that utilizes the learned relation embeddings to mine logical rules such as BornInCity(a,b) and CityInCountry(b,c) => Nationality(a,c). We find that embeddings learned from the bilinear objective are particularly good at capturing relational semantics and that the composition of relations is characterized by matrix multiplication. More interestingly, we demonstrate that our embedding-based rule extraction approach successfully outperforms a state-of-the-art confidence-based rule mining approach in mining Horn rules that involve compositional reasoning. ",
    "code_link": ""
  },
  "iclr2015_main_explainingandharnessingadversarialexamples": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Explaining and Harnessing Adversarial Examples",
    "authors": [
      "Ian Goodfellow",
      "Jon Shlens",
      "Christian Szegedy"
    ],
    "page_url": "http://arxiv.org/abs/1412.6572",
    "pdf_url": "https://arxiv.org/pdf/1412.6572",
    "published": "2015-05",
    "summary": "Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset. ",
    "code_link": ""
  },
  "iclr2015_main_modelingcompositionalitywithmultiplicativerecurrentneuralnetworks": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Modeling Compositionality with Multiplicative Recurrent Neural Networks",
    "authors": [
      "Ozan Irsoy",
      "Claire Cardie"
    ],
    "page_url": "http://arxiv.org/abs/1412.6577",
    "pdf_url": "https://arxiv.org/pdf/1412.6577",
    "published": "2015-05",
    "summary": "We present the multiplicative recurrent neural network as a general model for compositional meaning in language, and evaluate it on the task of fine-grained sentiment analysis. We establish a connection to the previously investigated matrix-space models for compositionality, and show they are special cases of the multiplicative recurrent net. Our experiments show that these models perform comparably or better than Elman-type additive recurrent neural networks and outperform matrix-space models on a standard fine-grained sentiment analysis corpus. Furthermore, they yield comparable results to structural deep models on the recently published Stanford Sentiment Treebank without the need for generating parse trees. ",
    "code_link": ""
  },
  "iclr2015_main_speeding-upconvolutionalneuralnetworksusingfine-tunedcp-decomposition": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition",
    "authors": [
      "Vadim Lebedev",
      "Yaroslav Ganin",
      "Victor Lempitsky",
      "Maksim Rakhuba",
      "Ivan Oseledets"
    ],
    "page_url": "http://arxiv.org/abs/1412.6553",
    "pdf_url": "https://arxiv.org/pdf/1412.6553",
    "published": "2015-05",
    "summary": "We propose a simple two-step approach for speeding up convolution layers within large convolutional neural networks based on tensor decomposition and discriminative fine-tuning. Given a layer, we use non-linear least squares to compute a low-rank CP-decomposition of the 4D convolution kernel tensor into a sum of a small number of rank-one tensors. At the second step, this decomposition is used to replace the original convolutional layer with a sequence of four convolutional layers with small kernels. After such replacement, the entire network is fine-tuned on the training data using standard backpropagation process. We evaluate this approach on two CNNs and show that it is competitive with previous approaches, leading to higher obtained CPU speedups at the cost of lower accuracy drops for the smaller of the two networks. Thus, for the 36-class character classification CNN, our approach obtains a 8.5x CPU speedup of the whole network with only minor accuracy drop (1% from 91% to 90%). For the standard ImageNet architecture (AlexNet), the approach speeds up the second convolution layer by a factor of 4x at the cost of $1\\%$ increase of the overall top-5 classification error. ",
    "code_link": ""
  },
  "iclr2015_main_zero-biasautoencodersandthebenefitsofco-adaptingfeatures": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Zero-bias autoencoders and the benefits of co-adapting features",
    "authors": [
      "Kishore Konda",
      "Roland Memisevic",
      "David Krueger"
    ],
    "page_url": "http://arxiv.org/abs/1402.3337",
    "pdf_url": "https://arxiv.org/pdf/1402.3337",
    "published": "2015-05",
    "summary": "Regularized training of an autoencoder typically results in hidden unit biases that take on large negative values. We show that negative biases are a natural result of using a hidden layer whose responsibility is to both represent the input data and act as a selection mechanism that ensures sparsity of the representation. We then show that negative biases impede the learning of data distributions whose intrinsic dimensionality is high. We also propose a new activation function that decouples the two roles of the hidden layer and that allows us to learn representations on data with very high intrinsic dimensionality, where standard autoencoders typically fail. Since the decoupled activation function acts like an implicit regularizer, the model can be trained by minimizing the reconstruction error of training data, without requiring any additional regularization. ",
    "code_link": ""
  },
  "iclr2015_main_automaticdiscoveryandoptimizationofpartsforimageclassification": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Automatic Discovery and Optimization of Parts for Image Classification",
    "authors": [
      "Sobhan Naderi Parizi",
      "Andrea Vedaldi",
      "Andrew Zisserman",
      "Pedro Felzenszwalb"
    ],
    "page_url": "http://arxiv.org/abs/1412.6598",
    "pdf_url": "https://arxiv.org/pdf/1412.6598",
    "published": "2015-05",
    "summary": "Part-based representations have been shown to be very useful for image classification. Learning part-based models is often viewed as a two-stage problem. First, a collection of informative parts is discovered, using heuristics that promote part distinctiveness and diversity, and then classifiers are trained on the vector of part responses. In this paper we unify the two stages and learn the image classifiers and a set of shared parts jointly. We generate an initial pool of parts by randomly sampling part candidates and selecting a good subset using L1/L2 regularization. All steps are driven directly by the same objective namely the classification loss on a training set. This lets us do away with engineered heuristics. We also introduce the notion of negative parts, intended as parts that are negatively correlated with one or more classes. Negative parts are complementary to the parts discovered by other methods, which look only for positive correlations. ",
    "code_link": ""
  },
  "iclr2015_main_understandinglocallycompetitivenetworks": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Understanding Locally Competitive Networks",
    "authors": [
      "Rupesh Srivastava",
      "Jonathan Masci",
      "Faustino Gomez",
      "Juergen Schmidhuber"
    ],
    "page_url": "http://arxiv.org/abs/1410.1165",
    "pdf_url": "https://arxiv.org/pdf/1410.1165",
    "published": "2015-05",
    "summary": "Recently proposed neural network activation functions such as rectified linear, maxout, and local winner-take-all have allowed for faster and more effective training of deep neural architectures on large and complex datasets. The common trait among these functions is that they implement local competition between small groups of computational units within a layer, so that only part of the network is activated for any given input pattern. In this paper, we attempt to visualize and understand this self-modularization, and suggest a unified explanation for the beneficial properties of such networks. We also show how our insights can be directly useful for efficiently performing retrieval over large datasets using neural networks. ",
    "code_link": "https://github.com/torontodeeplearning/convnet"
  },
  "iclr2015_main_leveragingmonolingualdataforcrosslingualcompositionalwordrepresentations": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Leveraging Monolingual Data for Crosslingual Compositional Word Representations",
    "authors": [
      "Hubert Soyer",
      "Pontus Stenetorp",
      "Akiko Aizawa"
    ],
    "page_url": "http://arxiv.org/abs/1412.6334",
    "pdf_url": "https://arxiv.org/pdf/1412.6334",
    "published": "2015-05",
    "summary": "In this work, we present a novel neural network based architecture for inducing compositional crosslingual word representations. Unlike previously proposed methods, our method fulfills the following three criteria; it constrains the word-level representations to be compositional, it is capable of leveraging both bilingual and monolingual data, and it is scalable to large vocabularies and large quantities of data. The key component of our approach is what we refer to as a monolingual inclusion criterion, that exploits the observation that phrases are more closely semantically related to their sub-phrases than to other randomly sampled phrases. We evaluate our method on a well-established crosslingual document classification task and achieve results that are either comparable, or greatly improve upon previous state-of-the-art methods. Concretely, our method reaches a level of 92.7% and 84.4% accuracy for the English to German and German to English sub-tasks respectively. The former advances the state of the art by 0.9% points of accuracy, the latter is an absolute improvement upon the previous state of the art by 7.7% points of accuracy and an improvement of 33.0% in error reduction. ",
    "code_link": "https://github.com/ogh/binclusion"
  },
  "iclr2015_main_moveevaluationingousingdeepconvolutionalneuralnetworks": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Move Evaluation in Go Using Deep Convolutional Neural Networks",
    "authors": [
      "Chris Maddison",
      "Aja Huang",
      "Ilya Sutskever",
      "David Silver"
    ],
    "page_url": "http://arxiv.org/abs/1412.6564",
    "pdf_url": "https://arxiv.org/pdf/1412.6564",
    "published": "2015-05",
    "summary": "The game of Go is more challenging than other board games, due to the difficulty of constructing a position or move evaluation function. In this paper we investigate whether deep convolutional networks can be used to directly represent and learn this knowledge. We train a large 12-layer convolutional neural network by supervised learning from a database of human professional games. The network correctly predicts the expert move in 55% of positions, equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional search program GnuGo in 97% of games, and matched the performance of a state-of-the-art Monte-Carlo tree search that simulates a million positions per move. ",
    "code_link": ""
  },
  "iclr2015_main_generativemodelingofconvolutionalneuralnetworks": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "Generative Modeling of Convolutional Neural Networks",
    "authors": [
      "Jifeng Dai",
      "Yang Lu",
      "Ying-Nian Wu"
    ],
    "page_url": "http://arxiv.org/abs/1412.6296",
    "pdf_url": "https://arxiv.org/pdf/1412.6296",
    "published": "2015-05",
    "summary": "The convolutional neural networks (CNNs) have proven to be a powerful tool for discriminative learning. Recently researchers have also started to show interest in the generative aspects of CNNs in order to gain a deeper understanding of what they have learned and how to further improve them. This paper investigates generative modeling of CNNs. The main contributions include: (1) We construct a generative model for the CNN in the form of exponential tilting of a reference distribution. (2) We propose a generative gradient for pre-training CNNs by a non-parametric importance sampling scheme, which is fundamentally different from the commonly used discriminative gradient, and yet has the same computational architecture and cost as the latter. (3) We propose a generative visualization method for the CNNs by sampling from an explicit parametric image distribution. The proposed visualization method can directly draw synthetic samples for any given node in a trained CNN by the Hamiltonian Monte Carlo (HMC) algorithm, without resorting to any extra hold-out images. Experiments on the challenging ImageNet benchmark show that the proposed generative gradient pre-training consistently helps improve the performances of CNNs, and the proposed generative visualization method generates meaningful and varied samples of synthetic images from a large-scale deep CNN. ",
    "code_link": ""
  },
  "iclr2015_main_aunifiedperspectiveonmulti-domainandmulti-tasklearning": {
    "conf_id": "ICLR2015",
    "conf_sub_id": "Main",
    "is_workshop": false,
    "conf_name": "ICLR2015",
    "title": "A Unified Perspective on Multi-Domain and Multi-Task Learning",
    "authors": [
      "Yongxin Yang",
      "Timothy Hospedales"
    ],
    "page_url": "http://arxiv.org/abs/1412.7489",
    "pdf_url": "https://arxiv.org/pdf/1412.7489",
    "published": "2015-05",
    "summary": "In this paper, we provide a new neural-network based perspective on multi-task learning (MTL) and multi-domain learning (MDL). By introducing the concept of a semantic descriptor, this framework unifies MDL and MTL as well as encompassing various classic and recent MTL/MDL algorithms by interpreting them as different ways of constructing semantic descriptors. Our interpretation provides an alternative pipeline for zero-shot learning (ZSL), where a model for a novel class can be constructed without training data. Moreover, it leads to a new and practically relevant problem setting of zero-shot domain adaptation (ZSDA), which is the analogous to ZSL but for novel domains: A model for an unseen domain can be generated by its semantic descriptor. Experiments across this range of problems demonstrate that our framework outperforms a variety of alternatives. ",
    "code_link": ""
  }
}